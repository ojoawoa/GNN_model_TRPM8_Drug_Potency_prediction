{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892b10a6",
   "metadata": {},
   "source": [
    "# Classification Training Pipeline\n",
    "\n",
    "This notebook implements a complete Graph Neural Network (GNN) pipeline for a 3-class classification task (`Low`, `Medium`, `High`).  It now includes additional metrics in hyperparameter tuning and enhanced model comparison visualizations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment & Setup](#step1)\n",
    "2. [Model Definition](#step2)\n",
    "3. [Evaluation Function](#step3)\n",
    "4. [Hyperparameter Sweep (10-Fold CV)](#step4)\n",
    "5. [Retraining & Validation (10-Fold CV)](#step5)\n",
    "6. [Cross-Validation Results Visualization](#step6)\n",
    "7. [Ensemble Averaging](#step7)\n",
    "8. [Final Model Training & Test Evaluation](#step8)\n",
    "9. [Baseline QSAR Comparison](#step9)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- PyTorch & PyTorch Geometric  \n",
    "- scikit-learn  \n",
    "- pandas, numpy, matplotlib  \n",
    "- RDKit (only for feature extraction)  \n",
    "- GPU recommended\n",
    "\n",
    "Install requirements:\n",
    "```bash\n",
    "pip install torch torch-geometric scikit-learn pandas numpy matplotlib rdkit-pypi\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"step1\"></a>\n",
    "## Step 1: Environment & Setup\n",
    "- Seed all random generators for reproducibility.  \n",
    "- Define paths for data splits and output.  \n",
    "- Detect GPU/CPU.\n",
    "\n",
    "<a id=\"step2\"></a>\n",
    "## Step 2: Model Definition\n",
    "Defines:\n",
    "- `edgeGCN` Taking into account edge features  \n",
    "- `DeepGNNWithEdgeFeatures`: GCN with GraphSAGE, incorporating edge features, global mean pool, and final linear head.\n",
    "\n",
    "<a id=\"step3\"></a>\n",
    "## Step 3: Evaluation Function\n",
    "`evaluate(model, loader)` returns concatenated logits and true labels.\n",
    "\n",
    "<a id=\"step4\"></a>\n",
    "## Step 4: Hyperparameter Sweep (10-Fold CV)\n",
    "**Updates:** Now tracks both **AUC-ROC** and **Balanced Accuracy** per fold.\n",
    "\n",
    "- Grid search over `hidden_channels`, `dropout`, `lr`.  \n",
    "- For each config, run 10-fold CV: train for 50 epochs, then evaluate validation set.\n",
    "- Compute per-fold metrics:\n",
    "  - **AUC-ROC** (one-vs-rest)\n",
    "  - **Balanced Accuracy** (accounts for class imbalance)\n",
    "- Record **mean ¬± std** for both metrics.\n",
    "- Results DataFrame `sweep_df` now contains `mean_auc`, `std_auc`, `mean_balanced_acc`, and `std_balanced_acc`.\n",
    "\n",
    "<a id=\"step5\"></a>\n",
    "## Step 5: Retraining & Validation (10-Fold CV)\n",
    "- Retrain each fold with best hyperparameters and early stopping.  \n",
    "- Save best model weights.  \n",
    "- Compute per-fold classification metrics: accuracy, precision, recall, F1, AUC-ROC.  \n",
    "- Save `crossval_summary.csv`.\n",
    "\n",
    "<a id=\"step6\"></a>\n",
    "## Step 6: Cross-Validation Results Visualization\n",
    "- Load `crossval_summary.csv`.  \n",
    "- Plot bar charts for each metric across folds.  \n",
    "- Print mean ¬± std.\n",
    "\n",
    "<a id=\"step7\"></a>\n",
    "## Step 7: Ensemble Averaging\n",
    "- Load fold checkpoints, run on test set, average logits.  \n",
    "- Save `ensemble_preds.csv` (True vs. Pred).\n",
    "- **Ensemble evaluation plots** include confusion matrix and per-class ROC curves.\n",
    "\n",
    "<a id=\"step8\"></a>\n",
    "## Step 8: Final Model Training & Test Evaluation\n",
    "- Merge all train+val folds, reserve 10% for validation.  \n",
    "- Train final model with early stopping and LR scheduler.  \n",
    "- Evaluate on hold-out test: accuracy, precision, recall, F1, AUC-ROC.\n",
    "- Plot confusion matrix and per-class ROC curves.  \n",
    "- Save `final_model_metrics.csv`, `final_confusion_matrix.png`, and `final_auc_roc.png`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Parameters & Extensions\n",
    "- **Epochs:** 50 for CV, 100 for final training  \n",
    "- **Patience:** 10 for early stopping  \n",
    "- **LR Scheduler:** `ReduceLROnPlateau` on validation loss  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f1c0d",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b107243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79ade2",
   "metadata": {},
   "source": [
    "## 2. Task and Reproducibility Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64234a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "# DataLoader seeding\n",
    "from torch.utils.data import DataLoader as _DL\n",
    "from torch.utils.data import get_worker_info\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = seed + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(seed)\n",
    "\n",
    "# task = \"classification\"  # or \"regression\"\n",
    "task = \"regression\"  # or \"classification\"\n",
    "num_classes = 3\n",
    "class_names = {0: \"Low\", 1: \"Medium\", 2: \"High\"}\n",
    "kfold = 10\n",
    "base_path = f\"../4_train_test_split/10fold_cv/{task}/\"\n",
    "results_dir = f\"GraphSAGE_results/{task}_{kfold}fold/\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ac03",
   "metadata": {},
   "source": [
    "## 3b. Define GraphSAGE Layer and GraphSAGE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c517152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "class EdgeGNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_channels, mlp_depth=2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Dimension of node features coming in.\n",
    "            out_channels (int): Dimension of node features going out.\n",
    "            edge_channels (int): Dimension of edge features.\n",
    "            mlp_depth (int): Number of hidden layers in the MLPs (minimum 1).\n",
    "        \"\"\"\n",
    "        super(EdgeGNNLayer, self).__init__(aggr='add')\n",
    "        \n",
    "        # Build a deeper node MLP: input dimension is (in_channels + edge_channels)\n",
    "        node_mlp_layers = []\n",
    "        input_dim = in_channels + edge_channels\n",
    "        hidden_channels = out_channels  # could also set a different hidden dimension if needed\n",
    "        for _ in range(mlp_depth - 1):\n",
    "            node_mlp_layers.append(torch.nn.Linear(input_dim, hidden_channels))\n",
    "            node_mlp_layers.append(torch.nn.ReLU())\n",
    "            input_dim = hidden_channels\n",
    "        node_mlp_layers.append(torch.nn.Linear(input_dim, out_channels))\n",
    "        self.node_mlp = torch.nn.Sequential(*node_mlp_layers)\n",
    "        \n",
    "        # Build a deeper edge MLP for transforming edge features\n",
    "        edge_mlp_layers = []\n",
    "        input_dim_e = edge_channels\n",
    "        hidden_channels_e = edge_channels  # preserving the original dimension\n",
    "        for _ in range(mlp_depth - 1):\n",
    "            edge_mlp_layers.append(torch.nn.Linear(input_dim_e, hidden_channels_e))\n",
    "            edge_mlp_layers.append(torch.nn.ReLU())\n",
    "            input_dim_e = hidden_channels_e\n",
    "        edge_mlp_layers.append(torch.nn.Linear(input_dim_e, edge_channels))\n",
    "        self.edge_mlp = torch.nn.Sequential(*edge_mlp_layers)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Transform edge features through a deeper MLP\n",
    "        edge_attr = self.edge_mlp(edge_attr)\n",
    "        # Propagate messages\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Concatenate neighboring node features with corresponding edge features\n",
    "        return torch.cat([x_j, edge_attr], dim=1)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Update node features after aggregation using the deeper MLP\n",
    "        return self.node_mlp(aggr_out)\n",
    "\n",
    "class DeepGNNWithEdgeFeatures(torch.nn.Module):\n",
    "    def __init__(self, in_channels, edge_channels, hidden_channels, out_channels, num_layers=6, mlp_depth=3, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Dimension of initial node features.\n",
    "            edge_channels (int): Dimension of edge features.\n",
    "            hidden_channels (int): Dimension for hidden layers.\n",
    "            out_channels (int): Dimension for output.\n",
    "            num_layers (int): Number of message passing layers.\n",
    "            mlp_depth (int): Depth of the MLPs inside each message passing layer.\n",
    "            dropout (float): Dropout probability for the output MLP.\n",
    "        \"\"\"\n",
    "        super(DeepGNNWithEdgeFeatures, self).__init__()\n",
    "        self.lin_in = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        \n",
    "        # Stack multiple message passing layers and norm layers.\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(EdgeGNNLayer(hidden_channels, hidden_channels, edge_channels, mlp_depth=mlp_depth))\n",
    "            self.norms.append(LayerNorm(hidden_channels))\n",
    "        \n",
    "        # A deeper output MLP to further transform after pooling.\n",
    "        self.lin_out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_channels, hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_channels, hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Initial feature transformation\n",
    "        x = F.relu(self.lin_in(x))\n",
    "        \n",
    "        # Passing through deeper stack of message passing layers with residual connections\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x_res = x  # save for residual connection\n",
    "            x = layer(x, edge_index, edge_attr)\n",
    "            x = x + x_res  # add residual connection\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        # Global pooling over nodes for each graph\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Final transformation for graph-level output\n",
    "        return self.lin_out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bd2cc",
   "metadata": {},
   "source": [
    "## 4. Evaluation Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d899a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds.append(out.cpu())\n",
    "            labels.append(batch.y.cpu())\n",
    "    return torch.cat(preds), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063855f",
   "metadata": {},
   "source": [
    "## 5. Input Dimensions and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f3414ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johng23\\AppData\\Local\\Temp\\ipykernel_9476\\303463795.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sample_data = torch.load(os.path.join(base_path, f\"{task}_train_fold0.pt\"))[0]\n"
     ]
    }
   ],
   "source": [
    "sample_data = torch.load(os.path.join(base_path, f\"{task}_train_fold0.pt\"))[0]\n",
    "input_dim = sample_data.x.size(1)\n",
    "edge_dim = sample_data.edge_attr.size(1)\n",
    "out_channels = num_classes if task == \"classification\" else 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5c45c",
   "metadata": {},
   "source": [
    "# ## Step 4: Select Best Hyperparameters\n",
    "# Use this section to manually define the best hyperparameters based on the sweep above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3602752f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Config: hidden_channels=64, dropout=0.0, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johng23\\AppData\\Local\\Temp\\ipykernel_9476\\2590439331.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
      "C:\\Users\\johng23\\AppData\\Local\\Temp\\ipykernel_9476\\2590439331.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m y_pred  \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# AUC‚ÄëROC (one-vs-rest)\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_binarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m auc_scores\u001b[38;5;241m.\u001b[39mappend(auc)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Balanced Accuracy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:648\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    641\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    642\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\metrics\\_base.py:119\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m     y_true_c \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    118\u001b[0m     y_score_c \u001b[38;5;241m=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m--> 119\u001b[0m     score[c] \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Average the results\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m     )\n\u001b[0;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "hidden_channelss = [64, 128, 256]\n",
    "dropouts    = [0.0, 0.2, 0.4]\n",
    "lrs         = [1e-3, 5e-4, 1e-4]\n",
    "\n",
    "results = []\n",
    "\n",
    "for hd in hidden_channelss:\n",
    "    for dp in dropouts:\n",
    "        for lr in lrs:\n",
    "            print(f\"\\nüîß Config: hidden_channels={hd}, dropout={dp}, lr={lr}\")\n",
    "            auc_scores = []\n",
    "            bal_scores = []\n",
    "            for fold in range(10):\n",
    "                # Load fold data\n",
    "                train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "                val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "                \n",
    "                model = DeepGNNWithEdgeFeatures(train_data[0].x.size(1),\n",
    "                             train_data[0].edge_attr.size(1),\n",
    "                             hidden_channels=hd,\n",
    "                             out_channels=out_channels,\n",
    "                             dropout=dp).to(device)\n",
    "                opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                tr = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                                worker_init_fn=seed_worker, generator=generator)\n",
    "                vl = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "                # Train\n",
    "                for epoch in range(1, 51):\n",
    "                    model.train()\n",
    "                    for batch in tr:\n",
    "                        batch = batch.to(device)\n",
    "                        opt.zero_grad()\n",
    "                        out = model(batch)\n",
    "                        loss = F.mse_loss(out.squeeze(), batch.y.float())\n",
    "                        loss.backward()\n",
    "                        opt.step()\n",
    "\n",
    "                # Eval\n",
    "                preds, labels = evaluate(model, vl)\n",
    "                y_true = labels.numpy().astype(int)\n",
    "                y_probs = F.softmax(preds, dim=1).numpy()\n",
    "                y_pred  = preds.argmax(dim=1).numpy()\n",
    "\n",
    "                # AUC‚ÄëROC (one-vs-rest)\n",
    "                auc = roc_auc_score(\n",
    "                    label_binarize(y_true, classes=np.arange(num_classes)),\n",
    "                    y_probs, multi_class='ovr'\n",
    "                )\n",
    "                auc_scores.append(auc)\n",
    "\n",
    "                # Balanced Accuracy\n",
    "                bal = balanced_accuracy_score(y_true, y_pred)\n",
    "                bal_scores.append(bal)\n",
    "\n",
    "            # Record mean¬±std for both metrics\n",
    "            results.append({\n",
    "                \"hidden_channels\": hd,\n",
    "                \"dropout\":    dp,\n",
    "                \"lr\":         lr,\n",
    "                \"m\n",
    "                # \"mean_auc\":   np.mean(auc_scores),\n",
    "                # \"std_auc\":    np.std(auc_scores),\n",
    "                # \"mean_balanced_acc\": np.mean(bal_scores),\n",
    "                # \"std_balanced_acc\":  np.std(bal_scores),\n",
    "            })\n",
    "\n",
    "            # print(f\"üìä AUC: {np.mean(auc_scores):.4f} ¬± {np.std(auc_scores):.4f} | \"\n",
    "            #       f\"Balanced Acc: {np.mean(bal_scores):.4f} ¬± {np.std(bal_scores):.4f}\")\n",
    "\n",
    "# Build DataFrame and sort by mean balanced accuracy (or mean_auc)\n",
    "sweep_df = pd.DataFrame(results)\n",
    "display(sweep_df.sort_values(\"mean_balanced_acc\", ascending=False))\n",
    "# Save the results\n",
    "sweep_df.to_csv(os.path.join(results_dir, \"sweep_results.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bef626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best config: hidden_channels=256, dropout=0.0, lr=0.0005\n",
    "# Load the best model configuration\n",
    "best_config = sweep_df.loc[sweep_df[\"mean_balanced_acc\"].idxmax()]\n",
    "best_hidden_channels = int(best_config[\"hidden_channels\"])\n",
    "best_dropout = best_config[\"dropout\"]\n",
    "best_lr = best_config[\"lr\"]\n",
    "print(f\"Best config: hidden_channels={best_hidden_channels}, dropout={best_dropout}, lr={best_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97989bc2",
   "metadata": {},
   "source": [
    "# ## Step 5a: Retrain All Folds with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8712251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pandas as pd\n",
    "fold_metrics = []\n",
    "\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\nüîÅ Retraining Fold {fold+1}/10\")\n",
    "    \n",
    "    train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "    \n",
    "    model = DeepGNNWithEdgeFeatures(train_data[0].x.size(1),\n",
    "                 train_data[0].edge_attr.size(1),\n",
    "                 hidden_channels=best_hidden_channels,\n",
    "                 out_channels=num_classes,\n",
    "                 dropout=best_dropout).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                    worker_init_fn=seed_worker, generator=generator)\n",
    "    val_loader = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "    best_val_loss = float('inf'); patience=0\n",
    "    for epoch in range(1, 101):\n",
    "        model.train(); total=0\n",
    "        for batch in tr:\n",
    "            batch=batch.to(device); opt.zero_grad(); out=model(batch)\n",
    "            loss=F.cross_entropy(out,batch.y.long()); loss.backward(); opt.step(); total+=loss.item()\n",
    "        preds, labels = evaluate(model, vl)\n",
    "        y_true = labels.numpy().astype(int)\n",
    "        y_probs = F.softmax(preds, dim=1).numpy()\n",
    "        val_loss = F.cross_entropy(preds, labels.long()).item()\n",
    "        print(f\"Epoch {epoch:03d} | Train Loss: {total / len(train_loader):.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss=val_loss; patience=0\n",
    "            torch.save(model.state_dict(), os.path.join(results_dir, f\"fold{fold+1}_model.pt\"))\n",
    "        else:\n",
    "            patience+=1\n",
    "            if patience>=10: break\n",
    "    print(f\"Best val loss: {best_val_loss:.4f} | Early stopping patience: {patience}\")\n",
    "    \n",
    "\n",
    "    # Metrics\n",
    "    y_pred = preds.argmax(dim=1).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    auc = roc_auc_score(label_binarize(y_true, classes=np.arange(num_classes)), y_probs, multi_class='ovr')\n",
    "    fold_metrics.append({\"fold\":fold+1,\"accuracy\":acc,\"precision\":precision,\"recall\":recall,\"f1_score\":f1,\"auc_roc\":auc})\n",
    "\n",
    "# Save CV summary\n",
    "cv_df = pd.DataFrame(fold_metrics)\n",
    "cv_df.to_csv(os.path.join(results_dir, \"crossval_summary.csv\"), index=False)\n",
    "print(\"‚úÖ Saved CV summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63f613",
   "metadata": {},
   "source": [
    "# ## Step 6: Visualize Cross-Validation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "cv_df = pd.read_csv(os.path.join(results_dir, \"crossval_summary.csv\"))\n",
    "metrics = ['accuracy','precision','recall','f1_score','auc_roc']\n",
    "fig, axs = plt.subplots(1,len(metrics), figsize=(20,4))\n",
    "for i,m in enumerate(metrics):\n",
    "    axs[i].bar(cv_df['fold'], cv_df[m]); axs[i].set_title(m.upper()); axs[i].set_xlabel('Fold'); axs[i].set_ylabel(m)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9ecc1",
   "metadata": {},
   "source": [
    "# ## Step 7: Ensemble Averaging from 10 CV Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "ess_preds=[]\n",
    "test_data=torch.load(os.path.join(base_path, f\"{task}_test.pt\"))\n",
    "tl=DataLoader(test_data, batch_size=32)\n",
    "for fold in range(10):\n",
    "    model = DeepGNNWithEdgeFeatures(test_data[0].x.size(1), test_data[0].edge_attr.size(1), hidden_channels=best_hidden_channels, out_channels=num_classes, dropout=best_dropout).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(results_dir, f\"fold{fold+1}_model.pt\")))\n",
    "    model.eval(); outs=[]\n",
    "    with torch.no_grad():\n",
    "        for b in tl: outs.append(model(b.to(device)).cpu())\n",
    "    ess_preds.append(torch.cat(outs,0))\n",
    "avg=torch.stack(ess_preds).mean(0)\n",
    "f_pred=avg.argmax(1).numpy(); t_true=torch.cat([d.y for d in test_data]).numpy().astype(int)\n",
    "pd.DataFrame({'True':t_true,'Pred':f_pred}).to_csv(os.path.join(results_dir,'ensemble_preds.csv'),index=False)\n",
    "print('‚úÖ Ensemble preds saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf71a7",
   "metadata": {},
   "source": [
    "# ## Step 7b: Ensemble Model Evaluation ‚Äì Confusion Matrix & AUC‚ÄëROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd80310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load ensemble predictions\n",
    "ens_df = pd.read_csv(os.path.join(results_dir, 'ensemble_preds.csv'))\n",
    "y_true_ens = ens_df['True'].values\n",
    "y_pred_ens = ens_df['Pred'].values\n",
    "\n",
    "# 1) Confusion matrix\n",
    "cm = confusion_matrix(y_true_ens, y_pred_ens)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[class_names[i] for i in range(num_classes)])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Ensemble Model ‚Äì Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) AUC‚ÄëROC per class\n",
    "# Need probability estimates ‚Äì reload avg_output if available or recompute probabilities\n",
    "# If you only have hard preds, rerun ensemble loop with model outputs saved as probs:\n",
    "# avg_probs = torch.stack(ensemble_prob_lists).mean(0).numpy()\n",
    "avg_output = avg\n",
    "# For now, assuming you have `avg_probs`:\n",
    "y_probs = avg_output.softmax(dim=1).numpy()  # or your stored avg_probs\n",
    "y_true_bin = label_binarize(y_true_ens, classes=np.arange(num_classes))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {auc(fpr, tpr):.2f})\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Ensemble Model ‚Äì AUC‚ÄëROC by Class\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec135d",
   "metadata": {},
   "source": [
    "# ## Step 8: Final Model Training on Combined Data & Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Merge train+val\n",
    "all_data=[]\n",
    "for fold in range(10):\n",
    "    all_data+=torch.load(os.path.join(base_path,f\"{task}_train_fold{fold}.pt\"))\n",
    "    all_data+=torch.load(os.path.join(base_path,f\"{task}_val_fold{fold}.pt\"))\n",
    "# small val\n",
    "sss=StratifiedShuffleSplit(n_splits=1,test_size=0.1,random_state=seed)\n",
    "labels=[int(d.y.item()) for d in all_data]\n",
    "train_idx,val_idx=next(sss.split(all_data,labels))\n",
    "train_split=[all_data[i] for i in train_idx]; val_split=[all_data[i] for i in val_idx]\n",
    "tr=DataLoader(train_split,batch_size=32,shuffle=True,worker_init_fn=seed_worker,generator=generator)\n",
    "vl=DataLoader(val_split,batch_size=32)\n",
    "model=DeepGNNWithEdgeFeatures(all_data[0].x.size(1),all_data[0].edge_attr.size(1),hidden_channels=best_hidden_channels,out_channels=num_classes,dropout=best_dropout).to(device)\n",
    "opt=torch.optim.Adam(model.parameters(),lr=best_lr)\n",
    "sched=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,mode='min',patience=5,factor=0.5,verbose=True)\n",
    "best_v=1e9;pat=0\n",
    "for epoch in range(1,301):\n",
    "    model.train();tot=0\n",
    "    for b in tr: b=b.to(device);opt.zero_grad();o=model(b);l=F.cross_entropy(o,b.y.long());l.backward();opt.step();tot+=l.item()\n",
    "    preds,labels=evaluate(model,vl);vloss=F.cross_entropy(preds,labels.long()).item();sched.step(vloss)\n",
    "    if vloss<best_v:best_v=vloss;pat=0;torch.save(model.state_dict(),os.path.join(results_dir,'final_model.pt'))\n",
    "    else: pat+=1\n",
    "    if pat>=10:break\n",
    "    print(f\"Epoch {epoch:03d} | Train Loss: {tot/len(tr):.4f} | Val Loss: {vloss:.4f} | Best Val Loss: {best_v:.4f} | Patience: {pat}\")\n",
    "\n",
    "# test eval\n",
    "model.load_state_dict(torch.load(os.path.join(results_dir,'final_model.pt')))\n",
    "td=DataLoader(torch.load(os.path.join(base_path,f\"{task}_test.pt\")),batch_size=32)\n",
    "preds,labels=evaluate(model,td);y_pred=preds.argmax(1).numpy();y_true=labels.numpy().astype(int)\n",
    "# metrics\n",
    "acc_f=accuracy_score(y_true,y_pred);prec,rec,f1,_=precision_recall_fscore_support(y_true,y_pred,average='weighted')\n",
    "# confusion\n",
    "cm=confusion_matrix(y_true,y_pred);disp=ConfusionMatrixDisplay(cm,display_labels=list(class_names.values()));disp.plot()\n",
    "plt.title('Final Model Confusion Matrix');plt.show()\n",
    "# final auc\n",
    " # Assume y_true is shape (n,) and preds is torch.Tensor of shape (n, num_classes)\n",
    "probs     = F.softmax(preds, dim=1).cpu().numpy()     # (n, C)\n",
    "y_true    = labels.numpy().astype(int)                 # (n,)\n",
    "y_true_bin= label_binarize(y_true, classes=np.arange(num_classes))  # (n, C)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], probs[:, i])\n",
    "    roc_auc     = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Chance\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Final Model ‚Äì AUC‚ÄëROC by Class\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparison table\n",
    "ensemble_df=pd.read_csv(os.path.join(results_dir,'ensemble_preds.csv'))\n",
    "ensemble_acc=accuracy_score(ensemble_df['True'],ensemble_df['Pred'])\n",
    "final_metrics = {'ensemble': ensemble_acc, 'final': acc_f}\n",
    "comp = pd.DataFrame.from_dict(final_metrics, orient='index', columns=['Accuracy'])\n",
    "display(comp)\n",
    "\n",
    "# Save final metrics\n",
    "final_metrics = {\n",
    "    'accuracy': acc_f,\n",
    "    'precision': prec,\n",
    "    'recall': rec,\n",
    "    'f1_score': f1,\n",
    "    'auc_roc': roc_auc_score(label_binarize(y_true, classes=np.arange(num_classes)), probs, multi_class='ovr')\n",
    "}\n",
    "final_metrics_df = pd.DataFrame(final_metrics, index=[0])\n",
    "final_metrics_df.to_csv(os.path.join(results_dir, 'final_metrics.csv'), index=False)\n",
    "print(\"‚úÖ Final metrics saved\")\n",
    "# Save final confusion matrix\n",
    "cm_df = pd.DataFrame(cm, index=class_names.values(), columns=class_names.values())\n",
    "cm_df.to_csv(os.path.join(results_dir, 'final_confusion_matrix.csv'))\n",
    "print(\"‚úÖ Final confusion matrix saved\")\n",
    "# Save final AUC-ROC\n",
    "roc_df = pd.DataFrame({'fpr': fpr, 'tpr': tpr})\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_df.to_csv(os.path.join(results_dir, 'final_auc_roc.csv'), index=False)\n",
    "print(\"‚úÖ Final AUC-ROC saved\")\n",
    "# Save final predictions\n",
    "preds_df = pd.DataFrame({'True': y_true, 'Pred': y_pred})\n",
    "preds_df.to_csv(os.path.join(results_dir, 'final_predictions.csv'), index=False)\n",
    "print(\"‚úÖ Final predictions saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce2b1f",
   "metadata": {},
   "source": [
    "## Step 9: compare ensemble averaging to final model training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "ensemble_df=pd.read_csv(os.path.join(results_dir,'ensemble_preds.csv'))\n",
    "ensemble_acc=accuracy_score(ensemble_df['True'],ensemble_df['Pred'])\n",
    "final_metrics = {'ensemble': ensemble_acc, 'final': acc_f}\n",
    "comp = pd.DataFrame.from_dict(final_metrics, orient='index', columns=['Accuracy'])\n",
    "display(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5121ad4-808e-4d76-8a6c-811c85ff5c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d514a836-812a-4ac9-a241-9bb7a1923b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos 2025",
   "language": "python",
   "name": "erdos_spring_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
