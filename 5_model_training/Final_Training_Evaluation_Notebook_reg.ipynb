{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a72147",
   "metadata": {},
   "source": [
    "# # Full Cross-Validation and Final Training Evaluation Notebook\n",
    "# \n",
    "# This notebook performs graph neural network (GNN)-based classification or regression using a custom Message Passing Neural Network (MPNN) architecture. It supports training with 5-fold cross-validation and then retrains a final model on combined data using early stopping. Performance is evaluated on a held-out test set.\n",
    "# \n",
    "# ## üß≠ Workflow Overview\n",
    "# \n",
    "# ### Step 1. Imports and Setup\n",
    "# - Load libraries including PyTorch, PyTorch Geometric, and scikit-learn.\n",
    "# - Configure plotting and file management tools.\n",
    "# \n",
    "# ### Step 2. Task and Reproducibility Setup\n",
    "# - Set task: `task = \"classification\"` or `\"regression\"`.\n",
    "# - Configure reproducibility with a fixed random seed for reproducibility\n",
    "# - Define class names if applicable and set up result directories.\n",
    "# \n",
    "# ### Step 3. Model Definition\n",
    "# - Define an MPNN layer and model using PyTorch Geometric.\n",
    "# - The model takes node and edge features and outputs class scores or scalar predictions.\n",
    "# \n",
    "# ### Step 4. Evaluation Helper Function\n",
    "# - Implements an `evaluate(model, loader)` function to return model outputs and ground truths.\n",
    "# \n",
    "# ### Step 5. Input Dimensions and Device Setup\n",
    "# - Determine input feature dimensions from dataset.\n",
    "# - Detect and assign appropriate device (CPU or GPU).\n",
    "# \n",
    "# ### Step 6. Cross-Validation Training and Evaluation\n",
    "# - Train the model across 5 folds using pre-split datasets from ../4_train_test_split/5fold_cv/{task}/\n",
    ".\n",
    "# - Log metrics per fold:\n",
    "#   - **Classification**: accuracy, precision, recall, F1, AUC-ROC\n",
    "#   - **Regression**: MAE, MSE, RMSE, R¬≤\n",
    "# - Save all results to CSV.\n",
    "# \n",
    "# ### Step 7. Final Model Training and Test Evaluation\n",
    "# - Merge all training and validation folds.\n",
    "# - Reserve a small stratified/random validation split.\n",
    "# - Train model with:\n",
    "#   - **Early stopping** (based on validation loss)\n",
    "#   - **Learning rate scheduler**\n",
    "#   - **Model checkpointing** (saves best model)\n",
    "# - Evaluate on the held-out test set and save predictions + plots.\n",
    "# \n",
    "# ### Step 8. Cross-Validation Results Visualization\n",
    "# - Plot fold-wise bar charts for key metrics.\n",
    "# - Display mean and standard deviation summary.\n",
    "# \n",
    "# ### Step 9. Interpreting Final Model AUC-ROC and Confusion Matrix\n",
    "# - Provide interpretation of model behavior:\n",
    "#   - AUC-ROC curve ‚Üí how well the model separates classes\n",
    "#   - Confusion matrix ‚Üí where the model gets confused\n",
    "# - Identify any class-specific issues \n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ## üõ† Parameters That Can Be optimized/tuned\n",
    "#\n",
    "# - **Hidden dimension** of MPNN: `hidden_dim`\n",
    "# - **Learning rate**: `lr` in `Adam` optimizer\n",
    "# - **Batch size**: affects convergence speed and generalization\n",
    "# - **Early stopping patience**: number of epochs without improvement\n",
    "# - **Scheduler factor/patience**: reduce LR when plateauing\n",
    "# - **Model depth**: number of MPNN layers\n",
    "# - **Number of epochs**: max training rounds\n",
    "# - **Loss function**: CrossEntropy vs. MSE depending on task\n",
    "# - **Stratified vs. random validation split**\n",
    "\n",
    "# ---\n",
    "#\n",
    "# ‚úÖ This notebook can be extended with additional model types (e.g., GAT, GIN), more complex featurization, or hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f1c0d",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b107243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79ade2",
   "metadata": {},
   "source": [
    "## 2. Task and Reproducibility Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64234a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "#task = \"classification\"  # or \"regression\"\n",
    "task = \"regression\"  # or \"classification\"\n",
    "num_classes = 3\n",
    "class_names = {0: \"Low\", 1: \"Medium\", 2: \"High\"}\n",
    "\n",
    "base_path = f\"../4_train_test_split/10fold_cv/{task}/\"\n",
    "results_dir = f\"MPNN_results/{task}/\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ac03",
   "metadata": {},
   "source": [
    "## 3b. Define MPNN Layer and MPNN Model with Dropout Support\n",
    "# Enhanced MPNN model with dropout layers after each message-passing block to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c517152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "        self.edge_proj = Linear(edge_dim, out_channels)\n",
    "        self.msg_lin = Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.lin(x)\n",
    "        edge_attr = self.edge_proj(edge_attr)\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return self.msg_lin(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return F.relu(aggr_out)\n",
    "\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, edge_dim, hidden_dim, output_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.mp1 = MPNNLayer(input_dim, hidden_dim, edge_dim)\n",
    "        self.mp2 = MPNNLayer(hidden_dim, hidden_dim, edge_dim)\n",
    "        self.out = Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.mp1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.mp2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bd2cc",
   "metadata": {},
   "source": [
    "## 4. Evaluation Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d899a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds.append(out.cpu())\n",
    "            labels.append(batch.y.cpu())\n",
    "    return torch.cat(preds), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063855f",
   "metadata": {},
   "source": [
    "## 5. Input Dimensions and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3414ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = torch.load(os.path.join(base_path, f\"{task}_train_fold0.pt\"))[0]\n",
    "input_dim = sample_data.x.size(1)\n",
    "edge_dim = sample_data.edge_attr.size(1)\n",
    "output_dim = num_classes if task == \"classification\" else 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ef9f7",
   "metadata": {},
   "source": [
    "# # Steps 3‚Äì7: Hyperparameter Tuning, Retraining, and Evaluation\n",
    "# This notebook covers the core stages in training and evaluating a GNN model using 5-fold CV and ensemble averaging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2e937",
   "metadata": {},
   "source": [
    "## Step 3: Cross-Validation Training with Hyperparameter Sweep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5c45c",
   "metadata": {},
   "source": [
    "# ## Step 4: Select Best Hyperparameters\n",
    "# Use this section to manually define the best hyperparameters based on the sweep above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8184324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter sweep over hidden_dim, dropout, and learning rate\n",
      "Config: hidden_dim=64, dropout=0.0, lr=0.001\n",
      "üìä R¬≤: 0.2214 ¬± 0.1476\n",
      "Config: hidden_dim=64, dropout=0.0, lr=0.0005\n",
      "üìä R¬≤: 0.2366 ¬± 0.0976\n",
      "Config: hidden_dim=64, dropout=0.0, lr=0.0001\n",
      "üìä R¬≤: 0.2123 ¬± 0.1229\n",
      "Config: hidden_dim=64, dropout=0.2, lr=0.001\n",
      "üìä R¬≤: 0.2658 ¬± 0.1017\n",
      "Config: hidden_dim=64, dropout=0.2, lr=0.0005\n",
      "üìä R¬≤: 0.2133 ¬± 0.1577\n",
      "Config: hidden_dim=64, dropout=0.2, lr=0.0001\n",
      "üìä R¬≤: 0.2034 ¬± 0.1476\n",
      "Config: hidden_dim=64, dropout=0.4, lr=0.001\n",
      "üìä R¬≤: 0.2548 ¬± 0.0943\n",
      "Config: hidden_dim=64, dropout=0.4, lr=0.0005\n",
      "üìä R¬≤: 0.2518 ¬± 0.1005\n",
      "Config: hidden_dim=64, dropout=0.4, lr=0.0001\n",
      "üìä R¬≤: 0.1980 ¬± 0.1425\n",
      "Config: hidden_dim=128, dropout=0.0, lr=0.001\n",
      "üìä R¬≤: 0.1913 ¬± 0.0887\n",
      "Config: hidden_dim=128, dropout=0.0, lr=0.0005\n",
      "üìä R¬≤: 0.2816 ¬± 0.0835\n",
      "Config: hidden_dim=128, dropout=0.0, lr=0.0001\n",
      "üìä R¬≤: 0.2245 ¬± 0.1339\n",
      "Config: hidden_dim=128, dropout=0.2, lr=0.001\n",
      "üìä R¬≤: 0.2679 ¬± 0.1280\n",
      "Config: hidden_dim=128, dropout=0.2, lr=0.0005\n",
      "üìä R¬≤: 0.2062 ¬± 0.2236\n",
      "Config: hidden_dim=128, dropout=0.2, lr=0.0001\n",
      "üìä R¬≤: 0.2451 ¬± 0.0998\n",
      "Config: hidden_dim=128, dropout=0.4, lr=0.001\n",
      "üìä R¬≤: 0.2162 ¬± 0.2646\n",
      "Config: hidden_dim=128, dropout=0.4, lr=0.0005\n",
      "üìä R¬≤: 0.2392 ¬± 0.1115\n",
      "Config: hidden_dim=128, dropout=0.4, lr=0.0001\n",
      "üìä R¬≤: 0.2259 ¬± 0.1416\n",
      "Config: hidden_dim=256, dropout=0.0, lr=0.001\n",
      "üìä R¬≤: 0.2324 ¬± 0.1263\n",
      "Config: hidden_dim=256, dropout=0.0, lr=0.0005\n",
      "üìä R¬≤: 0.2310 ¬± 0.1513\n",
      "Config: hidden_dim=256, dropout=0.0, lr=0.0001\n",
      "üìä R¬≤: 0.2419 ¬± 0.1312\n",
      "Config: hidden_dim=256, dropout=0.2, lr=0.001\n",
      "üìä R¬≤: 0.2764 ¬± 0.0964\n",
      "Config: hidden_dim=256, dropout=0.2, lr=0.0005\n",
      "üìä R¬≤: 0.2621 ¬± 0.1028\n",
      "Config: hidden_dim=256, dropout=0.2, lr=0.0001\n",
      "üìä R¬≤: 0.2378 ¬± 0.1206\n",
      "Config: hidden_dim=256, dropout=0.4, lr=0.001\n",
      "üìä R¬≤: 0.0450 ¬± 0.3143\n",
      "Config: hidden_dim=256, dropout=0.4, lr=0.0005\n",
      "üìä R¬≤: 0.1259 ¬± 0.1977\n",
      "Config: hidden_dim=256, dropout=0.4, lr=0.0001\n",
      "üìä R¬≤: 0.2088 ¬± 0.1972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_r2</th>\n",
       "      <th>std_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.281630</td>\n",
       "      <td>0.083463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.276357</td>\n",
       "      <td>0.096351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.267874</td>\n",
       "      <td>0.127969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.265816</td>\n",
       "      <td>0.101727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.262083</td>\n",
       "      <td>0.102781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.254844</td>\n",
       "      <td>0.094339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.251837</td>\n",
       "      <td>0.100538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.245068</td>\n",
       "      <td>0.099821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.241874</td>\n",
       "      <td>0.131203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.239222</td>\n",
       "      <td>0.111517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.237823</td>\n",
       "      <td>0.120637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.236646</td>\n",
       "      <td>0.097550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.232383</td>\n",
       "      <td>0.126289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.231037</td>\n",
       "      <td>0.151277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.225938</td>\n",
       "      <td>0.141570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.224499</td>\n",
       "      <td>0.133930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.221377</td>\n",
       "      <td>0.147593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.216155</td>\n",
       "      <td>0.264637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.213325</td>\n",
       "      <td>0.157666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.212286</td>\n",
       "      <td>0.122950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.208831</td>\n",
       "      <td>0.197240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.206178</td>\n",
       "      <td>0.223563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.203411</td>\n",
       "      <td>0.147581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.197996</td>\n",
       "      <td>0.142540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.191337</td>\n",
       "      <td>0.088666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.125920</td>\n",
       "      <td>0.197678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.044960</td>\n",
       "      <td>0.314331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_dim  dropout  learning_rate   mean_r2    std_r2\n",
       "10         128      0.0         0.0005  0.281630  0.083463\n",
       "21         256      0.2         0.0010  0.276357  0.096351\n",
       "12         128      0.2         0.0010  0.267874  0.127969\n",
       "3           64      0.2         0.0010  0.265816  0.101727\n",
       "22         256      0.2         0.0005  0.262083  0.102781\n",
       "6           64      0.4         0.0010  0.254844  0.094339\n",
       "7           64      0.4         0.0005  0.251837  0.100538\n",
       "14         128      0.2         0.0001  0.245068  0.099821\n",
       "20         256      0.0         0.0001  0.241874  0.131203\n",
       "16         128      0.4         0.0005  0.239222  0.111517\n",
       "23         256      0.2         0.0001  0.237823  0.120637\n",
       "1           64      0.0         0.0005  0.236646  0.097550\n",
       "18         256      0.0         0.0010  0.232383  0.126289\n",
       "19         256      0.0         0.0005  0.231037  0.151277\n",
       "17         128      0.4         0.0001  0.225938  0.141570\n",
       "11         128      0.0         0.0001  0.224499  0.133930\n",
       "0           64      0.0         0.0010  0.221377  0.147593\n",
       "15         128      0.4         0.0010  0.216155  0.264637\n",
       "4           64      0.2         0.0005  0.213325  0.157666\n",
       "2           64      0.0         0.0001  0.212286  0.122950\n",
       "26         256      0.4         0.0001  0.208831  0.197240\n",
       "13         128      0.2         0.0005  0.206178  0.223563\n",
       "5           64      0.2         0.0001  0.203411  0.147581\n",
       "8           64      0.4         0.0001  0.197996  0.142540\n",
       "9          128      0.0         0.0010  0.191337  0.088666\n",
       "25         256      0.4         0.0005  0.125920  0.197678\n",
       "24         256      0.4         0.0010  0.044960  0.314331"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameter grids\n",
    "hidden_dims = [64, 128, 256]\n",
    "dropouts = [0.0, 0.2, 0.4]\n",
    "lrs = [1e-3, 5e-4, 1e-4]\n",
    "\n",
    "results = []\n",
    "print(\"Starting hyperparameter sweep over hidden_dim, dropout, and learning rate\")\n",
    "for hd in hidden_dims:\n",
    "    for dp in dropouts:\n",
    "        for lr in lrs:\n",
    "            print(f\"Config: hidden_dim={hd}, dropout={dp}, lr={lr}\")\n",
    "            fold_metrics = []\n",
    "            for fold in range(10):\n",
    "                # Load fold data\n",
    "                train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "                val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "                # Initialize model and optimizer\n",
    "                model = MPNN(input_dim, edge_dim,\n",
    "                             hidden_dim=hd,\n",
    "                             output_dim=output_dim,\n",
    "                             dropout=dp).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                # Data loaders\n",
    "                train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "                val_loader   = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "                # Training loop\n",
    "                for epoch in range(1, 51):\n",
    "                    model.train()\n",
    "                    for batch in train_loader:\n",
    "                        batch = batch.to(device)\n",
    "                        optimizer.zero_grad()\n",
    "                        out = model(batch)\n",
    "                        loss = F.mse_loss(out.squeeze(), batch.y)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Validation\n",
    "                preds, trues = evaluate(model, val_loader)\n",
    "                y_true = trues.numpy()\n",
    "                y_pred = preds.squeeze().numpy()\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                fold_metrics.append(r2)\n",
    "\n",
    "            # Record mean and std\n",
    "            mean_r2 = np.mean(fold_metrics)\n",
    "            std_r2  = np.std(fold_metrics)\n",
    "            results.append((hd, dp, lr, mean_r2, std_r2))\n",
    "            print(f\"üìä R¬≤: {mean_r2:.4f} ¬± {std_r2:.4f}\")\n",
    "\n",
    "# Compile results into DataFrame\n",
    "sweep_df = pd.DataFrame(results,\n",
    "                        columns=[\"hidden_dim\", \"dropout\", \"learning_rate\", \"mean_r2\", \"std_r2\"])\n",
    "# Display sorted by best performance\n",
    "display(sweep_df.sort_values(\"mean_r2\", ascending=False))\n",
    "cv_df = pd.DataFrame(fold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95fd6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "best_hidden_dim = 128\n",
    "best_dropout = 0.0\n",
    "best_lr = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97989bc2",
   "metadata": {},
   "source": [
    "# ## Step 5a: Retrain All Folds with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74ca1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Re-training Fold 1/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 16.7980 | Val Loss: 6.6809\n",
      "Epoch 002 | Train Loss: 2.5564 | Val Loss: 1.2665\n",
      "Epoch 003 | Train Loss: 1.3276 | Val Loss: 0.9992\n",
      "Epoch 004 | Train Loss: 1.1166 | Val Loss: 1.1250\n",
      "Epoch 005 | Train Loss: 1.0899 | Val Loss: 0.8896\n",
      "Epoch 006 | Train Loss: 1.0719 | Val Loss: 1.1008\n",
      "Epoch 007 | Train Loss: 1.0587 | Val Loss: 0.9800\n",
      "Epoch 008 | Train Loss: 0.9765 | Val Loss: 0.8843\n",
      "Epoch 009 | Train Loss: 1.0166 | Val Loss: 0.9149\n",
      "Epoch 010 | Train Loss: 1.0040 | Val Loss: 0.9301\n",
      "Epoch 011 | Train Loss: 0.9809 | Val Loss: 0.9572\n",
      "Epoch 012 | Train Loss: 1.0067 | Val Loss: 0.9459\n",
      "Epoch 013 | Train Loss: 0.9763 | Val Loss: 0.9432\n",
      "Epoch 014 | Train Loss: 1.0162 | Val Loss: 0.8677\n",
      "Epoch 015 | Train Loss: 1.0114 | Val Loss: 0.8286\n",
      "Epoch 016 | Train Loss: 1.0861 | Val Loss: 0.8221\n",
      "Epoch 017 | Train Loss: 0.9716 | Val Loss: 0.8206\n",
      "Epoch 018 | Train Loss: 1.0088 | Val Loss: 0.8214\n",
      "Epoch 019 | Train Loss: 1.0265 | Val Loss: 0.8340\n",
      "Epoch 020 | Train Loss: 1.0635 | Val Loss: 0.8223\n",
      "Epoch 021 | Train Loss: 0.9677 | Val Loss: 0.8226\n",
      "Epoch 022 | Train Loss: 0.9875 | Val Loss: 0.9250\n",
      "Epoch 023 | Train Loss: 0.9578 | Val Loss: 0.9372\n",
      "Epoch 024 | Train Loss: 0.9416 | Val Loss: 0.8847\n",
      "Epoch 025 | Train Loss: 0.9308 | Val Loss: 1.2634\n",
      "Epoch 026 | Train Loss: 1.0052 | Val Loss: 0.8763\n",
      "Epoch 027 | Train Loss: 0.9607 | Val Loss: 0.9772\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 028 | Train Loss: 0.9427 | Val Loss: 0.8908\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 029 | Train Loss: 0.9451 | Val Loss: 0.8096\n",
      "Epoch 030 | Train Loss: 0.9609 | Val Loss: 0.9323\n",
      "Epoch 031 | Train Loss: 0.9363 | Val Loss: 0.8715\n",
      "Epoch 032 | Train Loss: 0.9894 | Val Loss: 1.0864\n",
      "Epoch 033 | Train Loss: 0.9174 | Val Loss: 0.8213\n",
      "Epoch 034 | Train Loss: 0.9067 | Val Loss: 0.8267\n",
      "Epoch 035 | Train Loss: 0.9371 | Val Loss: 1.0000\n",
      "Epoch 036 | Train Loss: 0.9233 | Val Loss: 1.1231\n",
      "Epoch 037 | Train Loss: 0.9514 | Val Loss: 0.9641\n",
      "Epoch 038 | Train Loss: 0.9142 | Val Loss: 0.9603\n",
      "Epoch 039 | Train Loss: 0.8971 | Val Loss: 0.9137\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 040 | Train Loss: 0.8883 | Val Loss: 1.1223\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 041 | Train Loss: 0.9714 | Val Loss: 0.8771\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 042 | Train Loss: 0.9890 | Val Loss: 0.8748\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 043 | Train Loss: 1.0206 | Val Loss: 0.8153\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 044 | Train Loss: 0.8951 | Val Loss: 0.8946\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 045 | Train Loss: 0.9480 | Val Loss: 0.8106\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 046 | Train Loss: 0.9283 | Val Loss: 0.8890\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 047 | Train Loss: 0.9387 | Val Loss: 0.8625\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 048 | Train Loss: 0.9272 | Val Loss: 0.8394\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 049 | Train Loss: 0.9257 | Val Loss: 0.8359\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 050 | Train Loss: 0.9335 | Val Loss: 1.0510\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 051 | Train Loss: 0.9029 | Val Loss: 0.9864\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 052 | Train Loss: 0.9357 | Val Loss: 0.8247\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 053 | Train Loss: 0.8844 | Val Loss: 0.7926\n",
      "Epoch 054 | Train Loss: 0.8813 | Val Loss: 0.8535\n",
      "Epoch 055 | Train Loss: 0.9423 | Val Loss: 0.8003\n",
      "Epoch 056 | Train Loss: 0.9079 | Val Loss: 0.8902\n",
      "Epoch 057 | Train Loss: 0.9114 | Val Loss: 0.7856\n",
      "Epoch 058 | Train Loss: 0.9484 | Val Loss: 0.8202\n",
      "Epoch 059 | Train Loss: 0.8630 | Val Loss: 0.9460\n",
      "Epoch 060 | Train Loss: 0.8826 | Val Loss: 0.9736\n",
      "Epoch 061 | Train Loss: 0.9343 | Val Loss: 0.8162\n",
      "Epoch 062 | Train Loss: 0.8687 | Val Loss: 0.8862\n",
      "Epoch 063 | Train Loss: 0.8817 | Val Loss: 1.2157\n",
      "Epoch 064 | Train Loss: 0.9251 | Val Loss: 0.8219\n",
      "Epoch 065 | Train Loss: 0.8798 | Val Loss: 0.7782\n",
      "Epoch 066 | Train Loss: 0.9390 | Val Loss: 1.0225\n",
      "Epoch 067 | Train Loss: 0.8625 | Val Loss: 0.8114\n",
      "Epoch 068 | Train Loss: 0.8919 | Val Loss: 0.7831\n",
      "Epoch 069 | Train Loss: 0.8716 | Val Loss: 0.7970\n",
      "Epoch 070 | Train Loss: 0.9334 | Val Loss: 0.7914\n",
      "Epoch 071 | Train Loss: 0.8890 | Val Loss: 0.7775\n",
      "Epoch 072 | Train Loss: 0.8638 | Val Loss: 0.8782\n",
      "Epoch 073 | Train Loss: 0.8576 | Val Loss: 0.8016\n",
      "Epoch 074 | Train Loss: 0.8980 | Val Loss: 0.8557\n",
      "Epoch 075 | Train Loss: 0.8863 | Val Loss: 0.8186\n",
      "Epoch 076 | Train Loss: 0.8380 | Val Loss: 0.8687\n",
      "Epoch 077 | Train Loss: 0.8735 | Val Loss: 0.8933\n",
      "Epoch 078 | Train Loss: 0.8601 | Val Loss: 0.8671\n",
      "Epoch 079 | Train Loss: 0.8879 | Val Loss: 0.8117\n",
      "Epoch 080 | Train Loss: 0.8742 | Val Loss: 0.8001\n",
      "Epoch 081 | Train Loss: 0.8558 | Val Loss: 0.9279\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 082 | Train Loss: 0.8701 | Val Loss: 0.8076\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 083 | Train Loss: 0.9437 | Val Loss: 0.8254\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 084 | Train Loss: 0.8741 | Val Loss: 0.8378\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 085 | Train Loss: 0.8706 | Val Loss: 0.7705\n",
      "Epoch 086 | Train Loss: 0.8982 | Val Loss: 1.2395\n",
      "Epoch 087 | Train Loss: 0.9055 | Val Loss: 0.9118\n",
      "Epoch 088 | Train Loss: 0.8520 | Val Loss: 0.8187\n",
      "Epoch 089 | Train Loss: 0.8359 | Val Loss: 0.8666\n",
      "Epoch 090 | Train Loss: 0.8585 | Val Loss: 0.8565\n",
      "Epoch 091 | Train Loss: 0.8986 | Val Loss: 0.7560\n",
      "Epoch 092 | Train Loss: 0.8652 | Val Loss: 0.8230\n",
      "Epoch 093 | Train Loss: 1.0441 | Val Loss: 0.8007\n",
      "Epoch 094 | Train Loss: 0.8567 | Val Loss: 1.0271\n",
      "Epoch 095 | Train Loss: 0.8295 | Val Loss: 0.7705\n",
      "Epoch 096 | Train Loss: 0.8428 | Val Loss: 0.7580\n",
      "Epoch 097 | Train Loss: 0.8246 | Val Loss: 0.7694\n",
      "Epoch 098 | Train Loss: 0.8489 | Val Loss: 0.9508\n",
      "Epoch 099 | Train Loss: 0.8498 | Val Loss: 0.7744\n",
      "Epoch 100 | Train Loss: 1.0488 | Val Loss: 0.8663\n",
      "Epoch 101 | Train Loss: 0.9306 | Val Loss: 1.1955\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 102 | Train Loss: 0.8984 | Val Loss: 0.7822\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 103 | Train Loss: 0.9321 | Val Loss: 0.7772\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 104 | Train Loss: 0.8504 | Val Loss: 0.8244\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 105 | Train Loss: 0.8850 | Val Loss: 0.7565\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 106 | Train Loss: 0.8695 | Val Loss: 0.8576\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 107 | Train Loss: 0.8350 | Val Loss: 0.9530\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 108 | Train Loss: 0.8378 | Val Loss: 0.7868\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 109 | Train Loss: 0.8101 | Val Loss: 0.7996\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 110 | Train Loss: 0.8223 | Val Loss: 0.7460\n",
      "Epoch 111 | Train Loss: 0.8302 | Val Loss: 0.7713\n",
      "Epoch 112 | Train Loss: 0.8291 | Val Loss: 0.8568\n",
      "Epoch 113 | Train Loss: 0.8250 | Val Loss: 0.8181\n",
      "Epoch 114 | Train Loss: 0.8281 | Val Loss: 0.8032\n",
      "Epoch 115 | Train Loss: 0.8157 | Val Loss: 0.7506\n",
      "Epoch 116 | Train Loss: 0.8314 | Val Loss: 0.9001\n",
      "Epoch 117 | Train Loss: 0.8423 | Val Loss: 0.7658\n",
      "Epoch 118 | Train Loss: 0.8627 | Val Loss: 0.7521\n",
      "Epoch 119 | Train Loss: 0.8500 | Val Loss: 1.1639\n",
      "Epoch 120 | Train Loss: 0.8499 | Val Loss: 0.7575\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 121 | Train Loss: 0.8711 | Val Loss: 0.7703\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 122 | Train Loss: 0.8716 | Val Loss: 0.9667\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 123 | Train Loss: 0.8219 | Val Loss: 0.8457\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 124 | Train Loss: 0.8208 | Val Loss: 0.7881\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 125 | Train Loss: 0.7921 | Val Loss: 0.8685\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 126 | Train Loss: 0.8391 | Val Loss: 0.7482\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 127 | Train Loss: 0.8395 | Val Loss: 0.8669\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 128 | Train Loss: 0.8585 | Val Loss: 0.7486\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 129 | Train Loss: 0.8358 | Val Loss: 1.0306\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 130 | Train Loss: 1.0519 | Val Loss: 0.7578\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 131 | Train Loss: 0.8252 | Val Loss: 0.7974\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 132 | Train Loss: 0.8048 | Val Loss: 0.9196\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 133 | Train Loss: 0.8455 | Val Loss: 0.7811\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 134 | Train Loss: 0.8548 | Val Loss: 0.7436\n",
      "Epoch 135 | Train Loss: 0.8798 | Val Loss: 1.2591\n",
      "Epoch 136 | Train Loss: 0.8171 | Val Loss: 0.7627\n",
      "Epoch 137 | Train Loss: 0.8421 | Val Loss: 0.9094\n",
      "Epoch 138 | Train Loss: 0.8061 | Val Loss: 1.0451\n",
      "Epoch 139 | Train Loss: 0.8252 | Val Loss: 0.8019\n",
      "Epoch 140 | Train Loss: 0.8818 | Val Loss: 0.7608\n",
      "Epoch 141 | Train Loss: 0.8456 | Val Loss: 0.7901\n",
      "Epoch 142 | Train Loss: 0.9319 | Val Loss: 0.9400\n",
      "Epoch 143 | Train Loss: 0.9708 | Val Loss: 0.8550\n",
      "Epoch 144 | Train Loss: 0.8296 | Val Loss: 0.9050\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 145 | Train Loss: 0.8232 | Val Loss: 0.8435\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 146 | Train Loss: 0.8052 | Val Loss: 0.8191\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 147 | Train Loss: 0.8174 | Val Loss: 1.0360\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 148 | Train Loss: 0.8718 | Val Loss: 0.7435\n",
      "Epoch 149 | Train Loss: 0.9006 | Val Loss: 0.7445\n",
      "Epoch 150 | Train Loss: 0.7911 | Val Loss: 0.7714\n",
      "Epoch 151 | Train Loss: 0.8120 | Val Loss: 0.7565\n",
      "Epoch 152 | Train Loss: 0.8240 | Val Loss: 0.8363\n",
      "Epoch 153 | Train Loss: 0.8030 | Val Loss: 0.7418\n",
      "Epoch 154 | Train Loss: 0.8348 | Val Loss: 0.7772\n",
      "Epoch 155 | Train Loss: 0.8140 | Val Loss: 0.8716\n",
      "Epoch 156 | Train Loss: 0.7737 | Val Loss: 0.7668\n",
      "Epoch 157 | Train Loss: 0.7917 | Val Loss: 0.8763\n",
      "Epoch 158 | Train Loss: 0.8716 | Val Loss: 0.7330\n",
      "Epoch 159 | Train Loss: 0.8338 | Val Loss: 0.7655\n",
      "Epoch 160 | Train Loss: 0.9276 | Val Loss: 0.9673\n",
      "Epoch 161 | Train Loss: 0.9011 | Val Loss: 0.7425\n",
      "Epoch 162 | Train Loss: 0.8147 | Val Loss: 0.7273\n",
      "Epoch 163 | Train Loss: 0.8559 | Val Loss: 0.7657\n",
      "Epoch 164 | Train Loss: 0.7952 | Val Loss: 0.7311\n",
      "Epoch 165 | Train Loss: 0.8279 | Val Loss: 0.8941\n",
      "Epoch 166 | Train Loss: 0.8583 | Val Loss: 0.8159\n",
      "Epoch 167 | Train Loss: 0.8616 | Val Loss: 0.7223\n",
      "Epoch 168 | Train Loss: 0.8425 | Val Loss: 1.0253\n",
      "Epoch 169 | Train Loss: 0.7913 | Val Loss: 0.7963\n",
      "Epoch 170 | Train Loss: 0.7733 | Val Loss: 0.8044\n",
      "Epoch 171 | Train Loss: 0.9675 | Val Loss: 0.9076\n",
      "Epoch 172 | Train Loss: 0.8740 | Val Loss: 0.7364\n",
      "Epoch 173 | Train Loss: 0.9001 | Val Loss: 0.8606\n",
      "Epoch 174 | Train Loss: 0.8022 | Val Loss: 0.8942\n",
      "Epoch 175 | Train Loss: 0.8331 | Val Loss: 1.0289\n",
      "Epoch 176 | Train Loss: 0.8258 | Val Loss: 0.7310\n",
      "Epoch 177 | Train Loss: 0.7783 | Val Loss: 0.8848\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 178 | Train Loss: 0.8504 | Val Loss: 0.8027\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 179 | Train Loss: 0.8430 | Val Loss: 0.7378\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 180 | Train Loss: 0.7827 | Val Loss: 0.9350\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 181 | Train Loss: 0.8601 | Val Loss: 0.7517\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 182 | Train Loss: 0.8375 | Val Loss: 0.7256\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 0.8120 | Val Loss: 1.1395\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 184 | Train Loss: 0.8530 | Val Loss: 0.7667\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 185 | Train Loss: 0.8287 | Val Loss: 0.7163\n",
      "Epoch 186 | Train Loss: 0.7646 | Val Loss: 0.7875\n",
      "Epoch 187 | Train Loss: 0.7511 | Val Loss: 0.7503\n",
      "Epoch 188 | Train Loss: 0.7680 | Val Loss: 0.9398\n",
      "Epoch 189 | Train Loss: 0.8217 | Val Loss: 0.7327\n",
      "Epoch 190 | Train Loss: 0.8201 | Val Loss: 0.7691\n",
      "Epoch 191 | Train Loss: 0.8293 | Val Loss: 0.8139\n",
      "Epoch 192 | Train Loss: 0.7818 | Val Loss: 0.8062\n",
      "Epoch 193 | Train Loss: 0.7538 | Val Loss: 0.7545\n",
      "Epoch 194 | Train Loss: 0.7669 | Val Loss: 0.7371\n",
      "Epoch 195 | Train Loss: 0.7518 | Val Loss: 0.8317\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 196 | Train Loss: 0.7521 | Val Loss: 0.7626\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 197 | Train Loss: 0.8088 | Val Loss: 0.7063\n",
      "Epoch 198 | Train Loss: 0.7751 | Val Loss: 0.7139\n",
      "Epoch 199 | Train Loss: 0.8439 | Val Loss: 0.7997\n",
      "Epoch 200 | Train Loss: 0.7833 | Val Loss: 0.7460\n",
      "\n",
      "üîÅ Re-training Fold 2/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 17.7009 | Val Loss: 6.9081\n",
      "Epoch 002 | Train Loss: 2.7550 | Val Loss: 1.7474\n",
      "Epoch 003 | Train Loss: 1.3397 | Val Loss: 1.1838\n",
      "Epoch 004 | Train Loss: 1.0962 | Val Loss: 1.0748\n",
      "Epoch 005 | Train Loss: 1.0196 | Val Loss: 1.0680\n",
      "Epoch 006 | Train Loss: 1.0186 | Val Loss: 1.0925\n",
      "Epoch 007 | Train Loss: 1.0193 | Val Loss: 1.0352\n",
      "Epoch 008 | Train Loss: 1.0202 | Val Loss: 1.0290\n",
      "Epoch 009 | Train Loss: 0.9927 | Val Loss: 1.0844\n",
      "Epoch 010 | Train Loss: 1.0133 | Val Loss: 1.0254\n",
      "Epoch 011 | Train Loss: 0.9863 | Val Loss: 1.0124\n",
      "Epoch 012 | Train Loss: 1.0020 | Val Loss: 1.0123\n",
      "Epoch 013 | Train Loss: 0.9594 | Val Loss: 1.0024\n",
      "Epoch 014 | Train Loss: 0.9920 | Val Loss: 0.9992\n",
      "Epoch 015 | Train Loss: 1.1085 | Val Loss: 0.9984\n",
      "Epoch 016 | Train Loss: 1.0468 | Val Loss: 1.0308\n",
      "Epoch 017 | Train Loss: 0.9611 | Val Loss: 0.9954\n",
      "Epoch 018 | Train Loss: 0.9731 | Val Loss: 1.0056\n",
      "Epoch 019 | Train Loss: 0.9723 | Val Loss: 1.0194\n",
      "Epoch 020 | Train Loss: 1.0243 | Val Loss: 0.9990\n",
      "Epoch 021 | Train Loss: 0.9747 | Val Loss: 0.9810\n",
      "Epoch 022 | Train Loss: 0.9737 | Val Loss: 0.9761\n",
      "Epoch 023 | Train Loss: 0.9351 | Val Loss: 0.9993\n",
      "Epoch 024 | Train Loss: 0.9820 | Val Loss: 0.9691\n",
      "Epoch 025 | Train Loss: 0.9513 | Val Loss: 0.9720\n",
      "Epoch 026 | Train Loss: 0.8969 | Val Loss: 0.9745\n",
      "Epoch 027 | Train Loss: 0.9795 | Val Loss: 0.9600\n",
      "Epoch 028 | Train Loss: 0.9573 | Val Loss: 1.0167\n",
      "Epoch 029 | Train Loss: 0.9023 | Val Loss: 0.9612\n",
      "Epoch 030 | Train Loss: 0.9556 | Val Loss: 0.9624\n",
      "Epoch 031 | Train Loss: 0.9318 | Val Loss: 1.0640\n",
      "Epoch 032 | Train Loss: 1.1200 | Val Loss: 0.9856\n",
      "Epoch 033 | Train Loss: 0.9729 | Val Loss: 0.9549\n",
      "Epoch 034 | Train Loss: 0.8951 | Val Loss: 0.9817\n",
      "Epoch 035 | Train Loss: 0.9157 | Val Loss: 1.0662\n",
      "Epoch 036 | Train Loss: 0.9094 | Val Loss: 1.0466\n",
      "Epoch 037 | Train Loss: 0.9232 | Val Loss: 1.1387\n",
      "Epoch 038 | Train Loss: 1.0445 | Val Loss: 1.2057\n",
      "Epoch 039 | Train Loss: 0.9093 | Val Loss: 1.0801\n",
      "Epoch 040 | Train Loss: 0.9153 | Val Loss: 0.9803\n",
      "Epoch 041 | Train Loss: 0.8814 | Val Loss: 0.9305\n",
      "Epoch 042 | Train Loss: 0.9363 | Val Loss: 1.0093\n",
      "Epoch 043 | Train Loss: 0.9575 | Val Loss: 1.0046\n",
      "Epoch 044 | Train Loss: 0.8737 | Val Loss: 0.9488\n",
      "Epoch 045 | Train Loss: 0.9055 | Val Loss: 0.9238\n",
      "Epoch 046 | Train Loss: 0.9457 | Val Loss: 0.9740\n",
      "Epoch 047 | Train Loss: 0.8904 | Val Loss: 0.9195\n",
      "Epoch 048 | Train Loss: 0.8925 | Val Loss: 0.9169\n",
      "Epoch 049 | Train Loss: 0.8742 | Val Loss: 0.9393\n",
      "Epoch 050 | Train Loss: 0.8760 | Val Loss: 0.9094\n",
      "Epoch 051 | Train Loss: 0.9457 | Val Loss: 0.9087\n",
      "Epoch 052 | Train Loss: 0.9063 | Val Loss: 0.9274\n",
      "Epoch 053 | Train Loss: 0.8570 | Val Loss: 0.9553\n",
      "Epoch 054 | Train Loss: 0.8907 | Val Loss: 0.9164\n",
      "Epoch 055 | Train Loss: 0.8507 | Val Loss: 0.9135\n",
      "Epoch 056 | Train Loss: 0.8336 | Val Loss: 0.9895\n",
      "Epoch 057 | Train Loss: 0.8632 | Val Loss: 1.1204\n",
      "Epoch 058 | Train Loss: 0.9477 | Val Loss: 0.8981\n",
      "Epoch 059 | Train Loss: 0.8815 | Val Loss: 0.9117\n",
      "Epoch 060 | Train Loss: 0.8830 | Val Loss: 0.9784\n",
      "Epoch 061 | Train Loss: 0.8566 | Val Loss: 0.9032\n",
      "Epoch 062 | Train Loss: 0.8395 | Val Loss: 0.8883\n",
      "Epoch 063 | Train Loss: 0.9089 | Val Loss: 0.9535\n",
      "Epoch 064 | Train Loss: 0.8899 | Val Loss: 0.9802\n",
      "Epoch 065 | Train Loss: 0.8753 | Val Loss: 0.8982\n",
      "Epoch 066 | Train Loss: 0.9581 | Val Loss: 0.9412\n",
      "Epoch 067 | Train Loss: 0.9141 | Val Loss: 1.1027\n",
      "Epoch 068 | Train Loss: 0.8816 | Val Loss: 0.8800\n",
      "Epoch 069 | Train Loss: 0.8674 | Val Loss: 0.9245\n",
      "Epoch 070 | Train Loss: 0.8668 | Val Loss: 0.8868\n",
      "Epoch 071 | Train Loss: 0.8304 | Val Loss: 0.8783\n",
      "Epoch 072 | Train Loss: 0.8307 | Val Loss: 0.8759\n",
      "Epoch 073 | Train Loss: 0.8515 | Val Loss: 0.8729\n",
      "Epoch 074 | Train Loss: 0.8315 | Val Loss: 0.8723\n",
      "Epoch 075 | Train Loss: 0.8177 | Val Loss: 0.8696\n",
      "Epoch 076 | Train Loss: 0.8251 | Val Loss: 0.8914\n",
      "Epoch 077 | Train Loss: 0.8465 | Val Loss: 1.0692\n",
      "Epoch 078 | Train Loss: 0.9517 | Val Loss: 0.8646\n",
      "Epoch 079 | Train Loss: 0.9178 | Val Loss: 0.9753\n",
      "Epoch 080 | Train Loss: 0.9018 | Val Loss: 0.9981\n",
      "Epoch 081 | Train Loss: 0.9221 | Val Loss: 0.8638\n",
      "Epoch 082 | Train Loss: 0.8827 | Val Loss: 0.9112\n",
      "Epoch 083 | Train Loss: 0.8914 | Val Loss: 0.8666\n",
      "Epoch 084 | Train Loss: 0.8755 | Val Loss: 0.9314\n",
      "Epoch 085 | Train Loss: 0.8445 | Val Loss: 0.8614\n",
      "Epoch 086 | Train Loss: 0.8578 | Val Loss: 0.8752\n",
      "Epoch 087 | Train Loss: 0.8720 | Val Loss: 0.8783\n",
      "Epoch 088 | Train Loss: 0.8958 | Val Loss: 1.0252\n",
      "Epoch 089 | Train Loss: 0.8233 | Val Loss: 0.8761\n",
      "Epoch 090 | Train Loss: 0.8753 | Val Loss: 0.9071\n",
      "Epoch 091 | Train Loss: 0.8394 | Val Loss: 0.8581\n",
      "Epoch 092 | Train Loss: 0.8200 | Val Loss: 0.9051\n",
      "Epoch 093 | Train Loss: 0.8417 | Val Loss: 0.8526\n",
      "Epoch 094 | Train Loss: 0.7990 | Val Loss: 0.8568\n",
      "Epoch 095 | Train Loss: 0.8686 | Val Loss: 0.8600\n",
      "Epoch 096 | Train Loss: 0.8684 | Val Loss: 0.9116\n",
      "Epoch 097 | Train Loss: 0.8701 | Val Loss: 0.8463\n",
      "Epoch 098 | Train Loss: 0.8137 | Val Loss: 0.9348\n",
      "Epoch 099 | Train Loss: 0.8171 | Val Loss: 0.8409\n",
      "Epoch 100 | Train Loss: 0.7939 | Val Loss: 0.9591\n",
      "Epoch 101 | Train Loss: 0.8785 | Val Loss: 0.8834\n",
      "Epoch 102 | Train Loss: 0.8733 | Val Loss: 0.8751\n",
      "Epoch 103 | Train Loss: 0.8838 | Val Loss: 0.8637\n",
      "Epoch 104 | Train Loss: 0.8518 | Val Loss: 0.8396\n",
      "Epoch 105 | Train Loss: 0.8367 | Val Loss: 0.8773\n",
      "Epoch 106 | Train Loss: 0.9257 | Val Loss: 0.9558\n",
      "Epoch 107 | Train Loss: 0.9520 | Val Loss: 0.9178\n",
      "Epoch 108 | Train Loss: 0.9803 | Val Loss: 0.8331\n",
      "Epoch 109 | Train Loss: 0.8571 | Val Loss: 1.0132\n",
      "Epoch 110 | Train Loss: 0.8511 | Val Loss: 0.8408\n",
      "Epoch 111 | Train Loss: 0.8200 | Val Loss: 0.8460\n",
      "Epoch 112 | Train Loss: 0.7931 | Val Loss: 0.8273\n",
      "Epoch 113 | Train Loss: 0.8139 | Val Loss: 0.8527\n",
      "Epoch 114 | Train Loss: 0.8572 | Val Loss: 0.8419\n",
      "Epoch 115 | Train Loss: 0.8000 | Val Loss: 0.8191\n",
      "Epoch 116 | Train Loss: 0.8169 | Val Loss: 0.8145\n",
      "Epoch 117 | Train Loss: 0.8254 | Val Loss: 0.8228\n",
      "Epoch 118 | Train Loss: 0.8264 | Val Loss: 0.8347\n",
      "Epoch 119 | Train Loss: 0.8324 | Val Loss: 0.8587\n",
      "Epoch 120 | Train Loss: 0.8524 | Val Loss: 0.8356\n",
      "Epoch 121 | Train Loss: 0.9727 | Val Loss: 0.9409\n",
      "Epoch 122 | Train Loss: 0.8517 | Val Loss: 0.8370\n",
      "Epoch 123 | Train Loss: 0.7717 | Val Loss: 0.8816\n",
      "Epoch 124 | Train Loss: 0.8511 | Val Loss: 0.8133\n",
      "Epoch 125 | Train Loss: 0.8026 | Val Loss: 0.8208\n",
      "Epoch 126 | Train Loss: 0.8070 | Val Loss: 0.8155\n",
      "Epoch 127 | Train Loss: 0.8220 | Val Loss: 0.8103\n",
      "Epoch 128 | Train Loss: 0.8399 | Val Loss: 0.9389\n",
      "Epoch 129 | Train Loss: 0.8829 | Val Loss: 1.0160\n",
      "Epoch 130 | Train Loss: 0.9976 | Val Loss: 0.8183\n",
      "Epoch 131 | Train Loss: 0.8235 | Val Loss: 0.8140\n",
      "Epoch 132 | Train Loss: 0.8197 | Val Loss: 0.8884\n",
      "Epoch 133 | Train Loss: 0.8528 | Val Loss: 0.8113\n",
      "Epoch 134 | Train Loss: 0.8503 | Val Loss: 1.0170\n",
      "Epoch 135 | Train Loss: 0.7940 | Val Loss: 0.8100\n",
      "Epoch 136 | Train Loss: 0.7996 | Val Loss: 0.8930\n",
      "Epoch 137 | Train Loss: 0.8055 | Val Loss: 0.8895\n",
      "Epoch 138 | Train Loss: 0.8082 | Val Loss: 0.8631\n",
      "Epoch 139 | Train Loss: 0.7857 | Val Loss: 0.8197\n",
      "Epoch 140 | Train Loss: 0.7839 | Val Loss: 1.1649\n",
      "Epoch 141 | Train Loss: 0.8873 | Val Loss: 0.8097\n",
      "Epoch 142 | Train Loss: 0.7838 | Val Loss: 0.8156\n",
      "Epoch 143 | Train Loss: 0.8158 | Val Loss: 0.8183\n",
      "Epoch 144 | Train Loss: 0.8020 | Val Loss: 0.8104\n",
      "Epoch 145 | Train Loss: 0.8137 | Val Loss: 0.8121\n",
      "Epoch 146 | Train Loss: 0.7852 | Val Loss: 0.8979\n",
      "Epoch 147 | Train Loss: 0.8233 | Val Loss: 0.8170\n",
      "Epoch 148 | Train Loss: 0.7937 | Val Loss: 0.9896\n",
      "Epoch 149 | Train Loss: 0.8210 | Val Loss: 0.8448\n",
      "Epoch 150 | Train Loss: 0.8002 | Val Loss: 0.8666\n",
      "Epoch 151 | Train Loss: 0.8101 | Val Loss: 0.8124\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 152 | Train Loss: 0.8224 | Val Loss: 0.8319\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 153 | Train Loss: 0.8810 | Val Loss: 0.8529\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 154 | Train Loss: 0.8491 | Val Loss: 0.9510\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 155 | Train Loss: 0.8969 | Val Loss: 0.9255\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 156 | Train Loss: 0.8498 | Val Loss: 0.8204\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 157 | Train Loss: 0.8729 | Val Loss: 0.8560\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 158 | Train Loss: 0.7886 | Val Loss: 0.8073\n",
      "Epoch 159 | Train Loss: 0.7773 | Val Loss: 0.8106\n",
      "Epoch 160 | Train Loss: 0.7921 | Val Loss: 0.8456\n",
      "Epoch 161 | Train Loss: 0.7948 | Val Loss: 0.9147\n",
      "Epoch 162 | Train Loss: 0.8502 | Val Loss: 0.8047\n",
      "Epoch 163 | Train Loss: 0.7739 | Val Loss: 0.8086\n",
      "Epoch 164 | Train Loss: 0.7711 | Val Loss: 0.8551\n",
      "Epoch 165 | Train Loss: 0.8162 | Val Loss: 0.9161\n",
      "Epoch 166 | Train Loss: 0.8229 | Val Loss: 0.8064\n",
      "Epoch 167 | Train Loss: 0.8038 | Val Loss: 0.8204\n",
      "Epoch 168 | Train Loss: 0.7539 | Val Loss: 0.8046\n",
      "Epoch 169 | Train Loss: 0.7764 | Val Loss: 0.9037\n",
      "Epoch 170 | Train Loss: 0.8217 | Val Loss: 0.8076\n",
      "Epoch 171 | Train Loss: 0.7889 | Val Loss: 0.8119\n",
      "Epoch 172 | Train Loss: 0.7657 | Val Loss: 0.8036\n",
      "Epoch 173 | Train Loss: 0.7955 | Val Loss: 0.8960\n",
      "Epoch 174 | Train Loss: 0.8349 | Val Loss: 0.8446\n",
      "Epoch 175 | Train Loss: 0.7743 | Val Loss: 0.8508\n",
      "Epoch 176 | Train Loss: 0.8601 | Val Loss: 0.8955\n",
      "Epoch 177 | Train Loss: 0.8302 | Val Loss: 0.8876\n",
      "Epoch 178 | Train Loss: 0.8367 | Val Loss: 0.8097\n",
      "Epoch 179 | Train Loss: 0.8123 | Val Loss: 0.8924\n",
      "Epoch 180 | Train Loss: 0.8794 | Val Loss: 0.8841\n",
      "Epoch 181 | Train Loss: 0.8623 | Val Loss: 0.8086\n",
      "Epoch 182 | Train Loss: 0.8600 | Val Loss: 1.3736\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 1.0394 | Val Loss: 0.9944\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 184 | Train Loss: 0.9037 | Val Loss: 0.8804\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 185 | Train Loss: 0.8578 | Val Loss: 0.8142\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 186 | Train Loss: 0.7782 | Val Loss: 0.8138\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 187 | Train Loss: 0.7704 | Val Loss: 0.8185\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 188 | Train Loss: 0.8235 | Val Loss: 0.8121\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 189 | Train Loss: 0.7964 | Val Loss: 0.8669\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 190 | Train Loss: 0.7864 | Val Loss: 0.8028\n",
      "Epoch 191 | Train Loss: 0.7784 | Val Loss: 0.8047\n",
      "Epoch 192 | Train Loss: 0.7908 | Val Loss: 0.8379\n",
      "Epoch 193 | Train Loss: 0.7915 | Val Loss: 0.8056\n",
      "Epoch 194 | Train Loss: 0.8122 | Val Loss: 0.8003\n",
      "Epoch 195 | Train Loss: 0.8126 | Val Loss: 0.8244\n",
      "Epoch 196 | Train Loss: 0.7557 | Val Loss: 0.8155\n",
      "Epoch 197 | Train Loss: 0.8337 | Val Loss: 0.7983\n",
      "Epoch 198 | Train Loss: 0.7645 | Val Loss: 0.7992\n",
      "Epoch 199 | Train Loss: 0.7968 | Val Loss: 0.9186\n",
      "Epoch 200 | Train Loss: 0.8764 | Val Loss: 0.9170\n",
      "\n",
      "üîÅ Re-training Fold 3/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 16.6315 | Val Loss: 4.1584\n",
      "Epoch 002 | Train Loss: 2.5514 | Val Loss: 3.6052\n",
      "Epoch 003 | Train Loss: 1.3044 | Val Loss: 0.8386\n",
      "Epoch 004 | Train Loss: 1.0794 | Val Loss: 1.1740\n",
      "Epoch 005 | Train Loss: 1.0072 | Val Loss: 1.1346\n",
      "Epoch 006 | Train Loss: 0.9935 | Val Loss: 1.0530\n",
      "Epoch 007 | Train Loss: 0.9772 | Val Loss: 1.1219\n",
      "Epoch 008 | Train Loss: 0.9804 | Val Loss: 1.2465\n",
      "Epoch 009 | Train Loss: 0.9522 | Val Loss: 1.1264\n",
      "Epoch 010 | Train Loss: 0.9651 | Val Loss: 1.1565\n",
      "Epoch 011 | Train Loss: 0.9540 | Val Loss: 0.9974\n",
      "Epoch 012 | Train Loss: 0.9752 | Val Loss: 1.1156\n",
      "Epoch 013 | Train Loss: 0.9732 | Val Loss: 1.1492\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 014 | Train Loss: 0.9830 | Val Loss: 1.1482\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 015 | Train Loss: 1.0068 | Val Loss: 1.1497\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 016 | Train Loss: 0.9999 | Val Loss: 1.5963\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 017 | Train Loss: 0.9813 | Val Loss: 1.0581\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 018 | Train Loss: 0.9449 | Val Loss: 1.3151\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 019 | Train Loss: 0.9299 | Val Loss: 0.8775\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 020 | Train Loss: 0.9454 | Val Loss: 1.0690\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 021 | Train Loss: 0.9375 | Val Loss: 1.1340\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 022 | Train Loss: 0.9492 | Val Loss: 1.0987\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 023 | Train Loss: 0.9291 | Val Loss: 1.0199\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 024 | Train Loss: 0.9692 | Val Loss: 1.1015\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 025 | Train Loss: 0.9277 | Val Loss: 1.3706\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 026 | Train Loss: 0.9454 | Val Loss: 1.0141\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 027 | Train Loss: 0.9538 | Val Loss: 1.1828\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 028 | Train Loss: 0.9422 | Val Loss: 1.0893\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 029 | Train Loss: 0.9414 | Val Loss: 1.2834\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 030 | Train Loss: 0.9027 | Val Loss: 1.0210\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 031 | Train Loss: 0.9182 | Val Loss: 1.2633\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 032 | Train Loss: 0.9673 | Val Loss: 1.0734\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 033 | Train Loss: 0.9439 | Val Loss: 0.7684\n",
      "Epoch 034 | Train Loss: 0.9611 | Val Loss: 0.8512\n",
      "Epoch 035 | Train Loss: 0.9126 | Val Loss: 0.9953\n",
      "Epoch 036 | Train Loss: 0.8872 | Val Loss: 0.8747\n",
      "Epoch 037 | Train Loss: 0.9055 | Val Loss: 0.8998\n",
      "Epoch 038 | Train Loss: 0.9180 | Val Loss: 0.9863\n",
      "Epoch 039 | Train Loss: 0.9103 | Val Loss: 0.9610\n",
      "Epoch 040 | Train Loss: 0.8728 | Val Loss: 1.0860\n",
      "Epoch 041 | Train Loss: 0.8736 | Val Loss: 1.5121\n",
      "Epoch 042 | Train Loss: 0.9122 | Val Loss: 1.6362\n",
      "Epoch 043 | Train Loss: 0.9199 | Val Loss: 1.3200\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 044 | Train Loss: 0.9807 | Val Loss: 0.7476\n",
      "Epoch 045 | Train Loss: 1.0410 | Val Loss: 0.7706\n",
      "Epoch 046 | Train Loss: 0.8820 | Val Loss: 0.9060\n",
      "Epoch 047 | Train Loss: 0.9684 | Val Loss: 1.1702\n",
      "Epoch 048 | Train Loss: 0.9408 | Val Loss: 1.1474\n",
      "Epoch 049 | Train Loss: 0.9362 | Val Loss: 1.2810\n",
      "Epoch 050 | Train Loss: 0.9482 | Val Loss: 1.2301\n",
      "Epoch 051 | Train Loss: 0.8757 | Val Loss: 1.0966\n",
      "Epoch 052 | Train Loss: 0.9195 | Val Loss: 0.8644\n",
      "Epoch 053 | Train Loss: 0.8441 | Val Loss: 1.2849\n",
      "Epoch 054 | Train Loss: 0.9822 | Val Loss: 1.0117\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 055 | Train Loss: 0.9007 | Val Loss: 0.7261\n",
      "Epoch 056 | Train Loss: 0.9823 | Val Loss: 1.0340\n",
      "Epoch 057 | Train Loss: 1.0835 | Val Loss: 1.5273\n",
      "Epoch 058 | Train Loss: 0.8806 | Val Loss: 1.0382\n",
      "Epoch 059 | Train Loss: 0.8424 | Val Loss: 0.9049\n",
      "Epoch 060 | Train Loss: 0.8513 | Val Loss: 0.8091\n",
      "Epoch 061 | Train Loss: 0.8482 | Val Loss: 1.0110\n",
      "Epoch 062 | Train Loss: 0.8471 | Val Loss: 1.0890\n",
      "Epoch 063 | Train Loss: 0.9040 | Val Loss: 1.2939\n",
      "Epoch 064 | Train Loss: 0.8137 | Val Loss: 1.0150\n",
      "Epoch 065 | Train Loss: 0.8397 | Val Loss: 0.8783\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 066 | Train Loss: 0.8289 | Val Loss: 0.9067\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 067 | Train Loss: 0.8579 | Val Loss: 1.2628\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 068 | Train Loss: 0.8837 | Val Loss: 0.7364\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 069 | Train Loss: 0.8653 | Val Loss: 0.9303\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 070 | Train Loss: 0.8538 | Val Loss: 1.0793\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 071 | Train Loss: 0.9162 | Val Loss: 0.7933\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 072 | Train Loss: 0.8661 | Val Loss: 1.2062\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 073 | Train Loss: 0.8828 | Val Loss: 0.8214\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 074 | Train Loss: 0.8151 | Val Loss: 0.9502\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 075 | Train Loss: 0.8112 | Val Loss: 0.7998\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 076 | Train Loss: 0.8603 | Val Loss: 1.2319\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 077 | Train Loss: 0.8331 | Val Loss: 0.7701\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 078 | Train Loss: 0.8521 | Val Loss: 1.2044\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 079 | Train Loss: 0.8793 | Val Loss: 0.9798\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 080 | Train Loss: 0.8131 | Val Loss: 0.7908\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 081 | Train Loss: 0.8375 | Val Loss: 1.0663\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 082 | Train Loss: 0.8600 | Val Loss: 1.0859\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 083 | Train Loss: 0.8913 | Val Loss: 0.7462\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 084 | Train Loss: 0.9148 | Val Loss: 1.5527\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 085 | Train Loss: 0.9310 | Val Loss: 0.7389\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 086 | Train Loss: 0.8348 | Val Loss: 0.9781\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 087 | Train Loss: 0.8361 | Val Loss: 1.2368\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 088 | Train Loss: 0.8619 | Val Loss: 0.8083\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 089 | Train Loss: 0.7990 | Val Loss: 1.2612\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 090 | Train Loss: 0.8088 | Val Loss: 0.7413\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 091 | Train Loss: 0.8243 | Val Loss: 1.0438\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 092 | Train Loss: 0.7910 | Val Loss: 1.0744\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 093 | Train Loss: 0.7885 | Val Loss: 0.8484\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 094 | Train Loss: 0.8405 | Val Loss: 1.2624\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 095 | Train Loss: 0.8860 | Val Loss: 0.8697\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 096 | Train Loss: 0.8062 | Val Loss: 1.4982\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 097 | Train Loss: 0.9363 | Val Loss: 0.8401\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 098 | Train Loss: 0.8347 | Val Loss: 1.2436\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 099 | Train Loss: 0.8351 | Val Loss: 1.0649\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 100 | Train Loss: 0.7909 | Val Loss: 1.1104\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 101 | Train Loss: 0.8621 | Val Loss: 0.7517\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 102 | Train Loss: 0.8476 | Val Loss: 0.9005\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 103 | Train Loss: 0.8290 | Val Loss: 0.7587\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 104 | Train Loss: 0.8983 | Val Loss: 0.7349\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 105 | Train Loss: 0.8093 | Val Loss: 1.2481\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 106 | Train Loss: 0.8365 | Val Loss: 0.8472\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 107 | Train Loss: 0.7940 | Val Loss: 1.2048\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 108 | Train Loss: 0.8310 | Val Loss: 0.8200\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 109 | Train Loss: 0.8498 | Val Loss: 0.9996\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 110 | Train Loss: 0.9372 | Val Loss: 0.8851\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 111 | Train Loss: 0.8258 | Val Loss: 0.8877\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 112 | Train Loss: 0.7844 | Val Loss: 0.9855\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 113 | Train Loss: 0.7741 | Val Loss: 0.8413\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 114 | Train Loss: 0.7736 | Val Loss: 1.0796\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 115 | Train Loss: 0.8311 | Val Loss: 0.7958\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 116 | Train Loss: 0.8064 | Val Loss: 0.8301\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 117 | Train Loss: 0.8489 | Val Loss: 1.1202\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 118 | Train Loss: 0.7919 | Val Loss: 0.7899\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 119 | Train Loss: 0.7952 | Val Loss: 0.9462\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 120 | Train Loss: 0.7946 | Val Loss: 1.0046\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 121 | Train Loss: 0.8821 | Val Loss: 1.1122\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 122 | Train Loss: 0.9469 | Val Loss: 0.7572\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 123 | Train Loss: 0.8448 | Val Loss: 1.4199\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 124 | Train Loss: 0.8342 | Val Loss: 0.9373\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 125 | Train Loss: 0.7899 | Val Loss: 0.8944\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 126 | Train Loss: 0.7885 | Val Loss: 0.8959\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 127 | Train Loss: 0.7984 | Val Loss: 0.8189\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 128 | Train Loss: 0.8552 | Val Loss: 1.1658\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 129 | Train Loss: 0.7822 | Val Loss: 0.9302\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 130 | Train Loss: 0.8259 | Val Loss: 0.8500\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 131 | Train Loss: 0.8172 | Val Loss: 0.8491\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 132 | Train Loss: 0.8145 | Val Loss: 1.0566\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 133 | Train Loss: 0.9411 | Val Loss: 1.1119\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 134 | Train Loss: 0.8150 | Val Loss: 0.9453\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 135 | Train Loss: 0.8020 | Val Loss: 1.1994\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 136 | Train Loss: 0.8529 | Val Loss: 0.8066\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 137 | Train Loss: 0.7919 | Val Loss: 1.0277\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 138 | Train Loss: 0.7935 | Val Loss: 1.2696\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 139 | Train Loss: 0.7852 | Val Loss: 0.9553\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 140 | Train Loss: 0.7843 | Val Loss: 0.8685\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 141 | Train Loss: 0.7555 | Val Loss: 0.9766\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 142 | Train Loss: 0.7852 | Val Loss: 0.8285\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 143 | Train Loss: 0.7905 | Val Loss: 0.9330\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 144 | Train Loss: 0.7567 | Val Loss: 0.8396\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 145 | Train Loss: 0.7806 | Val Loss: 1.0463\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 146 | Train Loss: 0.7972 | Val Loss: 1.0780\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 147 | Train Loss: 0.7462 | Val Loss: 0.8984\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 148 | Train Loss: 0.7718 | Val Loss: 0.7586\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 149 | Train Loss: 0.8715 | Val Loss: 1.1947\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 150 | Train Loss: 0.8276 | Val Loss: 0.8537\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 151 | Train Loss: 0.7916 | Val Loss: 0.9315\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 152 | Train Loss: 0.7589 | Val Loss: 0.8079\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 153 | Train Loss: 0.7792 | Val Loss: 0.9553\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 154 | Train Loss: 0.7636 | Val Loss: 0.8330\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 155 | Train Loss: 0.7708 | Val Loss: 0.7484\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 156 | Train Loss: 0.8271 | Val Loss: 1.1722\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 157 | Train Loss: 0.8540 | Val Loss: 0.7523\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 158 | Train Loss: 0.7948 | Val Loss: 1.1376\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 159 | Train Loss: 0.7702 | Val Loss: 0.7672\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 160 | Train Loss: 0.7593 | Val Loss: 1.1781\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 161 | Train Loss: 0.7725 | Val Loss: 0.8298\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 162 | Train Loss: 0.7863 | Val Loss: 0.7962\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 163 | Train Loss: 0.7569 | Val Loss: 1.0043\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 164 | Train Loss: 0.8148 | Val Loss: 0.8770\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 165 | Train Loss: 0.8167 | Val Loss: 0.7984\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 166 | Train Loss: 0.8022 | Val Loss: 0.9382\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 167 | Train Loss: 0.8256 | Val Loss: 0.9363\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 168 | Train Loss: 0.8405 | Val Loss: 0.9609\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 169 | Train Loss: 0.7509 | Val Loss: 0.8443\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 170 | Train Loss: 0.7491 | Val Loss: 1.1090\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 171 | Train Loss: 0.8259 | Val Loss: 0.7801\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 172 | Train Loss: 0.7669 | Val Loss: 1.0047\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 173 | Train Loss: 0.7709 | Val Loss: 0.9729\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 174 | Train Loss: 0.7633 | Val Loss: 1.0320\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 175 | Train Loss: 0.7595 | Val Loss: 0.9425\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 176 | Train Loss: 0.7457 | Val Loss: 0.7623\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 177 | Train Loss: 0.8157 | Val Loss: 0.9377\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 178 | Train Loss: 0.7479 | Val Loss: 1.3679\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 179 | Train Loss: 0.7682 | Val Loss: 0.8617\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 180 | Train Loss: 0.7664 | Val Loss: 1.0720\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 181 | Train Loss: 0.7442 | Val Loss: 0.9139\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 182 | Train Loss: 0.8035 | Val Loss: 0.7597\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 0.7728 | Val Loss: 1.1244\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 184 | Train Loss: 0.7978 | Val Loss: 1.0230\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 185 | Train Loss: 0.8478 | Val Loss: 0.7828\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 186 | Train Loss: 0.7488 | Val Loss: 1.0708\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 187 | Train Loss: 0.7346 | Val Loss: 0.7521\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 188 | Train Loss: 0.8377 | Val Loss: 0.9855\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 189 | Train Loss: 0.8362 | Val Loss: 0.8879\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 190 | Train Loss: 0.7855 | Val Loss: 1.3170\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 191 | Train Loss: 0.7500 | Val Loss: 0.8337\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 192 | Train Loss: 0.7496 | Val Loss: 0.7655\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 193 | Train Loss: 0.7542 | Val Loss: 1.2344\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 194 | Train Loss: 0.7256 | Val Loss: 0.7678\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 195 | Train Loss: 0.7376 | Val Loss: 0.7985\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 196 | Train Loss: 0.8131 | Val Loss: 0.9418\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 197 | Train Loss: 0.7559 | Val Loss: 0.9112\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 198 | Train Loss: 0.8119 | Val Loss: 0.7547\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 199 | Train Loss: 0.7853 | Val Loss: 1.0693\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 200 | Train Loss: 0.7542 | Val Loss: 0.8302\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîÅ Re-training Fold 4/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 14.3291 | Val Loss: 4.0186\n",
      "Epoch 002 | Train Loss: 2.2126 | Val Loss: 1.2793\n",
      "Epoch 003 | Train Loss: 1.2072 | Val Loss: 0.8529\n",
      "Epoch 004 | Train Loss: 1.1064 | Val Loss: 0.8649\n",
      "Epoch 005 | Train Loss: 1.0178 | Val Loss: 0.8317\n",
      "Epoch 006 | Train Loss: 1.0108 | Val Loss: 0.8438\n",
      "Epoch 007 | Train Loss: 1.0497 | Val Loss: 0.8125\n",
      "Epoch 008 | Train Loss: 1.0105 | Val Loss: 0.8948\n",
      "Epoch 009 | Train Loss: 1.0574 | Val Loss: 0.8200\n",
      "Epoch 010 | Train Loss: 1.0062 | Val Loss: 0.8361\n",
      "Epoch 011 | Train Loss: 0.9686 | Val Loss: 0.7990\n",
      "Epoch 012 | Train Loss: 0.9912 | Val Loss: 0.8309\n",
      "Epoch 013 | Train Loss: 0.9576 | Val Loss: 0.8444\n",
      "Epoch 014 | Train Loss: 0.9747 | Val Loss: 0.7918\n",
      "Epoch 015 | Train Loss: 0.9780 | Val Loss: 0.7935\n",
      "Epoch 016 | Train Loss: 0.9559 | Val Loss: 0.7829\n",
      "Epoch 017 | Train Loss: 0.9802 | Val Loss: 0.7793\n",
      "Epoch 018 | Train Loss: 0.9892 | Val Loss: 0.7979\n",
      "Epoch 019 | Train Loss: 0.9446 | Val Loss: 0.7855\n",
      "Epoch 020 | Train Loss: 0.9661 | Val Loss: 0.7857\n",
      "Epoch 021 | Train Loss: 0.9655 | Val Loss: 0.7699\n",
      "Epoch 022 | Train Loss: 0.9967 | Val Loss: 0.7796\n",
      "Epoch 023 | Train Loss: 1.1071 | Val Loss: 0.7675\n",
      "Epoch 024 | Train Loss: 1.0165 | Val Loss: 0.7671\n",
      "Epoch 025 | Train Loss: 0.9736 | Val Loss: 0.7600\n",
      "Epoch 026 | Train Loss: 1.0151 | Val Loss: 0.7695\n",
      "Epoch 027 | Train Loss: 0.9528 | Val Loss: 0.7836\n",
      "Epoch 028 | Train Loss: 0.9418 | Val Loss: 0.7578\n",
      "Epoch 029 | Train Loss: 0.9514 | Val Loss: 0.7849\n",
      "Epoch 030 | Train Loss: 0.9906 | Val Loss: 0.8549\n",
      "Epoch 031 | Train Loss: 0.9614 | Val Loss: 0.7578\n",
      "Epoch 032 | Train Loss: 0.9680 | Val Loss: 0.7593\n",
      "Epoch 033 | Train Loss: 0.9740 | Val Loss: 0.8727\n",
      "Epoch 034 | Train Loss: 1.0566 | Val Loss: 0.8455\n",
      "Epoch 035 | Train Loss: 1.0460 | Val Loss: 1.2100\n",
      "Epoch 036 | Train Loss: 1.0849 | Val Loss: 0.8704\n",
      "Epoch 037 | Train Loss: 0.9772 | Val Loss: 1.0872\n",
      "Epoch 038 | Train Loss: 1.0150 | Val Loss: 1.0716\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 039 | Train Loss: 1.0164 | Val Loss: 0.8098\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 040 | Train Loss: 0.9904 | Val Loss: 0.8316\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 041 | Train Loss: 0.9449 | Val Loss: 0.7655\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 042 | Train Loss: 0.9544 | Val Loss: 0.7429\n",
      "Epoch 043 | Train Loss: 0.9540 | Val Loss: 0.7534\n",
      "Epoch 044 | Train Loss: 0.9333 | Val Loss: 0.7470\n",
      "Epoch 045 | Train Loss: 0.9398 | Val Loss: 0.7721\n",
      "Epoch 046 | Train Loss: 0.9933 | Val Loss: 0.7423\n",
      "Epoch 047 | Train Loss: 0.9114 | Val Loss: 0.7457\n",
      "Epoch 048 | Train Loss: 0.9269 | Val Loss: 0.7487\n",
      "Epoch 049 | Train Loss: 0.9252 | Val Loss: 0.7936\n",
      "Epoch 050 | Train Loss: 0.9235 | Val Loss: 0.8420\n",
      "Epoch 051 | Train Loss: 0.9105 | Val Loss: 0.7629\n",
      "Epoch 052 | Train Loss: 0.8972 | Val Loss: 0.7328\n",
      "Epoch 053 | Train Loss: 0.8984 | Val Loss: 0.7578\n",
      "Epoch 054 | Train Loss: 0.9110 | Val Loss: 0.8424\n",
      "Epoch 055 | Train Loss: 0.9202 | Val Loss: 0.7458\n",
      "Epoch 056 | Train Loss: 0.8728 | Val Loss: 0.7250\n",
      "Epoch 057 | Train Loss: 0.9020 | Val Loss: 0.7662\n",
      "Epoch 058 | Train Loss: 1.0217 | Val Loss: 0.7458\n",
      "Epoch 059 | Train Loss: 0.9128 | Val Loss: 0.7219\n",
      "Epoch 060 | Train Loss: 0.9180 | Val Loss: 0.7534\n",
      "Epoch 061 | Train Loss: 0.9712 | Val Loss: 0.7390\n",
      "Epoch 062 | Train Loss: 0.9301 | Val Loss: 0.7223\n",
      "Epoch 063 | Train Loss: 0.8875 | Val Loss: 0.7250\n",
      "Epoch 064 | Train Loss: 0.8959 | Val Loss: 0.7173\n",
      "Epoch 065 | Train Loss: 0.8854 | Val Loss: 0.7883\n",
      "Epoch 066 | Train Loss: 0.9438 | Val Loss: 0.7062\n",
      "Epoch 067 | Train Loss: 0.8933 | Val Loss: 0.7704\n",
      "Epoch 068 | Train Loss: 0.9159 | Val Loss: 0.7474\n",
      "Epoch 069 | Train Loss: 0.8903 | Val Loss: 0.7066\n",
      "Epoch 070 | Train Loss: 0.8801 | Val Loss: 0.7952\n",
      "Epoch 071 | Train Loss: 0.9309 | Val Loss: 0.7182\n",
      "Epoch 072 | Train Loss: 1.0304 | Val Loss: 0.7080\n",
      "Epoch 073 | Train Loss: 0.8533 | Val Loss: 0.7582\n",
      "Epoch 074 | Train Loss: 0.9494 | Val Loss: 0.7406\n",
      "Epoch 075 | Train Loss: 0.9444 | Val Loss: 0.8071\n",
      "Epoch 076 | Train Loss: 0.9620 | Val Loss: 0.6993\n",
      "Epoch 077 | Train Loss: 0.8993 | Val Loss: 0.7263\n",
      "Epoch 078 | Train Loss: 0.8952 | Val Loss: 0.6982\n",
      "Epoch 079 | Train Loss: 0.8823 | Val Loss: 0.6906\n",
      "Epoch 080 | Train Loss: 0.8819 | Val Loss: 0.6883\n",
      "Epoch 081 | Train Loss: 0.8419 | Val Loss: 0.7596\n",
      "Epoch 082 | Train Loss: 0.8674 | Val Loss: 0.6872\n",
      "Epoch 083 | Train Loss: 0.8595 | Val Loss: 0.6940\n",
      "Epoch 084 | Train Loss: 0.8638 | Val Loss: 0.7717\n",
      "Epoch 085 | Train Loss: 0.8893 | Val Loss: 0.6756\n",
      "Epoch 086 | Train Loss: 0.8935 | Val Loss: 0.7285\n",
      "Epoch 087 | Train Loss: 0.8802 | Val Loss: 0.7051\n",
      "Epoch 088 | Train Loss: 0.8761 | Val Loss: 0.7058\n",
      "Epoch 089 | Train Loss: 0.8625 | Val Loss: 0.7281\n",
      "Epoch 090 | Train Loss: 0.8738 | Val Loss: 0.6992\n",
      "Epoch 091 | Train Loss: 0.8514 | Val Loss: 0.6842\n",
      "Epoch 092 | Train Loss: 0.8537 | Val Loss: 0.6811\n",
      "Epoch 093 | Train Loss: 0.8929 | Val Loss: 0.7190\n",
      "Epoch 094 | Train Loss: 0.8667 | Val Loss: 0.6821\n",
      "Epoch 095 | Train Loss: 0.8284 | Val Loss: 0.6989\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 096 | Train Loss: 0.9057 | Val Loss: 1.0079\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 097 | Train Loss: 0.9111 | Val Loss: 0.7058\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 098 | Train Loss: 0.8490 | Val Loss: 0.8115\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 099 | Train Loss: 0.8699 | Val Loss: 0.6834\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 100 | Train Loss: 0.8605 | Val Loss: 0.9119\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 101 | Train Loss: 0.9205 | Val Loss: 0.7921\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 102 | Train Loss: 0.8817 | Val Loss: 0.7285\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 103 | Train Loss: 0.9508 | Val Loss: 0.6683\n",
      "Epoch 104 | Train Loss: 0.9122 | Val Loss: 0.6941\n",
      "Epoch 105 | Train Loss: 0.9737 | Val Loss: 0.7302\n",
      "Epoch 106 | Train Loss: 0.8863 | Val Loss: 0.7548\n",
      "Epoch 107 | Train Loss: 0.9075 | Val Loss: 0.6941\n",
      "Epoch 108 | Train Loss: 0.9138 | Val Loss: 0.7027\n",
      "Epoch 109 | Train Loss: 0.8388 | Val Loss: 0.6623\n",
      "Epoch 110 | Train Loss: 0.8617 | Val Loss: 0.7092\n",
      "Epoch 111 | Train Loss: 0.8538 | Val Loss: 0.6844\n",
      "Epoch 112 | Train Loss: 0.8259 | Val Loss: 0.6713\n",
      "Epoch 113 | Train Loss: 0.8463 | Val Loss: 0.7212\n",
      "Epoch 114 | Train Loss: 0.8377 | Val Loss: 0.7272\n",
      "Epoch 115 | Train Loss: 0.8390 | Val Loss: 0.6671\n",
      "Epoch 116 | Train Loss: 0.8515 | Val Loss: 0.9310\n",
      "Epoch 117 | Train Loss: 0.9565 | Val Loss: 0.6995\n",
      "Epoch 118 | Train Loss: 0.8098 | Val Loss: 0.7240\n",
      "Epoch 119 | Train Loss: 0.8566 | Val Loss: 0.6624\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 120 | Train Loss: 0.8523 | Val Loss: 0.7606\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 121 | Train Loss: 0.8752 | Val Loss: 0.8657\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 122 | Train Loss: 0.8314 | Val Loss: 0.6700\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 123 | Train Loss: 0.8503 | Val Loss: 0.7640\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 124 | Train Loss: 0.8588 | Val Loss: 0.7616\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 125 | Train Loss: 0.8717 | Val Loss: 0.7341\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 126 | Train Loss: 0.8348 | Val Loss: 0.6574\n",
      "Epoch 127 | Train Loss: 0.8466 | Val Loss: 0.6739\n",
      "Epoch 128 | Train Loss: 0.8566 | Val Loss: 0.6656\n",
      "Epoch 129 | Train Loss: 0.8991 | Val Loss: 0.8153\n",
      "Epoch 130 | Train Loss: 0.8474 | Val Loss: 0.6917\n",
      "Epoch 131 | Train Loss: 0.8923 | Val Loss: 0.6727\n",
      "Epoch 132 | Train Loss: 0.8554 | Val Loss: 0.7222\n",
      "Epoch 133 | Train Loss: 0.8725 | Val Loss: 0.7576\n",
      "Epoch 134 | Train Loss: 0.8890 | Val Loss: 0.6646\n",
      "Epoch 135 | Train Loss: 0.8994 | Val Loss: 0.8807\n",
      "Epoch 136 | Train Loss: 0.9554 | Val Loss: 0.8795\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 137 | Train Loss: 0.9017 | Val Loss: 0.6717\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 138 | Train Loss: 0.8345 | Val Loss: 0.7855\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 139 | Train Loss: 0.9064 | Val Loss: 0.7209\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 140 | Train Loss: 0.8470 | Val Loss: 0.6724\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 141 | Train Loss: 0.8883 | Val Loss: 0.6637\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 142 | Train Loss: 0.8271 | Val Loss: 0.7149\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 143 | Train Loss: 0.8663 | Val Loss: 0.7326\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 144 | Train Loss: 0.9207 | Val Loss: 0.6634\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 145 | Train Loss: 0.8541 | Val Loss: 0.6940\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 146 | Train Loss: 0.8372 | Val Loss: 0.6653\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 147 | Train Loss: 0.9041 | Val Loss: 0.6596\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 148 | Train Loss: 0.8198 | Val Loss: 0.8197\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 149 | Train Loss: 0.9272 | Val Loss: 0.6639\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 150 | Train Loss: 0.9804 | Val Loss: 0.6703\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 151 | Train Loss: 0.8439 | Val Loss: 0.7366\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 152 | Train Loss: 0.8877 | Val Loss: 0.6531\n",
      "Epoch 153 | Train Loss: 0.8518 | Val Loss: 0.6518\n",
      "Epoch 154 | Train Loss: 0.8375 | Val Loss: 0.6507\n",
      "Epoch 155 | Train Loss: 0.8156 | Val Loss: 0.6644\n",
      "Epoch 156 | Train Loss: 0.8457 | Val Loss: 0.6452\n",
      "Epoch 157 | Train Loss: 0.8635 | Val Loss: 0.6777\n",
      "Epoch 158 | Train Loss: 0.8270 | Val Loss: 0.7638\n",
      "Epoch 159 | Train Loss: 0.8965 | Val Loss: 0.6698\n",
      "Epoch 160 | Train Loss: 0.8807 | Val Loss: 0.6885\n",
      "Epoch 161 | Train Loss: 0.8456 | Val Loss: 0.6822\n",
      "Epoch 162 | Train Loss: 0.8136 | Val Loss: 0.6776\n",
      "Epoch 163 | Train Loss: 0.9232 | Val Loss: 0.6423\n",
      "Epoch 164 | Train Loss: 0.8139 | Val Loss: 0.6544\n",
      "Epoch 165 | Train Loss: 0.8442 | Val Loss: 0.7378\n",
      "Epoch 166 | Train Loss: 0.9476 | Val Loss: 0.6766\n",
      "Epoch 167 | Train Loss: 1.0010 | Val Loss: 0.8642\n",
      "Epoch 168 | Train Loss: 0.8691 | Val Loss: 0.6706\n",
      "Epoch 169 | Train Loss: 0.8013 | Val Loss: 0.6847\n",
      "Epoch 170 | Train Loss: 0.8640 | Val Loss: 0.7009\n",
      "Epoch 171 | Train Loss: 0.7929 | Val Loss: 0.6546\n",
      "Epoch 172 | Train Loss: 0.8451 | Val Loss: 0.6529\n",
      "Epoch 173 | Train Loss: 0.8354 | Val Loss: 0.7496\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 174 | Train Loss: 0.8361 | Val Loss: 0.7002\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 175 | Train Loss: 0.8432 | Val Loss: 0.9091\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 176 | Train Loss: 0.8457 | Val Loss: 0.7120\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 177 | Train Loss: 0.8509 | Val Loss: 0.7275\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 178 | Train Loss: 0.8449 | Val Loss: 0.7258\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 179 | Train Loss: 0.8016 | Val Loss: 0.6640\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 180 | Train Loss: 0.8958 | Val Loss: 0.6613\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 181 | Train Loss: 0.8232 | Val Loss: 0.6437\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 182 | Train Loss: 0.8072 | Val Loss: 0.6937\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 0.8941 | Val Loss: 0.7089\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 184 | Train Loss: 0.8274 | Val Loss: 0.6381\n",
      "Epoch 185 | Train Loss: 0.8282 | Val Loss: 0.7386\n",
      "Epoch 186 | Train Loss: 0.8561 | Val Loss: 0.6930\n",
      "Epoch 187 | Train Loss: 0.8394 | Val Loss: 0.6766\n",
      "Epoch 188 | Train Loss: 0.8473 | Val Loss: 0.6775\n",
      "Epoch 189 | Train Loss: 0.8418 | Val Loss: 0.6495\n",
      "Epoch 190 | Train Loss: 0.8062 | Val Loss: 0.6648\n",
      "Epoch 191 | Train Loss: 0.8531 | Val Loss: 0.6684\n",
      "Epoch 192 | Train Loss: 0.8215 | Val Loss: 0.6480\n",
      "Epoch 193 | Train Loss: 0.8209 | Val Loss: 0.6427\n",
      "Epoch 194 | Train Loss: 0.7765 | Val Loss: 0.6639\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 195 | Train Loss: 0.8263 | Val Loss: 0.6542\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 196 | Train Loss: 0.7890 | Val Loss: 0.7123\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 197 | Train Loss: 0.8627 | Val Loss: 0.7351\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 198 | Train Loss: 0.8325 | Val Loss: 0.6801\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 199 | Train Loss: 0.8438 | Val Loss: 0.8466\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 200 | Train Loss: 0.8781 | Val Loss: 0.6437\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîÅ Re-training Fold 5/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 16.9292 | Val Loss: 7.0064\n",
      "Epoch 002 | Train Loss: 2.6704 | Val Loss: 1.8977\n",
      "Epoch 003 | Train Loss: 1.4534 | Val Loss: 1.1487\n",
      "Epoch 004 | Train Loss: 1.0431 | Val Loss: 1.0524\n",
      "Epoch 005 | Train Loss: 1.0646 | Val Loss: 1.0280\n",
      "Epoch 006 | Train Loss: 0.9685 | Val Loss: 1.1405\n",
      "Epoch 007 | Train Loss: 1.0123 | Val Loss: 0.9998\n",
      "Epoch 008 | Train Loss: 0.9999 | Val Loss: 0.9893\n",
      "Epoch 009 | Train Loss: 0.9750 | Val Loss: 1.1218\n",
      "Epoch 010 | Train Loss: 0.9789 | Val Loss: 1.0161\n",
      "Epoch 011 | Train Loss: 0.9809 | Val Loss: 0.9679\n",
      "Epoch 012 | Train Loss: 0.9761 | Val Loss: 0.9845\n",
      "Epoch 013 | Train Loss: 0.9998 | Val Loss: 0.9776\n",
      "Epoch 014 | Train Loss: 0.9588 | Val Loss: 1.0419\n",
      "Epoch 015 | Train Loss: 0.9582 | Val Loss: 1.0622\n",
      "Epoch 016 | Train Loss: 0.9651 | Val Loss: 0.9429\n",
      "Epoch 017 | Train Loss: 0.9850 | Val Loss: 0.9345\n",
      "Epoch 018 | Train Loss: 0.9850 | Val Loss: 0.9567\n",
      "Epoch 019 | Train Loss: 0.9602 | Val Loss: 0.9317\n",
      "Epoch 020 | Train Loss: 0.9886 | Val Loss: 1.0233\n",
      "Epoch 021 | Train Loss: 0.9556 | Val Loss: 0.9447\n",
      "Epoch 022 | Train Loss: 0.9737 | Val Loss: 0.9681\n",
      "Epoch 023 | Train Loss: 0.9304 | Val Loss: 0.9148\n",
      "Epoch 024 | Train Loss: 0.9286 | Val Loss: 0.9434\n",
      "Epoch 025 | Train Loss: 0.9480 | Val Loss: 1.0267\n",
      "Epoch 026 | Train Loss: 1.0068 | Val Loss: 0.9443\n",
      "Epoch 027 | Train Loss: 1.0419 | Val Loss: 0.9867\n",
      "Epoch 028 | Train Loss: 0.9451 | Val Loss: 0.9413\n",
      "Epoch 029 | Train Loss: 1.0024 | Val Loss: 0.8874\n",
      "Epoch 030 | Train Loss: 0.9679 | Val Loss: 0.9074\n",
      "Epoch 031 | Train Loss: 0.9016 | Val Loss: 0.9926\n",
      "Epoch 032 | Train Loss: 0.9612 | Val Loss: 0.8995\n",
      "Epoch 033 | Train Loss: 0.9356 | Val Loss: 0.8716\n",
      "Epoch 034 | Train Loss: 1.0130 | Val Loss: 0.8701\n",
      "Epoch 035 | Train Loss: 0.9258 | Val Loss: 0.8784\n",
      "Epoch 036 | Train Loss: 0.9689 | Val Loss: 0.9520\n",
      "Epoch 037 | Train Loss: 0.9862 | Val Loss: 0.8726\n",
      "Epoch 038 | Train Loss: 0.9221 | Val Loss: 0.8793\n",
      "Epoch 039 | Train Loss: 0.9922 | Val Loss: 0.9469\n",
      "Epoch 040 | Train Loss: 0.9698 | Val Loss: 0.8630\n",
      "Epoch 041 | Train Loss: 0.9092 | Val Loss: 0.8774\n",
      "Epoch 042 | Train Loss: 0.9382 | Val Loss: 0.8602\n",
      "Epoch 043 | Train Loss: 0.9094 | Val Loss: 0.8430\n",
      "Epoch 044 | Train Loss: 0.9567 | Val Loss: 0.8698\n",
      "Epoch 045 | Train Loss: 0.9344 | Val Loss: 0.8948\n",
      "Epoch 046 | Train Loss: 0.9484 | Val Loss: 1.0266\n",
      "Epoch 047 | Train Loss: 0.9869 | Val Loss: 0.8437\n",
      "Epoch 048 | Train Loss: 0.9749 | Val Loss: 0.8953\n",
      "Epoch 049 | Train Loss: 1.0373 | Val Loss: 0.9339\n",
      "Epoch 050 | Train Loss: 0.9062 | Val Loss: 0.8669\n",
      "Epoch 051 | Train Loss: 1.0157 | Val Loss: 0.9514\n",
      "Epoch 052 | Train Loss: 0.9226 | Val Loss: 0.8624\n",
      "Epoch 053 | Train Loss: 0.9088 | Val Loss: 0.8327\n",
      "Epoch 054 | Train Loss: 0.8823 | Val Loss: 0.8128\n",
      "Epoch 055 | Train Loss: 0.9227 | Val Loss: 0.8788\n",
      "Epoch 056 | Train Loss: 0.9121 | Val Loss: 0.9770\n",
      "Epoch 057 | Train Loss: 0.9920 | Val Loss: 0.8755\n",
      "Epoch 058 | Train Loss: 0.9025 | Val Loss: 0.8968\n",
      "Epoch 059 | Train Loss: 0.9353 | Val Loss: 0.8418\n",
      "Epoch 060 | Train Loss: 0.9129 | Val Loss: 0.9405\n",
      "Epoch 061 | Train Loss: 0.9561 | Val Loss: 0.7915\n",
      "Epoch 062 | Train Loss: 0.9291 | Val Loss: 0.9641\n",
      "Epoch 063 | Train Loss: 0.9204 | Val Loss: 0.7900\n",
      "Epoch 064 | Train Loss: 0.9297 | Val Loss: 0.7924\n",
      "Epoch 065 | Train Loss: 0.8730 | Val Loss: 0.8177\n",
      "Epoch 066 | Train Loss: 0.9335 | Val Loss: 0.7827\n",
      "Epoch 067 | Train Loss: 0.9510 | Val Loss: 0.8040\n",
      "Epoch 068 | Train Loss: 0.8951 | Val Loss: 0.8544\n",
      "Epoch 069 | Train Loss: 0.9927 | Val Loss: 0.8209\n",
      "Epoch 070 | Train Loss: 0.9165 | Val Loss: 0.7732\n",
      "Epoch 071 | Train Loss: 0.9427 | Val Loss: 0.8047\n",
      "Epoch 072 | Train Loss: 0.8630 | Val Loss: 0.7680\n",
      "Epoch 073 | Train Loss: 0.8589 | Val Loss: 1.3043\n",
      "Epoch 074 | Train Loss: 1.0213 | Val Loss: 0.8022\n",
      "Epoch 075 | Train Loss: 0.9514 | Val Loss: 0.7778\n",
      "Epoch 076 | Train Loss: 0.8953 | Val Loss: 0.9964\n",
      "Epoch 077 | Train Loss: 1.0072 | Val Loss: 0.8940\n",
      "Epoch 078 | Train Loss: 0.8827 | Val Loss: 0.7671\n",
      "Epoch 079 | Train Loss: 0.9021 | Val Loss: 0.7821\n",
      "Epoch 080 | Train Loss: 0.8904 | Val Loss: 0.8491\n",
      "Epoch 081 | Train Loss: 0.8660 | Val Loss: 0.7731\n",
      "Epoch 082 | Train Loss: 0.8754 | Val Loss: 0.9569\n",
      "Epoch 083 | Train Loss: 1.0289 | Val Loss: 0.9276\n",
      "Epoch 084 | Train Loss: 0.9628 | Val Loss: 0.7944\n",
      "Epoch 085 | Train Loss: 0.8703 | Val Loss: 0.8313\n",
      "Epoch 086 | Train Loss: 0.9123 | Val Loss: 0.7496\n",
      "Epoch 087 | Train Loss: 0.8665 | Val Loss: 0.7492\n",
      "Epoch 088 | Train Loss: 0.9819 | Val Loss: 0.7867\n",
      "Epoch 089 | Train Loss: 0.8776 | Val Loss: 0.7466\n",
      "Epoch 090 | Train Loss: 0.8403 | Val Loss: 0.7450\n",
      "Epoch 091 | Train Loss: 0.8763 | Val Loss: 0.7426\n",
      "Epoch 092 | Train Loss: 0.8711 | Val Loss: 0.7487\n",
      "Epoch 093 | Train Loss: 0.9345 | Val Loss: 0.7444\n",
      "Epoch 094 | Train Loss: 0.8971 | Val Loss: 0.7481\n",
      "Epoch 095 | Train Loss: 0.8633 | Val Loss: 0.8274\n",
      "Epoch 096 | Train Loss: 0.8840 | Val Loss: 0.7300\n",
      "Epoch 097 | Train Loss: 0.8791 | Val Loss: 0.7260\n",
      "Epoch 098 | Train Loss: 0.9594 | Val Loss: 0.8066\n",
      "Epoch 099 | Train Loss: 0.8506 | Val Loss: 0.7169\n",
      "Epoch 100 | Train Loss: 0.8302 | Val Loss: 0.7067\n",
      "Epoch 101 | Train Loss: 0.8303 | Val Loss: 0.7170\n",
      "Epoch 102 | Train Loss: 0.8382 | Val Loss: 0.7090\n",
      "Epoch 103 | Train Loss: 0.8676 | Val Loss: 0.7778\n",
      "Epoch 104 | Train Loss: 0.8690 | Val Loss: 0.6951\n",
      "Epoch 105 | Train Loss: 0.8375 | Val Loss: 0.7079\n",
      "Epoch 106 | Train Loss: 0.8703 | Val Loss: 0.6891\n",
      "Epoch 107 | Train Loss: 0.8149 | Val Loss: 0.6876\n",
      "Epoch 108 | Train Loss: 0.8358 | Val Loss: 0.6874\n",
      "Epoch 109 | Train Loss: 0.8640 | Val Loss: 0.6973\n",
      "Epoch 110 | Train Loss: 0.9249 | Val Loss: 0.6996\n",
      "Epoch 111 | Train Loss: 0.8726 | Val Loss: 0.6846\n",
      "Epoch 112 | Train Loss: 0.8187 | Val Loss: 0.6815\n",
      "Epoch 113 | Train Loss: 0.8085 | Val Loss: 0.6836\n",
      "Epoch 114 | Train Loss: 0.8713 | Val Loss: 0.6917\n",
      "Epoch 115 | Train Loss: 0.8310 | Val Loss: 0.6776\n",
      "Epoch 116 | Train Loss: 0.8884 | Val Loss: 0.7226\n",
      "Epoch 117 | Train Loss: 0.9290 | Val Loss: 0.7162\n",
      "Epoch 118 | Train Loss: 0.9518 | Val Loss: 0.8465\n",
      "Epoch 119 | Train Loss: 0.9335 | Val Loss: 0.9563\n",
      "Epoch 120 | Train Loss: 0.8589 | Val Loss: 0.6994\n",
      "Epoch 121 | Train Loss: 0.8389 | Val Loss: 0.7606\n",
      "Epoch 122 | Train Loss: 0.8198 | Val Loss: 0.7193\n",
      "Epoch 123 | Train Loss: 0.9042 | Val Loss: 0.6924\n",
      "Epoch 124 | Train Loss: 0.8348 | Val Loss: 0.8006\n",
      "Epoch 125 | Train Loss: 0.8569 | Val Loss: 0.7350\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 126 | Train Loss: 0.8914 | Val Loss: 0.7064\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 127 | Train Loss: 0.9543 | Val Loss: 0.6923\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 128 | Train Loss: 0.8390 | Val Loss: 0.6768\n",
      "Epoch 129 | Train Loss: 0.7903 | Val Loss: 0.6784\n",
      "Epoch 130 | Train Loss: 0.8769 | Val Loss: 0.9248\n",
      "Epoch 131 | Train Loss: 0.9083 | Val Loss: 0.6929\n",
      "Epoch 132 | Train Loss: 0.8929 | Val Loss: 0.7305\n",
      "Epoch 133 | Train Loss: 0.8200 | Val Loss: 0.6628\n",
      "Epoch 134 | Train Loss: 0.8526 | Val Loss: 0.6601\n",
      "Epoch 135 | Train Loss: 0.9122 | Val Loss: 0.6738\n",
      "Epoch 136 | Train Loss: 0.7939 | Val Loss: 0.6493\n",
      "Epoch 137 | Train Loss: 0.7944 | Val Loss: 0.7053\n",
      "Epoch 138 | Train Loss: 0.7954 | Val Loss: 0.6699\n",
      "Epoch 139 | Train Loss: 0.8139 | Val Loss: 0.6818\n",
      "Epoch 140 | Train Loss: 0.7792 | Val Loss: 0.7343\n",
      "Epoch 141 | Train Loss: 0.8537 | Val Loss: 0.7117\n",
      "Epoch 142 | Train Loss: 0.8268 | Val Loss: 0.6561\n",
      "Epoch 143 | Train Loss: 0.8472 | Val Loss: 0.7836\n",
      "Epoch 144 | Train Loss: 0.8220 | Val Loss: 0.7048\n",
      "Epoch 145 | Train Loss: 0.8102 | Val Loss: 0.6823\n",
      "Epoch 146 | Train Loss: 0.8497 | Val Loss: 0.6650\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 147 | Train Loss: 0.8089 | Val Loss: 0.7476\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 148 | Train Loss: 0.8037 | Val Loss: 0.6485\n",
      "Epoch 149 | Train Loss: 0.7875 | Val Loss: 0.7044\n",
      "Epoch 150 | Train Loss: 0.8145 | Val Loss: 0.7461\n",
      "Epoch 151 | Train Loss: 0.8495 | Val Loss: 0.6508\n",
      "Epoch 152 | Train Loss: 0.7801 | Val Loss: 0.6530\n",
      "Epoch 153 | Train Loss: 0.7688 | Val Loss: 0.7081\n",
      "Epoch 154 | Train Loss: 0.7952 | Val Loss: 0.6712\n",
      "Epoch 155 | Train Loss: 0.8252 | Val Loss: 0.6480\n",
      "Epoch 156 | Train Loss: 0.7702 | Val Loss: 0.7383\n",
      "Epoch 157 | Train Loss: 0.8660 | Val Loss: 0.8430\n",
      "Epoch 158 | Train Loss: 0.8587 | Val Loss: 0.7495\n",
      "Epoch 159 | Train Loss: 0.7988 | Val Loss: 0.6652\n",
      "Epoch 160 | Train Loss: 0.8085 | Val Loss: 0.6517\n",
      "Epoch 161 | Train Loss: 0.8078 | Val Loss: 0.6650\n",
      "Epoch 162 | Train Loss: 0.7846 | Val Loss: 0.6814\n",
      "Epoch 163 | Train Loss: 0.7657 | Val Loss: 0.7408\n",
      "Epoch 164 | Train Loss: 0.8268 | Val Loss: 0.6860\n",
      "Epoch 165 | Train Loss: 0.7956 | Val Loss: 0.6847\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 166 | Train Loss: 0.7941 | Val Loss: 0.8274\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 167 | Train Loss: 0.9482 | Val Loss: 1.0031\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 168 | Train Loss: 0.8324 | Val Loss: 0.6823\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 169 | Train Loss: 0.8089 | Val Loss: 0.7385\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 170 | Train Loss: 0.8277 | Val Loss: 0.7253\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 171 | Train Loss: 0.7658 | Val Loss: 0.7259\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 172 | Train Loss: 0.7589 | Val Loss: 0.6520\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 173 | Train Loss: 0.7593 | Val Loss: 0.6613\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 174 | Train Loss: 0.7481 | Val Loss: 0.6648\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 175 | Train Loss: 0.8028 | Val Loss: 0.6881\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 176 | Train Loss: 0.7608 | Val Loss: 0.6791\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 177 | Train Loss: 0.7821 | Val Loss: 0.7202\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 178 | Train Loss: 0.8720 | Val Loss: 0.7832\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 179 | Train Loss: 0.8694 | Val Loss: 0.7274\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 180 | Train Loss: 0.8334 | Val Loss: 0.7267\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 181 | Train Loss: 0.8040 | Val Loss: 0.6997\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 182 | Train Loss: 0.7799 | Val Loss: 0.7248\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 0.7802 | Val Loss: 0.6463\n",
      "Epoch 184 | Train Loss: 0.7753 | Val Loss: 0.6458\n",
      "Epoch 185 | Train Loss: 0.7552 | Val Loss: 0.6518\n",
      "Epoch 186 | Train Loss: 0.7608 | Val Loss: 0.8399\n",
      "Epoch 187 | Train Loss: 0.7669 | Val Loss: 0.8623\n",
      "Epoch 188 | Train Loss: 0.8979 | Val Loss: 0.6519\n",
      "Epoch 189 | Train Loss: 0.8186 | Val Loss: 0.7121\n",
      "Epoch 190 | Train Loss: 0.7820 | Val Loss: 0.6809\n",
      "Epoch 191 | Train Loss: 0.8942 | Val Loss: 0.6501\n",
      "Epoch 192 | Train Loss: 0.7921 | Val Loss: 0.6726\n",
      "Epoch 193 | Train Loss: 0.7369 | Val Loss: 0.6455\n",
      "Epoch 194 | Train Loss: 0.7771 | Val Loss: 0.6651\n",
      "Epoch 195 | Train Loss: 0.7799 | Val Loss: 0.8165\n",
      "Epoch 196 | Train Loss: 0.8735 | Val Loss: 0.7016\n",
      "Epoch 197 | Train Loss: 0.8255 | Val Loss: 0.6547\n",
      "Epoch 198 | Train Loss: 0.7301 | Val Loss: 0.6424\n",
      "Epoch 199 | Train Loss: 0.7699 | Val Loss: 0.6310\n",
      "Epoch 200 | Train Loss: 0.7345 | Val Loss: 0.6397\n",
      "\n",
      "üîÅ Re-training Fold 6/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 19.6174 | Val Loss: 5.4916\n",
      "Epoch 002 | Train Loss: 2.9626 | Val Loss: 2.5660\n",
      "Epoch 003 | Train Loss: 1.6291 | Val Loss: 0.9921\n",
      "Epoch 004 | Train Loss: 1.1108 | Val Loss: 0.9347\n",
      "Epoch 005 | Train Loss: 1.0242 | Val Loss: 0.9225\n",
      "Epoch 006 | Train Loss: 1.0281 | Val Loss: 0.9343\n",
      "Epoch 007 | Train Loss: 1.0132 | Val Loss: 0.9304\n",
      "Epoch 008 | Train Loss: 1.0075 | Val Loss: 0.9265\n",
      "Epoch 009 | Train Loss: 1.0125 | Val Loss: 0.9756\n",
      "Epoch 010 | Train Loss: 1.0500 | Val Loss: 0.9630\n",
      "Epoch 011 | Train Loss: 1.0459 | Val Loss: 0.8986\n",
      "Epoch 012 | Train Loss: 0.9748 | Val Loss: 0.9591\n",
      "Epoch 013 | Train Loss: 1.0103 | Val Loss: 0.9134\n",
      "Epoch 014 | Train Loss: 0.9779 | Val Loss: 0.8989\n",
      "Epoch 015 | Train Loss: 0.9778 | Val Loss: 0.8901\n",
      "Epoch 016 | Train Loss: 0.9897 | Val Loss: 0.9893\n",
      "Epoch 017 | Train Loss: 0.9992 | Val Loss: 0.9590\n",
      "Epoch 018 | Train Loss: 0.9707 | Val Loss: 0.8978\n",
      "Epoch 019 | Train Loss: 0.9907 | Val Loss: 1.0864\n",
      "Epoch 020 | Train Loss: 0.9458 | Val Loss: 0.8824\n",
      "Epoch 021 | Train Loss: 0.9861 | Val Loss: 0.8885\n",
      "Epoch 022 | Train Loss: 0.9772 | Val Loss: 0.8787\n",
      "Epoch 023 | Train Loss: 0.9386 | Val Loss: 0.8840\n",
      "Epoch 024 | Train Loss: 0.9979 | Val Loss: 0.9046\n",
      "Epoch 025 | Train Loss: 0.9366 | Val Loss: 0.8835\n",
      "Epoch 026 | Train Loss: 0.9443 | Val Loss: 0.8930\n",
      "Epoch 027 | Train Loss: 0.9365 | Val Loss: 0.9027\n",
      "Epoch 028 | Train Loss: 1.0070 | Val Loss: 0.8690\n",
      "Epoch 029 | Train Loss: 1.0420 | Val Loss: 0.8686\n",
      "Epoch 030 | Train Loss: 0.9292 | Val Loss: 0.8702\n",
      "Epoch 031 | Train Loss: 0.9365 | Val Loss: 0.8965\n",
      "Epoch 032 | Train Loss: 0.9989 | Val Loss: 0.8842\n",
      "Epoch 033 | Train Loss: 0.9825 | Val Loss: 1.0106\n",
      "Epoch 034 | Train Loss: 0.9916 | Val Loss: 0.8681\n",
      "Epoch 035 | Train Loss: 1.0075 | Val Loss: 0.8614\n",
      "Epoch 036 | Train Loss: 0.9484 | Val Loss: 0.8641\n",
      "Epoch 037 | Train Loss: 0.9250 | Val Loss: 0.8574\n",
      "Epoch 038 | Train Loss: 0.9616 | Val Loss: 0.8829\n",
      "Epoch 039 | Train Loss: 0.9235 | Val Loss: 0.8815\n",
      "Epoch 040 | Train Loss: 0.9361 | Val Loss: 0.9370\n",
      "Epoch 041 | Train Loss: 0.9544 | Val Loss: 0.8664\n",
      "Epoch 042 | Train Loss: 0.9598 | Val Loss: 0.8773\n",
      "Epoch 043 | Train Loss: 0.9500 | Val Loss: 1.0350\n",
      "Epoch 044 | Train Loss: 0.9457 | Val Loss: 0.8539\n",
      "Epoch 045 | Train Loss: 0.9434 | Val Loss: 0.8453\n",
      "Epoch 046 | Train Loss: 0.9567 | Val Loss: 0.9561\n",
      "Epoch 047 | Train Loss: 0.9478 | Val Loss: 0.9433\n",
      "Epoch 048 | Train Loss: 1.0098 | Val Loss: 0.9336\n",
      "Epoch 049 | Train Loss: 0.9368 | Val Loss: 0.8475\n",
      "Epoch 050 | Train Loss: 0.9334 | Val Loss: 0.9203\n",
      "Epoch 051 | Train Loss: 0.9558 | Val Loss: 0.8386\n",
      "Epoch 052 | Train Loss: 0.9005 | Val Loss: 0.9122\n",
      "Epoch 053 | Train Loss: 0.9041 | Val Loss: 0.9287\n",
      "Epoch 054 | Train Loss: 0.9253 | Val Loss: 0.8402\n",
      "Epoch 055 | Train Loss: 0.9246 | Val Loss: 0.8346\n",
      "Epoch 056 | Train Loss: 0.8832 | Val Loss: 0.8365\n",
      "Epoch 057 | Train Loss: 0.9313 | Val Loss: 0.8403\n",
      "Epoch 058 | Train Loss: 0.8780 | Val Loss: 0.8253\n",
      "Epoch 059 | Train Loss: 0.8873 | Val Loss: 0.8248\n",
      "Epoch 060 | Train Loss: 0.8623 | Val Loss: 0.8334\n",
      "Epoch 061 | Train Loss: 0.8687 | Val Loss: 0.8349\n",
      "Epoch 062 | Train Loss: 0.9455 | Val Loss: 0.8562\n",
      "Epoch 063 | Train Loss: 0.9793 | Val Loss: 0.9506\n",
      "Epoch 064 | Train Loss: 0.9178 | Val Loss: 0.8740\n",
      "Epoch 065 | Train Loss: 0.9039 | Val Loss: 0.8237\n",
      "Epoch 066 | Train Loss: 0.9076 | Val Loss: 0.8143\n",
      "Epoch 067 | Train Loss: 0.9122 | Val Loss: 0.8191\n",
      "Epoch 068 | Train Loss: 0.8654 | Val Loss: 0.8972\n",
      "Epoch 069 | Train Loss: 0.8822 | Val Loss: 0.8098\n",
      "Epoch 070 | Train Loss: 0.8535 | Val Loss: 0.8162\n",
      "Epoch 071 | Train Loss: 0.8943 | Val Loss: 0.8254\n",
      "Epoch 072 | Train Loss: 0.8602 | Val Loss: 0.8048\n",
      "Epoch 073 | Train Loss: 0.8656 | Val Loss: 0.8035\n",
      "Epoch 074 | Train Loss: 0.8922 | Val Loss: 0.8184\n",
      "Epoch 075 | Train Loss: 0.8550 | Val Loss: 0.8045\n",
      "Epoch 076 | Train Loss: 0.8448 | Val Loss: 0.8049\n",
      "Epoch 077 | Train Loss: 0.8580 | Val Loss: 0.8137\n",
      "Epoch 078 | Train Loss: 0.8475 | Val Loss: 0.8000\n",
      "Epoch 079 | Train Loss: 1.0647 | Val Loss: 0.8230\n",
      "Epoch 080 | Train Loss: 0.8659 | Val Loss: 0.8463\n",
      "Epoch 081 | Train Loss: 0.8908 | Val Loss: 0.8098\n",
      "Epoch 082 | Train Loss: 0.9233 | Val Loss: 0.8923\n",
      "Epoch 083 | Train Loss: 0.9854 | Val Loss: 1.0557\n",
      "Epoch 084 | Train Loss: 0.9455 | Val Loss: 0.8178\n",
      "Epoch 085 | Train Loss: 0.8990 | Val Loss: 0.8050\n",
      "Epoch 086 | Train Loss: 0.8380 | Val Loss: 0.7945\n",
      "Epoch 087 | Train Loss: 0.8551 | Val Loss: 0.7993\n",
      "Epoch 088 | Train Loss: 0.8983 | Val Loss: 0.8104\n",
      "Epoch 089 | Train Loss: 0.9064 | Val Loss: 0.8244\n",
      "Epoch 090 | Train Loss: 0.8986 | Val Loss: 0.8075\n",
      "Epoch 091 | Train Loss: 0.8316 | Val Loss: 0.8028\n",
      "Epoch 092 | Train Loss: 0.8358 | Val Loss: 0.7875\n",
      "Epoch 093 | Train Loss: 0.9379 | Val Loss: 0.8991\n",
      "Epoch 094 | Train Loss: 0.9202 | Val Loss: 0.7861\n",
      "Epoch 095 | Train Loss: 0.9090 | Val Loss: 1.2417\n",
      "Epoch 096 | Train Loss: 0.9503 | Val Loss: 0.7841\n",
      "Epoch 097 | Train Loss: 0.8467 | Val Loss: 0.8483\n",
      "Epoch 098 | Train Loss: 0.8554 | Val Loss: 0.8475\n",
      "Epoch 099 | Train Loss: 0.9408 | Val Loss: 0.7906\n",
      "Epoch 100 | Train Loss: 0.9064 | Val Loss: 0.7982\n",
      "Epoch 101 | Train Loss: 0.8411 | Val Loss: 0.7997\n",
      "Epoch 102 | Train Loss: 0.8260 | Val Loss: 0.8179\n",
      "Epoch 103 | Train Loss: 0.8387 | Val Loss: 1.0129\n",
      "Epoch 104 | Train Loss: 0.9082 | Val Loss: 0.8504\n",
      "Epoch 105 | Train Loss: 0.8911 | Val Loss: 0.7870\n",
      "Epoch 106 | Train Loss: 0.9681 | Val Loss: 0.8280\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 107 | Train Loss: 0.9702 | Val Loss: 0.8752\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 108 | Train Loss: 0.8283 | Val Loss: 0.7839\n",
      "Epoch 109 | Train Loss: 0.8459 | Val Loss: 0.7986\n",
      "Epoch 110 | Train Loss: 0.9395 | Val Loss: 1.0870\n",
      "Epoch 111 | Train Loss: 0.8899 | Val Loss: 0.7865\n",
      "Epoch 112 | Train Loss: 0.8721 | Val Loss: 0.8582\n",
      "Epoch 113 | Train Loss: 0.8683 | Val Loss: 0.8445\n",
      "Epoch 114 | Train Loss: 0.8210 | Val Loss: 0.7839\n",
      "Epoch 115 | Train Loss: 0.8570 | Val Loss: 0.8071\n",
      "Epoch 116 | Train Loss: 0.8512 | Val Loss: 0.8203\n",
      "Epoch 117 | Train Loss: 0.8413 | Val Loss: 0.7864\n",
      "Epoch 118 | Train Loss: 0.8259 | Val Loss: 0.7832\n",
      "Epoch 119 | Train Loss: 0.8112 | Val Loss: 0.8705\n",
      "Epoch 120 | Train Loss: 0.8323 | Val Loss: 0.7836\n",
      "Epoch 121 | Train Loss: 0.8148 | Val Loss: 0.8181\n",
      "Epoch 122 | Train Loss: 0.8409 | Val Loss: 0.7992\n",
      "Epoch 123 | Train Loss: 0.8275 | Val Loss: 0.7810\n",
      "Epoch 124 | Train Loss: 0.8472 | Val Loss: 0.7843\n",
      "Epoch 125 | Train Loss: 0.9121 | Val Loss: 0.9197\n",
      "Epoch 126 | Train Loss: 0.9677 | Val Loss: 0.8016\n",
      "Epoch 127 | Train Loss: 0.8153 | Val Loss: 0.7898\n",
      "Epoch 128 | Train Loss: 0.7989 | Val Loss: 0.8249\n",
      "Epoch 129 | Train Loss: 0.8369 | Val Loss: 0.7831\n",
      "Epoch 130 | Train Loss: 0.9173 | Val Loss: 0.8373\n",
      "Epoch 131 | Train Loss: 0.8697 | Val Loss: 0.7844\n",
      "Epoch 132 | Train Loss: 0.7833 | Val Loss: 0.9131\n",
      "Epoch 133 | Train Loss: 0.8565 | Val Loss: 0.7919\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 134 | Train Loss: 0.7942 | Val Loss: 0.8129\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 135 | Train Loss: 0.7937 | Val Loss: 0.7777\n",
      "Epoch 136 | Train Loss: 0.8119 | Val Loss: 0.7847\n",
      "Epoch 137 | Train Loss: 0.8577 | Val Loss: 0.7843\n",
      "Epoch 138 | Train Loss: 0.8299 | Val Loss: 0.7796\n",
      "Epoch 139 | Train Loss: 0.8276 | Val Loss: 0.8043\n",
      "Epoch 140 | Train Loss: 0.8484 | Val Loss: 0.7848\n",
      "Epoch 141 | Train Loss: 0.8113 | Val Loss: 0.7811\n",
      "Epoch 142 | Train Loss: 0.8277 | Val Loss: 0.8723\n",
      "Epoch 143 | Train Loss: 0.7853 | Val Loss: 0.7784\n",
      "Epoch 144 | Train Loss: 0.8072 | Val Loss: 0.7833\n",
      "Epoch 145 | Train Loss: 0.8135 | Val Loss: 0.8024\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 146 | Train Loss: 0.7892 | Val Loss: 0.8046\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 147 | Train Loss: 0.8227 | Val Loss: 0.8218\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 148 | Train Loss: 0.8209 | Val Loss: 0.7950\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 149 | Train Loss: 0.7973 | Val Loss: 0.7979\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 150 | Train Loss: 0.7905 | Val Loss: 0.7874\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 151 | Train Loss: 0.8285 | Val Loss: 0.8907\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 152 | Train Loss: 0.9089 | Val Loss: 0.8337\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 153 | Train Loss: 0.8133 | Val Loss: 0.8086\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 154 | Train Loss: 0.8988 | Val Loss: 0.7771\n",
      "Epoch 155 | Train Loss: 0.8818 | Val Loss: 0.8780\n",
      "Epoch 156 | Train Loss: 0.8478 | Val Loss: 0.8533\n",
      "Epoch 157 | Train Loss: 0.8514 | Val Loss: 0.8237\n",
      "Epoch 158 | Train Loss: 0.7915 | Val Loss: 0.7891\n",
      "Epoch 159 | Train Loss: 0.8248 | Val Loss: 0.7983\n",
      "Epoch 160 | Train Loss: 0.8474 | Val Loss: 0.7795\n",
      "Epoch 161 | Train Loss: 0.8115 | Val Loss: 0.7789\n",
      "Epoch 162 | Train Loss: 0.8073 | Val Loss: 0.9584\n",
      "Epoch 163 | Train Loss: 0.8496 | Val Loss: 0.8414\n",
      "Epoch 164 | Train Loss: 0.8230 | Val Loss: 0.8400\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 165 | Train Loss: 0.8007 | Val Loss: 0.9451\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 166 | Train Loss: 0.8745 | Val Loss: 0.7834\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 167 | Train Loss: 0.8473 | Val Loss: 0.8469\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 168 | Train Loss: 0.8716 | Val Loss: 0.7953\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 169 | Train Loss: 0.7745 | Val Loss: 0.8485\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 170 | Train Loss: 0.8360 | Val Loss: 0.9936\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 171 | Train Loss: 0.8742 | Val Loss: 0.7770\n",
      "Epoch 172 | Train Loss: 0.8123 | Val Loss: 0.7950\n",
      "Epoch 173 | Train Loss: 0.7998 | Val Loss: 0.7991\n",
      "Epoch 174 | Train Loss: 0.7847 | Val Loss: 0.7829\n",
      "Epoch 175 | Train Loss: 0.8269 | Val Loss: 0.8326\n",
      "Epoch 176 | Train Loss: 0.8009 | Val Loss: 0.7805\n",
      "Epoch 177 | Train Loss: 0.8179 | Val Loss: 0.8258\n",
      "Epoch 178 | Train Loss: 0.8210 | Val Loss: 0.7801\n",
      "Epoch 179 | Train Loss: 0.7884 | Val Loss: 0.8293\n",
      "Epoch 180 | Train Loss: 0.7914 | Val Loss: 0.7876\n",
      "Epoch 181 | Train Loss: 0.8375 | Val Loss: 0.8605\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 182 | Train Loss: 0.8095 | Val Loss: 0.7817\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 0.7989 | Val Loss: 0.8023\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 184 | Train Loss: 0.7759 | Val Loss: 0.7926\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 185 | Train Loss: 0.7854 | Val Loss: 0.7821\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 186 | Train Loss: 0.8012 | Val Loss: 0.7782\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 187 | Train Loss: 0.7922 | Val Loss: 0.8269\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 188 | Train Loss: 0.7987 | Val Loss: 0.7859\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 189 | Train Loss: 0.8091 | Val Loss: 1.1102\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 190 | Train Loss: 0.9081 | Val Loss: 1.0523\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 191 | Train Loss: 0.9241 | Val Loss: 0.9162\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 192 | Train Loss: 0.8095 | Val Loss: 0.7813\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 193 | Train Loss: 0.7832 | Val Loss: 0.8095\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 194 | Train Loss: 0.8706 | Val Loss: 0.7902\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 195 | Train Loss: 0.8742 | Val Loss: 0.7792\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 196 | Train Loss: 0.9340 | Val Loss: 0.8346\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 197 | Train Loss: 0.9166 | Val Loss: 0.9799\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 198 | Train Loss: 0.8847 | Val Loss: 0.8039\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 199 | Train Loss: 0.8887 | Val Loss: 0.7818\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 200 | Train Loss: 0.8166 | Val Loss: 0.7816\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîÅ Re-training Fold 7/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 16.0579 | Val Loss: 5.9415\n",
      "Epoch 002 | Train Loss: 2.3675 | Val Loss: 1.5097\n",
      "Epoch 003 | Train Loss: 1.1986 | Val Loss: 1.1334\n",
      "Epoch 004 | Train Loss: 1.0431 | Val Loss: 1.1002\n",
      "Epoch 005 | Train Loss: 1.0289 | Val Loss: 1.1666\n",
      "Epoch 006 | Train Loss: 1.0382 | Val Loss: 1.0805\n",
      "Epoch 007 | Train Loss: 0.9911 | Val Loss: 1.0765\n",
      "Epoch 008 | Train Loss: 0.9914 | Val Loss: 1.0957\n",
      "Epoch 009 | Train Loss: 0.9853 | Val Loss: 1.1102\n",
      "Epoch 010 | Train Loss: 1.0015 | Val Loss: 1.0868\n",
      "Epoch 011 | Train Loss: 0.9721 | Val Loss: 1.1178\n",
      "Epoch 012 | Train Loss: 0.9441 | Val Loss: 1.1691\n",
      "Epoch 013 | Train Loss: 0.9469 | Val Loss: 1.1459\n",
      "Epoch 014 | Train Loss: 0.9505 | Val Loss: 1.0876\n",
      "Epoch 015 | Train Loss: 0.9364 | Val Loss: 1.1082\n",
      "Epoch 016 | Train Loss: 0.9292 | Val Loss: 1.1074\n",
      "Epoch 017 | Train Loss: 1.0081 | Val Loss: 1.0884\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 018 | Train Loss: 0.9790 | Val Loss: 1.1318\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 019 | Train Loss: 0.9202 | Val Loss: 1.1074\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 020 | Train Loss: 0.9028 | Val Loss: 1.0956\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 021 | Train Loss: 0.9209 | Val Loss: 1.0922\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 022 | Train Loss: 0.9044 | Val Loss: 1.1959\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 023 | Train Loss: 0.9073 | Val Loss: 1.1792\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 024 | Train Loss: 0.9131 | Val Loss: 1.1131\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 025 | Train Loss: 0.9061 | Val Loss: 1.0887\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 026 | Train Loss: 0.9153 | Val Loss: 1.1430\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 027 | Train Loss: 0.9919 | Val Loss: 1.1828\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 028 | Train Loss: 0.9831 | Val Loss: 1.1197\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 029 | Train Loss: 0.9328 | Val Loss: 1.1080\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 030 | Train Loss: 0.9540 | Val Loss: 1.0783\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 031 | Train Loss: 0.9764 | Val Loss: 1.3187\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 032 | Train Loss: 0.8940 | Val Loss: 1.1079\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 033 | Train Loss: 0.9085 | Val Loss: 1.0917\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 034 | Train Loss: 0.9355 | Val Loss: 1.1709\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 035 | Train Loss: 0.9959 | Val Loss: 1.1411\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 036 | Train Loss: 0.9188 | Val Loss: 1.0838\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 037 | Train Loss: 0.8714 | Val Loss: 1.0833\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 038 | Train Loss: 0.9409 | Val Loss: 1.0886\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 039 | Train Loss: 0.9004 | Val Loss: 1.1131\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 040 | Train Loss: 0.8381 | Val Loss: 1.1224\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 041 | Train Loss: 0.8511 | Val Loss: 1.2839\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 042 | Train Loss: 0.8850 | Val Loss: 1.2747\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 043 | Train Loss: 1.0606 | Val Loss: 1.0763\n",
      "Epoch 044 | Train Loss: 0.9601 | Val Loss: 1.6730\n",
      "Epoch 045 | Train Loss: 1.2082 | Val Loss: 1.2395\n",
      "Epoch 046 | Train Loss: 0.9265 | Val Loss: 1.0751\n",
      "Epoch 047 | Train Loss: 0.8525 | Val Loss: 1.0784\n",
      "Epoch 048 | Train Loss: 0.8782 | Val Loss: 1.1888\n",
      "Epoch 049 | Train Loss: 0.8969 | Val Loss: 1.1876\n",
      "Epoch 050 | Train Loss: 0.8589 | Val Loss: 1.1115\n",
      "Epoch 051 | Train Loss: 0.8865 | Val Loss: 1.1349\n",
      "Epoch 052 | Train Loss: 0.8649 | Val Loss: 1.0971\n",
      "Epoch 053 | Train Loss: 0.8745 | Val Loss: 1.1080\n",
      "Epoch 054 | Train Loss: 0.9328 | Val Loss: 1.1423\n",
      "Epoch 055 | Train Loss: 0.9275 | Val Loss: 1.5647\n",
      "Epoch 056 | Train Loss: 1.0027 | Val Loss: 1.1217\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 057 | Train Loss: 0.8284 | Val Loss: 1.1123\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 058 | Train Loss: 0.8555 | Val Loss: 1.1200\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 059 | Train Loss: 0.8374 | Val Loss: 1.1395\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 060 | Train Loss: 0.8144 | Val Loss: 1.2002\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 061 | Train Loss: 0.8542 | Val Loss: 1.0907\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 062 | Train Loss: 0.8081 | Val Loss: 1.0878\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 063 | Train Loss: 0.8061 | Val Loss: 1.0937\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 064 | Train Loss: 0.7804 | Val Loss: 1.0933\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 065 | Train Loss: 0.7886 | Val Loss: 1.0942\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 066 | Train Loss: 0.8294 | Val Loss: 1.0719\n",
      "Epoch 067 | Train Loss: 0.7899 | Val Loss: 1.1631\n",
      "Epoch 068 | Train Loss: 0.7962 | Val Loss: 1.0843\n",
      "Epoch 069 | Train Loss: 0.8191 | Val Loss: 1.1256\n",
      "Epoch 070 | Train Loss: 0.8539 | Val Loss: 1.1282\n",
      "Epoch 071 | Train Loss: 0.8677 | Val Loss: 1.2010\n",
      "Epoch 072 | Train Loss: 0.8213 | Val Loss: 1.0876\n",
      "Epoch 073 | Train Loss: 0.8142 | Val Loss: 1.0896\n",
      "Epoch 074 | Train Loss: 0.8055 | Val Loss: 1.0807\n",
      "Epoch 075 | Train Loss: 0.7748 | Val Loss: 1.0806\n",
      "Epoch 076 | Train Loss: 0.7902 | Val Loss: 1.0873\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 077 | Train Loss: 0.7810 | Val Loss: 1.1249\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 078 | Train Loss: 0.8422 | Val Loss: 1.2908\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 079 | Train Loss: 0.8400 | Val Loss: 1.0519\n",
      "Epoch 080 | Train Loss: 0.8448 | Val Loss: 1.0683\n",
      "Epoch 081 | Train Loss: 0.8456 | Val Loss: 1.1672\n",
      "Epoch 082 | Train Loss: 0.8809 | Val Loss: 1.0922\n",
      "Epoch 083 | Train Loss: 0.8267 | Val Loss: 1.0753\n",
      "Epoch 084 | Train Loss: 0.7930 | Val Loss: 1.0804\n",
      "Epoch 085 | Train Loss: 0.7761 | Val Loss: 1.0912\n",
      "Epoch 086 | Train Loss: 0.7738 | Val Loss: 1.2821\n",
      "Epoch 087 | Train Loss: 0.8111 | Val Loss: 1.1175\n",
      "Epoch 088 | Train Loss: 0.7829 | Val Loss: 1.0893\n",
      "Epoch 089 | Train Loss: 0.7905 | Val Loss: 1.2862\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 090 | Train Loss: 0.8712 | Val Loss: 1.1620\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 091 | Train Loss: 0.9804 | Val Loss: 1.1914\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 092 | Train Loss: 0.9584 | Val Loss: 1.5695\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 093 | Train Loss: 0.9840 | Val Loss: 1.0600\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 094 | Train Loss: 0.8013 | Val Loss: 1.0823\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 095 | Train Loss: 0.7655 | Val Loss: 1.1505\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 096 | Train Loss: 0.8492 | Val Loss: 1.1134\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 097 | Train Loss: 0.7590 | Val Loss: 1.1362\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 098 | Train Loss: 0.8079 | Val Loss: 1.0902\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 099 | Train Loss: 0.8368 | Val Loss: 1.0682\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 100 | Train Loss: 0.7706 | Val Loss: 1.1070\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 101 | Train Loss: 0.8644 | Val Loss: 1.1206\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 102 | Train Loss: 0.7812 | Val Loss: 1.0652\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 103 | Train Loss: 0.7917 | Val Loss: 1.0727\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 104 | Train Loss: 0.7570 | Val Loss: 1.1022\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 105 | Train Loss: 0.7715 | Val Loss: 1.1253\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 106 | Train Loss: 0.8311 | Val Loss: 1.0513\n",
      "Epoch 107 | Train Loss: 0.8817 | Val Loss: 1.0619\n",
      "Epoch 108 | Train Loss: 0.8420 | Val Loss: 1.0980\n",
      "Epoch 109 | Train Loss: 0.8117 | Val Loss: 1.2994\n",
      "Epoch 110 | Train Loss: 0.8171 | Val Loss: 1.0885\n",
      "Epoch 111 | Train Loss: 0.8882 | Val Loss: 1.0919\n",
      "Epoch 112 | Train Loss: 0.7761 | Val Loss: 1.0951\n",
      "Epoch 113 | Train Loss: 0.8627 | Val Loss: 1.2806\n",
      "Epoch 114 | Train Loss: 0.7915 | Val Loss: 1.0724\n",
      "Epoch 115 | Train Loss: 0.7850 | Val Loss: 1.0530\n",
      "Epoch 116 | Train Loss: 0.7875 | Val Loss: 1.1235\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 117 | Train Loss: 0.7874 | Val Loss: 1.0471\n",
      "Epoch 118 | Train Loss: 0.7626 | Val Loss: 1.0694\n",
      "Epoch 119 | Train Loss: 0.7612 | Val Loss: 1.1145\n",
      "Epoch 120 | Train Loss: 0.7516 | Val Loss: 1.1388\n",
      "Epoch 121 | Train Loss: 0.7748 | Val Loss: 1.3643\n",
      "Epoch 122 | Train Loss: 0.8612 | Val Loss: 1.0365\n",
      "Epoch 123 | Train Loss: 0.8063 | Val Loss: 1.1050\n",
      "Epoch 124 | Train Loss: 0.7734 | Val Loss: 1.0466\n",
      "Epoch 125 | Train Loss: 0.8667 | Val Loss: 1.1060\n",
      "Epoch 126 | Train Loss: 0.8865 | Val Loss: 1.0339\n",
      "Epoch 127 | Train Loss: 0.8009 | Val Loss: 1.0548\n",
      "Epoch 128 | Train Loss: 0.7369 | Val Loss: 1.0918\n",
      "Epoch 129 | Train Loss: 0.7665 | Val Loss: 1.0514\n",
      "Epoch 130 | Train Loss: 0.7860 | Val Loss: 1.1639\n",
      "Epoch 131 | Train Loss: 0.8555 | Val Loss: 1.0728\n",
      "Epoch 132 | Train Loss: 0.8039 | Val Loss: 1.2555\n",
      "Epoch 133 | Train Loss: 0.7831 | Val Loss: 1.3191\n",
      "Epoch 134 | Train Loss: 0.8793 | Val Loss: 1.0705\n",
      "Epoch 135 | Train Loss: 0.8662 | Val Loss: 1.1262\n",
      "Epoch 136 | Train Loss: 0.8100 | Val Loss: 1.1419\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 137 | Train Loss: 0.7525 | Val Loss: 1.0398\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 138 | Train Loss: 0.7624 | Val Loss: 1.0487\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 139 | Train Loss: 0.7551 | Val Loss: 1.0232\n",
      "Epoch 140 | Train Loss: 0.8196 | Val Loss: 1.0786\n",
      "Epoch 141 | Train Loss: 0.7865 | Val Loss: 1.0092\n",
      "Epoch 142 | Train Loss: 0.7406 | Val Loss: 1.0250\n",
      "Epoch 143 | Train Loss: 0.7978 | Val Loss: 1.3078\n",
      "Epoch 144 | Train Loss: 0.8451 | Val Loss: 1.0272\n",
      "Epoch 145 | Train Loss: 0.7426 | Val Loss: 1.0255\n",
      "Epoch 146 | Train Loss: 0.7789 | Val Loss: 1.0332\n",
      "Epoch 147 | Train Loss: 0.8064 | Val Loss: 1.2536\n",
      "Epoch 148 | Train Loss: 0.7631 | Val Loss: 1.0352\n",
      "Epoch 149 | Train Loss: 0.7881 | Val Loss: 1.0414\n",
      "Epoch 150 | Train Loss: 0.8023 | Val Loss: 1.0498\n",
      "Epoch 151 | Train Loss: 0.7578 | Val Loss: 1.1428\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 152 | Train Loss: 0.8292 | Val Loss: 1.0159\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 153 | Train Loss: 0.8044 | Val Loss: 1.0929\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 154 | Train Loss: 0.7702 | Val Loss: 1.0383\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 155 | Train Loss: 0.8194 | Val Loss: 1.1094\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 156 | Train Loss: 0.8039 | Val Loss: 1.0734\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 157 | Train Loss: 0.7417 | Val Loss: 1.1471\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 158 | Train Loss: 0.7934 | Val Loss: 1.0351\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 159 | Train Loss: 0.7776 | Val Loss: 1.0424\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 160 | Train Loss: 0.7326 | Val Loss: 1.1123\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 161 | Train Loss: 0.7736 | Val Loss: 1.1289\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 162 | Train Loss: 0.7544 | Val Loss: 1.0043\n",
      "Epoch 163 | Train Loss: 0.8084 | Val Loss: 1.0341\n",
      "Epoch 164 | Train Loss: 0.8378 | Val Loss: 1.2164\n",
      "Epoch 165 | Train Loss: 0.7880 | Val Loss: 1.1285\n",
      "Epoch 166 | Train Loss: 0.8167 | Val Loss: 1.0192\n",
      "Epoch 167 | Train Loss: 0.7670 | Val Loss: 1.0220\n",
      "Epoch 168 | Train Loss: 0.8372 | Val Loss: 1.0183\n",
      "Epoch 169 | Train Loss: 0.8281 | Val Loss: 1.4717\n",
      "Epoch 170 | Train Loss: 0.8102 | Val Loss: 1.0056\n",
      "Epoch 171 | Train Loss: 0.7410 | Val Loss: 1.0514\n",
      "Epoch 172 | Train Loss: 0.7577 | Val Loss: 1.0267\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 173 | Train Loss: 0.7377 | Val Loss: 1.0217\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 174 | Train Loss: 0.7505 | Val Loss: 1.0676\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 175 | Train Loss: 0.8217 | Val Loss: 1.0022\n",
      "Epoch 176 | Train Loss: 0.8475 | Val Loss: 0.9996\n",
      "Epoch 177 | Train Loss: 0.7469 | Val Loss: 1.0113\n",
      "Epoch 178 | Train Loss: 0.7537 | Val Loss: 0.9904\n",
      "Epoch 179 | Train Loss: 0.7530 | Val Loss: 1.0425\n",
      "Epoch 180 | Train Loss: 0.7571 | Val Loss: 1.0533\n",
      "Epoch 181 | Train Loss: 0.7593 | Val Loss: 1.0113\n",
      "Epoch 182 | Train Loss: 0.7396 | Val Loss: 1.0259\n",
      "Epoch 183 | Train Loss: 0.7579 | Val Loss: 1.1070\n",
      "Epoch 184 | Train Loss: 0.8082 | Val Loss: 1.1057\n",
      "Epoch 185 | Train Loss: 0.8183 | Val Loss: 1.0860\n",
      "Epoch 186 | Train Loss: 0.7656 | Val Loss: 1.0091\n",
      "Epoch 187 | Train Loss: 0.7887 | Val Loss: 1.0163\n",
      "Epoch 188 | Train Loss: 0.7371 | Val Loss: 1.0357\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 189 | Train Loss: 0.7315 | Val Loss: 1.0385\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 190 | Train Loss: 0.7673 | Val Loss: 1.0355\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 191 | Train Loss: 0.7458 | Val Loss: 1.0016\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 192 | Train Loss: 0.7619 | Val Loss: 1.2753\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 193 | Train Loss: 0.8423 | Val Loss: 0.9948\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 194 | Train Loss: 0.7624 | Val Loss: 1.2407\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 195 | Train Loss: 0.9619 | Val Loss: 1.1535\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 196 | Train Loss: 0.7778 | Val Loss: 1.0297\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 197 | Train Loss: 0.7510 | Val Loss: 0.9940\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 198 | Train Loss: 0.7339 | Val Loss: 1.0076\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 199 | Train Loss: 0.7862 | Val Loss: 1.0326\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 200 | Train Loss: 0.7761 | Val Loss: 1.0211\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîÅ Re-training Fold 8/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 13.6990 | Val Loss: 3.1537\n",
      "Epoch 002 | Train Loss: 1.9393 | Val Loss: 1.1983\n",
      "Epoch 003 | Train Loss: 1.1821 | Val Loss: 0.7988\n",
      "Epoch 004 | Train Loss: 1.0482 | Val Loss: 0.7910\n",
      "Epoch 005 | Train Loss: 1.0929 | Val Loss: 0.8046\n",
      "Epoch 006 | Train Loss: 1.0518 | Val Loss: 0.7938\n",
      "Epoch 007 | Train Loss: 1.0070 | Val Loss: 0.7970\n",
      "Epoch 008 | Train Loss: 1.0580 | Val Loss: 0.7839\n",
      "Epoch 009 | Train Loss: 1.0126 | Val Loss: 0.9131\n",
      "Epoch 010 | Train Loss: 1.0880 | Val Loss: 0.7588\n",
      "Epoch 011 | Train Loss: 1.0512 | Val Loss: 0.8023\n",
      "Epoch 012 | Train Loss: 1.0150 | Val Loss: 0.7523\n",
      "Epoch 013 | Train Loss: 1.0377 | Val Loss: 0.7650\n",
      "Epoch 014 | Train Loss: 1.0582 | Val Loss: 0.9013\n",
      "Epoch 015 | Train Loss: 1.0419 | Val Loss: 0.7691\n",
      "Epoch 016 | Train Loss: 1.0594 | Val Loss: 0.8987\n",
      "Epoch 017 | Train Loss: 1.0037 | Val Loss: 0.8054\n",
      "Epoch 018 | Train Loss: 1.0065 | Val Loss: 0.7514\n",
      "Epoch 019 | Train Loss: 0.9723 | Val Loss: 0.7573\n",
      "Epoch 020 | Train Loss: 0.9978 | Val Loss: 0.7826\n",
      "Epoch 021 | Train Loss: 0.9653 | Val Loss: 0.7331\n",
      "Epoch 022 | Train Loss: 0.9760 | Val Loss: 0.7291\n",
      "Epoch 023 | Train Loss: 0.9899 | Val Loss: 0.7208\n",
      "Epoch 024 | Train Loss: 0.9331 | Val Loss: 0.7777\n",
      "Epoch 025 | Train Loss: 0.9441 | Val Loss: 0.7530\n",
      "Epoch 026 | Train Loss: 0.9625 | Val Loss: 0.8056\n",
      "Epoch 027 | Train Loss: 1.0372 | Val Loss: 0.7254\n",
      "Epoch 028 | Train Loss: 1.0210 | Val Loss: 0.7623\n",
      "Epoch 029 | Train Loss: 0.9660 | Val Loss: 0.7311\n",
      "Epoch 030 | Train Loss: 0.9653 | Val Loss: 0.7065\n",
      "Epoch 031 | Train Loss: 0.9492 | Val Loss: 0.8060\n",
      "Epoch 032 | Train Loss: 0.9506 | Val Loss: 0.7372\n",
      "Epoch 033 | Train Loss: 0.9589 | Val Loss: 0.7003\n",
      "Epoch 034 | Train Loss: 0.9357 | Val Loss: 0.7701\n",
      "Epoch 035 | Train Loss: 0.9130 | Val Loss: 0.7021\n",
      "Epoch 036 | Train Loss: 0.9282 | Val Loss: 0.6943\n",
      "Epoch 037 | Train Loss: 0.9133 | Val Loss: 0.7092\n",
      "Epoch 038 | Train Loss: 0.9126 | Val Loss: 0.7452\n",
      "Epoch 039 | Train Loss: 0.9373 | Val Loss: 0.9488\n",
      "Epoch 040 | Train Loss: 0.9563 | Val Loss: 0.6891\n",
      "Epoch 041 | Train Loss: 0.9094 | Val Loss: 0.7450\n",
      "Epoch 042 | Train Loss: 0.9565 | Val Loss: 0.7125\n",
      "Epoch 043 | Train Loss: 0.9967 | Val Loss: 0.7454\n",
      "Epoch 044 | Train Loss: 0.9624 | Val Loss: 0.6832\n",
      "Epoch 045 | Train Loss: 0.9057 | Val Loss: 0.6836\n",
      "Epoch 046 | Train Loss: 0.8941 | Val Loss: 0.6891\n",
      "Epoch 047 | Train Loss: 0.8978 | Val Loss: 0.7299\n",
      "Epoch 048 | Train Loss: 0.9075 | Val Loss: 0.6774\n",
      "Epoch 049 | Train Loss: 0.9148 | Val Loss: 0.7514\n",
      "Epoch 050 | Train Loss: 0.9221 | Val Loss: 0.6745\n",
      "Epoch 051 | Train Loss: 0.9631 | Val Loss: 0.6897\n",
      "Epoch 052 | Train Loss: 0.9947 | Val Loss: 0.7599\n",
      "Epoch 053 | Train Loss: 0.9315 | Val Loss: 0.6898\n",
      "Epoch 054 | Train Loss: 0.9221 | Val Loss: 0.7517\n",
      "Epoch 055 | Train Loss: 0.9201 | Val Loss: 0.7324\n",
      "Epoch 056 | Train Loss: 0.9019 | Val Loss: 0.6862\n",
      "Epoch 057 | Train Loss: 0.9422 | Val Loss: 0.7573\n",
      "Epoch 058 | Train Loss: 0.9033 | Val Loss: 0.7070\n",
      "Epoch 059 | Train Loss: 0.9021 | Val Loss: 0.6692\n",
      "Epoch 060 | Train Loss: 0.9380 | Val Loss: 0.7140\n",
      "Epoch 061 | Train Loss: 0.9023 | Val Loss: 0.6792\n",
      "Epoch 062 | Train Loss: 0.9148 | Val Loss: 0.6989\n",
      "Epoch 063 | Train Loss: 0.9619 | Val Loss: 0.7435\n",
      "Epoch 064 | Train Loss: 0.9223 | Val Loss: 0.6720\n",
      "Epoch 065 | Train Loss: 0.8829 | Val Loss: 0.6930\n",
      "Epoch 066 | Train Loss: 0.8801 | Val Loss: 0.9565\n",
      "Epoch 067 | Train Loss: 0.9968 | Val Loss: 0.6708\n",
      "Epoch 068 | Train Loss: 0.9589 | Val Loss: 0.6767\n",
      "Epoch 069 | Train Loss: 0.9339 | Val Loss: 0.7458\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 070 | Train Loss: 0.8974 | Val Loss: 0.6740\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 071 | Train Loss: 0.9350 | Val Loss: 0.6664\n",
      "Epoch 072 | Train Loss: 0.8577 | Val Loss: 0.6944\n",
      "Epoch 073 | Train Loss: 0.9580 | Val Loss: 0.6879\n",
      "Epoch 074 | Train Loss: 0.9098 | Val Loss: 0.8127\n",
      "Epoch 075 | Train Loss: 0.9615 | Val Loss: 0.7803\n",
      "Epoch 076 | Train Loss: 0.8730 | Val Loss: 0.6536\n",
      "Epoch 077 | Train Loss: 0.8997 | Val Loss: 0.7231\n",
      "Epoch 078 | Train Loss: 0.8972 | Val Loss: 0.6604\n",
      "Epoch 079 | Train Loss: 0.9591 | Val Loss: 0.6858\n",
      "Epoch 080 | Train Loss: 1.0096 | Val Loss: 0.7917\n",
      "Epoch 081 | Train Loss: 0.8796 | Val Loss: 0.9363\n",
      "Epoch 082 | Train Loss: 0.9536 | Val Loss: 0.7672\n",
      "Epoch 083 | Train Loss: 0.9870 | Val Loss: 0.6505\n",
      "Epoch 084 | Train Loss: 0.9039 | Val Loss: 0.7664\n",
      "Epoch 085 | Train Loss: 0.8856 | Val Loss: 0.6861\n",
      "Epoch 086 | Train Loss: 0.8999 | Val Loss: 0.6842\n",
      "Epoch 087 | Train Loss: 0.9011 | Val Loss: 0.6870\n",
      "Epoch 088 | Train Loss: 1.1716 | Val Loss: 1.2899\n",
      "Epoch 089 | Train Loss: 1.0450 | Val Loss: 0.6507\n",
      "Epoch 090 | Train Loss: 0.8741 | Val Loss: 0.6477\n",
      "Epoch 091 | Train Loss: 0.8923 | Val Loss: 0.6476\n",
      "Epoch 092 | Train Loss: 0.9556 | Val Loss: 0.6723\n",
      "Epoch 093 | Train Loss: 0.8953 | Val Loss: 0.6475\n",
      "Epoch 094 | Train Loss: 0.8973 | Val Loss: 0.8655\n",
      "Epoch 095 | Train Loss: 0.9766 | Val Loss: 0.6526\n",
      "Epoch 096 | Train Loss: 0.9212 | Val Loss: 0.6460\n",
      "Epoch 097 | Train Loss: 0.9094 | Val Loss: 0.6645\n",
      "Epoch 098 | Train Loss: 0.8641 | Val Loss: 0.6465\n",
      "Epoch 099 | Train Loss: 0.8411 | Val Loss: 0.6661\n",
      "Epoch 100 | Train Loss: 0.9592 | Val Loss: 0.7431\n",
      "Epoch 101 | Train Loss: 0.8727 | Val Loss: 0.6668\n",
      "Epoch 102 | Train Loss: 0.8871 | Val Loss: 0.6636\n",
      "Epoch 103 | Train Loss: 0.8413 | Val Loss: 0.6775\n",
      "Epoch 104 | Train Loss: 0.8770 | Val Loss: 0.7157\n",
      "Epoch 105 | Train Loss: 0.9512 | Val Loss: 0.8824\n",
      "Epoch 106 | Train Loss: 0.8965 | Val Loss: 0.6395\n",
      "Epoch 107 | Train Loss: 0.8478 | Val Loss: 0.6470\n",
      "Epoch 108 | Train Loss: 0.8633 | Val Loss: 0.6457\n",
      "Epoch 109 | Train Loss: 0.8578 | Val Loss: 0.7716\n",
      "Epoch 110 | Train Loss: 0.9152 | Val Loss: 0.6377\n",
      "Epoch 111 | Train Loss: 0.9155 | Val Loss: 0.7181\n",
      "Epoch 112 | Train Loss: 0.8757 | Val Loss: 0.6839\n",
      "Epoch 113 | Train Loss: 0.8287 | Val Loss: 0.6591\n",
      "Epoch 114 | Train Loss: 0.8208 | Val Loss: 0.7220\n",
      "Epoch 115 | Train Loss: 0.8197 | Val Loss: 0.6950\n",
      "Epoch 116 | Train Loss: 0.9028 | Val Loss: 0.8232\n",
      "Epoch 117 | Train Loss: 0.8533 | Val Loss: 0.6699\n",
      "Epoch 118 | Train Loss: 0.8308 | Val Loss: 0.6381\n",
      "Epoch 119 | Train Loss: 0.8427 | Val Loss: 0.6501\n",
      "Epoch 120 | Train Loss: 0.9168 | Val Loss: 0.6537\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 121 | Train Loss: 0.8677 | Val Loss: 0.7573\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 122 | Train Loss: 0.9284 | Val Loss: 0.6389\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 123 | Train Loss: 0.9117 | Val Loss: 0.7566\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 124 | Train Loss: 0.9393 | Val Loss: 0.8751\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 125 | Train Loss: 1.0358 | Val Loss: 0.8090\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 126 | Train Loss: 1.0707 | Val Loss: 0.6903\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 127 | Train Loss: 0.9623 | Val Loss: 0.6626\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 128 | Train Loss: 0.9068 | Val Loss: 0.9699\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 129 | Train Loss: 0.9219 | Val Loss: 0.9679\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 130 | Train Loss: 0.8504 | Val Loss: 0.6360\n",
      "Epoch 131 | Train Loss: 0.9039 | Val Loss: 0.6915\n",
      "Epoch 132 | Train Loss: 0.9469 | Val Loss: 0.8204\n",
      "Epoch 133 | Train Loss: 0.9025 | Val Loss: 0.7364\n",
      "Epoch 134 | Train Loss: 0.8774 | Val Loss: 0.8332\n",
      "Epoch 135 | Train Loss: 0.9977 | Val Loss: 0.6471\n",
      "Epoch 136 | Train Loss: 0.8321 | Val Loss: 0.6666\n",
      "Epoch 137 | Train Loss: 0.8211 | Val Loss: 0.6293\n",
      "Epoch 138 | Train Loss: 0.8550 | Val Loss: 0.6400\n",
      "Epoch 139 | Train Loss: 0.8990 | Val Loss: 0.6871\n",
      "Epoch 140 | Train Loss: 0.8631 | Val Loss: 0.6782\n",
      "Epoch 141 | Train Loss: 0.8488 | Val Loss: 0.7021\n",
      "Epoch 142 | Train Loss: 0.8177 | Val Loss: 0.6612\n",
      "Epoch 143 | Train Loss: 0.8187 | Val Loss: 0.6338\n",
      "Epoch 144 | Train Loss: 0.9274 | Val Loss: 1.0011\n",
      "Epoch 145 | Train Loss: 0.8488 | Val Loss: 0.6614\n",
      "Epoch 146 | Train Loss: 0.8425 | Val Loss: 0.6325\n",
      "Epoch 147 | Train Loss: 0.8093 | Val Loss: 0.6630\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 148 | Train Loss: 0.8254 | Val Loss: 0.7102\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 149 | Train Loss: 0.8303 | Val Loss: 0.6308\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 150 | Train Loss: 0.8630 | Val Loss: 0.8549\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 151 | Train Loss: 0.8485 | Val Loss: 0.8060\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 152 | Train Loss: 0.8279 | Val Loss: 0.6422\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 153 | Train Loss: 0.8417 | Val Loss: 0.6433\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 154 | Train Loss: 0.8281 | Val Loss: 0.6414\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 155 | Train Loss: 0.8096 | Val Loss: 0.6647\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 156 | Train Loss: 0.8421 | Val Loss: 0.6874\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 157 | Train Loss: 0.8510 | Val Loss: 0.6496\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 158 | Train Loss: 0.9068 | Val Loss: 0.6426\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 159 | Train Loss: 0.8107 | Val Loss: 0.7084\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 160 | Train Loss: 0.8809 | Val Loss: 0.6788\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 161 | Train Loss: 0.8089 | Val Loss: 0.6607\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 162 | Train Loss: 0.8133 | Val Loss: 0.6447\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 163 | Train Loss: 0.8244 | Val Loss: 0.8477\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 164 | Train Loss: 0.8751 | Val Loss: 0.6977\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 165 | Train Loss: 0.8784 | Val Loss: 0.6687\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 166 | Train Loss: 0.7982 | Val Loss: 0.7610\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 167 | Train Loss: 0.8232 | Val Loss: 0.6965\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 168 | Train Loss: 0.8950 | Val Loss: 0.6654\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 169 | Train Loss: 0.7848 | Val Loss: 0.7323\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 170 | Train Loss: 0.8068 | Val Loss: 0.6868\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 171 | Train Loss: 0.7900 | Val Loss: 0.7280\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 172 | Train Loss: 0.8579 | Val Loss: 0.6457\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 173 | Train Loss: 0.8275 | Val Loss: 0.7471\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 174 | Train Loss: 0.8444 | Val Loss: 0.6482\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 175 | Train Loss: 0.8642 | Val Loss: 0.7761\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 176 | Train Loss: 0.8357 | Val Loss: 0.9565\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 177 | Train Loss: 0.9211 | Val Loss: 0.6442\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 178 | Train Loss: 0.8075 | Val Loss: 0.6402\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 179 | Train Loss: 0.8224 | Val Loss: 0.6577\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 180 | Train Loss: 0.8630 | Val Loss: 0.7295\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 181 | Train Loss: 0.7912 | Val Loss: 0.7050\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 182 | Train Loss: 0.8379 | Val Loss: 0.6396\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 0.8505 | Val Loss: 0.7153\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 184 | Train Loss: 0.7977 | Val Loss: 0.6417\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 185 | Train Loss: 0.8114 | Val Loss: 0.6447\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 186 | Train Loss: 0.7907 | Val Loss: 0.8078\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 187 | Train Loss: 0.8839 | Val Loss: 0.6510\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 188 | Train Loss: 0.7909 | Val Loss: 0.7837\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 189 | Train Loss: 0.8056 | Val Loss: 0.6462\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 190 | Train Loss: 0.8448 | Val Loss: 0.6495\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 191 | Train Loss: 0.8273 | Val Loss: 0.6409\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 192 | Train Loss: 0.8591 | Val Loss: 0.7398\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 193 | Train Loss: 0.8458 | Val Loss: 0.8261\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 194 | Train Loss: 0.8611 | Val Loss: 0.6494\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 195 | Train Loss: 0.8280 | Val Loss: 0.6486\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 196 | Train Loss: 0.8075 | Val Loss: 0.6513\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 197 | Train Loss: 0.8690 | Val Loss: 0.7037\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 198 | Train Loss: 0.8605 | Val Loss: 0.7092\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 199 | Train Loss: 0.8351 | Val Loss: 0.7156\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 200 | Train Loss: 0.7917 | Val Loss: 0.6463\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîÅ Re-training Fold 9/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 15.1577 | Val Loss: 7.1100\n",
      "Epoch 002 | Train Loss: 2.5863 | Val Loss: 1.2188\n",
      "Epoch 003 | Train Loss: 1.2074 | Val Loss: 1.0622\n",
      "Epoch 004 | Train Loss: 0.9981 | Val Loss: 1.0782\n",
      "Epoch 005 | Train Loss: 0.9855 | Val Loss: 1.0113\n",
      "Epoch 006 | Train Loss: 0.9657 | Val Loss: 1.1251\n",
      "Epoch 007 | Train Loss: 1.0122 | Val Loss: 1.0756\n",
      "Epoch 008 | Train Loss: 0.9997 | Val Loss: 1.1753\n",
      "Epoch 009 | Train Loss: 1.0333 | Val Loss: 1.2430\n",
      "Epoch 010 | Train Loss: 1.0519 | Val Loss: 1.0333\n",
      "Epoch 011 | Train Loss: 0.9966 | Val Loss: 0.9860\n",
      "Epoch 012 | Train Loss: 1.0153 | Val Loss: 0.9910\n",
      "Epoch 013 | Train Loss: 0.9940 | Val Loss: 1.2220\n",
      "Epoch 014 | Train Loss: 0.9846 | Val Loss: 1.1816\n",
      "Epoch 015 | Train Loss: 0.9971 | Val Loss: 1.1380\n",
      "Epoch 016 | Train Loss: 0.9378 | Val Loss: 1.0510\n",
      "Epoch 017 | Train Loss: 0.9505 | Val Loss: 1.0721\n",
      "Epoch 018 | Train Loss: 0.9517 | Val Loss: 1.1372\n",
      "Epoch 019 | Train Loss: 0.9466 | Val Loss: 1.0696\n",
      "Epoch 020 | Train Loss: 0.9326 | Val Loss: 1.1547\n",
      "Epoch 021 | Train Loss: 0.9430 | Val Loss: 1.1339\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 022 | Train Loss: 0.9345 | Val Loss: 1.0056\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 023 | Train Loss: 0.9431 | Val Loss: 1.0568\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 024 | Train Loss: 0.9299 | Val Loss: 1.1302\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 025 | Train Loss: 0.9658 | Val Loss: 0.9980\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 026 | Train Loss: 0.9831 | Val Loss: 1.0006\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 027 | Train Loss: 0.9526 | Val Loss: 1.0406\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 028 | Train Loss: 0.9330 | Val Loss: 1.0874\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 029 | Train Loss: 0.8880 | Val Loss: 1.0018\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 030 | Train Loss: 1.0538 | Val Loss: 1.0199\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 031 | Train Loss: 1.0713 | Val Loss: 1.5431\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 032 | Train Loss: 1.0590 | Val Loss: 1.1700\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 033 | Train Loss: 0.9096 | Val Loss: 1.0015\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 034 | Train Loss: 0.9134 | Val Loss: 1.1262\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 035 | Train Loss: 0.9377 | Val Loss: 1.3956\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 036 | Train Loss: 0.9747 | Val Loss: 0.9973\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 037 | Train Loss: 0.8876 | Val Loss: 1.0080\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 038 | Train Loss: 0.9076 | Val Loss: 1.0327\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 039 | Train Loss: 0.9063 | Val Loss: 1.0699\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 040 | Train Loss: 0.9298 | Val Loss: 0.9924\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 041 | Train Loss: 0.9172 | Val Loss: 0.9940\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 042 | Train Loss: 0.9891 | Val Loss: 1.0068\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 043 | Train Loss: 0.9865 | Val Loss: 1.1970\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 044 | Train Loss: 0.9801 | Val Loss: 1.3293\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 045 | Train Loss: 0.9489 | Val Loss: 0.9903\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 046 | Train Loss: 0.9121 | Val Loss: 0.9894\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 047 | Train Loss: 0.8933 | Val Loss: 1.0084\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 048 | Train Loss: 0.8956 | Val Loss: 0.9974\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 049 | Train Loss: 0.9058 | Val Loss: 1.1037\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 050 | Train Loss: 0.8326 | Val Loss: 1.3338\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 051 | Train Loss: 0.9341 | Val Loss: 1.2130\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 052 | Train Loss: 0.8891 | Val Loss: 1.0433\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 053 | Train Loss: 0.8629 | Val Loss: 1.0318\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 054 | Train Loss: 0.8799 | Val Loss: 1.0517\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 055 | Train Loss: 0.8789 | Val Loss: 0.9960\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 056 | Train Loss: 0.9201 | Val Loss: 1.0009\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 057 | Train Loss: 0.9449 | Val Loss: 1.4214\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 058 | Train Loss: 0.8647 | Val Loss: 1.1213\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 059 | Train Loss: 0.8624 | Val Loss: 0.9902\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 060 | Train Loss: 0.8916 | Val Loss: 0.9933\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 061 | Train Loss: 0.9020 | Val Loss: 1.1999\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 062 | Train Loss: 0.9335 | Val Loss: 0.9905\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 063 | Train Loss: 0.8485 | Val Loss: 0.9953\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 064 | Train Loss: 0.8259 | Val Loss: 1.0113\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 065 | Train Loss: 0.8521 | Val Loss: 1.0251\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 066 | Train Loss: 0.8627 | Val Loss: 1.1085\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 067 | Train Loss: 0.9193 | Val Loss: 1.2167\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 068 | Train Loss: 0.8786 | Val Loss: 1.0306\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 069 | Train Loss: 0.8550 | Val Loss: 1.0460\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 070 | Train Loss: 0.8799 | Val Loss: 1.0475\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 071 | Train Loss: 0.8922 | Val Loss: 1.0158\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 072 | Train Loss: 0.8719 | Val Loss: 1.5445\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 073 | Train Loss: 0.9717 | Val Loss: 0.9965\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 074 | Train Loss: 0.8146 | Val Loss: 0.9894\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 075 | Train Loss: 0.9271 | Val Loss: 0.9998\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 076 | Train Loss: 0.9624 | Val Loss: 1.3428\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 077 | Train Loss: 0.9214 | Val Loss: 0.9775\n",
      "Epoch 078 | Train Loss: 0.8312 | Val Loss: 1.1231\n",
      "Epoch 079 | Train Loss: 0.8439 | Val Loss: 1.0935\n",
      "Epoch 080 | Train Loss: 0.8439 | Val Loss: 1.0197\n",
      "Epoch 081 | Train Loss: 0.7823 | Val Loss: 1.2620\n",
      "Epoch 082 | Train Loss: 0.8386 | Val Loss: 1.1784\n",
      "Epoch 083 | Train Loss: 0.8341 | Val Loss: 1.0243\n",
      "Epoch 084 | Train Loss: 0.7826 | Val Loss: 1.0048\n",
      "Epoch 085 | Train Loss: 0.8218 | Val Loss: 1.0070\n",
      "Epoch 086 | Train Loss: 0.8111 | Val Loss: 1.1120\n",
      "Epoch 087 | Train Loss: 0.8477 | Val Loss: 1.0310\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 088 | Train Loss: 0.7795 | Val Loss: 1.1223\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 089 | Train Loss: 0.8150 | Val Loss: 1.0522\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 090 | Train Loss: 0.8319 | Val Loss: 1.0503\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 091 | Train Loss: 0.7906 | Val Loss: 1.0320\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 092 | Train Loss: 0.7891 | Val Loss: 1.0024\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 093 | Train Loss: 0.8296 | Val Loss: 1.1127\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 094 | Train Loss: 0.8632 | Val Loss: 1.0058\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 095 | Train Loss: 0.7942 | Val Loss: 1.0506\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 096 | Train Loss: 0.8363 | Val Loss: 1.1025\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 097 | Train Loss: 0.7999 | Val Loss: 1.0571\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 098 | Train Loss: 0.9040 | Val Loss: 1.1201\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 099 | Train Loss: 0.8228 | Val Loss: 1.2339\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 100 | Train Loss: 0.8565 | Val Loss: 1.0590\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 101 | Train Loss: 0.7714 | Val Loss: 1.0567\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 102 | Train Loss: 0.8492 | Val Loss: 1.1620\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 103 | Train Loss: 1.1409 | Val Loss: 1.2008\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 104 | Train Loss: 0.9306 | Val Loss: 1.1001\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 105 | Train Loss: 0.8395 | Val Loss: 1.0873\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 106 | Train Loss: 0.8698 | Val Loss: 1.0567\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 107 | Train Loss: 0.7671 | Val Loss: 1.0895\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 108 | Train Loss: 0.8033 | Val Loss: 1.0169\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 109 | Train Loss: 0.8143 | Val Loss: 1.0863\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 110 | Train Loss: 0.7764 | Val Loss: 1.0334\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 111 | Train Loss: 0.8438 | Val Loss: 1.0257\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 112 | Train Loss: 0.7982 | Val Loss: 1.0045\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 113 | Train Loss: 0.7714 | Val Loss: 1.0177\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 114 | Train Loss: 0.7789 | Val Loss: 1.0272\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 115 | Train Loss: 0.8288 | Val Loss: 1.1160\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 116 | Train Loss: 0.8348 | Val Loss: 1.0229\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 117 | Train Loss: 0.8877 | Val Loss: 1.0380\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 118 | Train Loss: 0.8013 | Val Loss: 1.0514\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 119 | Train Loss: 0.7878 | Val Loss: 1.0762\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 120 | Train Loss: 0.7727 | Val Loss: 0.9990\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 121 | Train Loss: 0.7532 | Val Loss: 1.0928\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 122 | Train Loss: 0.7717 | Val Loss: 1.0314\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 123 | Train Loss: 0.7567 | Val Loss: 1.0402\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 124 | Train Loss: 0.7677 | Val Loss: 1.0315\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 125 | Train Loss: 0.7904 | Val Loss: 1.0433\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 126 | Train Loss: 0.8090 | Val Loss: 1.0727\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 127 | Train Loss: 0.9441 | Val Loss: 1.4777\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 128 | Train Loss: 0.9613 | Val Loss: 1.1879\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 129 | Train Loss: 0.8008 | Val Loss: 1.0213\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 130 | Train Loss: 0.7712 | Val Loss: 1.0476\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 131 | Train Loss: 0.7617 | Val Loss: 1.0286\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 132 | Train Loss: 0.7533 | Val Loss: 1.0818\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 133 | Train Loss: 0.7774 | Val Loss: 1.0258\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 134 | Train Loss: 0.7574 | Val Loss: 1.0410\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 135 | Train Loss: 0.7850 | Val Loss: 1.0816\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 136 | Train Loss: 0.8105 | Val Loss: 1.0366\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 137 | Train Loss: 0.8235 | Val Loss: 1.1121\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 138 | Train Loss: 0.7621 | Val Loss: 1.0327\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 139 | Train Loss: 0.7765 | Val Loss: 1.0154\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 140 | Train Loss: 0.7501 | Val Loss: 1.1341\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 141 | Train Loss: 0.7849 | Val Loss: 1.0666\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 142 | Train Loss: 0.8460 | Val Loss: 1.0143\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 143 | Train Loss: 0.7786 | Val Loss: 1.2548\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 144 | Train Loss: 0.8633 | Val Loss: 1.0829\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 145 | Train Loss: 0.7308 | Val Loss: 1.2735\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 146 | Train Loss: 0.8289 | Val Loss: 1.0230\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 147 | Train Loss: 0.8918 | Val Loss: 1.0371\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 148 | Train Loss: 0.8743 | Val Loss: 1.1075\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 149 | Train Loss: 0.7759 | Val Loss: 1.0211\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 150 | Train Loss: 0.7401 | Val Loss: 1.0589\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 151 | Train Loss: 0.7365 | Val Loss: 1.0242\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 152 | Train Loss: 0.7785 | Val Loss: 1.0473\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 153 | Train Loss: 0.7403 | Val Loss: 1.0468\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 154 | Train Loss: 0.7127 | Val Loss: 1.2053\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 155 | Train Loss: 0.8147 | Val Loss: 1.0312\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 156 | Train Loss: 0.7306 | Val Loss: 1.0214\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 157 | Train Loss: 0.7505 | Val Loss: 1.0811\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 158 | Train Loss: 0.8683 | Val Loss: 1.0976\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 159 | Train Loss: 0.7926 | Val Loss: 1.0530\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 160 | Train Loss: 0.7385 | Val Loss: 1.0727\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 161 | Train Loss: 0.7079 | Val Loss: 1.0398\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 162 | Train Loss: 0.7383 | Val Loss: 1.0712\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 163 | Train Loss: 0.8183 | Val Loss: 1.1569\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 164 | Train Loss: 0.8279 | Val Loss: 1.1448\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 165 | Train Loss: 0.7985 | Val Loss: 1.0096\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 166 | Train Loss: 0.7648 | Val Loss: 1.0664\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 167 | Train Loss: 0.7796 | Val Loss: 1.0204\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 168 | Train Loss: 0.7161 | Val Loss: 1.0422\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 169 | Train Loss: 0.7669 | Val Loss: 1.0484\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 170 | Train Loss: 0.7770 | Val Loss: 1.1155\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 171 | Train Loss: 0.7806 | Val Loss: 1.0417\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 172 | Train Loss: 0.7952 | Val Loss: 1.1072\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 173 | Train Loss: 0.7652 | Val Loss: 1.0164\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 174 | Train Loss: 0.7911 | Val Loss: 1.0511\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 175 | Train Loss: 0.7107 | Val Loss: 1.1409\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 176 | Train Loss: 0.7707 | Val Loss: 1.1331\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 177 | Train Loss: 0.7066 | Val Loss: 1.0439\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 178 | Train Loss: 0.7624 | Val Loss: 1.0878\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 179 | Train Loss: 0.7350 | Val Loss: 1.0556\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 180 | Train Loss: 0.7449 | Val Loss: 1.0192\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 181 | Train Loss: 0.7861 | Val Loss: 1.0800\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 182 | Train Loss: 0.8684 | Val Loss: 1.0560\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 183 | Train Loss: 0.7544 | Val Loss: 1.0387\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 184 | Train Loss: 0.7179 | Val Loss: 1.0427\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 185 | Train Loss: 0.8120 | Val Loss: 1.0944\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 186 | Train Loss: 0.7247 | Val Loss: 1.1810\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 187 | Train Loss: 0.7713 | Val Loss: 1.0313\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 188 | Train Loss: 0.7677 | Val Loss: 1.0370\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 189 | Train Loss: 0.7112 | Val Loss: 1.0351\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 190 | Train Loss: 0.7415 | Val Loss: 1.0386\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 191 | Train Loss: 0.7209 | Val Loss: 1.0872\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 192 | Train Loss: 0.7398 | Val Loss: 1.0041\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 193 | Train Loss: 0.7799 | Val Loss: 1.0691\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 194 | Train Loss: 0.7300 | Val Loss: 1.1532\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 195 | Train Loss: 0.8342 | Val Loss: 1.0874\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 196 | Train Loss: 0.7742 | Val Loss: 1.0293\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 197 | Train Loss: 0.7388 | Val Loss: 1.0333\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 198 | Train Loss: 0.7716 | Val Loss: 1.0425\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 199 | Train Loss: 0.7178 | Val Loss: 1.0338\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 200 | Train Loss: 0.7090 | Val Loss: 1.1329\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîÅ Re-training Fold 10/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 14.0917 | Val Loss: 3.9864\n",
      "Epoch 002 | Train Loss: 1.9068 | Val Loss: 1.6848\n",
      "Epoch 003 | Train Loss: 1.1778 | Val Loss: 1.2652\n",
      "Epoch 004 | Train Loss: 1.0513 | Val Loss: 1.2093\n",
      "Epoch 005 | Train Loss: 1.0158 | Val Loss: 1.2405\n",
      "Epoch 006 | Train Loss: 0.9750 | Val Loss: 1.2270\n",
      "Epoch 007 | Train Loss: 0.9948 | Val Loss: 1.1932\n",
      "Epoch 008 | Train Loss: 0.9781 | Val Loss: 1.1878\n",
      "Epoch 009 | Train Loss: 0.9917 | Val Loss: 1.1738\n",
      "Epoch 010 | Train Loss: 0.9838 | Val Loss: 1.2105\n",
      "Epoch 011 | Train Loss: 0.9368 | Val Loss: 1.1730\n",
      "Epoch 012 | Train Loss: 0.9451 | Val Loss: 1.1608\n",
      "Epoch 013 | Train Loss: 0.9919 | Val Loss: 1.1919\n",
      "Epoch 014 | Train Loss: 0.9949 | Val Loss: 1.2168\n",
      "Epoch 015 | Train Loss: 0.9737 | Val Loss: 1.1535\n",
      "Epoch 016 | Train Loss: 0.9318 | Val Loss: 1.2761\n",
      "Epoch 017 | Train Loss: 0.9191 | Val Loss: 1.1639\n",
      "Epoch 018 | Train Loss: 0.9824 | Val Loss: 1.1555\n",
      "Epoch 019 | Train Loss: 0.9515 | Val Loss: 1.2107\n",
      "Epoch 020 | Train Loss: 0.9073 | Val Loss: 1.1237\n",
      "Epoch 021 | Train Loss: 0.9426 | Val Loss: 1.1173\n",
      "Epoch 022 | Train Loss: 0.9308 | Val Loss: 1.1161\n",
      "Epoch 023 | Train Loss: 0.9027 | Val Loss: 1.2621\n",
      "Epoch 024 | Train Loss: 0.9577 | Val Loss: 1.2033\n",
      "Epoch 025 | Train Loss: 0.9001 | Val Loss: 1.1114\n",
      "Epoch 026 | Train Loss: 0.8916 | Val Loss: 1.1031\n",
      "Epoch 027 | Train Loss: 0.9643 | Val Loss: 1.1667\n",
      "Epoch 028 | Train Loss: 0.9007 | Val Loss: 1.0901\n",
      "Epoch 029 | Train Loss: 0.9443 | Val Loss: 1.1155\n",
      "Epoch 030 | Train Loss: 0.9009 | Val Loss: 1.0846\n",
      "Epoch 031 | Train Loss: 0.9004 | Val Loss: 1.1270\n",
      "Epoch 032 | Train Loss: 0.9128 | Val Loss: 1.2085\n",
      "Epoch 033 | Train Loss: 0.9407 | Val Loss: 1.0953\n",
      "Epoch 034 | Train Loss: 0.8930 | Val Loss: 1.1124\n",
      "Epoch 035 | Train Loss: 0.9778 | Val Loss: 1.0716\n",
      "Epoch 036 | Train Loss: 0.9090 | Val Loss: 1.0762\n",
      "Epoch 037 | Train Loss: 0.8680 | Val Loss: 1.0702\n",
      "Epoch 038 | Train Loss: 0.8700 | Val Loss: 1.0841\n",
      "Epoch 039 | Train Loss: 0.8707 | Val Loss: 1.2039\n",
      "Epoch 040 | Train Loss: 0.8626 | Val Loss: 1.0620\n",
      "Epoch 041 | Train Loss: 0.8605 | Val Loss: 1.0563\n",
      "Epoch 042 | Train Loss: 0.8742 | Val Loss: 1.1030\n",
      "Epoch 043 | Train Loss: 0.8670 | Val Loss: 1.0501\n",
      "Epoch 044 | Train Loss: 0.8778 | Val Loss: 1.1303\n",
      "Epoch 045 | Train Loss: 0.8932 | Val Loss: 1.0525\n",
      "Epoch 046 | Train Loss: 0.9023 | Val Loss: 1.0785\n",
      "Epoch 047 | Train Loss: 0.8900 | Val Loss: 1.1920\n",
      "Epoch 048 | Train Loss: 0.9934 | Val Loss: 1.0456\n",
      "Epoch 049 | Train Loss: 0.8598 | Val Loss: 1.0774\n",
      "Epoch 050 | Train Loss: 0.8806 | Val Loss: 1.0488\n",
      "Epoch 051 | Train Loss: 0.8956 | Val Loss: 1.1114\n",
      "Epoch 052 | Train Loss: 0.8487 | Val Loss: 1.0391\n",
      "Epoch 053 | Train Loss: 0.8646 | Val Loss: 1.1239\n",
      "Epoch 054 | Train Loss: 0.8912 | Val Loss: 1.1065\n",
      "Epoch 055 | Train Loss: 0.8750 | Val Loss: 1.0631\n",
      "Epoch 056 | Train Loss: 0.8385 | Val Loss: 1.1294\n",
      "Epoch 057 | Train Loss: 0.8785 | Val Loss: 1.0460\n",
      "Epoch 058 | Train Loss: 0.9532 | Val Loss: 1.0214\n",
      "Epoch 059 | Train Loss: 0.8389 | Val Loss: 1.0412\n",
      "Epoch 060 | Train Loss: 0.9502 | Val Loss: 1.0741\n",
      "Epoch 061 | Train Loss: 0.8555 | Val Loss: 1.0552\n",
      "Epoch 062 | Train Loss: 0.8374 | Val Loss: 1.0770\n",
      "Epoch 063 | Train Loss: 0.8669 | Val Loss: 1.0876\n",
      "Epoch 064 | Train Loss: 0.9069 | Val Loss: 1.2988\n",
      "Epoch 065 | Train Loss: 0.9615 | Val Loss: 1.0804\n",
      "Epoch 066 | Train Loss: 0.8981 | Val Loss: 1.0243\n",
      "Epoch 067 | Train Loss: 0.8422 | Val Loss: 1.0521\n",
      "Epoch 068 | Train Loss: 0.8222 | Val Loss: 1.0522\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 069 | Train Loss: 0.8530 | Val Loss: 1.0516\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 070 | Train Loss: 0.8569 | Val Loss: 1.0584\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 071 | Train Loss: 0.8288 | Val Loss: 1.0291\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 072 | Train Loss: 0.8631 | Val Loss: 1.1990\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 073 | Train Loss: 0.8495 | Val Loss: 1.1424\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 074 | Train Loss: 0.8877 | Val Loss: 1.0732\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 075 | Train Loss: 0.8883 | Val Loss: 1.0955\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 076 | Train Loss: 0.9000 | Val Loss: 1.2306\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 077 | Train Loss: 0.8282 | Val Loss: 1.0396\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 078 | Train Loss: 0.9380 | Val Loss: 1.1013\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 079 | Train Loss: 0.8597 | Val Loss: 1.0260\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 080 | Train Loss: 0.8181 | Val Loss: 1.0297\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 081 | Train Loss: 0.8791 | Val Loss: 1.0347\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 082 | Train Loss: 0.8315 | Val Loss: 1.0206\n",
      "Epoch 083 | Train Loss: 0.8180 | Val Loss: 1.0309\n",
      "Epoch 084 | Train Loss: 0.8419 | Val Loss: 1.0299\n",
      "Epoch 085 | Train Loss: 0.8374 | Val Loss: 1.0056\n",
      "Epoch 086 | Train Loss: 0.8302 | Val Loss: 1.0766\n",
      "Epoch 087 | Train Loss: 0.8144 | Val Loss: 1.0098\n",
      "Epoch 088 | Train Loss: 0.8164 | Val Loss: 0.9994\n",
      "Epoch 089 | Train Loss: 0.8037 | Val Loss: 1.0453\n",
      "Epoch 090 | Train Loss: 0.8830 | Val Loss: 1.0283\n",
      "Epoch 091 | Train Loss: 0.9052 | Val Loss: 1.0089\n",
      "Epoch 092 | Train Loss: 0.9247 | Val Loss: 1.2740\n",
      "Epoch 093 | Train Loss: 0.9605 | Val Loss: 1.0078\n",
      "Epoch 094 | Train Loss: 0.7988 | Val Loss: 1.0160\n",
      "Epoch 095 | Train Loss: 0.8105 | Val Loss: 1.0543\n",
      "Epoch 096 | Train Loss: 0.8186 | Val Loss: 0.9952\n",
      "Epoch 097 | Train Loss: 0.7818 | Val Loss: 1.0246\n",
      "Epoch 098 | Train Loss: 0.8114 | Val Loss: 0.9924\n",
      "Epoch 099 | Train Loss: 0.8160 | Val Loss: 1.0693\n",
      "Epoch 100 | Train Loss: 0.8432 | Val Loss: 1.0008\n",
      "Epoch 101 | Train Loss: 0.8496 | Val Loss: 0.9889\n",
      "Epoch 102 | Train Loss: 0.8017 | Val Loss: 1.0491\n",
      "Epoch 103 | Train Loss: 0.8101 | Val Loss: 1.0728\n",
      "Epoch 104 | Train Loss: 0.8655 | Val Loss: 1.0037\n",
      "Epoch 105 | Train Loss: 0.8185 | Val Loss: 1.1467\n",
      "Epoch 106 | Train Loss: 0.9021 | Val Loss: 0.9767\n",
      "Epoch 107 | Train Loss: 0.8458 | Val Loss: 1.0070\n",
      "Epoch 108 | Train Loss: 0.8129 | Val Loss: 1.0190\n",
      "Epoch 109 | Train Loss: 0.8492 | Val Loss: 0.9967\n",
      "Epoch 110 | Train Loss: 0.8763 | Val Loss: 1.0183\n",
      "Epoch 111 | Train Loss: 0.8153 | Val Loss: 0.9835\n",
      "Epoch 112 | Train Loss: 0.8177 | Val Loss: 1.0364\n",
      "Epoch 113 | Train Loss: 0.8615 | Val Loss: 0.9998\n",
      "Epoch 114 | Train Loss: 0.8247 | Val Loss: 1.0713\n",
      "Epoch 115 | Train Loss: 0.8444 | Val Loss: 1.2239\n",
      "Epoch 116 | Train Loss: 0.9171 | Val Loss: 0.9799\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 117 | Train Loss: 0.8752 | Val Loss: 1.1651\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 118 | Train Loss: 0.8116 | Val Loss: 0.9770\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 119 | Train Loss: 0.8330 | Val Loss: 1.0174\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 120 | Train Loss: 0.8169 | Val Loss: 0.9860\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 121 | Train Loss: 0.8024 | Val Loss: 0.9866\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 122 | Train Loss: 0.8455 | Val Loss: 0.9879\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 123 | Train Loss: 0.8041 | Val Loss: 1.0589\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 124 | Train Loss: 0.8018 | Val Loss: 1.0464\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 125 | Train Loss: 0.8090 | Val Loss: 1.1073\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 126 | Train Loss: 0.8976 | Val Loss: 0.9775\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 127 | Train Loss: 0.8263 | Val Loss: 0.9739\n",
      "Epoch 128 | Train Loss: 0.7699 | Val Loss: 1.0773\n",
      "Epoch 129 | Train Loss: 0.8604 | Val Loss: 1.0733\n",
      "Epoch 130 | Train Loss: 0.8044 | Val Loss: 0.9926\n",
      "Epoch 131 | Train Loss: 0.7717 | Val Loss: 0.9984\n",
      "Epoch 132 | Train Loss: 0.7957 | Val Loss: 0.9554\n",
      "Epoch 133 | Train Loss: 0.8334 | Val Loss: 0.9560\n",
      "Epoch 134 | Train Loss: 0.7732 | Val Loss: 0.9592\n",
      "Epoch 135 | Train Loss: 0.8170 | Val Loss: 1.0191\n",
      "Epoch 136 | Train Loss: 0.7832 | Val Loss: 0.9590\n",
      "Epoch 137 | Train Loss: 0.7995 | Val Loss: 0.9495\n",
      "Epoch 138 | Train Loss: 0.8590 | Val Loss: 1.1028\n",
      "Epoch 139 | Train Loss: 0.8381 | Val Loss: 0.9990\n",
      "Epoch 140 | Train Loss: 0.7709 | Val Loss: 0.9740\n",
      "Epoch 141 | Train Loss: 0.8865 | Val Loss: 1.0539\n",
      "Epoch 142 | Train Loss: 0.8104 | Val Loss: 0.9558\n",
      "Epoch 143 | Train Loss: 0.8227 | Val Loss: 0.9455\n",
      "Epoch 144 | Train Loss: 0.8457 | Val Loss: 0.9707\n",
      "Epoch 145 | Train Loss: 0.8106 | Val Loss: 0.9544\n",
      "Epoch 146 | Train Loss: 0.8089 | Val Loss: 1.0186\n",
      "Epoch 147 | Train Loss: 0.8204 | Val Loss: 1.0317\n",
      "Epoch 148 | Train Loss: 0.8321 | Val Loss: 0.9650\n",
      "Epoch 149 | Train Loss: 0.8396 | Val Loss: 0.9488\n",
      "Epoch 150 | Train Loss: 0.7415 | Val Loss: 0.9577\n",
      "Epoch 151 | Train Loss: 0.7813 | Val Loss: 0.9349\n",
      "Epoch 152 | Train Loss: 0.7803 | Val Loss: 0.9394\n",
      "Epoch 153 | Train Loss: 0.7964 | Val Loss: 0.9627\n",
      "Epoch 154 | Train Loss: 0.8222 | Val Loss: 0.9754\n",
      "Epoch 155 | Train Loss: 0.7833 | Val Loss: 0.9426\n",
      "Epoch 156 | Train Loss: 0.7798 | Val Loss: 0.9373\n",
      "Epoch 157 | Train Loss: 0.7715 | Val Loss: 0.9300\n",
      "Epoch 158 | Train Loss: 0.7720 | Val Loss: 0.9311\n",
      "Epoch 159 | Train Loss: 0.7692 | Val Loss: 0.9912\n",
      "Epoch 160 | Train Loss: 0.8214 | Val Loss: 1.0231\n",
      "Epoch 161 | Train Loss: 0.8489 | Val Loss: 0.9382\n",
      "Epoch 162 | Train Loss: 0.7721 | Val Loss: 0.9789\n",
      "Epoch 163 | Train Loss: 0.8468 | Val Loss: 0.9513\n",
      "Epoch 164 | Train Loss: 0.7825 | Val Loss: 0.9635\n",
      "Epoch 165 | Train Loss: 0.7587 | Val Loss: 0.9742\n",
      "Epoch 166 | Train Loss: 0.7600 | Val Loss: 1.0263\n",
      "Epoch 167 | Train Loss: 0.8130 | Val Loss: 0.9662\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 168 | Train Loss: 0.8775 | Val Loss: 1.1242\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 169 | Train Loss: 0.7801 | Val Loss: 0.9661\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 170 | Train Loss: 0.7757 | Val Loss: 0.9457\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 171 | Train Loss: 0.7557 | Val Loss: 0.9400\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 172 | Train Loss: 0.7530 | Val Loss: 1.0395\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 173 | Train Loss: 0.8279 | Val Loss: 1.0302\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 174 | Train Loss: 0.8615 | Val Loss: 0.9466\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 175 | Train Loss: 0.7944 | Val Loss: 0.9542\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 176 | Train Loss: 0.7697 | Val Loss: 0.9315\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 177 | Train Loss: 0.7869 | Val Loss: 1.0434\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 178 | Train Loss: 0.8065 | Val Loss: 0.9594\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 179 | Train Loss: 0.7518 | Val Loss: 0.9270\n",
      "Epoch 180 | Train Loss: 0.7588 | Val Loss: 0.9423\n",
      "Epoch 181 | Train Loss: 0.7717 | Val Loss: 1.0618\n",
      "Epoch 182 | Train Loss: 0.7702 | Val Loss: 0.9272\n",
      "Epoch 183 | Train Loss: 0.7412 | Val Loss: 0.9347\n",
      "Epoch 184 | Train Loss: 0.7785 | Val Loss: 0.9282\n",
      "Epoch 185 | Train Loss: 0.8809 | Val Loss: 0.9783\n",
      "Epoch 186 | Train Loss: 0.8231 | Val Loss: 1.2358\n",
      "Epoch 187 | Train Loss: 0.9566 | Val Loss: 0.9820\n",
      "Epoch 188 | Train Loss: 1.0442 | Val Loss: 0.9667\n",
      "Epoch 189 | Train Loss: 0.8579 | Val Loss: 1.1639\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 190 | Train Loss: 0.7661 | Val Loss: 1.0240\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 191 | Train Loss: 0.7738 | Val Loss: 1.0403\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 192 | Train Loss: 0.8498 | Val Loss: 0.9304\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 193 | Train Loss: 0.7527 | Val Loss: 0.9435\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 194 | Train Loss: 0.7675 | Val Loss: 0.9837\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "Epoch 195 | Train Loss: 0.7353 | Val Loss: 0.9141\n",
      "Epoch 196 | Train Loss: 0.7586 | Val Loss: 1.1560\n",
      "Epoch 197 | Train Loss: 0.7723 | Val Loss: 0.9774\n",
      "Epoch 198 | Train Loss: 0.7881 | Val Loss: 0.9552\n",
      "Epoch 199 | Train Loss: 0.7690 | Val Loss: 0.9699\n",
      "Epoch 200 | Train Loss: 0.7547 | Val Loss: 0.9102\n"
     ]
    }
   ],
   "source": [
    "for fold in range(10):\n",
    "    print(f\"\\nüîÅ Re-training Fold {fold+1}/10 with best hyperparameters\")\n",
    "    train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    val_data = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "    model = MPNN(input_dim, edge_dim, hidden_dim=best_hidden_dim, output_dim=output_dim, dropout=best_dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch)\n",
    "            loss = F.mse_loss(out.squeeze(), batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        outputs, targets = evaluate(model, val_loader)\n",
    "        val_loss = F.mse_loss(outputs.squeeze(), targets).item()\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Train Loss: {total_loss / len(train_loader):.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(results_dir, f\"fold{fold+1}_model.pt\"))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 10:\n",
    "                print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a70365de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Retraining Fold 1/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 19.4770 | Val Loss: 6.9815\n",
      "Epoch 002 | Train Loss: 2.7299 | Val Loss: 1.4769\n",
      "Epoch 003 | Train Loss: 1.3094 | Val Loss: 1.2020\n",
      "Epoch 004 | Train Loss: 1.1023 | Val Loss: 1.0399\n",
      "Epoch 005 | Train Loss: 1.0484 | Val Loss: 0.9014\n",
      "Epoch 006 | Train Loss: 1.0011 | Val Loss: 0.9211\n",
      "Epoch 007 | Train Loss: 1.0061 | Val Loss: 0.9527\n",
      "Epoch 008 | Train Loss: 0.9790 | Val Loss: 0.8577\n",
      "Epoch 009 | Train Loss: 1.0361 | Val Loss: 0.8302\n",
      "Epoch 010 | Train Loss: 1.0268 | Val Loss: 0.8859\n",
      "Epoch 011 | Train Loss: 0.9679 | Val Loss: 1.0130\n",
      "Epoch 012 | Train Loss: 0.9906 | Val Loss: 0.9331\n",
      "Epoch 013 | Train Loss: 0.9816 | Val Loss: 0.8253\n",
      "Epoch 014 | Train Loss: 0.9765 | Val Loss: 0.8148\n",
      "Epoch 015 | Train Loss: 1.0437 | Val Loss: 0.8344\n",
      "Epoch 016 | Train Loss: 0.9775 | Val Loss: 0.8799\n",
      "Epoch 017 | Train Loss: 0.9755 | Val Loss: 0.8786\n",
      "Epoch 018 | Train Loss: 1.0039 | Val Loss: 0.8214\n",
      "Epoch 019 | Train Loss: 1.0281 | Val Loss: 0.8489\n",
      "Epoch 020 | Train Loss: 1.0059 | Val Loss: 0.8034\n",
      "Epoch 021 | Train Loss: 1.0275 | Val Loss: 0.8350\n",
      "Epoch 022 | Train Loss: 0.9323 | Val Loss: 1.0180\n",
      "Epoch 023 | Train Loss: 0.9763 | Val Loss: 0.8485\n",
      "Epoch 024 | Train Loss: 0.9151 | Val Loss: 0.8157\n",
      "Epoch 025 | Train Loss: 1.0375 | Val Loss: 0.8953\n",
      "Epoch 026 | Train Loss: 0.9694 | Val Loss: 0.8524\n",
      "Epoch 027 | Train Loss: 0.9927 | Val Loss: 1.1204\n",
      "Epoch 028 | Train Loss: 0.9570 | Val Loss: 1.0869\n",
      "Epoch 029 | Train Loss: 1.0821 | Val Loss: 1.0792\n",
      "Epoch 030 | Train Loss: 0.9267 | Val Loss: 1.0422\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 2/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 17.0485 | Val Loss: 6.3263\n",
      "Epoch 002 | Train Loss: 2.0903 | Val Loss: 1.4627\n",
      "Epoch 003 | Train Loss: 1.2244 | Val Loss: 1.0404\n",
      "Epoch 004 | Train Loss: 1.0598 | Val Loss: 1.1048\n",
      "Epoch 005 | Train Loss: 1.0229 | Val Loss: 1.0014\n",
      "Epoch 006 | Train Loss: 0.9874 | Val Loss: 0.9993\n",
      "Epoch 007 | Train Loss: 0.9710 | Val Loss: 1.0709\n",
      "Epoch 008 | Train Loss: 0.9939 | Val Loss: 0.9919\n",
      "Epoch 009 | Train Loss: 0.9641 | Val Loss: 0.9864\n",
      "Epoch 010 | Train Loss: 0.9849 | Val Loss: 0.9876\n",
      "Epoch 011 | Train Loss: 0.9952 | Val Loss: 0.9922\n",
      "Epoch 012 | Train Loss: 0.9719 | Val Loss: 1.0038\n",
      "Epoch 013 | Train Loss: 0.9423 | Val Loss: 1.0007\n",
      "Epoch 014 | Train Loss: 1.0005 | Val Loss: 0.9875\n",
      "Epoch 015 | Train Loss: 0.9835 | Val Loss: 0.9801\n",
      "Epoch 016 | Train Loss: 0.9817 | Val Loss: 0.9806\n",
      "Epoch 017 | Train Loss: 0.9547 | Val Loss: 0.9834\n",
      "Epoch 018 | Train Loss: 0.9218 | Val Loss: 1.4056\n",
      "Epoch 019 | Train Loss: 1.0085 | Val Loss: 1.0688\n",
      "Epoch 020 | Train Loss: 0.9519 | Val Loss: 1.0017\n",
      "Epoch 021 | Train Loss: 0.9648 | Val Loss: 1.0096\n",
      "Epoch 022 | Train Loss: 0.9933 | Val Loss: 1.0495\n",
      "Epoch 023 | Train Loss: 0.9908 | Val Loss: 0.9711\n",
      "Epoch 024 | Train Loss: 0.9113 | Val Loss: 0.9738\n",
      "Epoch 025 | Train Loss: 0.9406 | Val Loss: 1.0830\n",
      "Epoch 026 | Train Loss: 0.9440 | Val Loss: 0.9591\n",
      "Epoch 027 | Train Loss: 0.9339 | Val Loss: 0.9552\n",
      "Epoch 028 | Train Loss: 0.9625 | Val Loss: 1.1956\n",
      "Epoch 029 | Train Loss: 0.9958 | Val Loss: 0.9831\n",
      "Epoch 030 | Train Loss: 0.9366 | Val Loss: 0.9545\n",
      "Epoch 031 | Train Loss: 0.9871 | Val Loss: 0.9615\n",
      "Epoch 032 | Train Loss: 0.9330 | Val Loss: 0.9649\n",
      "Epoch 033 | Train Loss: 0.9207 | Val Loss: 1.0845\n",
      "Epoch 034 | Train Loss: 0.9943 | Val Loss: 0.9609\n",
      "Epoch 035 | Train Loss: 0.9363 | Val Loss: 0.9527\n",
      "Epoch 036 | Train Loss: 0.9095 | Val Loss: 0.9616\n",
      "Epoch 037 | Train Loss: 0.9391 | Val Loss: 0.9389\n",
      "Epoch 038 | Train Loss: 0.9151 | Val Loss: 0.9559\n",
      "Epoch 039 | Train Loss: 1.0271 | Val Loss: 0.9431\n",
      "Epoch 040 | Train Loss: 1.0062 | Val Loss: 1.0151\n",
      "Epoch 041 | Train Loss: 0.9509 | Val Loss: 0.9320\n",
      "Epoch 042 | Train Loss: 0.8984 | Val Loss: 0.9532\n",
      "Epoch 043 | Train Loss: 0.9156 | Val Loss: 0.9593\n",
      "Epoch 044 | Train Loss: 0.9326 | Val Loss: 0.9501\n",
      "Epoch 045 | Train Loss: 0.8720 | Val Loss: 0.9488\n",
      "Epoch 046 | Train Loss: 0.8750 | Val Loss: 1.0413\n",
      "Epoch 047 | Train Loss: 0.9319 | Val Loss: 1.0217\n",
      "Epoch 048 | Train Loss: 0.8755 | Val Loss: 0.9192\n",
      "Epoch 049 | Train Loss: 0.8948 | Val Loss: 1.1195\n",
      "Epoch 050 | Train Loss: 0.9256 | Val Loss: 0.9180\n",
      "Epoch 051 | Train Loss: 0.8848 | Val Loss: 0.9302\n",
      "Epoch 052 | Train Loss: 0.8924 | Val Loss: 0.9200\n",
      "Epoch 053 | Train Loss: 0.8820 | Val Loss: 0.9385\n",
      "Epoch 054 | Train Loss: 0.9302 | Val Loss: 1.0750\n",
      "Epoch 055 | Train Loss: 0.8871 | Val Loss: 0.9076\n",
      "Epoch 056 | Train Loss: 0.8751 | Val Loss: 0.9130\n",
      "Epoch 057 | Train Loss: 0.8820 | Val Loss: 0.9040\n",
      "Epoch 058 | Train Loss: 0.9384 | Val Loss: 0.9877\n",
      "Epoch 059 | Train Loss: 0.8907 | Val Loss: 0.9399\n",
      "Epoch 060 | Train Loss: 0.8847 | Val Loss: 0.9008\n",
      "Epoch 061 | Train Loss: 0.9097 | Val Loss: 0.9121\n",
      "Epoch 062 | Train Loss: 0.9187 | Val Loss: 1.2912\n",
      "Epoch 063 | Train Loss: 0.9554 | Val Loss: 1.0053\n",
      "Epoch 064 | Train Loss: 0.9803 | Val Loss: 0.8935\n",
      "Epoch 065 | Train Loss: 0.8723 | Val Loss: 0.8856\n",
      "Epoch 066 | Train Loss: 0.9390 | Val Loss: 0.8829\n",
      "Epoch 067 | Train Loss: 0.9001 | Val Loss: 0.8977\n",
      "Epoch 068 | Train Loss: 0.8367 | Val Loss: 1.0083\n",
      "Epoch 069 | Train Loss: 0.8756 | Val Loss: 0.8779\n",
      "Epoch 070 | Train Loss: 0.8885 | Val Loss: 0.8822\n",
      "Epoch 071 | Train Loss: 0.9432 | Val Loss: 0.8834\n",
      "Epoch 072 | Train Loss: 0.9619 | Val Loss: 0.8895\n",
      "Epoch 073 | Train Loss: 0.9308 | Val Loss: 1.2120\n",
      "Epoch 074 | Train Loss: 1.0191 | Val Loss: 0.9582\n",
      "Epoch 075 | Train Loss: 1.0118 | Val Loss: 0.9101\n",
      "Epoch 076 | Train Loss: 0.9351 | Val Loss: 0.9211\n",
      "Epoch 077 | Train Loss: 0.8611 | Val Loss: 0.8783\n",
      "Epoch 078 | Train Loss: 0.8968 | Val Loss: 0.8651\n",
      "Epoch 079 | Train Loss: 0.8572 | Val Loss: 0.9262\n",
      "Epoch 080 | Train Loss: 0.9438 | Val Loss: 0.8724\n",
      "Epoch 081 | Train Loss: 0.8687 | Val Loss: 0.8743\n",
      "Epoch 082 | Train Loss: 0.8967 | Val Loss: 0.9149\n",
      "Epoch 083 | Train Loss: 0.9473 | Val Loss: 0.9605\n",
      "Epoch 084 | Train Loss: 0.9552 | Val Loss: 0.9538\n",
      "Epoch 085 | Train Loss: 0.8429 | Val Loss: 0.8607\n",
      "Epoch 086 | Train Loss: 0.8842 | Val Loss: 0.9828\n",
      "Epoch 087 | Train Loss: 0.8947 | Val Loss: 0.8585\n",
      "Epoch 088 | Train Loss: 0.8270 | Val Loss: 0.8986\n",
      "Epoch 089 | Train Loss: 0.9167 | Val Loss: 0.8763\n",
      "Epoch 090 | Train Loss: 0.8472 | Val Loss: 0.8529\n",
      "Epoch 091 | Train Loss: 0.8617 | Val Loss: 0.8523\n",
      "Epoch 092 | Train Loss: 0.8487 | Val Loss: 0.8534\n",
      "Epoch 093 | Train Loss: 0.8705 | Val Loss: 1.0032\n",
      "Epoch 094 | Train Loss: 0.9036 | Val Loss: 0.8454\n",
      "Epoch 095 | Train Loss: 0.8256 | Val Loss: 0.8567\n",
      "Epoch 096 | Train Loss: 0.8753 | Val Loss: 0.9266\n",
      "Epoch 097 | Train Loss: 0.9063 | Val Loss: 0.8438\n",
      "Epoch 098 | Train Loss: 0.8678 | Val Loss: 0.9967\n",
      "Epoch 099 | Train Loss: 0.8888 | Val Loss: 0.8839\n",
      "Epoch 100 | Train Loss: 0.8750 | Val Loss: 0.8487\n",
      "Epoch 101 | Train Loss: 0.8218 | Val Loss: 0.9733\n",
      "Epoch 102 | Train Loss: 0.9092 | Val Loss: 0.8878\n",
      "Epoch 103 | Train Loss: 0.8242 | Val Loss: 0.9124\n",
      "Epoch 104 | Train Loss: 0.8283 | Val Loss: 0.8358\n",
      "Epoch 105 | Train Loss: 0.8477 | Val Loss: 0.8900\n",
      "Epoch 106 | Train Loss: 0.8762 | Val Loss: 0.9380\n",
      "Epoch 107 | Train Loss: 0.8108 | Val Loss: 0.8632\n",
      "Epoch 108 | Train Loss: 0.8302 | Val Loss: 0.8309\n",
      "Epoch 109 | Train Loss: 0.8163 | Val Loss: 0.8860\n",
      "Epoch 110 | Train Loss: 0.8081 | Val Loss: 0.8289\n",
      "Epoch 111 | Train Loss: 0.8467 | Val Loss: 0.8814\n",
      "Epoch 112 | Train Loss: 0.8337 | Val Loss: 0.8257\n",
      "Epoch 113 | Train Loss: 0.8185 | Val Loss: 0.8372\n",
      "Epoch 114 | Train Loss: 0.8447 | Val Loss: 0.8540\n",
      "Epoch 115 | Train Loss: 0.8233 | Val Loss: 0.8297\n",
      "Epoch 116 | Train Loss: 0.8891 | Val Loss: 0.8631\n",
      "Epoch 117 | Train Loss: 0.8129 | Val Loss: 0.8539\n",
      "Epoch 118 | Train Loss: 0.8168 | Val Loss: 0.8188\n",
      "Epoch 119 | Train Loss: 0.8091 | Val Loss: 0.8215\n",
      "Epoch 120 | Train Loss: 0.7892 | Val Loss: 0.8399\n",
      "Epoch 121 | Train Loss: 0.7937 | Val Loss: 0.8768\n",
      "Epoch 122 | Train Loss: 0.8367 | Val Loss: 0.8184\n",
      "Epoch 123 | Train Loss: 0.8233 | Val Loss: 0.8477\n",
      "Epoch 124 | Train Loss: 0.9623 | Val Loss: 0.8364\n",
      "Epoch 125 | Train Loss: 0.8519 | Val Loss: 0.9382\n",
      "Epoch 126 | Train Loss: 0.8697 | Val Loss: 0.8115\n",
      "Epoch 127 | Train Loss: 0.8747 | Val Loss: 0.8189\n",
      "Epoch 128 | Train Loss: 0.8818 | Val Loss: 0.8588\n",
      "Epoch 129 | Train Loss: 0.8450 | Val Loss: 0.8102\n",
      "Epoch 130 | Train Loss: 0.8229 | Val Loss: 0.8218\n",
      "Epoch 131 | Train Loss: 0.8199 | Val Loss: 0.8094\n",
      "Epoch 132 | Train Loss: 0.8445 | Val Loss: 0.9985\n",
      "Epoch 133 | Train Loss: 0.9739 | Val Loss: 0.8174\n",
      "Epoch 134 | Train Loss: 0.9967 | Val Loss: 0.8186\n",
      "Epoch 135 | Train Loss: 0.8687 | Val Loss: 0.9329\n",
      "Epoch 136 | Train Loss: 0.8540 | Val Loss: 0.8565\n",
      "Epoch 137 | Train Loss: 0.8753 | Val Loss: 0.8230\n",
      "Epoch 138 | Train Loss: 0.8368 | Val Loss: 0.8469\n",
      "Epoch 139 | Train Loss: 0.8632 | Val Loss: 0.9207\n",
      "Epoch 140 | Train Loss: 0.8853 | Val Loss: 0.8112\n",
      "Epoch 141 | Train Loss: 0.7907 | Val Loss: 0.8094\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 3/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 14.1188 | Val Loss: 1.8940\n",
      "Epoch 002 | Train Loss: 1.7182 | Val Loss: 1.5252\n",
      "Epoch 003 | Train Loss: 1.0980 | Val Loss: 1.4339\n",
      "Epoch 004 | Train Loss: 1.0812 | Val Loss: 0.9401\n",
      "Epoch 005 | Train Loss: 0.9798 | Val Loss: 1.2936\n",
      "Epoch 006 | Train Loss: 0.9830 | Val Loss: 1.2026\n",
      "Epoch 007 | Train Loss: 0.9816 | Val Loss: 0.8939\n",
      "Epoch 008 | Train Loss: 1.0078 | Val Loss: 0.9849\n",
      "Epoch 009 | Train Loss: 0.9703 | Val Loss: 1.0004\n",
      "Epoch 010 | Train Loss: 0.9815 | Val Loss: 1.1978\n",
      "Epoch 011 | Train Loss: 0.9698 | Val Loss: 1.2883\n",
      "Epoch 012 | Train Loss: 1.0074 | Val Loss: 1.0675\n",
      "Epoch 013 | Train Loss: 1.0242 | Val Loss: 0.9130\n",
      "Epoch 014 | Train Loss: 0.9819 | Val Loss: 1.1255\n",
      "Epoch 015 | Train Loss: 0.9302 | Val Loss: 0.9096\n",
      "Epoch 016 | Train Loss: 0.9860 | Val Loss: 0.9512\n",
      "Epoch 017 | Train Loss: 0.9552 | Val Loss: 1.1098\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 4/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 11.7161 | Val Loss: 1.7047\n",
      "Epoch 002 | Train Loss: 1.7187 | Val Loss: 0.9211\n",
      "Epoch 003 | Train Loss: 1.4121 | Val Loss: 1.1076\n",
      "Epoch 004 | Train Loss: 1.0966 | Val Loss: 0.8851\n",
      "Epoch 005 | Train Loss: 1.0620 | Val Loss: 0.8725\n",
      "Epoch 006 | Train Loss: 1.0061 | Val Loss: 0.9000\n",
      "Epoch 007 | Train Loss: 1.0191 | Val Loss: 0.8771\n",
      "Epoch 008 | Train Loss: 0.9902 | Val Loss: 0.8906\n",
      "Epoch 009 | Train Loss: 1.0589 | Val Loss: 0.8456\n",
      "Epoch 010 | Train Loss: 0.9832 | Val Loss: 0.8292\n",
      "Epoch 011 | Train Loss: 0.9820 | Val Loss: 0.8252\n",
      "Epoch 012 | Train Loss: 0.9842 | Val Loss: 1.0391\n",
      "Epoch 013 | Train Loss: 1.0723 | Val Loss: 0.8257\n",
      "Epoch 014 | Train Loss: 1.0192 | Val Loss: 0.8132\n",
      "Epoch 015 | Train Loss: 1.0386 | Val Loss: 0.8083\n",
      "Epoch 016 | Train Loss: 0.9618 | Val Loss: 0.8078\n",
      "Epoch 017 | Train Loss: 0.9947 | Val Loss: 0.8305\n",
      "Epoch 018 | Train Loss: 1.0105 | Val Loss: 0.7952\n",
      "Epoch 019 | Train Loss: 0.9703 | Val Loss: 0.7931\n",
      "Epoch 020 | Train Loss: 0.9619 | Val Loss: 0.7918\n",
      "Epoch 021 | Train Loss: 1.0021 | Val Loss: 0.7866\n",
      "Epoch 022 | Train Loss: 0.9860 | Val Loss: 0.7847\n",
      "Epoch 023 | Train Loss: 0.9653 | Val Loss: 0.8031\n",
      "Epoch 024 | Train Loss: 0.9679 | Val Loss: 0.7775\n",
      "Epoch 025 | Train Loss: 1.0059 | Val Loss: 0.8363\n",
      "Epoch 026 | Train Loss: 0.9960 | Val Loss: 0.7762\n",
      "Epoch 027 | Train Loss: 0.9773 | Val Loss: 0.7725\n",
      "Epoch 028 | Train Loss: 0.9935 | Val Loss: 0.7705\n",
      "Epoch 029 | Train Loss: 0.9987 | Val Loss: 0.8248\n",
      "Epoch 030 | Train Loss: 0.9895 | Val Loss: 0.7692\n",
      "Epoch 031 | Train Loss: 0.9933 | Val Loss: 0.9164\n",
      "Epoch 032 | Train Loss: 1.0418 | Val Loss: 0.9171\n",
      "Epoch 033 | Train Loss: 1.0084 | Val Loss: 0.7855\n",
      "Epoch 034 | Train Loss: 0.9479 | Val Loss: 0.7710\n",
      "Epoch 035 | Train Loss: 0.9362 | Val Loss: 0.7623\n",
      "Epoch 036 | Train Loss: 0.9221 | Val Loss: 0.7698\n",
      "Epoch 037 | Train Loss: 0.9376 | Val Loss: 0.8213\n",
      "Epoch 038 | Train Loss: 0.9535 | Val Loss: 0.7583\n",
      "Epoch 039 | Train Loss: 0.9495 | Val Loss: 0.8027\n",
      "Epoch 040 | Train Loss: 1.0597 | Val Loss: 0.8620\n",
      "Epoch 041 | Train Loss: 1.0123 | Val Loss: 0.8514\n",
      "Epoch 042 | Train Loss: 0.9235 | Val Loss: 0.8134\n",
      "Epoch 043 | Train Loss: 0.9566 | Val Loss: 0.8302\n",
      "Epoch 044 | Train Loss: 0.9601 | Val Loss: 0.8203\n",
      "Epoch 045 | Train Loss: 0.9468 | Val Loss: 0.8638\n",
      "Epoch 046 | Train Loss: 0.9756 | Val Loss: 0.7478\n",
      "Epoch 047 | Train Loss: 0.9113 | Val Loss: 0.7964\n",
      "Epoch 048 | Train Loss: 0.9408 | Val Loss: 0.7442\n",
      "Epoch 049 | Train Loss: 0.9787 | Val Loss: 0.9015\n",
      "Epoch 050 | Train Loss: 0.9168 | Val Loss: 0.7488\n",
      "Epoch 051 | Train Loss: 0.9407 | Val Loss: 0.8130\n",
      "Epoch 052 | Train Loss: 1.0243 | Val Loss: 0.8020\n",
      "Epoch 053 | Train Loss: 0.9092 | Val Loss: 0.7386\n",
      "Epoch 054 | Train Loss: 0.9234 | Val Loss: 0.8165\n",
      "Epoch 055 | Train Loss: 0.9554 | Val Loss: 0.8093\n",
      "Epoch 056 | Train Loss: 0.9364 | Val Loss: 0.8366\n",
      "Epoch 057 | Train Loss: 0.9349 | Val Loss: 0.7490\n",
      "Epoch 058 | Train Loss: 1.0018 | Val Loss: 0.7286\n",
      "Epoch 059 | Train Loss: 0.9532 | Val Loss: 0.8751\n",
      "Epoch 060 | Train Loss: 0.9361 | Val Loss: 0.7456\n",
      "Epoch 061 | Train Loss: 0.9119 | Val Loss: 0.8214\n",
      "Epoch 062 | Train Loss: 0.9172 | Val Loss: 0.7726\n",
      "Epoch 063 | Train Loss: 0.9322 | Val Loss: 0.7793\n",
      "Epoch 064 | Train Loss: 0.9903 | Val Loss: 0.8827\n",
      "Epoch 065 | Train Loss: 1.0261 | Val Loss: 0.7266\n",
      "Epoch 066 | Train Loss: 0.8848 | Val Loss: 0.7387\n",
      "Epoch 067 | Train Loss: 0.9045 | Val Loss: 0.7440\n",
      "Epoch 068 | Train Loss: 0.8730 | Val Loss: 0.7399\n",
      "Epoch 069 | Train Loss: 0.8766 | Val Loss: 0.7333\n",
      "Epoch 070 | Train Loss: 0.8954 | Val Loss: 0.9637\n",
      "Epoch 071 | Train Loss: 0.8925 | Val Loss: 0.7219\n",
      "Epoch 072 | Train Loss: 0.8919 | Val Loss: 0.7469\n",
      "Epoch 073 | Train Loss: 0.8466 | Val Loss: 0.7231\n",
      "Epoch 074 | Train Loss: 0.8550 | Val Loss: 0.7306\n",
      "Epoch 075 | Train Loss: 0.8813 | Val Loss: 0.7141\n",
      "Epoch 076 | Train Loss: 0.8964 | Val Loss: 0.9536\n",
      "Epoch 077 | Train Loss: 0.9836 | Val Loss: 0.7366\n",
      "Epoch 078 | Train Loss: 0.8746 | Val Loss: 0.7620\n",
      "Epoch 079 | Train Loss: 0.8579 | Val Loss: 0.7998\n",
      "Epoch 080 | Train Loss: 0.9534 | Val Loss: 0.8320\n",
      "Epoch 081 | Train Loss: 0.9394 | Val Loss: 0.7382\n",
      "Epoch 082 | Train Loss: 0.8823 | Val Loss: 0.7144\n",
      "Epoch 083 | Train Loss: 0.9159 | Val Loss: 0.7088\n",
      "Epoch 084 | Train Loss: 0.8367 | Val Loss: 0.7188\n",
      "Epoch 085 | Train Loss: 0.8582 | Val Loss: 0.7202\n",
      "Epoch 086 | Train Loss: 0.8662 | Val Loss: 0.6932\n",
      "Epoch 087 | Train Loss: 0.8638 | Val Loss: 0.7589\n",
      "Epoch 088 | Train Loss: 0.8527 | Val Loss: 0.6969\n",
      "Epoch 089 | Train Loss: 0.8341 | Val Loss: 0.7891\n",
      "Epoch 090 | Train Loss: 0.8970 | Val Loss: 0.6945\n",
      "Epoch 091 | Train Loss: 0.8380 | Val Loss: 0.7108\n",
      "Epoch 092 | Train Loss: 0.8512 | Val Loss: 0.6881\n",
      "Epoch 093 | Train Loss: 0.8333 | Val Loss: 0.6844\n",
      "Epoch 094 | Train Loss: 0.8259 | Val Loss: 0.7269\n",
      "Epoch 095 | Train Loss: 0.8368 | Val Loss: 0.8167\n",
      "Epoch 096 | Train Loss: 0.8862 | Val Loss: 0.6798\n",
      "Epoch 097 | Train Loss: 0.8756 | Val Loss: 0.8053\n",
      "Epoch 098 | Train Loss: 0.9042 | Val Loss: 0.7264\n",
      "Epoch 099 | Train Loss: 1.0061 | Val Loss: 0.7211\n",
      "Epoch 100 | Train Loss: 0.8928 | Val Loss: 0.8544\n",
      "Epoch 101 | Train Loss: 0.9616 | Val Loss: 0.8505\n",
      "Epoch 102 | Train Loss: 1.0260 | Val Loss: 0.7037\n",
      "Epoch 103 | Train Loss: 0.9517 | Val Loss: 0.7010\n",
      "Epoch 104 | Train Loss: 0.8984 | Val Loss: 0.6909\n",
      "Epoch 105 | Train Loss: 0.8615 | Val Loss: 0.7150\n",
      "Epoch 106 | Train Loss: 0.8795 | Val Loss: 0.6936\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 5/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 17.1722 | Val Loss: 6.9328\n",
      "Epoch 002 | Train Loss: 2.3853 | Val Loss: 1.5762\n",
      "Epoch 003 | Train Loss: 1.3044 | Val Loss: 1.0784\n",
      "Epoch 004 | Train Loss: 1.0707 | Val Loss: 0.9982\n",
      "Epoch 005 | Train Loss: 1.0542 | Val Loss: 0.9707\n",
      "Epoch 006 | Train Loss: 0.9330 | Val Loss: 1.0932\n",
      "Epoch 007 | Train Loss: 0.9788 | Val Loss: 0.9562\n",
      "Epoch 008 | Train Loss: 0.9744 | Val Loss: 1.0085\n",
      "Epoch 009 | Train Loss: 0.9616 | Val Loss: 0.9595\n",
      "Epoch 010 | Train Loss: 1.0259 | Val Loss: 0.9466\n",
      "Epoch 011 | Train Loss: 0.9747 | Val Loss: 0.9544\n",
      "Epoch 012 | Train Loss: 0.9712 | Val Loss: 0.9399\n",
      "Epoch 013 | Train Loss: 0.9685 | Val Loss: 0.9409\n",
      "Epoch 014 | Train Loss: 0.9917 | Val Loss: 0.9486\n",
      "Epoch 015 | Train Loss: 1.0324 | Val Loss: 0.9282\n",
      "Epoch 016 | Train Loss: 0.9709 | Val Loss: 0.9952\n",
      "Epoch 017 | Train Loss: 0.9517 | Val Loss: 1.0192\n",
      "Epoch 018 | Train Loss: 0.9958 | Val Loss: 1.0592\n",
      "Epoch 019 | Train Loss: 0.9404 | Val Loss: 0.9279\n",
      "Epoch 020 | Train Loss: 0.9531 | Val Loss: 0.9382\n",
      "Epoch 021 | Train Loss: 0.9255 | Val Loss: 0.9111\n",
      "Epoch 022 | Train Loss: 0.9477 | Val Loss: 0.9468\n",
      "Epoch 023 | Train Loss: 0.9628 | Val Loss: 0.9075\n",
      "Epoch 024 | Train Loss: 1.0250 | Val Loss: 0.9160\n",
      "Epoch 025 | Train Loss: 1.0285 | Val Loss: 0.9208\n",
      "Epoch 026 | Train Loss: 0.9870 | Val Loss: 0.9035\n",
      "Epoch 027 | Train Loss: 0.9865 | Val Loss: 0.8998\n",
      "Epoch 028 | Train Loss: 0.9551 | Val Loss: 0.9249\n",
      "Epoch 029 | Train Loss: 0.9306 | Val Loss: 0.8893\n",
      "Epoch 030 | Train Loss: 0.9261 | Val Loss: 0.8933\n",
      "Epoch 031 | Train Loss: 0.9406 | Val Loss: 0.8974\n",
      "Epoch 032 | Train Loss: 0.9412 | Val Loss: 0.8820\n",
      "Epoch 033 | Train Loss: 0.9538 | Val Loss: 0.8809\n",
      "Epoch 034 | Train Loss: 0.9726 | Val Loss: 0.8760\n",
      "Epoch 035 | Train Loss: 0.9165 | Val Loss: 0.8946\n",
      "Epoch 036 | Train Loss: 0.9291 | Val Loss: 0.9229\n",
      "Epoch 037 | Train Loss: 1.0047 | Val Loss: 1.0816\n",
      "Epoch 038 | Train Loss: 0.9123 | Val Loss: 0.9714\n",
      "Epoch 039 | Train Loss: 0.9172 | Val Loss: 1.0446\n",
      "Epoch 040 | Train Loss: 0.9823 | Val Loss: 0.9778\n",
      "Epoch 041 | Train Loss: 0.9100 | Val Loss: 0.9141\n",
      "Epoch 042 | Train Loss: 0.9243 | Val Loss: 0.8593\n",
      "Epoch 043 | Train Loss: 0.9428 | Val Loss: 0.8550\n",
      "Epoch 044 | Train Loss: 0.8809 | Val Loss: 0.8628\n",
      "Epoch 045 | Train Loss: 0.9378 | Val Loss: 1.0098\n",
      "Epoch 046 | Train Loss: 1.0215 | Val Loss: 0.9513\n",
      "Epoch 047 | Train Loss: 1.0429 | Val Loss: 0.8520\n",
      "Epoch 048 | Train Loss: 1.0724 | Val Loss: 1.0137\n",
      "Epoch 049 | Train Loss: 0.9192 | Val Loss: 0.8550\n",
      "Epoch 050 | Train Loss: 0.9316 | Val Loss: 0.8308\n",
      "Epoch 051 | Train Loss: 0.9088 | Val Loss: 0.8288\n",
      "Epoch 052 | Train Loss: 0.9423 | Val Loss: 0.8253\n",
      "Epoch 053 | Train Loss: 0.8992 | Val Loss: 0.9105\n",
      "Epoch 054 | Train Loss: 0.9339 | Val Loss: 0.8413\n",
      "Epoch 055 | Train Loss: 0.8945 | Val Loss: 0.8699\n",
      "Epoch 056 | Train Loss: 0.8846 | Val Loss: 0.8750\n",
      "Epoch 057 | Train Loss: 0.9889 | Val Loss: 0.8667\n",
      "Epoch 058 | Train Loss: 0.8783 | Val Loss: 0.8964\n",
      "Epoch 059 | Train Loss: 0.9036 | Val Loss: 0.8830\n",
      "Epoch 060 | Train Loss: 0.9880 | Val Loss: 1.0335\n",
      "Epoch 061 | Train Loss: 0.8854 | Val Loss: 1.0440\n",
      "Epoch 062 | Train Loss: 0.9337 | Val Loss: 0.8039\n",
      "Epoch 063 | Train Loss: 0.9008 | Val Loss: 0.8258\n",
      "Epoch 064 | Train Loss: 0.8828 | Val Loss: 0.8050\n",
      "Epoch 065 | Train Loss: 0.8974 | Val Loss: 1.0993\n",
      "Epoch 066 | Train Loss: 1.0060 | Val Loss: 0.8402\n",
      "Epoch 067 | Train Loss: 0.9170 | Val Loss: 0.8153\n",
      "Epoch 068 | Train Loss: 0.8987 | Val Loss: 0.7884\n",
      "Epoch 069 | Train Loss: 0.8903 | Val Loss: 0.7870\n",
      "Epoch 070 | Train Loss: 0.8728 | Val Loss: 0.7894\n",
      "Epoch 071 | Train Loss: 0.8951 | Val Loss: 0.8916\n",
      "Epoch 072 | Train Loss: 0.9035 | Val Loss: 0.7811\n",
      "Epoch 073 | Train Loss: 0.8937 | Val Loss: 0.7851\n",
      "Epoch 074 | Train Loss: 0.8828 | Val Loss: 0.7849\n",
      "Epoch 075 | Train Loss: 0.9922 | Val Loss: 0.7839\n",
      "Epoch 076 | Train Loss: 0.9005 | Val Loss: 0.8922\n",
      "Epoch 077 | Train Loss: 0.9328 | Val Loss: 0.7760\n",
      "Epoch 078 | Train Loss: 0.8885 | Val Loss: 0.7711\n",
      "Epoch 079 | Train Loss: 0.8842 | Val Loss: 0.7673\n",
      "Epoch 080 | Train Loss: 0.8543 | Val Loss: 0.8102\n",
      "Epoch 081 | Train Loss: 0.8686 | Val Loss: 0.7656\n",
      "Epoch 082 | Train Loss: 0.8583 | Val Loss: 0.8569\n",
      "Epoch 083 | Train Loss: 0.8677 | Val Loss: 0.9533\n",
      "Epoch 084 | Train Loss: 0.8959 | Val Loss: 0.8777\n",
      "Epoch 085 | Train Loss: 0.8784 | Val Loss: 0.7860\n",
      "Epoch 086 | Train Loss: 0.8532 | Val Loss: 0.7458\n",
      "Epoch 087 | Train Loss: 0.8785 | Val Loss: 0.7784\n",
      "Epoch 088 | Train Loss: 0.8525 | Val Loss: 0.7747\n",
      "Epoch 089 | Train Loss: 0.8332 | Val Loss: 0.7756\n",
      "Epoch 090 | Train Loss: 0.8764 | Val Loss: 0.7389\n",
      "Epoch 091 | Train Loss: 0.8632 | Val Loss: 0.7729\n",
      "Epoch 092 | Train Loss: 0.9147 | Val Loss: 0.7335\n",
      "Epoch 093 | Train Loss: 0.8878 | Val Loss: 1.2434\n",
      "Epoch 094 | Train Loss: 0.9791 | Val Loss: 0.7799\n",
      "Epoch 095 | Train Loss: 0.8429 | Val Loss: 0.7318\n",
      "Epoch 096 | Train Loss: 0.8704 | Val Loss: 0.7522\n",
      "Epoch 097 | Train Loss: 0.8925 | Val Loss: 0.8047\n",
      "Epoch 098 | Train Loss: 0.8654 | Val Loss: 0.8025\n",
      "Epoch 099 | Train Loss: 0.9178 | Val Loss: 0.7552\n",
      "Epoch 100 | Train Loss: 0.9219 | Val Loss: 0.7790\n",
      "Epoch 101 | Train Loss: 0.8780 | Val Loss: 0.7362\n",
      "Epoch 102 | Train Loss: 0.8979 | Val Loss: 0.7158\n",
      "Epoch 103 | Train Loss: 1.0283 | Val Loss: 0.7170\n",
      "Epoch 104 | Train Loss: 0.9087 | Val Loss: 0.9772\n",
      "Epoch 105 | Train Loss: 0.8913 | Val Loss: 0.7302\n",
      "Epoch 106 | Train Loss: 0.8658 | Val Loss: 0.7212\n",
      "Epoch 107 | Train Loss: 0.8527 | Val Loss: 0.7168\n",
      "Epoch 108 | Train Loss: 0.8312 | Val Loss: 0.7270\n",
      "Epoch 109 | Train Loss: 0.9090 | Val Loss: 0.7116\n",
      "Epoch 110 | Train Loss: 0.9379 | Val Loss: 0.9740\n",
      "Epoch 111 | Train Loss: 0.8968 | Val Loss: 0.7134\n",
      "Epoch 112 | Train Loss: 0.9182 | Val Loss: 0.8114\n",
      "Epoch 113 | Train Loss: 0.8454 | Val Loss: 0.8150\n",
      "Epoch 114 | Train Loss: 0.8644 | Val Loss: 0.7029\n",
      "Epoch 115 | Train Loss: 0.8737 | Val Loss: 0.7043\n",
      "Epoch 116 | Train Loss: 0.8238 | Val Loss: 0.9010\n",
      "Epoch 117 | Train Loss: 1.0472 | Val Loss: 0.7025\n",
      "Epoch 118 | Train Loss: 1.0212 | Val Loss: 0.8255\n",
      "Epoch 119 | Train Loss: 0.8562 | Val Loss: 0.7316\n",
      "Epoch 120 | Train Loss: 0.8614 | Val Loss: 0.7037\n",
      "Epoch 121 | Train Loss: 0.8660 | Val Loss: 0.7058\n",
      "Epoch 122 | Train Loss: 0.8832 | Val Loss: 0.6942\n",
      "Epoch 123 | Train Loss: 0.8434 | Val Loss: 0.7017\n",
      "Epoch 124 | Train Loss: 0.8562 | Val Loss: 0.6901\n",
      "Epoch 125 | Train Loss: 0.8879 | Val Loss: 0.7174\n",
      "Epoch 126 | Train Loss: 0.8870 | Val Loss: 0.7749\n",
      "Epoch 127 | Train Loss: 0.8461 | Val Loss: 0.7300\n",
      "Epoch 128 | Train Loss: 0.8451 | Val Loss: 0.7158\n",
      "Epoch 129 | Train Loss: 0.8689 | Val Loss: 0.7115\n",
      "Epoch 130 | Train Loss: 0.8678 | Val Loss: 0.6925\n",
      "Epoch 131 | Train Loss: 0.8336 | Val Loss: 0.6975\n",
      "Epoch 132 | Train Loss: 0.8226 | Val Loss: 0.6964\n",
      "Epoch 133 | Train Loss: 0.8301 | Val Loss: 0.7756\n",
      "Epoch 134 | Train Loss: 0.8714 | Val Loss: 0.7076\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 6/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 16.5331 | Val Loss: 5.6456\n",
      "Epoch 002 | Train Loss: 2.7631 | Val Loss: 2.1527\n",
      "Epoch 003 | Train Loss: 1.4071 | Val Loss: 0.9642\n",
      "Epoch 004 | Train Loss: 1.1469 | Val Loss: 0.9322\n",
      "Epoch 005 | Train Loss: 1.0695 | Val Loss: 1.0132\n",
      "Epoch 006 | Train Loss: 1.0250 | Val Loss: 0.9255\n",
      "Epoch 007 | Train Loss: 0.9971 | Val Loss: 0.9248\n",
      "Epoch 008 | Train Loss: 1.0349 | Val Loss: 0.9379\n",
      "Epoch 009 | Train Loss: 0.9993 | Val Loss: 0.9635\n",
      "Epoch 010 | Train Loss: 1.0045 | Val Loss: 0.9176\n",
      "Epoch 011 | Train Loss: 1.0642 | Val Loss: 0.9422\n",
      "Epoch 012 | Train Loss: 0.9783 | Val Loss: 0.9160\n",
      "Epoch 013 | Train Loss: 1.0101 | Val Loss: 1.0355\n",
      "Epoch 014 | Train Loss: 1.0108 | Val Loss: 0.9154\n",
      "Epoch 015 | Train Loss: 1.0629 | Val Loss: 1.0386\n",
      "Epoch 016 | Train Loss: 1.0358 | Val Loss: 1.0579\n",
      "Epoch 017 | Train Loss: 1.0576 | Val Loss: 0.9745\n",
      "Epoch 018 | Train Loss: 1.0039 | Val Loss: 0.8969\n",
      "Epoch 019 | Train Loss: 1.0719 | Val Loss: 0.8979\n",
      "Epoch 020 | Train Loss: 1.0766 | Val Loss: 0.8924\n",
      "Epoch 021 | Train Loss: 0.9824 | Val Loss: 0.9449\n",
      "Epoch 022 | Train Loss: 1.0055 | Val Loss: 0.8866\n",
      "Epoch 023 | Train Loss: 0.9857 | Val Loss: 0.9222\n",
      "Epoch 024 | Train Loss: 0.9939 | Val Loss: 0.9394\n",
      "Epoch 025 | Train Loss: 0.9503 | Val Loss: 0.8979\n",
      "Epoch 026 | Train Loss: 0.9495 | Val Loss: 0.9319\n",
      "Epoch 027 | Train Loss: 0.9777 | Val Loss: 0.9435\n",
      "Epoch 028 | Train Loss: 1.0155 | Val Loss: 0.9765\n",
      "Epoch 029 | Train Loss: 0.9423 | Val Loss: 0.8873\n",
      "Epoch 030 | Train Loss: 0.9454 | Val Loss: 0.9125\n",
      "Epoch 031 | Train Loss: 0.9737 | Val Loss: 0.9303\n",
      "Epoch 032 | Train Loss: 0.9627 | Val Loss: 0.9272\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 7/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 18.0063 | Val Loss: 6.2253\n",
      "Epoch 002 | Train Loss: 2.9871 | Val Loss: 1.9739\n",
      "Epoch 003 | Train Loss: 1.3018 | Val Loss: 1.3726\n",
      "Epoch 004 | Train Loss: 1.0466 | Val Loss: 1.0951\n",
      "Epoch 005 | Train Loss: 0.9895 | Val Loss: 1.1207\n",
      "Epoch 006 | Train Loss: 1.0388 | Val Loss: 1.1222\n",
      "Epoch 007 | Train Loss: 1.0290 | Val Loss: 1.1900\n",
      "Epoch 008 | Train Loss: 1.0033 | Val Loss: 1.0995\n",
      "Epoch 009 | Train Loss: 0.9567 | Val Loss: 1.1075\n",
      "Epoch 010 | Train Loss: 0.9738 | Val Loss: 1.1572\n",
      "Epoch 011 | Train Loss: 1.0021 | Val Loss: 1.1267\n",
      "Epoch 012 | Train Loss: 0.9902 | Val Loss: 1.1576\n",
      "Epoch 013 | Train Loss: 0.9573 | Val Loss: 1.1307\n",
      "Epoch 014 | Train Loss: 0.9936 | Val Loss: 1.1247\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 8/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 17.3813 | Val Loss: 5.9066\n",
      "Epoch 002 | Train Loss: 2.8216 | Val Loss: 2.0796\n",
      "Epoch 003 | Train Loss: 1.3761 | Val Loss: 0.8137\n",
      "Epoch 004 | Train Loss: 1.0707 | Val Loss: 0.7939\n",
      "Epoch 005 | Train Loss: 1.1053 | Val Loss: 1.0211\n",
      "Epoch 006 | Train Loss: 1.0478 | Val Loss: 0.7965\n",
      "Epoch 007 | Train Loss: 1.0040 | Val Loss: 0.8071\n",
      "Epoch 008 | Train Loss: 1.0480 | Val Loss: 0.8704\n",
      "Epoch 009 | Train Loss: 1.0250 | Val Loss: 0.7803\n",
      "Epoch 010 | Train Loss: 0.9999 | Val Loss: 0.7703\n",
      "Epoch 011 | Train Loss: 1.0223 | Val Loss: 0.7656\n",
      "Epoch 012 | Train Loss: 0.9942 | Val Loss: 0.7858\n",
      "Epoch 013 | Train Loss: 0.9906 | Val Loss: 0.7608\n",
      "Epoch 014 | Train Loss: 0.9790 | Val Loss: 0.7536\n",
      "Epoch 015 | Train Loss: 1.0017 | Val Loss: 0.7540\n",
      "Epoch 016 | Train Loss: 0.9776 | Val Loss: 0.7510\n",
      "Epoch 017 | Train Loss: 0.9622 | Val Loss: 0.7417\n",
      "Epoch 018 | Train Loss: 0.9733 | Val Loss: 0.8119\n",
      "Epoch 019 | Train Loss: 0.9883 | Val Loss: 0.7326\n",
      "Epoch 020 | Train Loss: 0.9827 | Val Loss: 0.7745\n",
      "Epoch 021 | Train Loss: 0.9618 | Val Loss: 0.7252\n",
      "Epoch 022 | Train Loss: 0.9338 | Val Loss: 0.7648\n",
      "Epoch 023 | Train Loss: 0.9975 | Val Loss: 0.7599\n",
      "Epoch 024 | Train Loss: 0.9479 | Val Loss: 0.7099\n",
      "Epoch 025 | Train Loss: 0.9948 | Val Loss: 0.8521\n",
      "Epoch 026 | Train Loss: 1.0208 | Val Loss: 0.9134\n",
      "Epoch 027 | Train Loss: 0.9888 | Val Loss: 0.7035\n",
      "Epoch 028 | Train Loss: 0.9333 | Val Loss: 0.7129\n",
      "Epoch 029 | Train Loss: 0.9355 | Val Loss: 0.7176\n",
      "Epoch 030 | Train Loss: 0.9506 | Val Loss: 0.6898\n",
      "Epoch 031 | Train Loss: 0.9177 | Val Loss: 0.6857\n",
      "Epoch 032 | Train Loss: 0.9277 | Val Loss: 0.6809\n",
      "Epoch 033 | Train Loss: 0.9704 | Val Loss: 0.7819\n",
      "Epoch 034 | Train Loss: 0.8977 | Val Loss: 0.6873\n",
      "Epoch 035 | Train Loss: 0.9120 | Val Loss: 0.6697\n",
      "Epoch 036 | Train Loss: 0.9303 | Val Loss: 0.6670\n",
      "Epoch 037 | Train Loss: 0.9745 | Val Loss: 0.8095\n",
      "Epoch 038 | Train Loss: 0.9318 | Val Loss: 0.7280\n",
      "Epoch 039 | Train Loss: 1.0232 | Val Loss: 0.8229\n",
      "Epoch 040 | Train Loss: 0.9178 | Val Loss: 0.6867\n",
      "Epoch 041 | Train Loss: 0.9036 | Val Loss: 0.6737\n",
      "Epoch 042 | Train Loss: 0.8936 | Val Loss: 0.6570\n",
      "Epoch 043 | Train Loss: 0.8824 | Val Loss: 0.7287\n",
      "Epoch 044 | Train Loss: 0.9202 | Val Loss: 0.6538\n",
      "Epoch 045 | Train Loss: 0.8632 | Val Loss: 0.6961\n",
      "Epoch 046 | Train Loss: 0.9700 | Val Loss: 0.7259\n",
      "Epoch 047 | Train Loss: 0.9564 | Val Loss: 0.6409\n",
      "Epoch 048 | Train Loss: 0.9317 | Val Loss: 0.7292\n",
      "Epoch 049 | Train Loss: 0.9484 | Val Loss: 0.6339\n",
      "Epoch 050 | Train Loss: 0.8746 | Val Loss: 0.8355\n",
      "Epoch 051 | Train Loss: 0.9288 | Val Loss: 0.7189\n",
      "Epoch 052 | Train Loss: 0.8962 | Val Loss: 0.6439\n",
      "Epoch 053 | Train Loss: 0.8824 | Val Loss: 0.6752\n",
      "Epoch 054 | Train Loss: 0.8522 | Val Loss: 0.6337\n",
      "Epoch 055 | Train Loss: 0.8728 | Val Loss: 0.7117\n",
      "Epoch 056 | Train Loss: 0.9515 | Val Loss: 0.6258\n",
      "Epoch 057 | Train Loss: 0.8820 | Val Loss: 0.6459\n",
      "Epoch 058 | Train Loss: 0.8662 | Val Loss: 0.6239\n",
      "Epoch 059 | Train Loss: 0.8373 | Val Loss: 0.6212\n",
      "Epoch 060 | Train Loss: 0.8272 | Val Loss: 0.6404\n",
      "Epoch 061 | Train Loss: 0.8348 | Val Loss: 0.6205\n",
      "Epoch 062 | Train Loss: 0.8205 | Val Loss: 0.7438\n",
      "Epoch 063 | Train Loss: 0.8409 | Val Loss: 0.6265\n",
      "Epoch 064 | Train Loss: 0.8791 | Val Loss: 0.9460\n",
      "Epoch 065 | Train Loss: 0.9311 | Val Loss: 0.7034\n",
      "Epoch 066 | Train Loss: 0.8465 | Val Loss: 0.6218\n",
      "Epoch 067 | Train Loss: 0.8797 | Val Loss: 0.8718\n",
      "Epoch 068 | Train Loss: 0.8889 | Val Loss: 0.7210\n",
      "Epoch 069 | Train Loss: 0.8431 | Val Loss: 0.6448\n",
      "Epoch 070 | Train Loss: 1.0593 | Val Loss: 0.6222\n",
      "Epoch 071 | Train Loss: 0.9336 | Val Loss: 0.9538\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 9/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 16.3723 | Val Loss: 7.8085\n",
      "Epoch 002 | Train Loss: 2.8196 | Val Loss: 1.4274\n",
      "Epoch 003 | Train Loss: 1.3972 | Val Loss: 1.1307\n",
      "Epoch 004 | Train Loss: 1.1860 | Val Loss: 1.0958\n",
      "Epoch 005 | Train Loss: 1.0401 | Val Loss: 0.9839\n",
      "Epoch 006 | Train Loss: 1.0238 | Val Loss: 0.9962\n",
      "Epoch 007 | Train Loss: 0.9606 | Val Loss: 1.1877\n",
      "Epoch 008 | Train Loss: 1.0153 | Val Loss: 1.1071\n",
      "Epoch 009 | Train Loss: 1.0272 | Val Loss: 1.0312\n",
      "Epoch 010 | Train Loss: 0.9722 | Val Loss: 1.0912\n",
      "Epoch 011 | Train Loss: 1.0073 | Val Loss: 1.0391\n",
      "Epoch 012 | Train Loss: 0.9755 | Val Loss: 1.1486\n",
      "Epoch 013 | Train Loss: 0.9758 | Val Loss: 1.0440\n",
      "Epoch 014 | Train Loss: 0.9820 | Val Loss: 1.0661\n",
      "Epoch 015 | Train Loss: 0.9608 | Val Loss: 1.1999\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üîÅ Retraining Fold 10/10 with best hyperparameters\n",
      "Epoch 001 | Train Loss: 15.8798 | Val Loss: 4.7379\n",
      "Epoch 002 | Train Loss: 2.0467 | Val Loss: 1.8024\n",
      "Epoch 003 | Train Loss: 1.2198 | Val Loss: 1.2882\n",
      "Epoch 004 | Train Loss: 1.0312 | Val Loss: 1.2357\n",
      "Epoch 005 | Train Loss: 0.9792 | Val Loss: 1.2639\n",
      "Epoch 006 | Train Loss: 0.9786 | Val Loss: 1.2306\n",
      "Epoch 007 | Train Loss: 0.9689 | Val Loss: 1.2608\n",
      "Epoch 008 | Train Loss: 0.9898 | Val Loss: 1.2061\n",
      "Epoch 009 | Train Loss: 0.9982 | Val Loss: 1.2154\n",
      "Epoch 010 | Train Loss: 0.9711 | Val Loss: 1.2251\n",
      "Epoch 011 | Train Loss: 0.9648 | Val Loss: 1.1949\n",
      "Epoch 012 | Train Loss: 0.9681 | Val Loss: 1.2162\n",
      "Epoch 013 | Train Loss: 1.0134 | Val Loss: 1.1882\n",
      "Epoch 014 | Train Loss: 1.0238 | Val Loss: 1.2404\n",
      "Epoch 015 | Train Loss: 1.0239 | Val Loss: 1.2649\n",
      "Epoch 016 | Train Loss: 1.0151 | Val Loss: 1.1731\n",
      "Epoch 017 | Train Loss: 1.0224 | Val Loss: 1.1713\n",
      "Epoch 018 | Train Loss: 0.9234 | Val Loss: 1.2083\n",
      "Epoch 019 | Train Loss: 0.9306 | Val Loss: 1.1982\n",
      "Epoch 020 | Train Loss: 0.9491 | Val Loss: 1.1638\n",
      "Epoch 021 | Train Loss: 0.9387 | Val Loss: 1.2189\n",
      "Epoch 022 | Train Loss: 0.9922 | Val Loss: 1.3257\n",
      "Epoch 023 | Train Loss: 1.0425 | Val Loss: 1.2126\n",
      "Epoch 024 | Train Loss: 0.9498 | Val Loss: 1.1427\n",
      "Epoch 025 | Train Loss: 0.9762 | Val Loss: 1.1588\n",
      "Epoch 026 | Train Loss: 0.9680 | Val Loss: 1.1933\n",
      "Epoch 027 | Train Loss: 0.9808 | Val Loss: 1.2165\n",
      "Epoch 028 | Train Loss: 1.0772 | Val Loss: 1.3762\n",
      "Epoch 029 | Train Loss: 0.9655 | Val Loss: 1.3771\n",
      "Epoch 030 | Train Loss: 0.9913 | Val Loss: 1.1331\n",
      "Epoch 031 | Train Loss: 0.9217 | Val Loss: 1.1241\n",
      "Epoch 032 | Train Loss: 0.9972 | Val Loss: 1.1688\n",
      "Epoch 033 | Train Loss: 0.9818 | Val Loss: 1.1135\n",
      "Epoch 034 | Train Loss: 0.9797 | Val Loss: 1.1429\n",
      "Epoch 035 | Train Loss: 0.9294 | Val Loss: 1.1793\n",
      "Epoch 036 | Train Loss: 1.0128 | Val Loss: 1.1256\n",
      "Epoch 037 | Train Loss: 0.9479 | Val Loss: 1.2487\n",
      "Epoch 038 | Train Loss: 0.9209 | Val Loss: 1.1348\n",
      "Epoch 039 | Train Loss: 0.9184 | Val Loss: 1.0967\n",
      "Epoch 040 | Train Loss: 0.8922 | Val Loss: 1.1725\n",
      "Epoch 041 | Train Loss: 0.9319 | Val Loss: 1.0946\n",
      "Epoch 042 | Train Loss: 0.9055 | Val Loss: 1.1020\n",
      "Epoch 043 | Train Loss: 0.9009 | Val Loss: 1.1179\n",
      "Epoch 044 | Train Loss: 0.8918 | Val Loss: 1.0754\n",
      "Epoch 045 | Train Loss: 0.8713 | Val Loss: 1.2952\n",
      "Epoch 046 | Train Loss: 0.9990 | Val Loss: 1.0705\n",
      "Epoch 047 | Train Loss: 0.9487 | Val Loss: 1.0769\n",
      "Epoch 048 | Train Loss: 0.8979 | Val Loss: 1.1692\n",
      "Epoch 049 | Train Loss: 0.9150 | Val Loss: 1.0975\n",
      "Epoch 050 | Train Loss: 0.9308 | Val Loss: 1.0662\n",
      "Epoch 051 | Train Loss: 0.9125 | Val Loss: 1.0832\n",
      "Epoch 052 | Train Loss: 0.9591 | Val Loss: 1.0874\n",
      "Epoch 053 | Train Loss: 1.0100 | Val Loss: 1.0634\n",
      "Epoch 054 | Train Loss: 0.9044 | Val Loss: 1.2366\n",
      "Epoch 055 | Train Loss: 0.9239 | Val Loss: 1.0697\n",
      "Epoch 056 | Train Loss: 0.8972 | Val Loss: 1.0719\n",
      "Epoch 057 | Train Loss: 0.9137 | Val Loss: 1.0478\n",
      "Epoch 058 | Train Loss: 0.9055 | Val Loss: 1.1171\n",
      "Epoch 059 | Train Loss: 0.8650 | Val Loss: 1.0639\n",
      "Epoch 060 | Train Loss: 0.8681 | Val Loss: 1.0368\n",
      "Epoch 061 | Train Loss: 0.8658 | Val Loss: 1.0872\n",
      "Epoch 062 | Train Loss: 0.8497 | Val Loss: 1.0274\n",
      "Epoch 063 | Train Loss: 0.8443 | Val Loss: 1.0276\n",
      "Epoch 064 | Train Loss: 0.9214 | Val Loss: 1.0679\n",
      "Epoch 065 | Train Loss: 0.9054 | Val Loss: 1.0550\n",
      "Epoch 066 | Train Loss: 0.8640 | Val Loss: 1.0244\n",
      "Epoch 067 | Train Loss: 0.8348 | Val Loss: 1.0207\n",
      "Epoch 068 | Train Loss: 0.8634 | Val Loss: 1.0502\n",
      "Epoch 069 | Train Loss: 0.9404 | Val Loss: 1.0465\n",
      "Epoch 070 | Train Loss: 0.8860 | Val Loss: 1.0739\n",
      "Epoch 071 | Train Loss: 0.9051 | Val Loss: 1.1463\n",
      "Epoch 072 | Train Loss: 0.9431 | Val Loss: 1.0201\n",
      "Epoch 073 | Train Loss: 0.9292 | Val Loss: 1.0261\n",
      "Epoch 074 | Train Loss: 0.8985 | Val Loss: 1.1643\n",
      "Epoch 075 | Train Loss: 0.8834 | Val Loss: 1.0458\n",
      "Epoch 076 | Train Loss: 0.8129 | Val Loss: 1.0151\n",
      "Epoch 077 | Train Loss: 0.8361 | Val Loss: 1.0318\n",
      "Epoch 078 | Train Loss: 0.8272 | Val Loss: 1.0925\n",
      "Epoch 079 | Train Loss: 0.8499 | Val Loss: 1.0105\n",
      "Epoch 080 | Train Loss: 0.8694 | Val Loss: 1.0698\n",
      "Epoch 081 | Train Loss: 0.8470 | Val Loss: 1.0318\n",
      "Epoch 082 | Train Loss: 0.8401 | Val Loss: 1.0250\n",
      "Epoch 083 | Train Loss: 0.8430 | Val Loss: 1.0246\n",
      "Epoch 084 | Train Loss: 0.8392 | Val Loss: 1.0723\n",
      "Epoch 085 | Train Loss: 0.8464 | Val Loss: 1.0778\n",
      "Epoch 086 | Train Loss: 0.9312 | Val Loss: 1.1073\n",
      "Epoch 087 | Train Loss: 0.8542 | Val Loss: 1.0325\n",
      "Epoch 088 | Train Loss: 0.8817 | Val Loss: 1.0483\n",
      "Epoch 089 | Train Loss: 0.8250 | Val Loss: 1.0054\n",
      "Epoch 090 | Train Loss: 0.8190 | Val Loss: 1.0248\n",
      "Epoch 091 | Train Loss: 0.8986 | Val Loss: 1.0141\n",
      "Epoch 092 | Train Loss: 0.8932 | Val Loss: 1.0095\n",
      "Epoch 093 | Train Loss: 0.8632 | Val Loss: 1.0083\n",
      "Epoch 094 | Train Loss: 0.8330 | Val Loss: 1.0074\n",
      "Epoch 095 | Train Loss: 0.8517 | Val Loss: 1.1079\n",
      "Epoch 096 | Train Loss: 0.9233 | Val Loss: 0.9983\n",
      "Epoch 097 | Train Loss: 0.8778 | Val Loss: 1.0100\n",
      "Epoch 098 | Train Loss: 0.8309 | Val Loss: 1.0017\n",
      "Epoch 099 | Train Loss: 0.8592 | Val Loss: 1.0050\n",
      "Epoch 100 | Train Loss: 0.9143 | Val Loss: 1.1368\n",
      "Epoch 101 | Train Loss: 0.8776 | Val Loss: 1.1925\n",
      "Epoch 102 | Train Loss: 1.0226 | Val Loss: 1.0051\n",
      "Epoch 103 | Train Loss: 0.9082 | Val Loss: 1.1325\n",
      "Epoch 104 | Train Loss: 0.8480 | Val Loss: 1.0556\n",
      "Epoch 105 | Train Loss: 0.8223 | Val Loss: 1.0158\n",
      "Epoch 106 | Train Loss: 0.8465 | Val Loss: 1.0306\n",
      "‚èπÔ∏è Early stopping\n",
      "‚úÖ Saved cross‚Äëvalidation summary to MPNN_results/regression/crossval_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\nüîÅ Retraining Fold {fold+1}/10 with best hyperparameters\")\n",
    "    train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "    model = MPNN(input_dim, edge_dim,\n",
    "                 hidden_dim=best_hidden_dim,\n",
    "                 output_dim=output_dim,\n",
    "                 dropout=best_dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader   = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 0\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    for epoch in range(1, 301):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch)\n",
    "            loss = (F.cross_entropy(out, batch.y.long())\n",
    "                    if task==\"classification\"\n",
    "                    else F.mse_loss(out.squeeze(), batch.y))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluate on validation\n",
    "        preds, targets = evaluate(model, val_loader)\n",
    "        val_loss = (F.cross_entropy(preds, targets.long()).item()\n",
    "                    if task==\"classification\"\n",
    "                    else F.mse_loss(preds.squeeze(), targets).item())\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save best\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(results_dir, f\"fold{fold+1}_model.pt\"))\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 10:\n",
    "                print(\"‚èπÔ∏è Early stopping\")\n",
    "                break\n",
    "\n",
    "    # --- After training this fold, compute metrics on its validation set ---\n",
    "    preds_np = preds.squeeze().cpu().numpy()\n",
    "    trues_np = targets.cpu().numpy()\n",
    "\n",
    "    if task == \"classification\":\n",
    "        from sklearn.metrics import (\n",
    "            accuracy_score,\n",
    "            precision_recall_fscore_support,\n",
    "            roc_auc_score\n",
    "        )\n",
    "        y_true = trues_np.astype(int)\n",
    "        y_probs = F.softmax(preds, dim=1).cpu().numpy()\n",
    "        y_pred  = preds.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "        auc = roc_auc_score(\n",
    "            label_binarize(y_true, classes=np.arange(num_classes)),\n",
    "            y_probs, multi_class=\"ovr\")\n",
    "\n",
    "        fold_metrics.append({\n",
    "            \"fold\": fold+1,\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"auc_roc\": auc\n",
    "        })\n",
    "    else:  # regression\n",
    "        mae  = mean_absolute_error(trues_np, preds_np)\n",
    "        mse  = mean_squared_error(trues_np, preds_np)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2   = r2_score(trues_np, preds_np)\n",
    "\n",
    "        fold_metrics.append({\n",
    "            \"fold\": fold+1,\n",
    "            \"mae\": mae,\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "\n",
    "# --- Save the cross-validation summary ---\n",
    "cv_df = pd.DataFrame(fold_metrics)\n",
    "cv_path = os.path.join(results_dir, \"crossval_summary.csv\")\n",
    "cv_df.to_csv(cv_path, index=False)\n",
    "print(f\"‚úÖ Saved cross‚Äëvalidation summary to {cv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5e6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e028e5",
   "metadata": {},
   "source": [
    "## Step 5b: Visualize Cross-Validation Results\n",
    "# This section plots per-fold metrics from the cross-validation summary to assess stability across folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88b8c48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Mean ¬± Std for Cross-Validation Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.7699</td>\n",
       "      <td>0.0762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.1755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.1912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean     std\n",
       "mae   0.7699  0.0762\n",
       "mse   0.9599  0.1755\n",
       "rmse  0.9759  0.0917\n",
       "r2    0.2265  0.1912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load summary\n",
    "cv_path = os.path.join(results_dir, \"crossval_summary.csv\")\n",
    "cv_df = pd.read_csv(cv_path)\n",
    "\n",
    "# Choose metrics\n",
    "task_metrics = (\n",
    "    ['accuracy','precision','recall','f1_score','auc_roc']\n",
    "    if task==\"classification\"\n",
    "    else ['mae','mse','rmse','r2']\n",
    ")\n",
    "\n",
    "# Plot bar charts per fold\n",
    "fig, axs = plt.subplots(1, len(task_metrics), figsize=(18, 4))\n",
    "for i, metric in enumerate(task_metrics):\n",
    "    axs[i].bar(cv_df['fold'], cv_df[metric], color='skyblue')\n",
    "    axs[i].set_title(f\"{metric.upper()} per Fold\")\n",
    "    axs[i].set_xlabel(\"Fold\")\n",
    "    axs[i].set_ylabel(metric)\n",
    "    axs[i].set_xticks(cv_df['fold'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display mean ¬± std\n",
    "summary_stats = cv_df[task_metrics].agg(['mean','std']).T\n",
    "print(\"üìä Mean ¬± Std for Cross-Validation Metrics:\")\n",
    "display(summary_stats.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457ff60",
   "metadata": {},
   "source": [
    "# ## Step 6a: Ensemble Averaging from Cross-Validation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c35a6ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ensemble predictions ready: shape (53,)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "ensemble_preds = []\n",
    "test_data = torch.load(os.path.join(base_path, f\"{task}_test.pt\"))\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Ensure model configuration matches\n",
    "output_dim = num_classes if task == \"classification\" else 1\n",
    "\n",
    "# Collect predictions from each fold model\n",
    "for fold in range(10):\n",
    "    model = MPNN(input_dim, edge_dim, hidden_dim=best_hidden_dim, output_dim=output_dim, dropout=best_dropout).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(results_dir, f\"fold{fold+1}_model.pt\")))\n",
    "    model.eval()\n",
    "    fold_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            fold_outputs.append(out.cpu())\n",
    "    ensemble_preds.append(torch.cat(fold_outputs, dim=0))\n",
    "\n",
    "# Average predictions across folds\n",
    "avg_output = torch.stack(ensemble_preds).mean(dim=0)\n",
    "\n",
    "# Prepare final predictions and true labels\n",
    "if task == \"classification\":\n",
    "    final_pred = avg_output.argmax(dim=1).numpy()\n",
    "    true_labels = torch.cat([data.y for data in test_data]).numpy().astype(int)\n",
    "else:\n",
    "    final_pred = avg_output.squeeze().numpy()\n",
    "    true_value = torch.cat([data.y for data in test_data]).numpy()\n",
    "\n",
    "print(f\"‚úÖ Ensemble predictions ready: shape {final_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e124b",
   "metadata": {},
   "source": [
    "# ## Step 6b: Ensemble Evaluation & Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "713bfc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble: MAE=0.740, RMSE=0.915, R2=0.370\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAHqCAYAAADyPMGQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZ6UlEQVR4nO3deVxU9f7H8dcAwyrgiooiKmWadtM0Lc1c0ixtNy2XNM1umf1MbdFb3bIyK2+W3RZtdc3K0qxrlmV1u5W5a2XmnmiuKAgIAgNzfn+cQBHEAWbmzDDv5+PhQ85hmPnAUXjz/X7P52szDMNARERERM4qyOoCRERERPyFgpOIiIiIixScRERERFyk4CQiIiLiIgUnERERERcpOImIiIi4SMFJRERExEUKTiIiIiIuUnASERERcZGCk4iXzZo1C5vNdsY///3vf60usVL++9//YrPZ+Oijj8762IkTJ2Kz2dzyuo0bNy7z61r4Z9asWW55PV/VtWvXYp9vREQEF154IdOmTcPpdHr89Quvv7//OxY5kxCrCxAJVDNnzqR58+Ylzp9//vkWVOP/Pv74Y3Jzc4uO33rrLd5++22++OILYmNji84nJSVZUZ5XNW3alHfffReAw4cPM2PGDMaOHcuBAwd47rnnLK5OxL8pOIlYpFWrVrRr187qMqqMNm3aFDv+4osvAGjbti21a9c+48dlZ2cTGRnp0dq8LSIigksuuaTo+Oqrr6Z58+a88sorTJo0CbvdXuJjDMMgJyeHiIgIb5Yq4nc0VSfiw2w2G/feey9z586lRYsWREZGcuGFF7JkyZJij0tJSeHvf/87CQkJhIWFUadOHTp16sTy5cuLPW758uVcccUVxMTEEBkZSadOnfj666+LPaZw+uyXX36hX79+xMbGUrNmTcaNG0d+fj5bt27lqquuIjo6msaNGzNlypRSa8/JyWHcuHHUq1ePiIgIunTpwoYNG1z6vD/44AMuvfRSoqKiqFatGr169XL5Y8ty++23U61aNX799VeuvPJKoqOjueKKKwBzqu/2228v8TFdu3ala9euxc5lZGTwwAMP0KRJE0JDQ2nQoAFjxowhKyurzNcfM2YMUVFRZGRklHjfLbfcQt26dXE4HAB88803dO3alVq1ahEREUGjRo3o27cv2dnZ5f687XY7bdu2JTs7m5SUFODkv60ZM2bQokULwsLCmD17NgDbt29n4MCBxMXFERYWRosWLXj11VdLPO+WLVu46qqriIyMpHbt2tx9991kZmaWuz4Rf6LgJGKRgoIC8vPzi/0pKCgo8bjPPvuMV155hSeffJKFCxdSs2ZNbrzxRnbt2lX0mNtuu43Fixfz2GOP8eWXX/LWW2/Ro0cPjh49WvSYefPmceWVVxITE8Ps2bNZsGABNWvWpFevXiXCE0D//v258MILWbhwIXfeeScvvvgiY8eO5YYbbqBPnz58/PHHdO/enfHjx7No0aISH//www+za9cu3nrrLd566y32799P165di9VdmsmTJzNgwADOP/98FixYwNy5c8nMzKRz585s3ry5PF/iUuXl5XHdddfRvXt3PvnkE5544olyfXx2djZdunRh9uzZjB49ms8//5zx48cza9YsrrvuOgzDOOPHDh8+nOzsbBYsWFDs/LFjx/jkk08YPHgwdrud3bt306dPH0JDQ3nnnXf44osvePbZZ4mKiiIvL69Cn/fOnTsJCQmhRo0aRecWL17M9OnTeeyxx1i2bFnR1/jiiy9m06ZNTJ06lSVLltCnTx9Gjx5d7Gt16NAhunTpwqZNm3jttdeYO3cux48f5957761QfSJ+wxARr5o5c6YBlPonODi42GMBo27dukZGRkbRuYMHDxpBQUHGM888U3SuWrVqxpgxY874mllZWUbNmjWNa6+9ttj5goIC48ILLzTat29fdO7xxx83AGPq1KnFHtu6dWsDMBYtWlR0zuFwGHXq1DFuuummonPffvutARgXXXSR4XQ6i87v3r3bsNvtxogRI0q8VqE9e/YYISEhxv/93/8Ve+3MzEyjXr16Rv/+/c/4OZ6u8LlTUlKKzg0dOtQAjHfeeafE4xMTE42hQ4eWON+lSxejS5cuRcfPPPOMERQUZKxZs6bY4z766CMDMJYuXVpmXRdddJHRsWPHYudee+01AzB+/fXXYs+1cePGs32apdbbsmVLw+FwGA6Hw9i/f78xYcIEAzD69etX9DjAiI2NNVJTU4t9fK9evYyGDRsa6enpxc7fe++9Rnh4eNHjx48fb9hsthI19uzZ0wCMb7/9tty1i/gDjTiJWGTOnDmsWbOm2J9Vq1aVeFy3bt2Ijo4uOq5bty5xcXEkJycXnWvfvj2zZs1i0qRJrFy5smi6p9CKFStITU1l6NChxUa4nE4nV111FWvWrCkxzXTNNdcUO27RogU2m42rr7666FxISAjnnHNOsVoKDRw4sNgdc4mJiXTs2JFvv/32jF+TZcuWkZ+fz5AhQ4rVGR4eTpcuXdx2p1bfvn0r/LFLliyhVatWtG7duliNvXr1culusmHDhrFixQq2bt1adG7mzJlcfPHFtGrVCoDWrVsTGhrK3//+d2bPnn3WUbrT/fbbb9jtdux2O/Hx8UydOpVBgwbx5ptvFntc9+7di41A5eTk8PXXX3PjjTcSGRlZ7PPr3bs3OTk5rFy5EoBvv/2Wli1bcuGFFxZ7zoEDB5arVhF/o+AkYpEWLVrQrl27Yn/atm1b4nG1atUqcS4sLIwTJ04UHX/wwQcMHTqUt956i0svvZSaNWsyZMgQDh48CJjTKgA333xz0Q/Uwj/PPfcchmGQmppa7DVq1qxZ7Dg0NJTIyEjCw8NLnM/JySlRY7169Uo9d+r04ekK67z44otL1PnBBx9w5MiRM36sqyIjI4mJianwxx86dIhffvmlRH3R0dEYhnHWGgcNGkRYWFhRW4TNmzezZs0ahg0bVvSYpKQkli9fTlxcHKNGjSIpKYmkpCReeukll2pMSkpizZo1rF27lk2bNnHs2DHmzZtX7O5CgPr16xc7Pnr0KPn5+bz88sslPr/evXsDFH1+R48ePeM1FqnKdFedSBVQu3Ztpk2bxrRp09izZw+ffvopEyZM4PDhw3zxxRdFd5W9/PLLxe62OlXdunXdWlNhaDv9XGlBsFBhnR999BGJiYlurafQmfpGhYeHF2tnUOjIkSPF7sqrXbs2ERERvPPOO6U+T1l38AHUqFGD66+/njlz5jBp0iRmzpxJeHg4AwYMKPa4zp0707lzZwoKCli7di0vv/wyY8aMoW7dutx6661lvkZ4eLhLd2ye/rWoUaMGwcHB3HbbbYwaNarUj2nSpAlgBvozXWORqkzBSaSKadSoEffeey9ff/01P/74IwCdOnWievXqbN682WuLd9977z3GjRtX9MM5OTmZFStWMGTIkDN+TK9evQgJCWHnzp2Vmk6riMaNG/PLL78UO7dt2za2bt1aLAxdc801TJ48mVq1ahWFiPIaNmwYCxYsYOnSpcybN48bb7yR6tWrl/rY4OBgOnToQPPmzXn33XdZv379WYNTRUVGRtKtWzc2bNjA3/72N0JDQ8/42G7dujFlyhR+/vnnYtN18+fP90htIr5CwUnEIps2bSI/P7/E+aSkJOrUqePy86Snp9OtWzcGDhxI8+bNiY6OZs2aNXzxxRfcdNNNAFSrVo2XX36ZoUOHkpqays0330xcXBwpKSn8/PPPpKSkMH36dLd9bmA2Xrzxxhu58847SU9P5/HHHyc8PJx//OMfZ/yYxo0b8+STT/LII4+wa9currrqKmrUqMGhQ4dYvXo1UVFR5b4LzlW33XYbgwcP5p577qFv374kJyczZcqUEtdizJgxLFy4kMsvv5yxY8fyt7/9DafTyZ49e/jyyy+5//776dChQ5mvdeWVV9KwYUPuueceDh48WGyaDmDGjBl888039OnTh0aNGpGTk1M0wtWjRw/3fuKneemll7jsssvo3LkzI0eOpHHjxmRmZrJjxw7+85//8M033wDm1+Gdd96hT58+TJo0ibp16/Luu++yZcsWj9YnYjUFJxGLnP7DstCbb77JiBEjXH6e8PBwOnTowNy5c9m9ezcOh4NGjRoxfvx4HnrooaLHDR48mEaNGjFlyhTuuusuMjMziYuLo3Xr1qX2L6qsyZMnF63dycjIoH379rz//vtn7dz9j3/8g/PPP5+XXnqJ9957j9zcXOrVq8fFF1/M3Xff7fY6Cw0cOJD9+/czY8YMZs6cSatWrZg+fXqJoBYVFcX333/Ps88+yxtvvMEff/xR1GepR48eNG7c+KyvFRQUxJAhQ5g8eTIJCQlFvaQKtW7dmi+//JLHH3+cgwcPUq1aNVq1asWnn37KlVde6c5Pu4Tzzz+f9evX89RTT/Hoo49y+PBhqlevzrnnnlu0zgnMtUzfffcd9913HyNHjiQyMpIbb7yRV155heuvv96jNYpYyWYYZTQdEREREZEiuqtORERExEUKTiIiIiIuUnASERERcZGCk4iIiIiLFJxEREREXKTgJCIiIuIiv+7j5HQ62b9/P9HR0WfcRkFERESkLIZhkJmZSXx8PEFBZY8p+XVw2r9/PwkJCVaXISIiIlXA3r17adiwYZmP8evgFB0dDZifaGV2Ow9UDoeDL7/8kiuvvBK73W51OQFL18F6uga+QdfBNwTidcjIyCAhIaEoV5TFr4NT4fRcTEyMglMFOBwOIiMjiYmJCZj/HL5I18F6uga+QdfBNwTydXBl2Y8Wh4uIiIi4SMFJRERExEUKTiIiIiIuUnASERERcZGCk4iIiIiLFJxEREREXKTgJCIiIuIiBScRERERFyk4iYiIiLhIwUlERETERQpOIiIiIi5ScBIRERFxkYKTiIiIiIsUnERERERcpOAkIiIivs0wrK6giIKTiIiI+K7XXoN777W6iiIKTiIiIuK7OnaEd96BlSutrgSAEKsLEBERESnmyBGoXdt8u3Vr2LQJkpIsLamQRpxERETENxgGTJsGjRvD6tUnz/tIaAIFJxEREfEF6enQrx+MHQtZWfD++1ZXVCpN1YmIiIi1fv4Zbr4ZduwAux1efBHuucfqqkql4CQiIiLWeecdGDUKcnKgUSP48ENo397qqs5IU3UiIiJijc8+gzvuMENT796wfr1PhybQiJOIiIhY5eqr4YYb4OKLYcIECPL98RwFJxEREfGezz6Drl0hKsoMSgsX+kVgKuQ/lYqIiIj/ysuDMWPgmmtg5MiT26j4UWgCjTiJiIiIp+3dC/37n+z+Xb++GZxsNmvrqgAFJxEREfGcZctg0CA4ehSqV4fZs+G666yuqsL8a3xMRERE/ENBATz2mLkA/OhRaNvWvGvOj0MTKDiJiIiIJxw5AjNmmFNyI0fCDz9AkyZWV1VpmqoTERER96tbF957Dw4eNKfqqggFJxEREak8w4AXXjA36O3b1zx3xRWWluQJCk4iIiJSOceOwbBhsHgxREfDpZdCfLzVVXmEgpOIiIhU3IYN5ga9u3ZBaChMmWK2G6iiFJxERESk/AwD3noL/u//IDfXnKL78ENo187qyjxKwUlERETKx+k0p+bmzDGPr7nGfLtGDWvr8gK1IxAREZHyCQoyQ1JQEDz7LHzySUCEJtCIk4iIiLgqNxfCwsy3p0yBgQOhfXtra/IyjTiJiIhI2XJzzbVMPXqAw2GeCw0NuNAEGnESERGRsiQnmxv0rl5tHn/9NVx1lbU1WcjSEafMzEzGjBlDYmIiERERdOzYkTVr1lhZkoiIiBT6/HO46CIzNNWoAUuWBHRoAouD04gRI/jqq6+YO3cuv/76K1deeSU9evRg3759VpYlIiIS2AoKCHrsMejdG1JT4eKLzQ16+/SxujLLWRacTpw4wcKFC5kyZQqXX34555xzDhMnTqRJkyZMnz7dqrJEREQC3t/efJPgZ581D0aNgu+/N/s0iXVrnPLz8ykoKCA8PLzY+YiICH744YdSPyY3N5fc3Nyi44yMDAAcDgeOwsVq4rLCr5m+dtbSdbCeroFv0HXwDQ6Hg119+tB4wwYKpk7F6N+/8B3WFuZB5fk3ZzMMw/BgLWXq2LEjoaGhzJ8/n7p16/Lee+8xZMgQzj33XLZu3Vri8RMnTuSJJ54ocX7+/PlERkZ6o2QREZGqx+mkxo4dpDVrVnQqKDcXZ2HrgSouOzubgQMHkp6eTkxMTJmPtTQ47dy5k+HDh/O///2P4OBgLrroIpo1a8b69evZvHlziceXNuKUkJDAkSNHzvqJSkkOh4OvvvqKnj17YrfbrS4nYOk6WE/XwDfoOlgkLY3gO+7AtnQpBV9+Sd6llwbcdcjIyKB27douBSdL2xEkJSXx3XffkZWVRUZGBvXr1+eWW26hSZMmpT4+LCyMsFLSr91uD5iL6wn6+vkGXQfr6Rr4Bl0HL1q3Dvr1gz/+gLAwQg4cwPjrax9I16E8n6dPNMCMioqifv36pKWlsWzZMq6//nqrSxIREam6DANefx06djRDU5MmsGIFDB5sdWU+z9IRp2XLlmEYBueddx47duzgwQcf5LzzzmPYsGFWliUiIlJ1ZWXB3XfDvHnm8fXXw6xZUL26lVX5DUtHnNLT0xk1ahTNmzdnyJAhXHbZZXz55ZcBMzQoIiLidQsXmqEpOBj+9S/4+GOFpnKwdMSpf//+9C+8zVFEREQ877bbzGaWfftC585WV+N3fGKNk4iIiHhIbi48/jikp5vHNhtMm6bQVEHa5FdERKSq2r3bvGtu7Vr47Tf46COrK/J7GnESERGpipYsMTfoXbsWataEO+6wuqIqQcFJRESkKsnPh4cfhmuvhbQ06NABNmyAq6+2urIqQVN1IiIiVcWhQ3DLLfDdd+bx6NHmnXOhodbWVYUoOImIiFQVQUGwYwdUqwZvvw26c93tFJxERET8mWGYd8oB1Klj9mWKiYHzzrO2ripKa5xERET8VWoqXHcdzJ598tzFFys0eZCCk4iIiD9au9a8a27JEhg3DjIzra4oICg4iYiI+BPDgOnToVMnSE6GpCRYvhyio62uLCAoOImIiPiL48dh0CC45x7Iy4Mbb4R166BNG6srCxhaHC4iIuIPcnLMnkybN0NICDz3HIwde3JhuHiFgpOIiIg/CA83R5jS0+GDD8ypOvE6TdWJiIj4qpwcOHjw5PETT8DGjQpNFlJwEhER8UW7dkHHjubWKbm55rngYKhd29q6ApyCk4iIiK/55BOz1cCGDfDHH7Btm9UVyV8UnERERHyFwwEPPQQ33GCuZbr0UjM8XXCB1ZXJX7Q4XERExBfs329u0PvDD+bxmDHmnXPaoNenKDiJiIj4ghEjzNAUHQ0zZ0LfvlZXJKXQVJ2IiIgvePVV6NLFbGip0OSzFJxERESscPQovPvuyeMmTeC//4Vzz7WsJDk7TdWJiIh426pV0K8f7N0LtWrBVVdZXZG4SCNOIiIi3mIY8PLL0LmzGZrOOQfq17e6KikHjTiJiIh4Q0aGuQD8ww/N47594e23ITbW2rqkXBScREREPO3XX+Hmm81GliEh8PzzMHq0Nuj1QwpOIiIinrZ+vRmaGjaEBQvMxpbilxScREREPG3oUHOqbsAA7TXn57Q4XERExN127jQ35z1y5OS5//s/haYqQMFJRETEnT7+2Nygd8kSuO8+q6sRN1NwEhERcQeHA+6/H266yZyW69QJpkyxuipxMwUnERGRytq3D7p1gxdeMI/vvx++/RYaNLC2LnE7LQ4XERGpjHXr4OqrISUFYmJg1iy48UarqxIPUXASERGpjKQkiI42R5c++sg8lipLwUlERKS80tPN0SWbDapXh6++MrdOiYiwujLxMK1xEhERKY+ffoJWrWD69JPnmjZVaAoQCk4iIiKuMAx46SW4/HL480+YMQPy862uSrxMwUlERORsMjKgXz8YM8YMS/37w48/mvvOSUDRFRcRESnLL7+YG/Ru3w52u9lyYNQobdAboBScREREzuTIEbOR5fHjkJAAH34IHTpYXZVYSMFJRETkTGrXhkcege++g3nzoFYtqysSi2mNk4iIyKm2b4dt204eP/QQfPaZQpMACk4iIiInLVwIbdua+81lZZnngoLMPyIoOImIiEBeHowday4Cz8yEGjVOBieRUyg4iYhIYNu7F7p2hWnTzOMHH4RvvoG4OCurEh+lxeEiIhK4li2DQYPg6FGIjYXZs+H6662uSnyYgpOIiAQmw4DJk83QdNFFZquBpk2trkp8nKbqREQkMNlsMH8+3H+/2QVcoUlcoOAkIiKB48cf4emnTx43aADPPw/h4dbVJH5FU3UiIlL1GYa5Vcr48VBQABdeCNdcY3VV4ocUnEREpGo7dgyGD4ePPzaPb73VvItOpAIUnEREpOrauNHszbRzp7lB77RpMHKkNuiVClNwEhGRqmnOHPj73yE3FxITzbvmLr7Y6qrEz2lxuIiIVE2RkWZo6tMH1q9XaBK30IiTiIhUHfn5EPLXj7abb4avvoLu3bXXnLiN/iWJiEjVsGABtGgB+/efPNejh0KTuJX+NYmIiH/Ly4PRo+GWW2DHDpg61eqKpArTVJ2IiPivPXugf39Ytco8njABnnrK2pqkSlNwEhER//T55zB4MKSmQvXqMHeumlqKxyk4iYiI/1m0CPr2Nd9u29ZsNdCkibU1SUBQcBIREf/Tqxecf77ZAfyFFyAszOqKJEAoOImIiH/49Vdo2dK8Sy4qClauhOhoq6uSAKO76kRExLcZBjz/PLRpY/5dSKFJLKARJxER8V3HjsGwYbB4sXm8ebMZpLTXnFjE0hGn/Px8Hn30UZo0aUJERARNmzblySefxOl0WlmWiIj4gvXrzYXfixdDaCjMmAEzZyo0iaUsHXF67rnnmDFjBrNnz6Zly5asXbuWYcOGERsby3333WdlaSIiYhXDgDfeMJta5uaad8t9+KEZokQsZmlw+umnn7j++uvp06cPAI0bN+a9995j7dq1VpYlIiJW2rUL7r0XHA647jqYNQtq1LC6KhHA4qm6yy67jK+//ppt27YB8PPPP/PDDz/Qu3dvK8sSERErJSXBSy/BlCnmNJ1Ck/gQS0ecxo8fT3p6Os2bNyc4OJiCggKefvppBgwYUOrjc3Nzyc3NLTrOyMgAwOFw4HA4vFJzVVL4NdPXzlq6DtbTNbCe7YMPyE9KAv66DiNGmO/Iz7ewqsAUiP8fyvO52gzDMDxYS5nef/99HnzwQf71r3/RsmVLNm7cyJgxY3jhhRcYOnRoicdPnDiRJ554osT5+fPnExkZ6Y2SRUTEjYIcDlrOnEnTpUs5Xq8e373wAvn6fi5elp2dzcCBA0lPTycmJqbMx1oanBISEpgwYQKjRo0qOjdp0iTmzZvHli1bSjy+tBGnhIQEjhw5ctZPVEpyOBx89dVX9OzZE7vdbnU5AUvXwXq6BhbZvZvggQMJ+mtdq+PBB/n8kkvocdVVug4WCsT/DxkZGdSuXdul4GTpVF12djZBQcWXWQUHB5+xHUFYWBhhpbTVt9vtAXNxPUFfP9+g62A9XQMv+uwzuO02SEsz1zDNnQtXXomxdKmug48IpOtQns/T0uB07bXX8vTTT9OoUSNatmzJhg0beOGFFxg+fLiVZYmIiKcUFMBjj8HkyebxxRebrQYSE8276ER8nKXB6eWXX+af//wn99xzD4cPHyY+Pp677rqLxx57zMqyRETEk9asMf++915zCxVt0Ct+xNLgFB0dzbRp05g2bZqVZYiIiKcVbpMSHAzvvgvffQc332x1VSLlpk1+RUTEc5xOeO45uOeek+fq1FFoEr+lTX5FRMQz0tJgyBBYssQ8HjAALr/c2ppEKknBSURE3G/tWujXD3bvNtcwvfwydO5sdVUilaapOhERcR/DgOnToVMnMzQ1aQIrVsCdd5prnET8nIKTiIi4z+jR5nqmvDy4/npYvx4uusjqqkTcRsFJRETcp3dvsNvhX/+Cjz+G6tWtrkjErbTGSUREKufAAahf33z76qth505ISLC2JhEP0YiTiIhUTE4OjBwJLVvCH3+cPK/QJFWYgpOIiJTfH3+YC8BnzIBjx+Drr62uSMQrFJxERKR8Pv3UXPC9fj3UqgVLl8KIEVZXJeIVCk4iIuKa/HwYP968W+7YMbjkEtiwAa66yurKRLxGwUlERFzz73/DlCnm2/fdZ+43p/VMEmB0V52IiLjmnnvM7VNGjjS7gosEII04iYhI6ZxOmDsXCgrM4/BwcxG4QpMEMAUnEREp6ehRuPZac5PeJ544eb6MbVOcToMtBzNYtesoWw5m4HQaXihUxLs0VSciIsWtXm2OKu3ZY44yNW581g9Zl5zK7BXJ7Dh8nLz8AkJDgjknrhpDOybSNrGm52sW8RKNOImIiMkw4JVX4LLLzNCUlAQ//QTDh5f5YeuSU3n6s9/ZtC+dmPAQGtaIJCY8hN/2p/P0Z7+zLjn1rC/tdBpsO5QJwLZDmRqtEp+lEScREYHMTLjzTvjgA/P4ppvgnXcgNrbMD3M6DWavSOZYtoPGtSKx/TWVFxUWQmRoMMmp2cxZkUybhBoEBZU+zVc4WpWcksnwRHh40SYS60RrtKqCnE6DbYczSc92EBtpp1lc9Bm/9lJ+Ck4iIgLJyWZjy5AQs+XAmDFlrmcqtO1wJjsOHycuOqwoNBWy2WzUqRbG9sPH2XY4k+b1Ykp8fOFo1bFsB/ExdgCiw4OLRqse6dNC4akcNGXqeZqqExERaNUKZs0yezONHetSaAJIz3aQl19AuD241PeH24PJyy8gPdtR4n2nj1ZFhZq/y0eFhpBYM5L0Ew7mrEjWtJ2L3DFlKmen4CQiEohycsy+TD/9dPJc//7QsWO5niY20k5oSDA5joLSX8ZhjnrERtpLvK88o1VSthIhNCyE4CAbUWEKoe6m4CQiEmh27TID0vTpMGAA5OZW+KmaxUVzTlw1Uo7nYhjFfygbhkHK8VzOjatGs7joEh9bmdEqKU4h1HsUnEREAsknn5gb9G7YALVrw5tvQlhYhZ8uKMjG0I6JxEbYSU7NJis3nwKnQVZuPsmp2cRG2BnSMbHUxcmVGa2S4hRCvUfBSUQkEDgc8NBDcMMNkJ5ujjht2AA9e1bqaZ1Og6iwEG5o3YCEGpFk5OTzZ1o2GTn5tIqPLXNxd2VGq6S46PAQnMDhzByO5+Zz+oScQqj76K46EZGqLiMD+vSBH34wj8eNg2efBXvlfoiefgeXPTiIujHhdG8RR/smNc96G3zhaNXTn/1Ocmo29aPNerLy8jmQ6ShztEpOWpecyqwfd3MkM5cTjgJCg4Oo9tfi8OoR9qIQ2io+ViHUDRScRESquuhoc1ouJgZmzjR7NFXSqW0E4qLDCLeHkeMoYG9aNos37KNlfIxLgadtYk0e6dOiqI8TQGZOAa3iYxmiW+jP6tTrkFAjgr1pJ8grcJJ+wkF2bgaNakWR4yhQCHUjBScRkarI6TQXfUdEmK0FZs6EI0fgnHPc8NSVb3p5qraJNWmTUIPf96exY933TL6pFS3iXfvYQFbadQi3h/BnWjZZefnk5DvZm5pN1/Pi1MfJjRScRESqmiNH4LbboHp1mD/fDE7Vq5t/3KCyTS9LExRko1ndaHYAzeqq07UrSrsO1SPtxEbEkJVbQGaOg5x8J3d3bcr59cvuAO/LfK0TuoKTiEhVsnKl2Y9p715zg96tW6F5c7e+xMk7uEq/Gy/cHsyR47m6g8vDznQdbDYb1cJDiAgN5s+0bDJP5FtUYeX5Yid03VUnIlIVGAb8+99w+eVmaDr3XFi1yu2hCbzfRsDpNNhyMINVu46y5WCGmjj+paq3c/DVTugacRIR8XcZGTBiBHz4oXl8883w9tvmYnAPKGwj8Nv+dCJDg4tN17n7Di5fHHHwFd68Dt7m7nV07qQRJxERf2YYcN11ZmgKCYGXXoIFCzwWmqByTS/Lw1dHHHyFt66DFXy5E7qCk4iIP7PZYOJEaNwY/vc/GD3a5Q16K6OwjUDL+NhyNb10lfZec42nr4NVfLkTuqbqRET8zYkT8PPPcMkl5nHXruYi8NBQr5ZR2EbAE3c8eeLOvbL42p1b5eHJ62CVU9dvRYWVjCpWrt9ScBIR8Sc7dphrmHbuhDVrTi7+dkNoKk94OP2xFzeu6dYf1N68c68qrKMKCrK5JUD6Cl9ev6XgJCLiLxYtgmHDzMXgdepASorb7porT3jwRtDw1ojDmTqgF66j8ufpLn92+nY8daqFEW43/z2kHM+1dP2W1jiJlJNujfZvfnn9HA64/37o29cMTZ06mRv0du7slqcvzyJsby3Y9sYGwFpH5dt8df2WRpxEyqEqDOkHsjNdv9s6NPDYa1Z67cyff8Itt8CKFebx/ffDM89UeoPeU+tz9bZvwGu3iHtjxMHb66gK+fN6Km/zxfVbCk4iLtKQvn8r6/o9v+w4A+PL/5xn+wHolqD95ptmaIqJgVmz4MYby19oGcp727c3g8apGwDvOHycI8dzCQ0JdtsGwFZ0QNcvX+Xna+u3FJxEXODLzdjk7M52/Q6kZRU9zlVn+wFY0aBdIow9/AhBhw7Bgw9CUpJ7viCnKG948HbQ8OSIg7fv3NIvX1WDgpOIC6wa0hf3ONv1q1XNvCNtR8pxWjY8+w+us/0A/MfVLZi7svxBe11yKgu/2MhFH7zJm1fdQXBYmBnG/jHZYz9QyxserLhF3FMjDt68c0u/fFUdWhwu4gJfacbmlwubfYAr1w8g48TZr58rC4pf++8Oth/KLFfX43XJqXz08gLGjr+Fm799n/u+ne2VLtnlWYTtjQXb3uTNztu+3AlbykcjTiIu8IVmbFobUXGuXD+AmIizXz9XfgD+cSSLAqdB3ZjwUp/j9CktZ4GT5Eef5qn5LxHiLOBAvURWdurjttGIstZilXcRtq/eIl5Rnl5HVciK9VTiGQpOIi6wuhmb1kZUztmu39HjeVAXzqlT7azP5coPwAKnQZDN5lrQTk8na+Bt3LT0PwCsbt+T2bc/TE5EFFD5qWBXAnd5woO3goY3eePOLV/45UvcQ8FJxAVWNmPT2ojKO9v1qx0ZUvS4s3HlB2B0uJ246DD2pmWXHbQPJ0Pfm4jesQNHcAjv3zqG/17Rr8RecxUdjShP4C5PeHBH0ChtFMxKnr5zy+pfvsR9FJxEXGTVb9pamO4eZV2/wR0asP/Xn1x6Hld/AA6+tBHPLN1SdtDOPQKHDuFokMCD/R/h4Hl/I6qUDXorMhpRkcBdnvBQmaBhRT8tq/lyJ2wpHwUnkXKwohmb1kacVNnGgWe6fgUF+ez/1bXncPUH4JmC2gX1orntsiZ/Be2asGQJwS3Ox7l8LyluHI3w1cDtiX5a/qIqTnMGIgUnkXLydjM2rY0wuWtxfGnXr6CgfLW4+gPw9KBW+0AyTe+9A1v9qZDY3Xyyyy8nCBjaMcitoxG+GLg90U/L3/hiJ2wpHwUnER+ntRG+uTje1R+ARUHtww/hjjsgMxPGjjX3mgsKKvZ87hyN8MXA7e5+Wv7K1zphS/koOIn4uEBfG+HLi+Nd+gGYlwcPPQQvvWQed+4M779fLDQVcudohLsDtzv2V3NlFAxc66clYhUFJxE/EMhrI3x1rY5L9u6F/v1h5UrzePx4mDQJQs78rdddoxHuDNzumiZ1Zz8tEasoOIn4iUBdG+GLa3Vc8uef0KYNHD0K1avD7Nlw3XUVfrqKjPi4I3C7c5rUnf20RKyi4CTiRwJxbYQvrtVxSYMGcPXVsHkzfPQRNGlS4aeqzIhPZQK3u6dJ3dlPS8Qq2qvOx2lvMgl0frU/2uHDkJZmvm2zweuvw48/Vjo0Pf3Z72zal05MeAgNa0SWew+7wsDdoWktmteLcTmYeGJ/tcJRsJbxsWTk5PNnWjYZOfm0io/lgV7nufw8IlbRiJMP095kIn60OP7HH831TG3bwuLF5uLvyMhKPaXVC+M9NU3qjn5aIlbRiJOPcsdvmSJVRVmjFO5uRVDuUV7DgKlToUsX2L8ftm+HI0fcUosnRnzK49Rp0tJUZpr09FEwgG2HMov+1ui6+CqNOPkgq3/LFPFF3lgcv3FvGnNX7XN9lPfYMRg+HD7+2DweMADeeAOquWdxs9UL473VQ6xwdD05JZPhifDwok0k1onW6Lr4JI04+SCrf8sU8VUVXavjqueXbXV9lHfjRmjXzgxNoaHw2mvw7rtuC03g2REfVxROk8ZG2Nl9NIuUzByOHs8lJTOH3Uez3DJNeuroenS42ccpOjxYo+visxScfNDJ3zKDS31/uD2YvPwC37v9WsRPFU4LpZ/Ip3GtSKLCQggOshEVFkJizUjSTziYsyL55PRRQQHceivs3AmJieb6ppEjzQXhbuQLC+PbJtakb9uG5OY72XroOL8dyGDroePk5jvp27ZhpUaETh9djwo1J0GiQs/wdRfxAQpOPsjq3zJFAs2OlOMA1K4W6toob3AwzJkDN90E69ebI08ecOqIT3JqNlm5+RQ4DbJy80lOzfbKwvh1yaksXPcnYSHBnFc3mpbxMZxXN5rwkGAWrvuzUiNCGl0Xf6Tg5IN84bdMkUByLDsPgFxHAcdz8kv8vwu3BxO3/w+CCtcyAbRvDwsXQk3PrsHx5sL4050+IlQnOoxaUWHUiQ4jsVblR4Q0ui7+SIvDfZDf3H4tUgWsS05l5o+7ubYmbDt8nAKCiAo11zhV/2tUt81Py7hz7jOE2wy49EJo3dqrNVrVNd7T2934bXNTCWgKTj4qkPcmE/GWwoXJ2Tl5UBNsQEhQEJm5+Ww/nEmLGmHc+Z/X6PH1hwAYXbpA3bqW1GpF13hP39V3+l17nJLN3HnXnog7KTj5sEDdm0ykUEX2ZyvPcxdOQ51TKwLIwB4cRFa+E3uQjdpHD/LPt56h1b6tABy4Zwz1X/pXmRv0VjWeHhE6fXS9frT5PFl5+RzIdGh0XXySy98B2rRpU2Ko9kzWr1/v0uMaN25McnJyifP33HMPr776qqulVWmBuDeZCHi+c35p01BJcdX4IzWHNptW8uziKVQ/kcnxyBgOvjyDc4YPqPRr+htv9HE6dXQ9OcVcBJ6ZU6DRdfFZLgenG264oejtnJwcXnvtNc4//3wuvfRSAFauXMlvv/3GPffc4/KLr1mzhoKCk3eObdq0iZ49e9KvXz+Xn0NEqp7CKbRj2Q7iosMIt4eR4ygo6u3jjkXRxaehzMXNseF2WsaHccVPu6l+IpPfG55Hzrz3aNOljRs+K//jrfWWhaPrv+9PY8e675l8UytaxKvBr/gml4PT448/XvT2iBEjGD16NE899VSJx+zdu9flF69Tp06x42effZakpCS6dOni8nOIiLXcPZ3mrc75p05DhYWdvMHYBiy7cQTHo2L5+OLeTDkvqcKvURV4a71lUJCNZnWj2QE0q6slCeK7KjRZ/+GHH7J27doS5wcPHky7du145513yv2ceXl5zJs3j3Hjxp1xSjA3N5fc3Nyi44yMDAAcDgcOh25XLa/Cr5m+dtby5+uwcW8a81ftZVdKVtF0WtM6UQzskEDrhBoVes5thzJJTskkPsaO3WZQOBoEgA3qR9vZnZLJ7/vTaFbXtSkip9NgR8pxMk44iImwc06dajSpEc55cZFsOZBB+z9+p8Pyd/j2789zIjQCwwYL2l9Di/oxNKkR7pfXxp3+Fh/Nv25qWeJrGBRkc9vXxuk02HbwGABb9qfRrF51hSeL+PP3pIoqz+dqM05vWOKCevXq8cwzzzBs2LBi52fOnMmECRM4dOhQeZ+SBQsWMHDgQPbs2UN8fHypj5k4cSJPPPFEifPz588nspK7kItIADIMzvn4Y1rMm0eQ08mWW25h64DAW8skEuiys7MZOHAg6enpxMSUva64QsHp2WefZeLEiYwYMYJLLrkEMNc4vfPOOzz22GNMmDCh3EX36tWL0NBQ/vOf/5zxMaWNOCUkJHDkyJGzfqJSksPh4KuvvqJnz57Y7eqTYhV/vA5Op8GERb/y+4EMGtWIKLFoeG/aCVrUj+GZmy4o96jBtkOZPLxoE9HhwUVbcJwqKy+fzJwCJt/U6qwjThv3pvH8sq2kn8indrXQovU5R4/nUd84wdQv/k2N5csA2NulC+OuepC8yGiS6kQxoBKjZuK6U69RvegQboxL5ePDNTmUmU9MRAgP9DpP18HL/PF7UmVlZGRQu3Ztl4JThabqJkyYQNOmTXnppZeYP38+AC1atGDWrFn079+/3M+XnJzM8uXLWbRoUZmPCwsLIyysZD8Ru90eMBfXE/T18w3+dB22HMxg6+FsqkeFU2A7reuzDWKjwtlyOJs/0nLKfVdoi/gaJNaJ5rf96STWtJcIZQcyHbSKjz3r4mGn02Duqn2kZBXQuFYUNpsNAwgLDeaS9B3c+co/qJF6ACM0lPypL7C+YQPGtWxHjegItf3wktOvkTk1C2H2UOrXCCM5NZt5q/bRtnEdXQ8L+NP3pMoqz+dZ4YYk/fv3r1BIKs3MmTOJi4ujT58+bnk+EfEsTzZGdNedXGfqet1m3bfcNeNR7PkODtSqT86779Gwe0dYupR2jWsGzA8KX1DyGp2cAHFHZ3IRT6jwXnXHjh3jrbfe4uGHHyY11dzkcf369ezbt69cz+N0Opk5cyZDhw4lJIAay4n4M09vRO2O/dnOtA/ansTm5IZFsL51Z0be9zqHz21VoRql8rRXnfijCiWVX375hR49ehAbG8vu3bsZMWIENWvW5OOPPyY5OZk5c+a4/FzLly9nz549DB8+vCKliIgFvNUYsTKd808Nd3GO42RVqw7A0dr1mfTYLHbH1CUvt8DyfdA82R3d12mvOvFHFQpO48aN4/bbb2fKlClER5/8xnj11VczcODAcj3XlVdeWWInchHxbd5qjFiZzvmF4a7ukoXcv/BFXr/7KX5p3RmAw3UakJKaXRTuCgryK1VnRXm6O7qv01514o8qNFW3Zs0a7rrrrhLnGzRowMGDBytdlIivcjoNthzMYNWuo2w5mIHTGbih3x3TaZ4U5Mjj0aUv88j8pwnPzeaS//2HAqdBVm4+yanZlu+DVtgdfdO+dGLCQ2hYI5KY8JCi7ujrklMtqcubCgN4bISd5NRssvLMAJuV5xvXSKQ0FRpxCg8PL2o+eaqtW7eW6AYuUlUE+uhAaXx2I+rdu6FfP+L+atT7xQ0jeOXyQeSkZXuk63V5eas7uj/QXnXibyoUnK6//nqefPJJFixYAJh3P+zZs4cJEybQt29ftxYo4gu8sXeav/K5jaiXLIEhQyAtDWrWhHnzuLLXVTT2oXB3pjv+IDDvJtNedeJPKjRV9/zzz5OSkkJcXBwnTpygS5cunHPOOURHR/P000+7u0YRS50+OhAVFkJwkI2osBASa0aSfsLBnBXJAT1t5zN+/hmuvdYMTe3bw4YNcPXVReGuQ9NaNK8XY/kP5Kp0N5m7pq8L96oD7VUnvq1CI04xMTH88MMPfPPNN6xfvx6n08lFF11Ejx493F2fiOU0OuBHLrwQ7r4b7HZ4/nkIDXX7S7jjLriqcjeZpq8lEJU7OOXn5xMeHs7GjRvp3r073bt390RdIj7Dk80exQ3+9z847zyoW9c8fvVVCKpwi7oyuSsoeKOdg6dp+loCVbm/u4SEhJCYmEhBQemN70SqGk83e5QKcjrhmWegWzcYOBAKvyd5MDS56y64EneT5eb71B1/Z6PpawlkFfoO8+ijj/KPf/yjqGO4SFVWODqQcjy3RM+xwtGBc+Oq+fToQJWTmgrXXQcPP2wGqIYNweG5ET9PBAVfb+dQlvJMX4tUNRVa4/Tvf/+bHTt2EB8fT2JiIlFRUcXev379ercUJ+ILvNXsUVy0di3cfDMkJ0NYGLzyCtxxB9g89/X31Do3n23ncBaavpZAVqHgdMMNN5g7javjtwSIU3vN7Dh8nCPHc32iH1BAMQyYMQPGjIG8PEhKgg8/hDZtPP7Snt7U2N9uKqgqi9tFKqJcwSk7O5sHH3yQxYsX43A4uOKKK3j55ZepXbu2p+oT8Rn+OjpQZZw4AS++aIamG26AmTOhenWvvLQvBAVf2tOuKixuF6mocgWnxx9/nFmzZjFo0CAiIiKYP38+I0eO5MMPP/RUfSI+xR9HB6qMyEhYuBCWLzdHnTw4NXc6q4OCr932r+lrCWTlCk6LFi3i7bff5tZbbwVg0KBBdOrUiYKCAoKDS2/kJiJSYe++CxkZMHKkeXzBBeYfL7MyKPjqbf+avpZAVa7gtHfvXjp37lx03L59e0JCQti/fz8JCQluL05EAlRODowda65pCgmBTp3gb3+ztCQrgoKv72mn6WsJROUKTgUFBYSe1ok3JCSE/Px8txYlIgHsjz/Mu+bWrzen4x55BFq2tLoqwPtBwR1383l6bZSmryXQlCs4GYbB7bffTljYyTtLcnJyuPvuu4u1JFi0aJH7KhSRwPHppzB0KBw7BrVqmVN1vXpZXVUx3gwKrt7Nl5aVx5aDGSXCka+tjRKpCsoVnIYOHVri3ODBg91WjIgEsEcfhcJNwi+5BBYsgABfAuDK3Xz5ToPXv9vF4czcYuGoQ9OaLFz3p8+tjRLxd+UKTjNnzvRUHSIS6GrUMP8eMwaee84jG/T6m7Pdzbc3LZvsvAL2pGYXC0eb9h3j++0pRIYGc17daJ9bGyXizzyzqZOIiCtyc0++PW6cuWHviy9aFpq2Hcpk1a6jbDmY4RP7rJW1p93uo1lk5xUQGRpcYhuY2tXCyMrNN/dX1JYoIm5Voc7hIiKVUrhB73vvwcqVUK2a+QP+lLt2vWnj3jQAHl60iSyH06fWAp3pbr7EmlE4jSzqxYSXWDie7zQICrKR43CSlZtPtdOm+bQlikjFKTiJuJkvdXj2SUePwm23weefm8fvvQd33mlZOeuSU3l+2VYGxkN0eDA1qoX73Fqg0u7mO5bl4NHFvxJuL9lDzx4URHCQjQKngaPAWeL92hJFpOIUnETcSHcxncWqVdC/P+zZA+Hh8OqrMHy4ZeUU9klKP2G2VIkKDSEfm0+uBTr9br4tBzPOuHA8KiyY8JBgMnPyCTmtbm2JIlI5WuMk4gKn02DLwYwy178UdnjetC+dmPAQGtaIJCY8pGjkYl1yqgWV+wjDgFdeMafi9uyBc84xp+gsDE1wsk9S7Wol11T5+lqgwoXjKcdzS91wPdweRFRYMEeP5xVbG5Wcmq0tUUQqQSNOImfhyiiSr3d4ttyzz8LDD5tv9+0Lb78NsbHW1sSpfZJKn7Ly5bVAZ9sGpm5MOH3bNmTVrlRtiSLiRgpOImVwdZ8wd3R4rtKGDYPp08075+67zyMb9FZkbdmpfZJK4+trgVzZBmbAxY205k7EjRScRM6gPKNIrnZ49sWRC49ZvRratzffrlcPtm6FiAiPvFRF15YVTndtP3AM6hZ/n7+sBTrbNjDaEkXEvbTGSQKSK2uWyjOK5O8jF26VkwN//zt06AAffHDyvAdDU0XXlhVOd8VEmL9DZuX551qgwnDUoWktmteL8fl6RfyZRpwk4Lg6OlHWKJIBFDgN0k/k8euf6dzYukGZHZ79YeTCLXbuNDfo3bjRnI5LTvboy7ljbVnbxJo80Os89v/6E5k5BWQ5HFoLJCJnpOAkAcXVNUtw5n3Cjp1w8GdaNpkn8sl3Opn+3518v/0IHZrW5M+07FIX6vrLyEWlLF4Mt98O6elQuzbMnw89e3r0Jd21tqx1Qg32/wqTb2rF8TxDa4FE5IwUnCRglHd0orR9wo6dcLD9UCaOfCeGDapHhlKnWii/7U/nz7TswLyLyeGAf/wDpk41jzt2NKfoGjb06Ms6nQa//plOenYekaHBGIZRIjyVd21Zs7rR2M9wh52ICCg4SQAp7+jE6bd7164Wxt7ULPLynQQF2bAH2UioEUm1cDtRYSEkp2azelcqL/S7kB1HjgfOXUzff38yNI0bZ7Ye8HD4KJxu3bQ/nZTjeaRlO4j+a31T9VPWkblzbZk6wosIKDj5LH2Tdr+K3Pl26u3em/ancyzb7MQcHR5Cw+onf0ifGrx2HDleobuYth3K9M9pou7dYeJEuOACuOkmj7/cqdOtdaLDOJ7jICMnn8zcfLYfzuTcuGiqR9rdurZMHeFFpJCCkw/SN2nPONOapUJnGp0ovN174fo/mfbVNupXjyAmPKTS00KFfHmD2VI5nfD88zBw4MnpuMcf99JLl5xuTagZZU6fFjjJKzDYm5ZNSFAkR7Ly3LK2rDzr4kSk6lM7Ah+jbTs8p6wtKgpHJ86Nq1bq6ERQkI0LGsYSGxlKSJCtRGiCik0LFW4wC+YGsz5/vY8cgd69Yfx4c8+5gtLbL3hKadOt1SPsnFs3mpgIO0HYOJadR8rxPFrFx1Y61Jwe1KLCQggOMveyS6wZSfoJB3NWJJfazkJEqiYFJx+ib9KeVbhmKTbCTnJqdrn376pM8CpNaRvM+vT1/uknaNMGli0zezLdfTcEB3u1hJPTrcVft3qEnZbxsbSMj6FOdBgjuybx4i2tKz0SVJ51cSISGBScfIi+SXte4ZqllvGxZOTk82daNhk5+S6NTlQ2eJ3ObzaYNQx46SW4/HL4809o1gxWrYIhQ7xeSlmNRm1AcJCN2IhQLmgY65Y1YmcKaoXC7cHk5RcEVkd4kQCnNU4+RNt2eMfZtqg428eebW8wV/nFBrOZmTB8OHz0kXncvz+89RZEW9PIs7QWEYU80Wi0ouviRKTqUnDyIfom7T2V2b+rMsHrVH6xTUtwsLnHnN0OL7wAo0Z5ZINeV53eIsLTjUa9HdRExPcpOJ2BFe0A9E3af7hj41Sf3mDWMMyAFBlpjjalpZl7z/kAd476nY23g5qI+D4Fp1JY1Q5A36QDS+H1nrL0OGBuMBsSYrf2ep84AffeC0lJ8PDD5rlmzbz3+i5y16ifq6/lraAmIr5Pwek0Vvds0TfpwOJTG8xu3w79+sHPP5tTc7fdBgkJ3nv9cnLHqJ+rvBnURMS3KTidwh07rbtDVfgmrc7nrvOJDWYXLYJhwyAjA+Li4L33fDo0WcGbQU1EfJeC0ynctdO6O/jzN2l1Pq8YSzaYdTjMZpYvvmged+4M778P8fHerUNExE+oj9MpXO3ZcizLwZaDGazadZQtBzN8p0GhD1Dncz9iGNCr18nQ9NBD8M03Ck0iImXQiNMpXGkHkO80mPHdTg5n5mo05TS+MtUpLrLZzL5M69fDnDlw3XVWVyQi4vM04nSKs22psTctm/QTDpKPZmk0pRTqfO4HCgrM7t+F7rrL7NOk0CQi4hIFp1OUuaXG0Wyy8wqIsAfTpHaU9pErhban8HEpKXD11ebWKWlp5jmbDerWLfvjRESkiILTac60l1mjWpHERthpVDNSoyln4BedsAPVihXmBr1ffQWHDsGGDVZXJCLil7TGqRSltQNIy8rjn4s3lTmaYvm+YhZT53MfZBgwbZq58Ds/H847DxYuhJYtra5MRMQvacTpDArbAXRoWovm9WKoERWq0ZSzKHOqMzVbnc+9LT0dbr4Zxo0zQ9Ott8KaNQpNIiKVoODkorMtHE85nsu5cdUCfjTlTFOdreJjPd51XU4zfrzZ2NJuh1degfnzITqw/32KiFSWpupc5I195KpKt+2q0Pm8Snj6adi8GZ5/Htq3t7oaEZEqQcGpHDy5j1xV67btz53P/VZ2Nnzwgbl1CkCtWvC//1lbk4hIFaPgVE6eGE2xemNhqQK2bTPXM/36q7kgfPhwqysSEamSFJwqwJ2jKeq2LZX24Ydwxx2QmWn2ZGrSxOqKRESqLC0Ot5i6bUuF5eXBffeZ26ZkZkKXLmZ/pm7drK5MRKTKUnCymLptS4Xs2WN2AP/3v83jCRNg+XKoX9/aukREqjhN1VnMlY2FA70/lJRi61ZYvRqqV4e5c+Gaa6yuSEQkIGjEyWLqDyUV0rMnvPkmrF+v0CQi4kUKThZTt21xyeHDcNNNsHPnyXN33KGF4CIiXqapOh/gyf5QUgX88APccgvs3w9HjsB334FNQVpExAoKTj5C3balBMOAqVPNhd8FBdCiBbz+ukKTiIiFFJx8iLptS5Fjx8wO4IsXm8eDBsGMGVCtmpVViYgEPAUnEV/zxx/Qowfs2gWhofDSS3DXXRppEhHxAZYvDt+3bx+DBw+mVq1aREZG0rp1a9atW2d1WSLWiY8395lr3BhWrIC771ZoEhHxEZaOOKWlpdGpUye6devG559/TlxcHDt37qR69epWliXidcE5OZCfD3Y7hIXBokUQFQU1alhdmoiInMLS4PTcc8+RkJDAzJkzi841btzYuoJErLBlC5c/9BBB69bBlCnmuYYNra1JRERKZWlw+vTTT+nVqxf9+vXju+++o0GDBtxzzz3ceeedpT4+NzeX3NzcouOMjAwAHA4HDoe2JCmvwq+ZvnbWsX3wASEjRxJz/DjOefNwPPQQxMZaXVbA0f8F36Dr4BsC8TqU53O1Gae3q/ai8PBwAMaNG0e/fv1YvXo1Y8aM4fXXX2fIkCElHj9x4kSeeOKJEufnz59PZGSkx+sVcZcgh4OWM2fSdOlSAFIuuIB1999PrqapRUS8Ljs7m4EDB5Kenk5MTNl3t1sanEJDQ2nXrh0rVqwoOjd69GjWrFnDTz/9VOLxpY04JSQkcOTIkbN+olKSw+Hgq6++omfPntjt2gvPa5KTCR44kKA1awBwPPQQSzt0oOdVV+k6WET/F3yDroNvCMTrkJGRQe3atV0KTpZO1dWvX5/zzz+/2LkWLVqwcOHCUh8fFhZGWFhYifN2uz1gLq4n6OvnRbm50L077N0LNWuaG/T27AlLl+o6+ABdA9+g6+AbAuk6lOfztLQdQadOndi6dWuxc9u2bSMxMdGiikQ8LCwMJk+G9u3NDXp797a6IhERKQdLg9PYsWNZuXIlkydPZseOHcyfP5833niDUaNGWVmWiHsdPAgbNpw8HjwYfvwR9AuCiIjfsTQ4XXzxxXz88ce89957tGrViqeeeopp06YxaNAgK8sScZ/vvoM2beDaa+Hw4ZPnQ9S0X0TEH1n+3fuaa67hmmuusboMEfdyOuFf/4KHHzbfbtkSMjMhLs7qykREpBIsD04iVU5aGgwZAkuWmMe33QbTp5udwEVExK8pOIm409q10K8f7N5tLgR/+WUYMUJ7zYmIVBEKTiLu9OKLZmhq2hQ++shc3yQiIlWGgpOIO02fbvZneuopUBdwEZEqx9K76kT83ubNMGECFDbgj4kxp+cUmkREqiSNOIlU1Pz5cOedkJ0NTZrAXXdZXZGIiHiYRpxEyis3F+65BwYNMkNT9+5www1WVyUiIl6g4CRSHn/8AZ06mWuZAP75T/jyS6hb19q6RETEKzRVJ+KqL76AAQPg2DFzAfi8eXD11VZXJSIiXqTgJOKqqCiz+3eHDrBgATRqZHVFIiLiZQpOImXJzz+5r1znzua03GWXQWiotXWJiIgltMZJ5Ey+/RaaNzdbDhTq3l2hSUQkgCk4iZzO6YTJk6FHD9i5EyZOtLoiERHxEZqqEznV0aPmBr1Ll5rHt98Or75qaUkiIuI7FJxECq1ebW7Qu2cPhIebgWn4cKurEhERH6LgJAKwYgV07QoOByQlmRv0tm5tdVUiIuJjFJxEANq3h0svhdq14Z13IDbW6opERMQHKThJ4Nq61dxjLjTUbDmwZAlUqwY2m9WViYiIj9JddRKY5s6FNm3ggQdOnouOVmgSEZEyKThJYMnJgb//3bxz7sQJ2LIF8vKsrkpERPyEgpMEjp07oWNHePNNc2Rp4kT4/HM1tBQREZdpjZMEhsWLzZ5M6enmAvB334Urr7S6KhER8TMKTlL1paWdDE2XXmpu0NuwodVViYiIH1JwkqqvRg2YORO+/x6eew7sdqsrEhERP6XgJFXT11+bf19xhfn3jTeaf0RERCpBi8OlanE6YdIk6NkTbr0V9u2zuiIREalCNOIkVceRI3DbbfDFF+bx9ddDzZrW1iQiIlWKgpNUDStXQv/+sHcvRETAa6+ZC8KrMKfTYNvhTNKzHcRG2mkWF01QkBp4ioh4koKT+DfDgFdegfvvNzfoPfdcWLgQLrjA6so8al1yKrNXJLPj8HHy8gsIDQnmnLhqDO2YSNtEjbKJiHiK1jiJ/1u3zgxN/frB2rUBEZqe/ux3Nu1LJyY8hIY1IokJD+G3/ek8/dnvrEtOtbpEEZEqSyNO4t9sNnNarls3cxuVKr7XnNNpMHtFMseyHTSuFYntr883KiyEyNBgklOzmbMimTYJNTRtJyLiARpxEv8ze7Y5uuR0mseRkTB0aJUPTQDbDmey4/Bx4qLDikJTIZvNRp1qYWw/fJxthzMtqlBEpGpTcBL/ceIEjBhhLvr+6CN4/32rK/K69GwHefkFhNuDS31/uD2YvPwC0rMdXq5MRCQwaKpO/MOOHXDzzfDzz+bI0pNPmn2aAkxspJ3QkGByHAVEhZX875vjMBeKx0aqO7qIiCdoxEl836JF0LatGZrq1IEvv4RHH4WgwPvn2ywumnPiqpFyPBfDMIq9zzAMUo7ncm5cNZrFRVtUoYhI1RZ4P3nEv0yZAn37QkYGdOoEGzZAjx5WV2WZoCAbQzsmEhthJzk1m6zcfAqcBlm5+SSnZhMbYWdIx0QtDBcR8RAFJ/Ft3btDWJjZp+nbb6FBA6srslzbxJo80qcFLeNjycjJ58+0bDJy8mkVH8sjfVqoj5OIiAdpjZP4noMHoV498+127WDbNmjUyNqafEzbxJq0SaihzuEiIl6mESfxHQUF8MQT0LQprF9/8rxCU6mCgmw0rxdDh6a1aF4vRqFJRMQLFJzEN6SkQO/eMHGi2Xbgk0+srkhERKQETdWJ9VasMDfo3bfP3KB3xgyzC7iIiIiP0YiTWMcwYNo06NLFDE3NmsGqVQpNIiLisxScxDoffQRjx0J+vjniFAAb9IqIiH/TVJ1Yp29fuP56sy/TqFEBsdeciIj4NwUn8a4PP4Q+fcyNeYOC4OOPFZhERMRvaKpOvCM7G4YNM6fk7r335HmFJhER8SMacRLP27bN3KD311/NUaakJHNhuEKTiIj4GQUn8awPP4Q77oDMTIiLg/ffh27drK5KRESkQjRVJ56RlwdjxphTc5mZ0LmzuUGvQpOIiPgxBSfxjJQUmDfPfHv8ePjmG4iPt7YmERGRStJUnXhGgwbw3nvm9inXXWd1NSIiIm6h4CTuUbhB70UXwQ03mOd69rS0JBEREXdTcJLKO3wYBg6Er7+G2FjYsQNq17a6KhEREbdTcJLK+eEHuOUW2L/fbGr56qsKTSIiUmVpcbhUjGHA1KnQtasZmpo3hzVrYNAgqysTERHxGI04SfkVbsr78cfm8YAB8MYbUK2atXWJiIh4mEacpPxCQszWAqGh8Npr8O67Ck0iIhIQNOIkrjEMs7VAZKR5PHUq3HknXHihtXWJiIh4kUac5OwKN+jt08ecpgMIC1NoEhGRgKMRJynb1q3mBr2bNpkb9P74I3TpYnVVIiIiltCIk5zZggXQrp0ZmurVM7dNUWgSEZEApuAkJeXlwejRZn+m48fNlgMbNig0iYhIwFNwkpLuuANeftl8++GH4auvzBEnERGRAGdpcJo4cSI2m63Yn3r6AW29CROgYUNYsgSeftpsPyAiIiLWLw5v2bIly5cvLzoODg62sJoAVVAAq1dDp07mccuWsHOn2adJREREilgenEJCQjTKZKGwY8cI7t0bvv8e/vvfk+FJoUlERKQEy9c4bd++nfj4eJo0acKtt97Krl27rC4pYNi+/56uY8cS9O23Zl+mw4etLklERMSnWTri1KFDB+bMmUOzZs04dOgQkyZNomPHjvz222/UqlWrxONzc3PJzc0tOs7IyADA4XDgcDi8VrffMwyCpk4l+J//JKSgAGeLFhS8/z60aAH6Onpd4b9d/Ru2jq6Bb9B18A2BeB3K87naDMMwPFhLuWRlZZGUlMRDDz3EuHHjSrx/4sSJPPHEEyXOz58/n8jCrUCkTPbjx2nz739Tf/VqAPZ26cLPI0dSEB5ucWUiIiLWyM7OZuDAgaSnpxMTE1PmY30qOAH07NmTc845h+nTp5d4X2kjTgkJCRw5cuSsn6iYbG+/TcjIkRihoTief57PExLoeeWV2O12q0sLWA6Hg6+++oqePXvqOlhE18A36Dr4hkC8DhkZGdSuXdul4GT54vBT5ebm8vvvv9O5c+dS3x8WFkZYWFiJ83a7PWAubqXddRds3Ypt8GBsf/sbLF2qr5+P0HWwnq6Bb9B18A2BdB3K83laujj8gQce4LvvvuOPP/5g1apV3HzzzWRkZDB06FAry6pasrJg/Hj4az0YNhu8+CK0bWttXSIiIn7I0hGnP//8kwEDBnDkyBHq1KnDJZdcwsqVK0lMTLSyrKrj99/NDXo3b4a9e2H+fKsrEhER8WuWBqf333/fypev2t57D+680xxxql8f7r7b6opERET8nuV9nMTNcnNh1CgYONAMTd26mRv0Xn651ZWJiIj4PQWnqmTvXrjsMnjtNfP4kUfMDXrr1rW2LhERkSrCp+6qk0oKDYV9+6BmTZg7F3r3troiERGRKkXByd85nRD018Bh3brwyScQFwdaYC8iIuJ2mqrzZwcPwhVXwLvvnjx38cUKTSIiIh6i4OSvvvsO2rSB//4XHngATpywuiIREZEqT8HJ3zid8Mwz0L27OeLUqpUZniIirK5MRESkytMaJ3+SmgpDhsBnn5nHQ4bA9OmgDY5FRES8QsHJXxw/Du3awR9/QFgYvPIK3HGHuYWKiIiIeIWm6vxFtWrQvz8kJcFPP8GIEQpNIiIiXqbg5MuOH4cDB04eT5oE69aZi8JFRETE6xScfNVvv5mtBW64AfLyzHMhIRAba2lZIiIigUzByRfNmwft28OWLfDnn7B7t9UViYiICApOviUnB+6+G267DbKzoUcPc4PeZs2srkxERERQcPIdu3ZBp07w+uvmou/HHoMvvjC3TxERERGfoHYEvmLECFi/HmrVMrdQ6dXL6opERETkNBpx8hVvvglXXWVOzSk0iYiI+CQFJ6scOABz5548TkqCzz+HhATrahIREZEyaarOCt9+CwMGwOHDUK8e9OxpdUUiIiLiAo04eZPTCZMnm3fLHToEF1wAiYlWVyUiIiIu0oiTtxw9am7Ku3SpeTxsmLnfnDboFRER8RsKTt6wejX06wd79kB4OLz2mhmcRERExK8oOHnDr7+aoemcc+Cjj+DCC62uSERERCpAwckbhg8Hh8NcEK695kRERPyWFod7wqZNZk+m1FTz2GYzt1JRaBIREfFrCk7uNmeOuUHvsmXw4INWVyMiIiJupODkLjk58Pe/w9ChcOIEXHklPPus1VWJiIiIGyk4ucPOnXDppea2KTYbTJxoth2oU8fqykRERMSNtDi8sn78Efr0gfR0qF0b5s9XJ3AREZEqSsGpss4/H2rUgJYt4YMPoGFDqysSERERD1FwqojUVDMs2Wzm3998YwYmu93qykRERMSDtMapvJYvh+bNzfVMhZo0UWgSEREJAApOrnI64amnzLvlUlLgnXfMcyIiIhIwFJxcceQI9O4Njz0GhgF33AHffgtB+vKJiIgEEq1xOpuVK80Nev/8EyIizA16b7/d6qpERETEAgpOZTlwALp1M5tbnnsuLFwIF1xgdVUiIiJiEQWnstSvD488Ar/8Am+9BTExVlckIiIiFlJwOpuHHzbbDthsVlciIiIiFlNwOhstABcREZG/KBWIiIiIuEjBSURERMRFCk4iIiIiLlJwEhEREXGRgpOIiIiIixScRERERFyk4CQiIiLiIgUnERERERcpOImIiIi4SMFJRERExEUKTiIiIiIuUnASERERcZGCk4iIiIiLFJxEREREXKTgJCIiIuKiEKsLqAzDMADIyMiwuBL/5HA4yM7OJiMjA7vdbnU5AUvXwXq6Br5B18E3BOJ1KMwRhbmiLH4dnDIzMwFISEiwuBIRERHxd5mZmcTGxpb5GJvhSrzyUU6nk/379xMdHY3NZrO6HL+TkZFBQkICe/fuJSYmxupyApaug/V0DXyDroNvCMTrYBgGmZmZxMfHExRU9iomvx5xCgoKomHDhlaX4fdiYmIC5j+HL9N1sJ6ugW/QdfANgXYdzjbSVEiLw0VERERcpOAkIiIi4iIFpwAWFhbG448/TlhYmNWlBDRdB+vpGvgGXQffoOtQNr9eHC4iIiLiTRpxEhEREXGRgpOIiIiIixScRERERFyk4BSAJk6ciM1mK/anXr16VpcVcPbt28fgwYOpVasWkZGRtG7dmnXr1lldVkBp3Lhxif8LNpuNUaNGWV1aQMnPz+fRRx+lSZMmRERE0LRpU5588kmcTqfVpQWUzMxMxowZQ2JiIhEREXTs2JE1a9ZYXZbP8esGmFJxLVu2ZPny5UXHwcHBFlYTeNLS0ujUqRPdunXj888/Jy4ujp07d1K9enWrSwsoa9asoaCgoOh406ZN9OzZk379+llYVeB57rnnmDFjBrNnz6Zly5asXbuWYcOGERsby3333Wd1eQFjxIgRbNq0iblz5xIfH8+8efPo0aMHmzdvpkGDBlaX5zN0V10AmjhxIosXL2bjxo1WlxKwJkyYwI8//sj3339vdSlyijFjxrBkyRK2b9+ubZy86JprrqFu3bq8/fbbRef69u1LZGQkc+fOtbCywHHixAmio6P55JNP6NOnT9H51q1bc8011zBp0iQLq/MtmqoLUNu3byc+Pp4mTZpw6623smvXLqtLCiiffvop7dq1o1+/fsTFxdGmTRvefPNNq8sKaHl5ecybN4/hw4crNHnZZZddxtdff822bdsA+Pnnn/nhhx/o3bu3xZUFjvz8fAoKCggPDy92PiIigh9++MGiqnyTglMA6tChA3PmzGHZsmW8+eabHDx4kI4dO3L06FGrSwsYu3btYvr06Zx77rksW7aMu+++m9GjRzNnzhyrSwtYixcv5tixY9x+++1WlxJwxo8fz4ABA2jevDl2u502bdowZswYBgwYYHVpASM6OppLL72Up556iv3791NQUMC8efNYtWoVBw4csLo8n6KpOiErK4ukpCQeeughxo0bZ3U5ASE0NJR27dqxYsWKonOjR49mzZo1/PTTTxZWFrh69epFaGgo//nPf6wuJeC8//77PPjgg/zrX/+iZcuWbNy4kTFjxvDCCy8wdOhQq8sLGDt37mT48OH873//Izg4mIsuuohmzZqxfv16Nm/ebHV5PkOLw4WoqCguuOACtm/fbnUpAaN+/fqcf/75xc61aNGChQsXWlRRYEtOTmb58uUsWrTI6lIC0oMPPsiECRO49dZbAbjgggtITk7mmWeeUXDyoqSkJL777juysrLIyMigfv363HLLLTRp0sTq0nyKpuqE3Nxcfv/9d+rXr291KQGjU6dObN26tdi5bdu2kZiYaFFFgW3mzJnExcUVWxQr3pOdnU1QUPEfR8HBwWpHYJGoqCjq169PWloay5Yt4/rrr7e6JJ+iEacA9MADD3DttdfSqFEjDh8+zKRJk8jIyNBvdl40duxYOnbsyOTJk+nfvz+rV6/mjTfe4I033rC6tIDjdDqZOXMmQ4cOJSRE3xKtcO211/L000/TqFEjWrZsyYYNG3jhhRcYPny41aUFlGXLlmEYBueddx47duzgwQcf5LzzzmPYsGFWl+ZbDAk4t9xyi1G/fn3Dbrcb8fHxxk033WT89ttvVpcVcP7zn/8YrVq1MsLCwozmzZsbb7zxhtUlBaRly5YZgLF161arSwlYGRkZxn333Wc0atTICA8PN5o2bWo88sgjRm5urtWlBZQPPvjAaNq0qREaGmrUq1fPGDVqlHHs2DGry/I5WhwuIiIi4iKtcRIRERFxkYKTiIiIiIsUnERERERcpOAkIiIi4iIFJxEREREXKTiJiIiIuEjBSURERMRFCk4iIiIiLlJwEhEREXGRgpOI+AWbzVbmn9tvv93qEkUkAGhHSxHxCwcOHCh6+4MPPuCxxx5j69atReciIiKKPd7hcGC3271Wn4gEBo04iYhfqFevXtGf2NhYbDZb0XFOTg7Vq1dnwYIFdO3alfDwcObNm8fEiRNp3bp1seeZNm0ajRs3LnZu5syZtGjRgvDwcJo3b85rr73mvU9MRPyKgpOIVBnjx49n9OjR/P777/Tq1culj3nzzTd55JFHePrpp/n999+ZPHky//znP5k9e7aHqxURf6SpOhGpMsaMGcNNN91Uro956qmnmDp1atHHNWnShM2bN/P6668zdOhQT5QpIn5MwUlEqox27dqV6/EpKSns3buXO+64gzvvvLPofH5+PrGxse4uT0SqAAUnEakyoqKiih0HBQVhGEaxcw6Ho+htp9MJmNN1HTp0KPa44OBgD1UpIv5MwUlEqqw6depw8OBBDMPAZrMBsHHjxqL3161blwYNGrBr1y4GDRpkUZUi4k8UnESkyuratSspKSlMmTKFm2++mS+++ILPP/+cmJiYosdMnDiR0aNHExMTw9VXX01ubi5r164lLS2NcePGWVi9iPgi3VUnIlVWixYteO2113j11Ve58MILWb16NQ888ECxx4wYMYK33nqLWbNmccEFF9ClSxdmzZpFkyZNLKpaRHyZzTh9AYCIiIiIlEojTiIiIiIuUnASERERcZGCk4iIiIiLFJxEREREXKTgJCIiIuIiBScRERERFyk4iYiIiLhIwUlERETERQpOIiIiIi5ScBIRERFxkYKTiIiIiIsUnERERERc9P87vd+1LTxbXgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "mae = mean_absolute_error(true_value, final_pred)\n",
    "mse = mean_squared_error  (true_value, final_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "r2  = r2_score           (true_value, final_pred)\n",
    "print(f\"Ensemble: MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.3f}\")\n",
    "plt.figure(figsize=(6,5)); plt.scatter(true_value,final_pred,alpha=0.7)\n",
    "plt.plot([true_value.min(),true_value.max()],[true_value.min(),true_value.max()], 'r--'); plt.xlabel(\"True\"); plt.ylabel(\"Pred\"); plt.title(\"Ensemble True vs Pred\"); plt.grid(True); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909fd41",
   "metadata": {},
   "source": [
    "# ## Step 7: Final Model Training on Combined Data & Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a0190ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train 2.6383 | Val 0.8345\n",
      "Epoch 02 | Train 1.0867 | Val 0.8507\n",
      "Epoch 03 | Train 1.0685 | Val 1.1212\n",
      "Epoch 04 | Train 1.0951 | Val 0.9653\n",
      "Epoch 05 | Train 1.1139 | Val 1.0248\n",
      "Epoch 06 | Train 1.1170 | Val 0.7761\n",
      "Epoch 07 | Train 1.0806 | Val 1.0999\n",
      "Epoch 08 | Train 1.0465 | Val 0.7472\n",
      "Epoch 09 | Train 1.0652 | Val 0.7656\n",
      "Epoch 10 | Train 1.2027 | Val 1.0557\n",
      "Epoch 11 | Train 0.9890 | Val 0.7543\n",
      "Epoch 12 | Train 1.0269 | Val 0.7997\n",
      "Epoch 13 | Train 0.9624 | Val 1.1722\n",
      "Epoch 14 | Train 1.0560 | Val 0.7600\n",
      "Epoch 15 | Train 1.0514 | Val 0.7684\n",
      "Epoch 16 | Train 0.9559 | Val 1.1936\n",
      "Epoch 17 | Train 0.9564 | Val 0.7782\n",
      "Epoch 18 | Train 0.9951 | Val 0.7294\n",
      "Epoch 19 | Train 0.9799 | Val 0.7456\n",
      "Epoch 20 | Train 1.0125 | Val 0.8608\n",
      "Epoch 21 | Train 0.9507 | Val 0.7771\n",
      "Epoch 22 | Train 0.9062 | Val 0.7507\n",
      "Epoch 23 | Train 0.8997 | Val 0.8416\n",
      "Epoch 24 | Train 0.9636 | Val 0.7332\n",
      "Epoch 25 | Train 0.9397 | Val 0.7671\n",
      "Epoch 26 | Train 0.9106 | Val 0.7301\n",
      "Epoch 27 | Train 0.9144 | Val 0.7627\n",
      "Epoch 28 | Train 0.8860 | Val 0.7141\n",
      "Epoch 29 | Train 0.8881 | Val 0.7592\n",
      "Epoch 30 | Train 0.8896 | Val 0.7330\n",
      "Epoch 31 | Train 0.8698 | Val 0.7305\n",
      "Epoch 32 | Train 0.8972 | Val 0.7027\n",
      "Epoch 33 | Train 0.8759 | Val 0.7176\n",
      "Epoch 34 | Train 0.8857 | Val 0.7366\n",
      "Epoch 35 | Train 0.8881 | Val 0.8757\n",
      "Epoch 36 | Train 0.8830 | Val 0.7004\n",
      "Epoch 37 | Train 0.8806 | Val 0.7074\n",
      "Epoch 38 | Train 0.8724 | Val 0.7304\n",
      "Epoch 39 | Train 0.9304 | Val 0.9491\n",
      "Epoch 40 | Train 0.9114 | Val 0.8219\n",
      "Epoch 41 | Train 0.9068 | Val 0.8713\n",
      "Epoch 42 | Train 0.9217 | Val 0.7377\n",
      "Epoch 43 | Train 0.8730 | Val 0.7707\n",
      "Epoch 44 | Train 0.8651 | Val 0.8694\n",
      "Epoch 45 | Train 0.8750 | Val 0.7956\n",
      "Epoch 46 | Train 0.8504 | Val 0.7230\n",
      "‚èπÔ∏è Early stopping\n",
      "Final: MAE=0.722, RMSE=0.936, R2=0.340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.785776</td>\n",
       "      <td>0.722072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.936037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.272208</td>\n",
       "      <td>0.340379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric  ensemble     final\n",
       "0    MAE  0.785776  0.722072\n",
       "1   RMSE  0.983218  0.936037\n",
       "2     R2  0.272208  0.340379"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data=[]\n",
    "for fold in range(5):\n",
    "    all_data += torch.load(os.path.join(base_path,f\"{task}_train_fold{fold}.pt\"))\n",
    "    all_data += torch.load(os.path.join(base_path,f\"{task}_val_fold{fold}.pt\"))\n",
    "# Split off small validation for early stopping\n",
    "tidx, vidx = train_test_split(range(len(all_data)), test_size=0.1, random_state=seed)\n",
    "train_split=[all_data[i] for i in tidx]; val_split=[all_data[i] for i in vidx]\n",
    "train_loader=DataLoader(train_split,batch_size=32,shuffle=True)\n",
    "val_loader  =DataLoader(val_split,  batch_size=32)\n",
    "model=MPNN(input_dim,edge_dim,hidden_dim=best_hidden_dim,output_dim=output_dim,dropout=best_dropout).to(device)\n",
    "opt=torch.optim.Adam(model.parameters(),lr=best_lr)\n",
    "scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=5,factor=0.5,verbose=True)\n",
    "best_val = float('inf')\n",
    "pt = 0\n",
    "for epoch in range(1,100):\n",
    "    model.train(); tot=0\n",
    "    for b in train_loader: b=b.to(device); opt.zero_grad(); o=model(b); l=F.mse_loss(o.squeeze(),b.y); l.backward(); opt.step(); tot+=l.item()\n",
    "    preds,trues=evaluate(model,val_loader); vloss=F.mse_loss(preds.squeeze(),trues).item()\n",
    "    scheduler.step(vloss); print(f\"Epoch {epoch:02d} | Train {tot/len(train_loader):.4f} | Val {vloss:.4f}\")\n",
    "    if vloss<best_val: best_val=vloss; pt=0; torch.save(model.state_dict(),os.path.join(results_dir,\"final_model.pt\"))\n",
    "    else: pt+=1; \n",
    "    if pt>=10: \n",
    "        print(\"‚èπÔ∏è Early stopping\"); \n",
    "        break\n",
    "# Load best and evaluate on test\n",
    "model.load_state_dict(torch.load(os.path.join(results_dir,\"final_model.pt\")))\n",
    "out,tru=evaluate(model,DataLoader(test_data,batch_size=32))\n",
    "pred_final=out.squeeze().numpy(); true_final=tru.numpy()\n",
    "mae_f=mean_absolute_error(true_final,pred_final); mse_f=mean_squared_error(true_final,pred_final)\n",
    "rmse_f=np.sqrt(mse_f); r2_f=r2_score(true_final,pred_final)\n",
    "print(f\"Final: MAE={mae_f:.3f}, RMSE={rmse_f:.3f}, R2={r2_f:.3f}\")\n",
    "# Compare\n",
    "comp = pd.DataFrame({ 'metric':['MAE','RMSE','R2'], 'ensemble':[mae, rmse, r2], 'final':[mae_f, rmse_f, r2_f] })\n",
    "display(comp)\n",
    "\n",
    "# Side-by-side scatter plots for Ensemble vs Final Model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Ensemble plot\n",
    "axes[0].scatter(true_value, final_pred, alpha=0.7)\n",
    "axes[0].plot([true_value.min(), true_value.max()], [true_value.min(), true_value.max()], 'r--')\n",
    "axes[0].set_title('Ensemble: True vs Predicted')\n",
    "axes[0].set_xlabel('True pChEMBL')\n",
    "axes[0].set_ylabel('Ensemble Prediction')\n",
    "\n",
    "# Final model plot\n",
    "axes[1].scatter(true_final, pred_final, alpha=0.7)\n",
    "axes[1].plot([true_final.min(), true_final.max()], [true_final.min(), true_final.max()], 'r--')\n",
    "axes[1].set_title('Final Model: True vs Predicted')\n",
    "axes[1].set_xlabel('True pChEMBL')\n",
    "axes[1].set_ylabel('Final Model Prediction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3e175a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 3.3237 | Val Loss: 0.9466\n",
      "Epoch 002 | Train Loss: 0.9995 | Val Loss: 0.9226\n",
      "Epoch 003 | Train Loss: 0.9738 | Val Loss: 0.9021\n",
      "Epoch 004 | Train Loss: 0.9420 | Val Loss: 0.9192\n",
      "Epoch 005 | Train Loss: 0.9335 | Val Loss: 0.8853\n",
      "Epoch 006 | Train Loss: 0.9264 | Val Loss: 0.9203\n",
      "Epoch 007 | Train Loss: 0.9150 | Val Loss: 1.0024\n",
      "Epoch 008 | Train Loss: 0.9362 | Val Loss: 1.0411\n",
      "Epoch 009 | Train Loss: 0.8821 | Val Loss: 0.9191\n",
      "Epoch 010 | Train Loss: 0.8631 | Val Loss: 0.8930\n",
      "Epoch 011 | Train Loss: 0.8806 | Val Loss: 0.8755\n",
      "Epoch 012 | Train Loss: 0.8545 | Val Loss: 0.9670\n",
      "Epoch 013 | Train Loss: 0.8447 | Val Loss: 0.8770\n",
      "Epoch 014 | Train Loss: 0.8205 | Val Loss: 0.8717\n",
      "Epoch 015 | Train Loss: 0.8374 | Val Loss: 0.8620\n",
      "Epoch 016 | Train Loss: 0.7958 | Val Loss: 0.8777\n",
      "Epoch 017 | Train Loss: 0.8441 | Val Loss: 0.9276\n",
      "Epoch 018 | Train Loss: 0.8084 | Val Loss: 0.9082\n",
      "Epoch 019 | Train Loss: 0.8204 | Val Loss: 1.0908\n",
      "Epoch 020 | Train Loss: 0.7951 | Val Loss: 0.9142\n",
      "Epoch 021 | Train Loss: 0.7794 | Val Loss: 0.9896\n",
      "Epoch 022 | Train Loss: 0.7754 | Val Loss: 0.8757\n",
      "Epoch 023 | Train Loss: 0.7626 | Val Loss: 0.8518\n",
      "Epoch 024 | Train Loss: 0.7559 | Val Loss: 0.8445\n",
      "Epoch 025 | Train Loss: 0.7679 | Val Loss: 1.0686\n",
      "Epoch 026 | Train Loss: 0.7855 | Val Loss: 0.8550\n",
      "Epoch 027 | Train Loss: 0.7623 | Val Loss: 0.8821\n",
      "Epoch 028 | Train Loss: 0.7673 | Val Loss: 0.8363\n",
      "Epoch 029 | Train Loss: 0.7631 | Val Loss: 0.8306\n",
      "Epoch 030 | Train Loss: 0.7507 | Val Loss: 0.8401\n",
      "Epoch 031 | Train Loss: 0.7576 | Val Loss: 0.8344\n",
      "Epoch 032 | Train Loss: 0.7527 | Val Loss: 0.8544\n",
      "Epoch 033 | Train Loss: 0.7878 | Val Loss: 0.8229\n",
      "Epoch 034 | Train Loss: 0.7398 | Val Loss: 0.9236\n",
      "Epoch 035 | Train Loss: 0.7447 | Val Loss: 0.8121\n",
      "Epoch 036 | Train Loss: 0.7453 | Val Loss: 0.9257\n",
      "Epoch 037 | Train Loss: 0.7199 | Val Loss: 0.7823\n",
      "Epoch 038 | Train Loss: 0.7146 | Val Loss: 0.7844\n",
      "Epoch 039 | Train Loss: 0.7127 | Val Loss: 0.7612\n",
      "Epoch 040 | Train Loss: 0.7181 | Val Loss: 0.7619\n",
      "Epoch 041 | Train Loss: 0.6977 | Val Loss: 0.8822\n",
      "Epoch 042 | Train Loss: 0.6917 | Val Loss: 0.7684\n",
      "Epoch 043 | Train Loss: 0.6722 | Val Loss: 0.8218\n",
      "Epoch 044 | Train Loss: 0.6692 | Val Loss: 0.7228\n",
      "Epoch 045 | Train Loss: 0.6563 | Val Loss: 0.7430\n",
      "Epoch 046 | Train Loss: 0.6528 | Val Loss: 0.7027\n",
      "Epoch 047 | Train Loss: 0.6247 | Val Loss: 0.7539\n",
      "Epoch 048 | Train Loss: 0.6138 | Val Loss: 0.6763\n",
      "Epoch 049 | Train Loss: 0.6266 | Val Loss: 0.6901\n",
      "Epoch 050 | Train Loss: 0.6126 | Val Loss: 0.7261\n",
      "Epoch 051 | Train Loss: 0.5931 | Val Loss: 0.6627\n",
      "Epoch 052 | Train Loss: 0.5824 | Val Loss: 0.7045\n",
      "Epoch 053 | Train Loss: 0.5688 | Val Loss: 0.6846\n",
      "Epoch 054 | Train Loss: 0.5525 | Val Loss: 0.6467\n",
      "Epoch 055 | Train Loss: 0.5589 | Val Loss: 0.6692\n",
      "Epoch 056 | Train Loss: 0.5328 | Val Loss: 0.6807\n",
      "Epoch 057 | Train Loss: 0.5363 | Val Loss: 0.6446\n",
      "Epoch 058 | Train Loss: 0.5337 | Val Loss: 0.6248\n",
      "Epoch 059 | Train Loss: 0.5307 | Val Loss: 0.6349\n",
      "Epoch 060 | Train Loss: 0.5131 | Val Loss: 0.5995\n",
      "Epoch 061 | Train Loss: 0.5267 | Val Loss: 0.6125\n",
      "Epoch 062 | Train Loss: 0.4971 | Val Loss: 0.6170\n",
      "Epoch 063 | Train Loss: 0.4911 | Val Loss: 0.5846\n",
      "Epoch 064 | Train Loss: 0.5099 | Val Loss: 0.5631\n",
      "Epoch 065 | Train Loss: 0.5002 | Val Loss: 0.5703\n",
      "Epoch 066 | Train Loss: 0.4823 | Val Loss: 0.5779\n",
      "Epoch 067 | Train Loss: 0.4926 | Val Loss: 0.6586\n",
      "Epoch 068 | Train Loss: 0.4817 | Val Loss: 0.5517\n",
      "Epoch 069 | Train Loss: 0.4590 | Val Loss: 0.5435\n",
      "Epoch 070 | Train Loss: 0.4609 | Val Loss: 0.5848\n",
      "Epoch 071 | Train Loss: 0.4540 | Val Loss: 0.5348\n",
      "Epoch 072 | Train Loss: 0.4563 | Val Loss: 0.5661\n",
      "Epoch 073 | Train Loss: 0.4402 | Val Loss: 0.5427\n",
      "Epoch 074 | Train Loss: 0.4424 | Val Loss: 0.5592\n",
      "Epoch 075 | Train Loss: 0.4258 | Val Loss: 0.5338\n",
      "Epoch 076 | Train Loss: 0.4318 | Val Loss: 0.5823\n",
      "Epoch 077 | Train Loss: 0.4338 | Val Loss: 0.5175\n",
      "Epoch 078 | Train Loss: 0.4155 | Val Loss: 0.4954\n",
      "Epoch 079 | Train Loss: 0.4266 | Val Loss: 0.5073\n",
      "Epoch 080 | Train Loss: 0.4119 | Val Loss: 0.4942\n",
      "Epoch 081 | Train Loss: 0.4092 | Val Loss: 0.5107\n",
      "Epoch 082 | Train Loss: 0.4131 | Val Loss: 0.5097\n",
      "Epoch 083 | Train Loss: 0.4100 | Val Loss: 0.4889\n",
      "Epoch 084 | Train Loss: 0.4018 | Val Loss: 0.4820\n",
      "Epoch 085 | Train Loss: 0.4073 | Val Loss: 0.4935\n",
      "Epoch 086 | Train Loss: 0.3932 | Val Loss: 0.6016\n",
      "Epoch 087 | Train Loss: 0.4001 | Val Loss: 0.4967\n",
      "Epoch 088 | Train Loss: 0.3819 | Val Loss: 0.4783\n",
      "Epoch 089 | Train Loss: 0.3999 | Val Loss: 0.4781\n",
      "Epoch 090 | Train Loss: 0.3812 | Val Loss: 0.5893\n",
      "Epoch 091 | Train Loss: 0.3843 | Val Loss: 0.4721\n",
      "Epoch 092 | Train Loss: 0.3785 | Val Loss: 0.4734\n",
      "Epoch 093 | Train Loss: 0.3724 | Val Loss: 0.4740\n",
      "Epoch 094 | Train Loss: 0.3777 | Val Loss: 0.4580\n",
      "Epoch 095 | Train Loss: 0.3665 | Val Loss: 0.4700\n",
      "Epoch 096 | Train Loss: 0.3643 | Val Loss: 0.4720\n",
      "Epoch 097 | Train Loss: 0.3745 | Val Loss: 0.5860\n",
      "Epoch 098 | Train Loss: 0.3873 | Val Loss: 0.5010\n",
      "Epoch 099 | Train Loss: 0.3758 | Val Loss: 0.4410\n",
      "Epoch 100 | Train Loss: 0.3581 | Val Loss: 0.4451\n",
      "Epoch 101 | Train Loss: 0.3475 | Val Loss: 0.4612\n",
      "Epoch 102 | Train Loss: 0.3511 | Val Loss: 0.4340\n",
      "Epoch 103 | Train Loss: 0.3424 | Val Loss: 0.4411\n",
      "Epoch 104 | Train Loss: 0.3402 | Val Loss: 0.4404\n",
      "Epoch 105 | Train Loss: 0.4147 | Val Loss: 0.5300\n",
      "Epoch 106 | Train Loss: 0.3630 | Val Loss: 0.4390\n",
      "Epoch 107 | Train Loss: 0.3436 | Val Loss: 0.4234\n",
      "Epoch 108 | Train Loss: 0.3417 | Val Loss: 0.4503\n",
      "Epoch 109 | Train Loss: 0.3425 | Val Loss: 0.4189\n",
      "Epoch 110 | Train Loss: 0.3258 | Val Loss: 0.4300\n",
      "Epoch 111 | Train Loss: 0.3344 | Val Loss: 0.4692\n",
      "Epoch 112 | Train Loss: 0.3476 | Val Loss: 0.4710\n",
      "Epoch 113 | Train Loss: 0.3247 | Val Loss: 0.4040\n",
      "Epoch 114 | Train Loss: 0.3399 | Val Loss: 0.4526\n",
      "Epoch 115 | Train Loss: 0.3332 | Val Loss: 0.4074\n",
      "Epoch 116 | Train Loss: 0.3406 | Val Loss: 0.4080\n",
      "Epoch 117 | Train Loss: 0.3217 | Val Loss: 0.4001\n",
      "Epoch 118 | Train Loss: 0.3157 | Val Loss: 0.3845\n",
      "Epoch 119 | Train Loss: 0.3319 | Val Loss: 0.4112\n",
      "Epoch 120 | Train Loss: 0.3150 | Val Loss: 0.3889\n",
      "Epoch 121 | Train Loss: 0.3130 | Val Loss: 0.3924\n",
      "Epoch 122 | Train Loss: 0.3068 | Val Loss: 0.3938\n",
      "Epoch 123 | Train Loss: 0.3127 | Val Loss: 0.3924\n",
      "Epoch 124 | Train Loss: 0.3216 | Val Loss: 0.3894\n",
      "Epoch 125 | Train Loss: 0.2960 | Val Loss: 0.3707\n",
      "Epoch 126 | Train Loss: 0.2899 | Val Loss: 0.3685\n",
      "Epoch 127 | Train Loss: 0.2889 | Val Loss: 0.3597\n",
      "Epoch 128 | Train Loss: 0.2883 | Val Loss: 0.3794\n",
      "Epoch 129 | Train Loss: 0.2869 | Val Loss: 0.3679\n",
      "Epoch 130 | Train Loss: 0.2924 | Val Loss: 0.3988\n",
      "Epoch 131 | Train Loss: 0.2926 | Val Loss: 0.3598\n",
      "Epoch 132 | Train Loss: 0.2934 | Val Loss: 0.3548\n",
      "Epoch 133 | Train Loss: 0.2922 | Val Loss: 0.3613\n",
      "Epoch 134 | Train Loss: 0.2843 | Val Loss: 0.3578\n",
      "Epoch 135 | Train Loss: 0.2919 | Val Loss: 0.4258\n",
      "Epoch 136 | Train Loss: 0.2862 | Val Loss: 0.3548\n",
      "Epoch 137 | Train Loss: 0.2832 | Val Loss: 0.3605\n",
      "Epoch 138 | Train Loss: 0.2804 | Val Loss: 0.3420\n",
      "Epoch 139 | Train Loss: 0.2824 | Val Loss: 0.3610\n",
      "Epoch 140 | Train Loss: 0.2832 | Val Loss: 0.3542\n",
      "Epoch 141 | Train Loss: 0.2793 | Val Loss: 0.3535\n",
      "Epoch 142 | Train Loss: 0.2881 | Val Loss: 0.3665\n",
      "Epoch 143 | Train Loss: 0.2740 | Val Loss: 0.3365\n",
      "Epoch 144 | Train Loss: 0.2756 | Val Loss: 0.3721\n",
      "Epoch 145 | Train Loss: 0.2784 | Val Loss: 0.3395\n",
      "Epoch 146 | Train Loss: 0.2818 | Val Loss: 0.3429\n",
      "Epoch 147 | Train Loss: 0.2748 | Val Loss: 0.3353\n",
      "Epoch 148 | Train Loss: 0.2750 | Val Loss: 0.3358\n",
      "Epoch 149 | Train Loss: 0.2755 | Val Loss: 0.3367\n",
      "Epoch 150 | Train Loss: 0.2821 | Val Loss: 0.3496\n",
      "Epoch 151 | Train Loss: 0.2718 | Val Loss: 0.3536\n",
      "Epoch 152 | Train Loss: 0.2690 | Val Loss: 0.3372\n",
      "Epoch 153 | Train Loss: 0.2702 | Val Loss: 0.3406\n",
      "Epoch 154 | Train Loss: 0.2599 | Val Loss: 0.3274\n",
      "Epoch 155 | Train Loss: 0.2592 | Val Loss: 0.3353\n",
      "Epoch 156 | Train Loss: 0.2573 | Val Loss: 0.3249\n",
      "Epoch 157 | Train Loss: 0.2617 | Val Loss: 0.3232\n",
      "Epoch 158 | Train Loss: 0.2559 | Val Loss: 0.3233\n",
      "Epoch 159 | Train Loss: 0.2559 | Val Loss: 0.3238\n",
      "Epoch 160 | Train Loss: 0.2563 | Val Loss: 0.3292\n",
      "Epoch 161 | Train Loss: 0.2612 | Val Loss: 0.3270\n",
      "Epoch 162 | Train Loss: 0.2535 | Val Loss: 0.3249\n",
      "Epoch 163 | Train Loss: 0.2566 | Val Loss: 0.3195\n",
      "Epoch 164 | Train Loss: 0.2528 | Val Loss: 0.3183\n",
      "Epoch 165 | Train Loss: 0.2523 | Val Loss: 0.3167\n",
      "Epoch 166 | Train Loss: 0.2550 | Val Loss: 0.3146\n",
      "Epoch 167 | Train Loss: 0.2517 | Val Loss: 0.3137\n",
      "Epoch 168 | Train Loss: 0.2521 | Val Loss: 0.3145\n",
      "Epoch 169 | Train Loss: 0.2520 | Val Loss: 0.3096\n",
      "Epoch 170 | Train Loss: 0.2504 | Val Loss: 0.3190\n",
      "Epoch 171 | Train Loss: 0.2545 | Val Loss: 0.3089\n",
      "Epoch 172 | Train Loss: 0.2489 | Val Loss: 0.3286\n",
      "Epoch 173 | Train Loss: 0.2511 | Val Loss: 0.3089\n",
      "Epoch 174 | Train Loss: 0.2484 | Val Loss: 0.3153\n",
      "Epoch 175 | Train Loss: 0.2470 | Val Loss: 0.3107\n",
      "Epoch 176 | Train Loss: 0.2542 | Val Loss: 0.3149\n",
      "Epoch 177 | Train Loss: 0.2458 | Val Loss: 0.3015\n",
      "Epoch 178 | Train Loss: 0.2493 | Val Loss: 0.3320\n",
      "Epoch 179 | Train Loss: 0.2486 | Val Loss: 0.3038\n",
      "Epoch 180 | Train Loss: 0.2467 | Val Loss: 0.3051\n",
      "Epoch 181 | Train Loss: 0.2471 | Val Loss: 0.3121\n",
      "Epoch 182 | Train Loss: 0.2411 | Val Loss: 0.3150\n",
      "Epoch 183 | Train Loss: 0.2463 | Val Loss: 0.3027\n",
      "Epoch 184 | Train Loss: 0.2399 | Val Loss: 0.3000\n",
      "Epoch 185 | Train Loss: 0.2406 | Val Loss: 0.3021\n",
      "Epoch 186 | Train Loss: 0.2399 | Val Loss: 0.3134\n",
      "Epoch 187 | Train Loss: 0.2409 | Val Loss: 0.2988\n",
      "Epoch 188 | Train Loss: 0.2381 | Val Loss: 0.3038\n",
      "Epoch 189 | Train Loss: 0.2387 | Val Loss: 0.2974\n",
      "Epoch 190 | Train Loss: 0.2370 | Val Loss: 0.2996\n",
      "Epoch 191 | Train Loss: 0.2402 | Val Loss: 0.2938\n",
      "Epoch 192 | Train Loss: 0.2419 | Val Loss: 0.3019\n",
      "Epoch 193 | Train Loss: 0.2383 | Val Loss: 0.3022\n",
      "Epoch 194 | Train Loss: 0.2371 | Val Loss: 0.2969\n",
      "Epoch 195 | Train Loss: 0.2381 | Val Loss: 0.2906\n",
      "Epoch 196 | Train Loss: 0.2377 | Val Loss: 0.2927\n",
      "Epoch 197 | Train Loss: 0.2352 | Val Loss: 0.2922\n",
      "Epoch 198 | Train Loss: 0.2356 | Val Loss: 0.2911\n",
      "Epoch 199 | Train Loss: 0.2357 | Val Loss: 0.2931\n",
      "Epoch 200 | Train Loss: 0.2371 | Val Loss: 0.3035\n",
      "Epoch 201 | Train Loss: 0.2343 | Val Loss: 0.2913\n",
      "Epoch 202 | Train Loss: 0.2329 | Val Loss: 0.2931\n",
      "Epoch 203 | Train Loss: 0.2322 | Val Loss: 0.2917\n",
      "Epoch 204 | Train Loss: 0.2319 | Val Loss: 0.2917\n",
      "Epoch 205 | Train Loss: 0.2319 | Val Loss: 0.2894\n",
      "Epoch 206 | Train Loss: 0.2312 | Val Loss: 0.2902\n",
      "Epoch 207 | Train Loss: 0.2305 | Val Loss: 0.2893\n",
      "Epoch 208 | Train Loss: 0.2315 | Val Loss: 0.2894\n",
      "Epoch 209 | Train Loss: 0.2317 | Val Loss: 0.2901\n",
      "Epoch 210 | Train Loss: 0.2315 | Val Loss: 0.2895\n",
      "Epoch 211 | Train Loss: 0.2311 | Val Loss: 0.2875\n",
      "Epoch 212 | Train Loss: 0.2311 | Val Loss: 0.2887\n",
      "Epoch 213 | Train Loss: 0.2309 | Val Loss: 0.2959\n",
      "Epoch 214 | Train Loss: 0.2298 | Val Loss: 0.2960\n",
      "Epoch 215 | Train Loss: 0.2307 | Val Loss: 0.2871\n",
      "Epoch 216 | Train Loss: 0.2303 | Val Loss: 0.2872\n",
      "Epoch 217 | Train Loss: 0.2308 | Val Loss: 0.2875\n",
      "Epoch 218 | Train Loss: 0.2297 | Val Loss: 0.2869\n",
      "Epoch 219 | Train Loss: 0.2292 | Val Loss: 0.2837\n",
      "Epoch 220 | Train Loss: 0.2302 | Val Loss: 0.2852\n",
      "Epoch 221 | Train Loss: 0.2284 | Val Loss: 0.2846\n",
      "Epoch 222 | Train Loss: 0.2305 | Val Loss: 0.2898\n",
      "Epoch 223 | Train Loss: 0.2299 | Val Loss: 0.2844\n",
      "Epoch 224 | Train Loss: 0.2295 | Val Loss: 0.2844\n",
      "Epoch 225 | Train Loss: 0.2284 | Val Loss: 0.2895\n",
      "Epoch 226 | Train Loss: 0.2283 | Val Loss: 0.2836\n",
      "Epoch 227 | Train Loss: 0.2272 | Val Loss: 0.2833\n",
      "Epoch 228 | Train Loss: 0.2269 | Val Loss: 0.2838\n",
      "Epoch 229 | Train Loss: 0.2272 | Val Loss: 0.2833\n",
      "Epoch 230 | Train Loss: 0.2270 | Val Loss: 0.2910\n",
      "Epoch 231 | Train Loss: 0.2282 | Val Loss: 0.2841\n",
      "Epoch 232 | Train Loss: 0.2269 | Val Loss: 0.2856\n",
      "Epoch 233 | Train Loss: 0.2264 | Val Loss: 0.2834\n",
      "Epoch 234 | Train Loss: 0.2259 | Val Loss: 0.2830\n",
      "Epoch 235 | Train Loss: 0.2255 | Val Loss: 0.2834\n",
      "Epoch 236 | Train Loss: 0.2258 | Val Loss: 0.2821\n",
      "Epoch 237 | Train Loss: 0.2264 | Val Loss: 0.2826\n",
      "Epoch 238 | Train Loss: 0.2261 | Val Loss: 0.2831\n",
      "Epoch 239 | Train Loss: 0.2255 | Val Loss: 0.2833\n",
      "Epoch 240 | Train Loss: 0.2254 | Val Loss: 0.2825\n",
      "Epoch 241 | Train Loss: 0.2256 | Val Loss: 0.2817\n",
      "Epoch 242 | Train Loss: 0.2260 | Val Loss: 0.2829\n",
      "Epoch 243 | Train Loss: 0.2255 | Val Loss: 0.2820\n",
      "Epoch 244 | Train Loss: 0.2258 | Val Loss: 0.2821\n",
      "Epoch 245 | Train Loss: 0.2257 | Val Loss: 0.2819\n",
      "Epoch 246 | Train Loss: 0.2255 | Val Loss: 0.2821\n",
      "Epoch 247 | Train Loss: 0.2256 | Val Loss: 0.2816\n",
      "Epoch 248 | Train Loss: 0.2252 | Val Loss: 0.2823\n",
      "Epoch 249 | Train Loss: 0.2255 | Val Loss: 0.2819\n",
      "Epoch 250 | Train Loss: 0.2256 | Val Loss: 0.2832\n",
      "Epoch 251 | Train Loss: 0.2256 | Val Loss: 0.2823\n",
      "Epoch 252 | Train Loss: 0.2254 | Val Loss: 0.2843\n",
      "Epoch 253 | Train Loss: 0.2252 | Val Loss: 0.2812\n",
      "Epoch 254 | Train Loss: 0.2251 | Val Loss: 0.2819\n",
      "Epoch 255 | Train Loss: 0.2251 | Val Loss: 0.2821\n",
      "Epoch 256 | Train Loss: 0.2254 | Val Loss: 0.2842\n",
      "Epoch 257 | Train Loss: 0.2253 | Val Loss: 0.2813\n",
      "Epoch 258 | Train Loss: 0.2255 | Val Loss: 0.2817\n",
      "Epoch 259 | Train Loss: 0.2258 | Val Loss: 0.2820\n",
      "Epoch 260 | Train Loss: 0.2247 | Val Loss: 0.2825\n",
      "Epoch 261 | Train Loss: 0.2246 | Val Loss: 0.2814\n",
      "Epoch 262 | Train Loss: 0.2245 | Val Loss: 0.2833\n",
      "Epoch 263 | Train Loss: 0.2245 | Val Loss: 0.2809\n",
      "Epoch 264 | Train Loss: 0.2245 | Val Loss: 0.2807\n",
      "Epoch 265 | Train Loss: 0.2245 | Val Loss: 0.2808\n",
      "Epoch 266 | Train Loss: 0.2245 | Val Loss: 0.2821\n",
      "Epoch 267 | Train Loss: 0.2244 | Val Loss: 0.2810\n",
      "Epoch 268 | Train Loss: 0.2244 | Val Loss: 0.2826\n",
      "Epoch 269 | Train Loss: 0.2246 | Val Loss: 0.2807\n",
      "Epoch 270 | Train Loss: 0.2244 | Val Loss: 0.2810\n",
      "Epoch 271 | Train Loss: 0.2245 | Val Loss: 0.2806\n",
      "Epoch 272 | Train Loss: 0.2245 | Val Loss: 0.2812\n",
      "Epoch 273 | Train Loss: 0.2243 | Val Loss: 0.2807\n",
      "Epoch 274 | Train Loss: 0.2241 | Val Loss: 0.2815\n",
      "Epoch 275 | Train Loss: 0.2242 | Val Loss: 0.2806\n",
      "Epoch 276 | Train Loss: 0.2243 | Val Loss: 0.2810\n",
      "Epoch 277 | Train Loss: 0.2244 | Val Loss: 0.2811\n",
      "Epoch 278 | Train Loss: 0.2241 | Val Loss: 0.2811\n",
      "Epoch 279 | Train Loss: 0.2240 | Val Loss: 0.2811\n",
      "Epoch 280 | Train Loss: 0.2240 | Val Loss: 0.2813\n",
      "Epoch 281 | Train Loss: 0.2241 | Val Loss: 0.2810\n",
      "‚èπÔ∏è Early stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 113\u001b[0m\n\u001b[1;32m    110\u001b[0m     final_metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae_f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse_f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse_f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2_f}\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# 6) Compare to Ensemble\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m comp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mensemble\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrmse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrecall\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mauc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# adjust accordingly\u001b[39;49;00m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m display(comp)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# 7) Side-by-side scatter plots (regression example)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Step 8: Final Model Training on Combined Train+Val & Test Evaluation (Hold‚ÄëOut Test)\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Merge all train+val folds\n",
    "all_data = []\n",
    "for fold in range(10):\n",
    "    all_data += torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    all_data += torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "# 2) Reserve a small val split for early stopping\n",
    "tidx, vidx = train_test_split(\n",
    "    list(range(len(all_data))),\n",
    "    test_size=0.10,\n",
    "    random_state=seed,\n",
    "    shuffle=True\n",
    ")\n",
    "train_split = [all_data[i] for i in tidx]\n",
    "val_split   = [all_data[i] for i in vidx]\n",
    "\n",
    "train_loader = DataLoader(train_split, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_split,   batch_size=32)\n",
    "\n",
    "# 3) Instantiate & train final model\n",
    "model     = MPNN(input_dim, edge_dim,\n",
    "                 hidden_dim=best_hidden_dim,\n",
    "                 output_dim=output_dim,\n",
    "                 dropout=best_dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', patience=5, factor=0.5, verbose=True\n",
    ")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience      = 0\n",
    "\n",
    "for epoch in range(1, 300):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = (F.cross_entropy(out, batch.y.long())\n",
    "                if task == \"classification\"\n",
    "                else F.mse_loss(out.squeeze(), batch.y))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation for early stopping\n",
    "    preds, targets = evaluate(model, val_loader)\n",
    "    val_loss = (F.cross_entropy(preds, targets.long()).item()\n",
    "                if task == \"classification\"\n",
    "                else F.mse_loss(preds.squeeze(), targets).item())\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch {epoch:03d} | Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience      = 0\n",
    "        torch.save(model.state_dict(), os.path.join(results_dir, \"final_model.pt\"))\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= 10:\n",
    "            print(\"‚èπÔ∏è Early stopping\")\n",
    "            break\n",
    "\n",
    "# 4) Load best final model & evaluate on ORIGINAL TEST set\n",
    "model.load_state_dict(torch.load(os.path.join(results_dir, \"final_model.pt\")))\n",
    "test_data   = torch.load(os.path.join(base_path, f\"{task}_test.pt\"))\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "preds, targets = evaluate(model, test_loader)\n",
    "pred_final     = (preds.argmax(dim=1).numpy() \n",
    "                  if task==\"classification\" \n",
    "                  else preds.squeeze().numpy())\n",
    "true_final     = torch.cat([d.y for d in test_data]).numpy().astype(int if task==\"classification\" else float)\n",
    "\n",
    "# 5) Compute final metrics\n",
    "if task == \"classification\":\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score,\n",
    "        precision_recall_fscore_support,\n",
    "        roc_auc_score\n",
    "    )\n",
    "    acc       = accuracy_score(true_final, pred_final)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_final, pred_final, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "    probs     = F.softmax(preds, dim=1).cpu().numpy()\n",
    "    auc       = roc_auc_score(\n",
    "        label_binarize(true_final, classes=np.arange(num_classes)),\n",
    "        probs, multi_class=\"ovr\"\n",
    "    )\n",
    "    final_metrics = {\n",
    "        \"accuracy\": acc, \"precision\": precision,\n",
    "        \"recall\": recall, \"f1_score\": f1, \"auc_roc\": auc\n",
    "    }\n",
    "else:\n",
    "    mae_f  = mean_absolute_error(true_final, pred_final)\n",
    "    mse_f  = mean_squared_error(true_final, pred_final)\n",
    "    rmse_f = np.sqrt(mse_f)\n",
    "    r2_f   = r2_score(true_final, pred_final)\n",
    "    final_metrics = {\"mae\": mae_f, \"mse\": mse_f, \"rmse\": rmse_f, \"r2\": r2_f}\n",
    "\n",
    "# 6) Compare to Ensemble\n",
    "comp = pd.DataFrame({\n",
    "    \"metric\":    list(final_metrics.keys()),\n",
    "    \"ensemble\":  list(comp.values()) if 'comp' in locals() else [mae, rmse, r2] if task!=\"classification\" else [acc,precision,recall,f1,auc],  # adjust accordingly\n",
    "    \"final\":     list(final_metrics.values())\n",
    "})\n",
    "display(comp)\n",
    "\n",
    "# 7) Side-by-side scatter plots (regression example)\n",
    "if task != \"classification\":\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    # Ensemble\n",
    "    axes[0].scatter(true_labels, final_pred, alpha=0.7)\n",
    "    axes[0].plot([true_labels.min(), true_labels.max()],\n",
    "                 [true_labels.min(), true_labels.max()], 'r--')\n",
    "    axes[0].set_title(\"Ensemble: True vs Predicted\")\n",
    "    axes[0].set_xlabel(\"True pChEMBL\")\n",
    "    axes[0].set_ylabel(\"Ensemble Prediction\")\n",
    "    # Final\n",
    "    axes[1].scatter(true_final, pred_final, alpha=0.7)\n",
    "    axes[1].plot([true_final.min(), true_final.max()],\n",
    "                 [true_final.min(), true_final.max()], 'r--')\n",
    "    axes[1].set_title(\"Final Model: True vs Predicted\")\n",
    "    axes[1].set_xlabel(\"True pChEMBL\")\n",
    "    axes[1].set_ylabel(\"Final Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00a6c134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mae</td>\n",
       "      <td>0.740341</td>\n",
       "      <td>0.584790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.836766</td>\n",
       "      <td>0.615157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.914749</td>\n",
       "      <td>0.784319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.370252</td>\n",
       "      <td>0.537035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric  ensemble     final\n",
       "0    mae  0.740341  0.584790\n",
       "1    mse  0.836766  0.615157\n",
       "2   rmse  0.914749  0.784319\n",
       "3     r2  0.370252  0.537035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6) Compare to Ensemble\n",
    "# Prepare ensemble metrics list\n",
    "if task == \"classification\":\n",
    "    ensemble_metrics = [acc, precision, recall, f1, auc]\n",
    "else:\n",
    "    ensemble_metrics = [mae, mse, rmse, r2]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comp = pd.DataFrame({\n",
    "    \"metric\":   list(final_metrics.keys()),\n",
    "    \"ensemble\": ensemble_metrics,\n",
    "    \"final\":    list(final_metrics.values())\n",
    "})\n",
    "display(comp)\n",
    "\n",
    "# 7) Side-by-side scatter plots\n",
    "if task != \"classification\":\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Ensemble plot\n",
    "    axes[0].scatter(true_value, final_pred, alpha=0.7)\n",
    "    axes[0].plot(\n",
    "        [true_value.min(), true_value.max()],\n",
    "        [true_value.min(), true_value.max()],\n",
    "        'r--'\n",
    "    )\n",
    "    axes[0].set_title(\"Ensemble: True vs Predicted\")\n",
    "    axes[0].set_xlabel(\"True pChEMBL\")\n",
    "    axes[0].set_ylabel(\"Ensemble Prediction\")\n",
    "\n",
    "    # Final model plot\n",
    "    axes[1].scatter(true_final, pred_final, alpha=0.7)\n",
    "    axes[1].plot(\n",
    "        [true_final.min(), true_final.max()],\n",
    "        [true_final.min(), true_final.max()],\n",
    "        'r--'\n",
    "    )\n",
    "    axes[1].set_title(\"Final Model: True vs Predicted\")\n",
    "    axes[1].set_xlabel(\"True pChEMBL\")\n",
    "    axes[1].set_ylabel(\"Final Model Prediction\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
