{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892b10a6",
   "metadata": {},
   "source": [
    "# Classification Training Pipeline\n",
    "\n",
    "This notebook implements a complete Graph Neural Network (GNN) pipeline for a 3-class classification task (`Low`, `Medium`, `High`).  It now includes additional metrics in hyperparameter tuning and enhanced model comparison visualizations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment & Setup](#step1)\n",
    "2. [Model Definition](#step2)\n",
    "3. [Evaluation Function](#step3)\n",
    "4. [Hyperparameter Sweep (10-Fold CV)](#step4)\n",
    "5. [Retraining & Validation (10-Fold CV)](#step5)\n",
    "6. [Cross-Validation Results Visualization](#step6)\n",
    "7. [Ensemble Averaging](#step7)\n",
    "8. [Final Model Training & Test Evaluation](#step8)\n",
    "9. [Baseline QSAR Comparison](#step9)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- PyTorch & PyTorch Geometric  \n",
    "- scikit-learn  \n",
    "- pandas, numpy, matplotlib  \n",
    "- RDKit (only for feature extraction)  \n",
    "- GPU recommended\n",
    "\n",
    "Install requirements:\n",
    "```bash\n",
    "pip install torch torch-geometric scikit-learn pandas numpy matplotlib rdkit-pypi\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"step1\"></a>\n",
    "## Step 1: Environment & Setup\n",
    "- Seed all random generators for reproducibility.  \n",
    "- Define paths for data splits and output.  \n",
    "- Detect GPU/CPU.\n",
    "\n",
    "<a id=\"step2\"></a>\n",
    "## Step 2: Model Definition\n",
    "Defines:\n",
    "- `MPNNLayer`: message-passing with dropout support.  \n",
    "- `MPNN`: stacks layers, global mean pool, and final linear head.\n",
    "\n",
    "<a id=\"step3\"></a>\n",
    "## Step 3: Evaluation Function\n",
    "`evaluate(model, loader)` returns concatenated logits and true labels.\n",
    "\n",
    "<a id=\"step4\"></a>\n",
    "## Step 4: Hyperparameter Sweep (10-Fold CV)\n",
    "**Updates:** Now tracks both **AUC-ROC** and **Balanced Accuracy** per fold.\n",
    "\n",
    "- Grid search over `hidden_dim`, `dropout`, `lr`.  \n",
    "- For each config, run 10-fold CV: train for 50 epochs, then evaluate validation set.\n",
    "- Compute per-fold metrics:\n",
    "  - **AUC-ROC** (one-vs-rest)\n",
    "  - **Balanced Accuracy** (accounts for class imbalance)\n",
    "- Record **mean ¬± std** for both metrics.\n",
    "- Results DataFrame `sweep_df` now contains `mean_auc`, `std_auc`, `mean_balanced_acc`, and `std_balanced_acc`.\n",
    "\n",
    "<a id=\"step5\"></a>\n",
    "## Step 5: Retraining & Validation (10-Fold CV)\n",
    "- Retrain each fold with best hyperparameters and early stopping.  \n",
    "- Save best model weights.  \n",
    "- Compute per-fold classification metrics: accuracy, precision, recall, F1, AUC-ROC.  \n",
    "- Save `crossval_summary.csv`.\n",
    "\n",
    "<a id=\"step6\"></a>\n",
    "## Step 6: Cross-Validation Results Visualization\n",
    "- Load `crossval_summary.csv`.  \n",
    "- Plot bar charts for each metric across folds.  \n",
    "- Print mean ¬± std.\n",
    "\n",
    "<a id=\"step7\"></a>\n",
    "## Step 7: Ensemble Averaging\n",
    "- Load fold checkpoints, run on test set, average logits.  \n",
    "- Save `ensemble_preds.csv` (True vs. Pred).\n",
    "- **Ensemble evaluation plots** include confusion matrix and per-class ROC curves.\n",
    "\n",
    "<a id=\"step8\"></a>\n",
    "## Step 8: Final Model Training & Test Evaluation\n",
    "- Merge all train+val folds, reserve 10% for validation.  \n",
    "- Train final model with early stopping and LR scheduler.  \n",
    "- Evaluate on hold-out test: accuracy, precision, recall, F1, AUC-ROC.\n",
    "- Plot confusion matrix and per-class ROC curves.  \n",
    "- Save `final_model_metrics.csv`, `final_confusion_matrix.png`, and `final_auc_roc.png`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Parameters & Extensions\n",
    "- **Epochs:** 50 for CV, 100 for final training  \n",
    "- **Patience:** 10 for early stopping  \n",
    "- **LR Scheduler:** `ReduceLROnPlateau` on validation loss  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f1c0d",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b107243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79ade2",
   "metadata": {},
   "source": [
    "## 2. Task and Reproducibility Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64234a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "# DataLoader seeding\n",
    "from torch.utils.data import DataLoader as _DL\n",
    "from torch.utils.data import get_worker_info\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = seed + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(seed)\n",
    "\n",
    "task = \"classification\"  # or \"regression\"\n",
    "#task = \"regression\"  # or \"classification\"\n",
    "num_classes = 3\n",
    "class_names = {0: \"Low\", 1: \"Medium\", 2: \"High\"}\n",
    "kfold = 10\n",
    "base_path = f\"../4_train_test_split/10fold_cv/{task}/\"\n",
    "results_dir = f\"MPNN_results/{task}_{kfold}fold/\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ac03",
   "metadata": {},
   "source": [
    "## 3b. Define MPNN Layer and MPNN Model with Dropout Support\n",
    "# Enhanced MPNN model with dropout layers after each message-passing block to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c517152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "        self.edge_proj = Linear(edge_dim, out_channels)\n",
    "        self.msg_lin = Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.lin(x)\n",
    "        edge_attr = self.edge_proj(edge_attr)\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return self.msg_lin(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return F.relu(aggr_out)\n",
    "\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, edge_dim, hidden_dim, output_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.mp1 = MPNNLayer(input_dim, hidden_dim, edge_dim)\n",
    "        self.mp2 = MPNNLayer(hidden_dim, hidden_dim, edge_dim)\n",
    "        self.out = Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.mp1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.mp2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bd2cc",
   "metadata": {},
   "source": [
    "## 4. Evaluation Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d899a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds.append(out.cpu())\n",
    "            labels.append(batch.y.cpu())\n",
    "    return torch.cat(preds), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063855f",
   "metadata": {},
   "source": [
    "## 5. Input Dimensions and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3414ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = torch.load(os.path.join(base_path, f\"{task}_train_fold0.pt\"))[0]\n",
    "input_dim = sample_data.x.size(1)\n",
    "edge_dim = sample_data.edge_attr.size(1)\n",
    "output_dim = num_classes if task == \"classification\" else 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5c45c",
   "metadata": {},
   "source": [
    "# ## Step 4: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d2bc592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.0, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.8949 | Val Loss: 0.8664\n",
      "Epoch 02 | Train Loss: 0.8785 | Val Loss: 0.8628\n",
      "Epoch 03 | Train Loss: 0.8721 | Val Loss: 0.8559\n",
      "Epoch 04 | Train Loss: 0.8679 | Val Loss: 0.8545\n",
      "Epoch 05 | Train Loss: 0.8593 | Val Loss: 0.8383\n",
      "Epoch 06 | Train Loss: 0.8413 | Val Loss: 0.8149\n",
      "Epoch 07 | Train Loss: 0.8040 | Val Loss: 0.7891\n",
      "Epoch 08 | Train Loss: 0.7854 | Val Loss: 0.7565\n",
      "Epoch 09 | Train Loss: 0.7875 | Val Loss: 0.7233\n",
      "Epoch 10 | Train Loss: 0.7507 | Val Loss: 0.7179\n",
      "Epoch 11 | Train Loss: 0.7515 | Val Loss: 0.7210\n",
      "Epoch 12 | Train Loss: 0.7560 | Val Loss: 0.7173\n",
      "Epoch 13 | Train Loss: 0.7325 | Val Loss: 0.6958\n",
      "Epoch 14 | Train Loss: 0.7480 | Val Loss: 0.7214\n",
      "Epoch 15 | Train Loss: 0.7384 | Val Loss: 0.7050\n",
      "Epoch 16 | Train Loss: 0.7649 | Val Loss: 0.7033\n",
      "Epoch 17 | Train Loss: 0.7493 | Val Loss: 0.6951\n",
      "Epoch 18 | Train Loss: 0.7574 | Val Loss: 0.6871\n",
      "Epoch 19 | Train Loss: 0.7423 | Val Loss: 0.6947\n",
      "Epoch 20 | Train Loss: 0.7302 | Val Loss: 0.6893\n",
      "Epoch 21 | Train Loss: 0.7268 | Val Loss: 0.6805\n",
      "Epoch 22 | Train Loss: 0.7082 | Val Loss: 0.6925\n",
      "Epoch 23 | Train Loss: 0.7427 | Val Loss: 0.6895\n",
      "Epoch 24 | Train Loss: 0.7282 | Val Loss: 0.6791\n",
      "Epoch 25 | Train Loss: 0.7218 | Val Loss: 0.6942\n",
      "Epoch 26 | Train Loss: 0.7297 | Val Loss: 0.7482\n",
      "Epoch 27 | Train Loss: 0.7318 | Val Loss: 0.6898\n",
      "Epoch 28 | Train Loss: 0.7566 | Val Loss: 0.6740\n",
      "Epoch 29 | Train Loss: 0.7097 | Val Loss: 0.6745\n",
      "Epoch 30 | Train Loss: 0.7448 | Val Loss: 0.6996\n",
      "Epoch 31 | Train Loss: 0.7140 | Val Loss: 0.6759\n",
      "Epoch 32 | Train Loss: 0.7161 | Val Loss: 0.6740\n",
      "Epoch 33 | Train Loss: 0.7217 | Val Loss: 0.6842\n",
      "Epoch 34 | Train Loss: 0.7403 | Val Loss: 0.6768\n",
      "Epoch 35 | Train Loss: 0.7106 | Val Loss: 0.6802\n",
      "Epoch 36 | Train Loss: 0.7145 | Val Loss: 0.6806\n",
      "Epoch 37 | Train Loss: 0.7140 | Val Loss: 0.7182\n",
      "Epoch 38 | Train Loss: 0.7195 | Val Loss: 0.6821\n",
      "Epoch 39 | Train Loss: 0.7371 | Val Loss: 0.6826\n",
      "Epoch 40 | Train Loss: 0.7104 | Val Loss: 0.7009\n",
      "Epoch 41 | Train Loss: 0.7270 | Val Loss: 0.6793\n",
      "Epoch 42 | Train Loss: 0.7051 | Val Loss: 0.6852\n",
      "Epoch 43 | Train Loss: 0.7105 | Val Loss: 0.6804\n",
      "Epoch 44 | Train Loss: 0.7206 | Val Loss: 0.6833\n",
      "Epoch 45 | Train Loss: 0.7328 | Val Loss: 0.6838\n",
      "Epoch 46 | Train Loss: 0.7226 | Val Loss: 0.6909\n",
      "Epoch 47 | Train Loss: 0.7272 | Val Loss: 0.6995\n",
      "Epoch 48 | Train Loss: 0.7010 | Val Loss: 0.6816\n",
      "Epoch 49 | Train Loss: 0.7101 | Val Loss: 0.6937\n",
      "Epoch 50 | Train Loss: 0.7059 | Val Loss: 0.6840\n",
      "Fold 1 ‚ñ∂ AUC: 0.791, Balanced Acc: 0.497\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9059 | Val Loss: 0.8929\n",
      "Epoch 02 | Train Loss: 0.8741 | Val Loss: 0.8995\n",
      "Epoch 03 | Train Loss: 0.8724 | Val Loss: 0.8766\n",
      "Epoch 04 | Train Loss: 0.8805 | Val Loss: 0.8658\n",
      "Epoch 05 | Train Loss: 0.8606 | Val Loss: 0.8524\n",
      "Epoch 06 | Train Loss: 0.8624 | Val Loss: 0.8456\n",
      "Epoch 07 | Train Loss: 0.8413 | Val Loss: 0.8431\n",
      "Epoch 08 | Train Loss: 0.8281 | Val Loss: 0.9570\n",
      "Epoch 09 | Train Loss: 0.8604 | Val Loss: 0.8238\n",
      "Epoch 10 | Train Loss: 0.8328 | Val Loss: 0.8786\n",
      "Epoch 11 | Train Loss: 0.8685 | Val Loss: 0.8296\n",
      "Epoch 12 | Train Loss: 0.8245 | Val Loss: 0.8171\n",
      "Epoch 13 | Train Loss: 0.8198 | Val Loss: 0.8235\n",
      "Epoch 14 | Train Loss: 0.7831 | Val Loss: 0.7810\n",
      "Epoch 15 | Train Loss: 0.7660 | Val Loss: 0.7545\n",
      "Epoch 16 | Train Loss: 0.7728 | Val Loss: 0.7725\n",
      "Epoch 17 | Train Loss: 0.7362 | Val Loss: 0.7908\n",
      "Epoch 18 | Train Loss: 0.7772 | Val Loss: 0.7805\n",
      "Epoch 19 | Train Loss: 0.7611 | Val Loss: 0.8472\n",
      "Epoch 20 | Train Loss: 0.7987 | Val Loss: 0.8230\n",
      "Epoch 21 | Train Loss: 0.7694 | Val Loss: 0.7630\n",
      "Epoch 22 | Train Loss: 0.7383 | Val Loss: 0.7384\n",
      "Epoch 23 | Train Loss: 0.7615 | Val Loss: 0.7407\n",
      "Epoch 24 | Train Loss: 0.7420 | Val Loss: 0.7354\n",
      "Epoch 25 | Train Loss: 0.7259 | Val Loss: 0.7421\n",
      "Epoch 26 | Train Loss: 0.7240 | Val Loss: 0.7858\n",
      "Epoch 27 | Train Loss: 0.7181 | Val Loss: 0.7366\n",
      "Epoch 28 | Train Loss: 0.7302 | Val Loss: 0.7088\n",
      "Epoch 29 | Train Loss: 0.7257 | Val Loss: 0.7436\n",
      "Epoch 30 | Train Loss: 0.7311 | Val Loss: 0.7180\n",
      "Epoch 31 | Train Loss: 0.7276 | Val Loss: 0.7208\n",
      "Epoch 32 | Train Loss: 0.7244 | Val Loss: 0.7979\n",
      "Epoch 33 | Train Loss: 0.7427 | Val Loss: 0.7176\n",
      "Epoch 34 | Train Loss: 0.7396 | Val Loss: 0.7227\n",
      "Epoch 35 | Train Loss: 0.7361 | Val Loss: 0.7318\n",
      "Epoch 36 | Train Loss: 0.7276 | Val Loss: 0.7558\n",
      "Epoch 37 | Train Loss: 0.7549 | Val Loss: 0.7248\n",
      "Epoch 38 | Train Loss: 0.7185 | Val Loss: 0.7456\n",
      "Epoch 39 | Train Loss: 0.7213 | Val Loss: 0.7108\n",
      "Epoch 40 | Train Loss: 0.7150 | Val Loss: 0.7381\n",
      "Epoch 41 | Train Loss: 0.7296 | Val Loss: 0.7074\n",
      "Epoch 42 | Train Loss: 0.7277 | Val Loss: 0.7270\n",
      "Epoch 43 | Train Loss: 0.7091 | Val Loss: 0.7359\n",
      "Epoch 44 | Train Loss: 0.7135 | Val Loss: 0.7148\n",
      "Epoch 45 | Train Loss: 0.7088 | Val Loss: 0.7591\n",
      "Epoch 46 | Train Loss: 0.7054 | Val Loss: 0.7321\n",
      "Epoch 47 | Train Loss: 0.7222 | Val Loss: 0.7110\n",
      "Epoch 48 | Train Loss: 0.7434 | Val Loss: 0.7541\n",
      "Epoch 49 | Train Loss: 0.7083 | Val Loss: 0.8456\n",
      "Epoch 50 | Train Loss: 0.7391 | Val Loss: 0.7707\n",
      "Fold 2 ‚ñ∂ AUC: 0.655, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9812 | Val Loss: 0.8962\n",
      "Epoch 02 | Train Loss: 0.8949 | Val Loss: 0.8642\n",
      "Epoch 03 | Train Loss: 0.8867 | Val Loss: 0.8474\n",
      "Epoch 04 | Train Loss: 0.8552 | Val Loss: 0.8463\n",
      "Epoch 05 | Train Loss: 0.8570 | Val Loss: 0.8475\n",
      "Epoch 06 | Train Loss: 0.8456 | Val Loss: 0.8301\n",
      "Epoch 07 | Train Loss: 0.8356 | Val Loss: 0.8179\n",
      "Epoch 08 | Train Loss: 0.8247 | Val Loss: 0.8024\n",
      "Epoch 09 | Train Loss: 0.8135 | Val Loss: 0.7878\n",
      "Epoch 10 | Train Loss: 0.7875 | Val Loss: 0.7652\n",
      "Epoch 11 | Train Loss: 0.7928 | Val Loss: 0.7622\n",
      "Epoch 12 | Train Loss: 0.7783 | Val Loss: 0.7513\n",
      "Epoch 13 | Train Loss: 0.7661 | Val Loss: 0.7653\n",
      "Epoch 14 | Train Loss: 0.7911 | Val Loss: 0.7445\n",
      "Epoch 15 | Train Loss: 0.7603 | Val Loss: 0.7454\n",
      "Epoch 16 | Train Loss: 0.7891 | Val Loss: 0.7633\n",
      "Epoch 17 | Train Loss: 0.7561 | Val Loss: 0.7625\n",
      "Epoch 18 | Train Loss: 0.7532 | Val Loss: 0.7903\n",
      "Epoch 19 | Train Loss: 0.7713 | Val Loss: 0.7990\n",
      "Epoch 20 | Train Loss: 0.7592 | Val Loss: 0.7496\n",
      "Epoch 21 | Train Loss: 0.7582 | Val Loss: 0.7399\n",
      "Epoch 22 | Train Loss: 0.7520 | Val Loss: 0.7336\n",
      "Epoch 23 | Train Loss: 0.7496 | Val Loss: 0.7350\n",
      "Epoch 24 | Train Loss: 0.7437 | Val Loss: 0.7434\n",
      "Epoch 25 | Train Loss: 0.7229 | Val Loss: 0.7358\n",
      "Epoch 26 | Train Loss: 0.7359 | Val Loss: 0.7240\n",
      "Epoch 27 | Train Loss: 0.7218 | Val Loss: 0.7440\n",
      "Epoch 28 | Train Loss: 0.7588 | Val Loss: 0.7386\n",
      "Epoch 29 | Train Loss: 0.7751 | Val Loss: 0.8091\n",
      "Epoch 30 | Train Loss: 0.7406 | Val Loss: 0.7401\n",
      "Epoch 31 | Train Loss: 0.7271 | Val Loss: 0.7264\n",
      "Epoch 32 | Train Loss: 0.7270 | Val Loss: 0.7258\n",
      "Epoch 33 | Train Loss: 0.7303 | Val Loss: 0.7247\n",
      "Epoch 34 | Train Loss: 0.7325 | Val Loss: 0.7239\n",
      "Epoch 35 | Train Loss: 0.7363 | Val Loss: 0.7474\n",
      "Epoch 36 | Train Loss: 0.7148 | Val Loss: 0.7190\n",
      "Epoch 37 | Train Loss: 0.7374 | Val Loss: 0.7250\n",
      "Epoch 38 | Train Loss: 0.7251 | Val Loss: 0.7408\n",
      "Epoch 39 | Train Loss: 0.7035 | Val Loss: 0.7196\n",
      "Epoch 40 | Train Loss: 0.7159 | Val Loss: 0.7191\n",
      "Epoch 41 | Train Loss: 0.7035 | Val Loss: 0.7319\n",
      "Epoch 42 | Train Loss: 0.7255 | Val Loss: 0.7386\n",
      "Epoch 43 | Train Loss: 0.7204 | Val Loss: 0.7334\n",
      "Epoch 44 | Train Loss: 0.7181 | Val Loss: 0.7180\n",
      "Epoch 45 | Train Loss: 0.6985 | Val Loss: 0.7128\n",
      "Epoch 46 | Train Loss: 0.7030 | Val Loss: 0.7124\n",
      "Epoch 47 | Train Loss: 0.7061 | Val Loss: 0.7211\n",
      "Epoch 48 | Train Loss: 0.7048 | Val Loss: 0.7257\n",
      "Epoch 49 | Train Loss: 0.7254 | Val Loss: 0.7778\n",
      "Epoch 50 | Train Loss: 0.7165 | Val Loss: 0.7315\n",
      "Fold 3 ‚ñ∂ AUC: 0.777, Balanced Acc: 0.511\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9278 | Val Loss: 0.8644\n",
      "Epoch 02 | Train Loss: 0.8793 | Val Loss: 0.8456\n",
      "Epoch 03 | Train Loss: 0.8651 | Val Loss: 0.8340\n",
      "Epoch 04 | Train Loss: 0.8616 | Val Loss: 0.8816\n",
      "Epoch 05 | Train Loss: 0.8678 | Val Loss: 0.8273\n",
      "Epoch 06 | Train Loss: 0.8389 | Val Loss: 0.8077\n",
      "Epoch 07 | Train Loss: 0.8295 | Val Loss: 0.7847\n",
      "Epoch 08 | Train Loss: 0.8112 | Val Loss: 0.7738\n",
      "Epoch 09 | Train Loss: 0.7890 | Val Loss: 0.7417\n",
      "Epoch 10 | Train Loss: 0.7789 | Val Loss: 0.7258\n",
      "Epoch 11 | Train Loss: 0.7646 | Val Loss: 0.7762\n",
      "Epoch 12 | Train Loss: 0.8057 | Val Loss: 0.7395\n",
      "Epoch 13 | Train Loss: 0.7767 | Val Loss: 0.7239\n",
      "Epoch 14 | Train Loss: 0.7603 | Val Loss: 0.7038\n",
      "Epoch 15 | Train Loss: 0.7651 | Val Loss: 0.7054\n",
      "Epoch 16 | Train Loss: 0.7636 | Val Loss: 0.6973\n",
      "Epoch 17 | Train Loss: 0.7491 | Val Loss: 0.6960\n",
      "Epoch 18 | Train Loss: 0.7470 | Val Loss: 0.6839\n",
      "Epoch 19 | Train Loss: 0.7795 | Val Loss: 0.7077\n",
      "Epoch 20 | Train Loss: 0.7472 | Val Loss: 0.6818\n",
      "Epoch 21 | Train Loss: 0.7466 | Val Loss: 0.7017\n",
      "Epoch 22 | Train Loss: 0.7377 | Val Loss: 0.6858\n",
      "Epoch 23 | Train Loss: 0.7369 | Val Loss: 0.6730\n",
      "Epoch 24 | Train Loss: 0.7490 | Val Loss: 0.6712\n",
      "Epoch 25 | Train Loss: 0.7353 | Val Loss: 0.6727\n",
      "Epoch 26 | Train Loss: 0.7396 | Val Loss: 0.6687\n",
      "Epoch 27 | Train Loss: 0.7528 | Val Loss: 0.6768\n",
      "Epoch 28 | Train Loss: 0.7319 | Val Loss: 0.6670\n",
      "Epoch 29 | Train Loss: 0.7494 | Val Loss: 0.6742\n",
      "Epoch 30 | Train Loss: 0.7313 | Val Loss: 0.6606\n",
      "Epoch 31 | Train Loss: 0.7340 | Val Loss: 0.6607\n",
      "Epoch 32 | Train Loss: 0.7269 | Val Loss: 0.6781\n",
      "Epoch 33 | Train Loss: 0.7215 | Val Loss: 0.6608\n",
      "Epoch 34 | Train Loss: 0.7380 | Val Loss: 0.6829\n",
      "Epoch 35 | Train Loss: 0.7230 | Val Loss: 0.6679\n",
      "Epoch 36 | Train Loss: 0.7293 | Val Loss: 0.6631\n",
      "Epoch 37 | Train Loss: 0.7261 | Val Loss: 0.6809\n",
      "Epoch 38 | Train Loss: 0.7223 | Val Loss: 0.6860\n",
      "Epoch 39 | Train Loss: 0.7329 | Val Loss: 0.6766\n",
      "Epoch 40 | Train Loss: 0.7240 | Val Loss: 0.6671\n",
      "Epoch 41 | Train Loss: 0.7067 | Val Loss: 0.7082\n",
      "Epoch 42 | Train Loss: 0.7236 | Val Loss: 0.6736\n",
      "Epoch 43 | Train Loss: 0.7023 | Val Loss: 0.6800\n",
      "Epoch 44 | Train Loss: 0.7269 | Val Loss: 0.6659\n",
      "Epoch 45 | Train Loss: 0.7388 | Val Loss: 0.6745\n",
      "Epoch 46 | Train Loss: 0.7062 | Val Loss: 0.6787\n",
      "Epoch 47 | Train Loss: 0.7111 | Val Loss: 0.6828\n",
      "Epoch 48 | Train Loss: 0.7131 | Val Loss: 0.6803\n",
      "Epoch 49 | Train Loss: 0.7109 | Val Loss: 0.6809\n",
      "Epoch 50 | Train Loss: 0.7019 | Val Loss: 0.6838\n",
      "Fold 4 ‚ñ∂ AUC: 0.761, Balanced Acc: 0.532\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9577 | Val Loss: 0.9597\n",
      "Epoch 02 | Train Loss: 0.8932 | Val Loss: 0.8933\n",
      "Epoch 03 | Train Loss: 0.8689 | Val Loss: 0.8915\n",
      "Epoch 04 | Train Loss: 0.8525 | Val Loss: 0.8879\n",
      "Epoch 05 | Train Loss: 0.8609 | Val Loss: 0.8813\n",
      "Epoch 06 | Train Loss: 0.8428 | Val Loss: 0.8724\n",
      "Epoch 07 | Train Loss: 0.8311 | Val Loss: 0.8666\n",
      "Epoch 08 | Train Loss: 0.8184 | Val Loss: 0.8479\n",
      "Epoch 09 | Train Loss: 0.8152 | Val Loss: 0.9032\n",
      "Epoch 10 | Train Loss: 0.8578 | Val Loss: 0.8373\n",
      "Epoch 11 | Train Loss: 0.7946 | Val Loss: 0.8562\n",
      "Epoch 12 | Train Loss: 0.8021 | Val Loss: 0.8193\n",
      "Epoch 13 | Train Loss: 0.7945 | Val Loss: 0.8182\n",
      "Epoch 14 | Train Loss: 0.7680 | Val Loss: 0.8235\n",
      "Epoch 15 | Train Loss: 0.7551 | Val Loss: 0.8387\n",
      "Epoch 16 | Train Loss: 0.7814 | Val Loss: 0.8101\n",
      "Epoch 17 | Train Loss: 0.7323 | Val Loss: 0.8104\n",
      "Epoch 18 | Train Loss: 0.7417 | Val Loss: 0.8209\n",
      "Epoch 19 | Train Loss: 0.7398 | Val Loss: 0.8054\n",
      "Epoch 20 | Train Loss: 0.7337 | Val Loss: 0.8018\n",
      "Epoch 21 | Train Loss: 0.7547 | Val Loss: 0.8398\n",
      "Epoch 22 | Train Loss: 0.7419 | Val Loss: 0.7970\n",
      "Epoch 23 | Train Loss: 0.7148 | Val Loss: 0.7947\n",
      "Epoch 24 | Train Loss: 0.7344 | Val Loss: 0.8019\n",
      "Epoch 25 | Train Loss: 0.7137 | Val Loss: 0.7882\n",
      "Epoch 26 | Train Loss: 0.7266 | Val Loss: 0.7867\n",
      "Epoch 27 | Train Loss: 0.7188 | Val Loss: 0.7837\n",
      "Epoch 28 | Train Loss: 0.7229 | Val Loss: 0.7854\n",
      "Epoch 29 | Train Loss: 0.7139 | Val Loss: 0.7973\n",
      "Epoch 30 | Train Loss: 0.7199 | Val Loss: 0.7841\n",
      "Epoch 31 | Train Loss: 0.7230 | Val Loss: 0.8077\n",
      "Epoch 32 | Train Loss: 0.7282 | Val Loss: 0.7940\n",
      "Epoch 33 | Train Loss: 0.7326 | Val Loss: 0.7839\n",
      "Epoch 34 | Train Loss: 0.7129 | Val Loss: 0.7854\n",
      "Epoch 35 | Train Loss: 0.7060 | Val Loss: 0.7904\n",
      "Epoch 36 | Train Loss: 0.7090 | Val Loss: 0.7823\n",
      "Epoch 37 | Train Loss: 0.7184 | Val Loss: 0.7905\n",
      "Epoch 38 | Train Loss: 0.7112 | Val Loss: 0.7853\n",
      "Epoch 39 | Train Loss: 0.7186 | Val Loss: 0.7810\n",
      "Epoch 40 | Train Loss: 0.7286 | Val Loss: 0.8366\n",
      "Epoch 41 | Train Loss: 0.7286 | Val Loss: 0.7838\n",
      "Epoch 42 | Train Loss: 0.7059 | Val Loss: 0.7892\n",
      "Epoch 43 | Train Loss: 0.7052 | Val Loss: 0.7881\n",
      "Epoch 44 | Train Loss: 0.7068 | Val Loss: 0.8039\n",
      "Epoch 45 | Train Loss: 0.7033 | Val Loss: 0.7857\n",
      "Epoch 46 | Train Loss: 0.7248 | Val Loss: 0.7977\n",
      "Epoch 47 | Train Loss: 0.7017 | Val Loss: 0.7877\n",
      "Epoch 48 | Train Loss: 0.6953 | Val Loss: 0.7940\n",
      "Epoch 49 | Train Loss: 0.7232 | Val Loss: 0.7869\n",
      "Epoch 50 | Train Loss: 0.7053 | Val Loss: 0.8224\n",
      "Fold 5 ‚ñ∂ AUC: 0.739, Balanced Acc: 0.477\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9702 | Val Loss: 0.9391\n",
      "Epoch 02 | Train Loss: 0.8731 | Val Loss: 0.8946\n",
      "Epoch 03 | Train Loss: 0.8667 | Val Loss: 0.8958\n",
      "Epoch 04 | Train Loss: 0.8787 | Val Loss: 0.8900\n",
      "Epoch 05 | Train Loss: 0.8439 | Val Loss: 0.9024\n",
      "Epoch 06 | Train Loss: 0.8669 | Val Loss: 0.9122\n",
      "Epoch 07 | Train Loss: 0.8530 | Val Loss: 0.8851\n",
      "Epoch 08 | Train Loss: 0.8417 | Val Loss: 0.8772\n",
      "Epoch 09 | Train Loss: 0.8306 | Val Loss: 0.9078\n",
      "Epoch 10 | Train Loss: 0.8251 | Val Loss: 0.8636\n",
      "Epoch 11 | Train Loss: 0.8190 | Val Loss: 0.8541\n",
      "Epoch 12 | Train Loss: 0.7975 | Val Loss: 0.8472\n",
      "Epoch 13 | Train Loss: 0.7775 | Val Loss: 0.8781\n",
      "Epoch 14 | Train Loss: 0.7599 | Val Loss: 0.8289\n",
      "Epoch 15 | Train Loss: 0.7726 | Val Loss: 0.8513\n",
      "Epoch 16 | Train Loss: 0.7478 | Val Loss: 0.8782\n",
      "Epoch 17 | Train Loss: 0.7652 | Val Loss: 0.8318\n",
      "Epoch 18 | Train Loss: 0.7536 | Val Loss: 0.8531\n",
      "Epoch 19 | Train Loss: 0.7504 | Val Loss: 0.8436\n",
      "Epoch 20 | Train Loss: 0.7434 | Val Loss: 0.8252\n",
      "Epoch 21 | Train Loss: 0.7556 | Val Loss: 0.8260\n",
      "Epoch 22 | Train Loss: 0.7577 | Val Loss: 0.9003\n",
      "Epoch 23 | Train Loss: 0.7573 | Val Loss: 0.8180\n",
      "Epoch 24 | Train Loss: 0.7351 | Val Loss: 0.8223\n",
      "Epoch 25 | Train Loss: 0.7294 | Val Loss: 0.8406\n",
      "Epoch 26 | Train Loss: 0.7406 | Val Loss: 0.8149\n",
      "Epoch 27 | Train Loss: 0.7126 | Val Loss: 0.8177\n",
      "Epoch 28 | Train Loss: 0.7337 | Val Loss: 0.8245\n",
      "Epoch 29 | Train Loss: 0.7516 | Val Loss: 0.8382\n",
      "Epoch 30 | Train Loss: 0.7328 | Val Loss: 0.8183\n",
      "Epoch 31 | Train Loss: 0.7198 | Val Loss: 0.8435\n",
      "Epoch 32 | Train Loss: 0.7212 | Val Loss: 0.8313\n",
      "Epoch 33 | Train Loss: 0.7087 | Val Loss: 0.8325\n",
      "Epoch 34 | Train Loss: 0.7085 | Val Loss: 0.8296\n",
      "Epoch 35 | Train Loss: 0.7152 | Val Loss: 0.8197\n",
      "Epoch 36 | Train Loss: 0.7106 | Val Loss: 0.8401\n",
      "Epoch 37 | Train Loss: 0.7453 | Val Loss: 0.8306\n",
      "Epoch 38 | Train Loss: 0.7217 | Val Loss: 0.8236\n",
      "Epoch 39 | Train Loss: 0.7176 | Val Loss: 0.8362\n",
      "Epoch 40 | Train Loss: 0.7718 | Val Loss: 0.8161\n",
      "Epoch 41 | Train Loss: 0.7251 | Val Loss: 0.8186\n",
      "Epoch 42 | Train Loss: 0.7092 | Val Loss: 0.8234\n",
      "Epoch 43 | Train Loss: 0.7305 | Val Loss: 0.8365\n",
      "Epoch 44 | Train Loss: 0.7207 | Val Loss: 0.8301\n",
      "Epoch 45 | Train Loss: 0.7305 | Val Loss: 0.8200\n",
      "Epoch 46 | Train Loss: 0.7330 | Val Loss: 0.8346\n",
      "Epoch 47 | Train Loss: 0.7305 | Val Loss: 0.8208\n",
      "Epoch 48 | Train Loss: 0.6912 | Val Loss: 0.8262\n",
      "Epoch 49 | Train Loss: 0.7262 | Val Loss: 0.8388\n",
      "Epoch 50 | Train Loss: 0.6954 | Val Loss: 0.8187\n",
      "Fold 6 ‚ñ∂ AUC: 0.735, Balanced Acc: 0.467\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9594 | Val Loss: 0.8790\n",
      "Epoch 02 | Train Loss: 0.8922 | Val Loss: 0.8500\n",
      "Epoch 03 | Train Loss: 0.8717 | Val Loss: 0.8445\n",
      "Epoch 04 | Train Loss: 0.8689 | Val Loss: 0.8623\n",
      "Epoch 05 | Train Loss: 0.8627 | Val Loss: 0.8508\n",
      "Epoch 06 | Train Loss: 0.8428 | Val Loss: 0.8351\n",
      "Epoch 07 | Train Loss: 0.8431 | Val Loss: 0.8446\n",
      "Epoch 08 | Train Loss: 0.8299 | Val Loss: 0.7861\n",
      "Epoch 09 | Train Loss: 0.8403 | Val Loss: 0.7569\n",
      "Epoch 10 | Train Loss: 0.8176 | Val Loss: 0.7509\n",
      "Epoch 11 | Train Loss: 0.8002 | Val Loss: 0.7441\n",
      "Epoch 12 | Train Loss: 0.7977 | Val Loss: 0.7270\n",
      "Epoch 13 | Train Loss: 0.7713 | Val Loss: 0.7054\n",
      "Epoch 14 | Train Loss: 0.8023 | Val Loss: 0.6961\n",
      "Epoch 15 | Train Loss: 0.7672 | Val Loss: 0.7571\n",
      "Epoch 16 | Train Loss: 0.7770 | Val Loss: 0.7184\n",
      "Epoch 17 | Train Loss: 0.7627 | Val Loss: 0.6862\n",
      "Epoch 18 | Train Loss: 0.7546 | Val Loss: 0.7315\n",
      "Epoch 19 | Train Loss: 0.7581 | Val Loss: 0.6875\n",
      "Epoch 20 | Train Loss: 0.7688 | Val Loss: 0.6944\n",
      "Epoch 21 | Train Loss: 0.7491 | Val Loss: 0.6881\n",
      "Epoch 22 | Train Loss: 0.7374 | Val Loss: 0.6922\n",
      "Epoch 23 | Train Loss: 0.7486 | Val Loss: 0.6912\n",
      "Epoch 24 | Train Loss: 0.7521 | Val Loss: 0.6991\n",
      "Epoch 25 | Train Loss: 0.7524 | Val Loss: 0.6982\n",
      "Epoch 26 | Train Loss: 0.7673 | Val Loss: 0.7299\n",
      "Epoch 27 | Train Loss: 0.7427 | Val Loss: 0.7090\n",
      "Epoch 28 | Train Loss: 0.7190 | Val Loss: 0.6931\n",
      "Epoch 29 | Train Loss: 0.7217 | Val Loss: 0.6924\n",
      "Epoch 30 | Train Loss: 0.7249 | Val Loss: 0.7052\n",
      "Epoch 31 | Train Loss: 0.7329 | Val Loss: 0.7131\n",
      "Epoch 32 | Train Loss: 0.7371 | Val Loss: 0.7018\n",
      "Epoch 33 | Train Loss: 0.7239 | Val Loss: 0.7914\n",
      "Epoch 34 | Train Loss: 0.7525 | Val Loss: 0.6946\n",
      "Epoch 35 | Train Loss: 0.7473 | Val Loss: 0.7600\n",
      "Epoch 36 | Train Loss: 0.7200 | Val Loss: 0.7104\n",
      "Epoch 37 | Train Loss: 0.7134 | Val Loss: 0.6980\n",
      "Epoch 38 | Train Loss: 0.7076 | Val Loss: 0.7290\n",
      "Epoch 39 | Train Loss: 0.7144 | Val Loss: 0.7020\n",
      "Epoch 40 | Train Loss: 0.7282 | Val Loss: 0.7041\n",
      "Epoch 41 | Train Loss: 0.7064 | Val Loss: 0.7182\n",
      "Epoch 42 | Train Loss: 0.7160 | Val Loss: 0.7115\n",
      "Epoch 43 | Train Loss: 0.7182 | Val Loss: 0.6984\n",
      "Epoch 44 | Train Loss: 0.6990 | Val Loss: 0.7051\n",
      "Epoch 45 | Train Loss: 0.7015 | Val Loss: 0.7315\n",
      "Epoch 46 | Train Loss: 0.7134 | Val Loss: 0.7464\n",
      "Epoch 47 | Train Loss: 0.7076 | Val Loss: 0.7016\n",
      "Epoch 48 | Train Loss: 0.7166 | Val Loss: 0.7101\n",
      "Epoch 49 | Train Loss: 0.7155 | Val Loss: 0.7020\n",
      "Epoch 50 | Train Loss: 0.7064 | Val Loss: 0.6995\n",
      "Fold 7 ‚ñ∂ AUC: 0.792, Balanced Acc: 0.499\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9056 | Val Loss: 0.8653\n",
      "Epoch 02 | Train Loss: 0.8699 | Val Loss: 0.8731\n",
      "Epoch 03 | Train Loss: 0.8723 | Val Loss: 0.8515\n",
      "Epoch 04 | Train Loss: 0.8652 | Val Loss: 0.8599\n",
      "Epoch 05 | Train Loss: 0.8583 | Val Loss: 0.8515\n",
      "Epoch 06 | Train Loss: 0.8513 | Val Loss: 0.8431\n",
      "Epoch 07 | Train Loss: 0.8456 | Val Loss: 0.8420\n",
      "Epoch 08 | Train Loss: 0.8508 | Val Loss: 0.8203\n",
      "Epoch 09 | Train Loss: 0.8433 | Val Loss: 0.8283\n",
      "Epoch 10 | Train Loss: 0.8338 | Val Loss: 0.8326\n",
      "Epoch 11 | Train Loss: 0.8097 | Val Loss: 0.8270\n",
      "Epoch 12 | Train Loss: 0.8223 | Val Loss: 0.7898\n",
      "Epoch 13 | Train Loss: 0.7905 | Val Loss: 0.8041\n",
      "Epoch 14 | Train Loss: 0.7782 | Val Loss: 0.8226\n",
      "Epoch 15 | Train Loss: 0.7684 | Val Loss: 0.7770\n",
      "Epoch 16 | Train Loss: 0.7541 | Val Loss: 0.7894\n",
      "Epoch 17 | Train Loss: 0.7753 | Val Loss: 0.7827\n",
      "Epoch 18 | Train Loss: 0.7595 | Val Loss: 0.8238\n",
      "Epoch 19 | Train Loss: 0.7708 | Val Loss: 0.7922\n",
      "Epoch 20 | Train Loss: 0.7447 | Val Loss: 0.7887\n",
      "Epoch 21 | Train Loss: 0.7436 | Val Loss: 0.8042\n",
      "Epoch 22 | Train Loss: 0.7486 | Val Loss: 0.7991\n",
      "Epoch 23 | Train Loss: 0.7344 | Val Loss: 0.8270\n",
      "Epoch 24 | Train Loss: 0.7325 | Val Loss: 0.7976\n",
      "Epoch 25 | Train Loss: 0.7434 | Val Loss: 0.8062\n",
      "Epoch 26 | Train Loss: 0.7216 | Val Loss: 0.8425\n",
      "Epoch 27 | Train Loss: 0.7387 | Val Loss: 0.8115\n",
      "Epoch 28 | Train Loss: 0.7077 | Val Loss: 0.8092\n",
      "Epoch 29 | Train Loss: 0.7120 | Val Loss: 0.8144\n",
      "Epoch 30 | Train Loss: 0.7297 | Val Loss: 0.8131\n",
      "Epoch 31 | Train Loss: 0.7284 | Val Loss: 0.8097\n",
      "Epoch 32 | Train Loss: 0.7079 | Val Loss: 0.8039\n",
      "Epoch 33 | Train Loss: 0.7218 | Val Loss: 0.8113\n",
      "Epoch 34 | Train Loss: 0.7036 | Val Loss: 0.8240\n",
      "Epoch 35 | Train Loss: 0.7504 | Val Loss: 0.8040\n",
      "Epoch 36 | Train Loss: 0.7241 | Val Loss: 0.8546\n",
      "Epoch 37 | Train Loss: 0.7334 | Val Loss: 0.7957\n",
      "Epoch 38 | Train Loss: 0.7169 | Val Loss: 0.8106\n",
      "Epoch 39 | Train Loss: 0.7066 | Val Loss: 0.8043\n",
      "Epoch 40 | Train Loss: 0.7157 | Val Loss: 0.8011\n",
      "Epoch 41 | Train Loss: 0.7035 | Val Loss: 0.7946\n",
      "Epoch 42 | Train Loss: 0.7138 | Val Loss: 0.7979\n",
      "Epoch 43 | Train Loss: 0.7024 | Val Loss: 0.8016\n",
      "Epoch 44 | Train Loss: 0.7218 | Val Loss: 0.8003\n",
      "Epoch 45 | Train Loss: 0.7030 | Val Loss: 0.7991\n",
      "Epoch 46 | Train Loss: 0.7047 | Val Loss: 0.8522\n",
      "Epoch 47 | Train Loss: 0.7299 | Val Loss: 0.7887\n",
      "Epoch 48 | Train Loss: 0.7156 | Val Loss: 0.7834\n",
      "Epoch 49 | Train Loss: 0.7080 | Val Loss: 0.8032\n",
      "Epoch 50 | Train Loss: 0.7019 | Val Loss: 0.8246\n",
      "Fold 8 ‚ñ∂ AUC: 0.703, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9234 | Val Loss: 0.8730\n",
      "Epoch 02 | Train Loss: 0.8756 | Val Loss: 0.8750\n",
      "Epoch 03 | Train Loss: 0.8780 | Val Loss: 0.8751\n",
      "Epoch 04 | Train Loss: 0.8577 | Val Loss: 0.8723\n",
      "Epoch 05 | Train Loss: 0.8529 | Val Loss: 0.8562\n",
      "Epoch 06 | Train Loss: 0.8339 | Val Loss: 0.8562\n",
      "Epoch 07 | Train Loss: 0.8215 | Val Loss: 0.8391\n",
      "Epoch 08 | Train Loss: 0.7998 | Val Loss: 0.8288\n",
      "Epoch 09 | Train Loss: 0.7728 | Val Loss: 0.8309\n",
      "Epoch 10 | Train Loss: 0.8025 | Val Loss: 0.8761\n",
      "Epoch 11 | Train Loss: 0.8045 | Val Loss: 0.8367\n",
      "Epoch 12 | Train Loss: 0.7770 | Val Loss: 0.8124\n",
      "Epoch 13 | Train Loss: 0.7642 | Val Loss: 0.8133\n",
      "Epoch 14 | Train Loss: 0.7641 | Val Loss: 0.8772\n",
      "Epoch 15 | Train Loss: 0.7597 | Val Loss: 0.8004\n",
      "Epoch 16 | Train Loss: 0.7538 | Val Loss: 0.8173\n",
      "Epoch 17 | Train Loss: 0.7587 | Val Loss: 0.8050\n",
      "Epoch 18 | Train Loss: 0.7321 | Val Loss: 0.8069\n",
      "Epoch 19 | Train Loss: 0.7337 | Val Loss: 0.8070\n",
      "Epoch 20 | Train Loss: 0.7279 | Val Loss: 0.7994\n",
      "Epoch 21 | Train Loss: 0.7321 | Val Loss: 0.8118\n",
      "Epoch 22 | Train Loss: 0.7705 | Val Loss: 0.8191\n",
      "Epoch 23 | Train Loss: 0.7420 | Val Loss: 0.8116\n",
      "Epoch 24 | Train Loss: 0.7206 | Val Loss: 0.7775\n",
      "Epoch 25 | Train Loss: 0.7317 | Val Loss: 0.8076\n",
      "Epoch 26 | Train Loss: 0.7351 | Val Loss: 0.7913\n",
      "Epoch 27 | Train Loss: 0.7216 | Val Loss: 0.7859\n",
      "Epoch 28 | Train Loss: 0.7234 | Val Loss: 0.7918\n",
      "Epoch 29 | Train Loss: 0.7392 | Val Loss: 0.8227\n",
      "Epoch 30 | Train Loss: 0.7224 | Val Loss: 0.7839\n",
      "Epoch 31 | Train Loss: 0.7128 | Val Loss: 0.7870\n",
      "Epoch 32 | Train Loss: 0.7257 | Val Loss: 0.7838\n",
      "Epoch 33 | Train Loss: 0.7288 | Val Loss: 0.7912\n",
      "Epoch 34 | Train Loss: 0.7335 | Val Loss: 0.7829\n",
      "Epoch 35 | Train Loss: 0.7230 | Val Loss: 0.7739\n",
      "Epoch 36 | Train Loss: 0.7242 | Val Loss: 0.7742\n",
      "Epoch 37 | Train Loss: 0.7311 | Val Loss: 0.7764\n",
      "Epoch 38 | Train Loss: 0.7273 | Val Loss: 0.8055\n",
      "Epoch 39 | Train Loss: 0.7126 | Val Loss: 0.7655\n",
      "Epoch 40 | Train Loss: 0.7243 | Val Loss: 0.7738\n",
      "Epoch 41 | Train Loss: 0.7345 | Val Loss: 0.7715\n",
      "Epoch 42 | Train Loss: 0.7096 | Val Loss: 0.7703\n",
      "Epoch 43 | Train Loss: 0.7025 | Val Loss: 0.7807\n",
      "Epoch 44 | Train Loss: 0.7187 | Val Loss: 0.7650\n",
      "Epoch 45 | Train Loss: 0.7317 | Val Loss: 0.7762\n",
      "Epoch 46 | Train Loss: 0.7382 | Val Loss: 0.7706\n",
      "Epoch 47 | Train Loss: 0.7141 | Val Loss: 0.7629\n",
      "Epoch 48 | Train Loss: 0.7118 | Val Loss: 0.7720\n",
      "Epoch 49 | Train Loss: 0.7021 | Val Loss: 0.7829\n",
      "Epoch 50 | Train Loss: 0.7164 | Val Loss: 0.8084\n",
      "Fold 9 ‚ñ∂ AUC: 0.731, Balanced Acc: 0.490\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9502 | Val Loss: 0.8946\n",
      "Epoch 02 | Train Loss: 0.8829 | Val Loss: 0.8718\n",
      "Epoch 03 | Train Loss: 0.8615 | Val Loss: 0.8602\n",
      "Epoch 04 | Train Loss: 0.8560 | Val Loss: 0.8511\n",
      "Epoch 05 | Train Loss: 0.8682 | Val Loss: 0.8451\n",
      "Epoch 06 | Train Loss: 0.8408 | Val Loss: 0.8339\n",
      "Epoch 07 | Train Loss: 0.8411 | Val Loss: 0.8200\n",
      "Epoch 08 | Train Loss: 0.8288 | Val Loss: 0.8100\n",
      "Epoch 09 | Train Loss: 0.7952 | Val Loss: 0.7915\n",
      "Epoch 10 | Train Loss: 0.8025 | Val Loss: 0.7781\n",
      "Epoch 11 | Train Loss: 0.7727 | Val Loss: 0.7729\n",
      "Epoch 12 | Train Loss: 0.7693 | Val Loss: 0.7659\n",
      "Epoch 13 | Train Loss: 0.7606 | Val Loss: 0.7901\n",
      "Epoch 14 | Train Loss: 0.7711 | Val Loss: 0.7651\n",
      "Epoch 15 | Train Loss: 0.7396 | Val Loss: 0.7602\n",
      "Epoch 16 | Train Loss: 0.7321 | Val Loss: 0.7832\n",
      "Epoch 17 | Train Loss: 0.7362 | Val Loss: 0.7579\n",
      "Epoch 18 | Train Loss: 0.7443 | Val Loss: 0.7701\n",
      "Epoch 19 | Train Loss: 0.7608 | Val Loss: 0.7615\n",
      "Epoch 20 | Train Loss: 0.7300 | Val Loss: 0.7807\n",
      "Epoch 21 | Train Loss: 0.7215 | Val Loss: 0.8045\n",
      "Epoch 22 | Train Loss: 0.7111 | Val Loss: 0.7771\n",
      "Epoch 23 | Train Loss: 0.7206 | Val Loss: 0.8009\n",
      "Epoch 24 | Train Loss: 0.7168 | Val Loss: 0.7795\n",
      "Epoch 25 | Train Loss: 0.7114 | Val Loss: 0.7697\n",
      "Epoch 26 | Train Loss: 0.7117 | Val Loss: 0.7749\n",
      "Epoch 27 | Train Loss: 0.7280 | Val Loss: 0.7704\n",
      "Epoch 28 | Train Loss: 0.7273 | Val Loss: 0.7850\n",
      "Epoch 29 | Train Loss: 0.6994 | Val Loss: 0.7739\n",
      "Epoch 30 | Train Loss: 0.7019 | Val Loss: 0.7776\n",
      "Epoch 31 | Train Loss: 0.7016 | Val Loss: 0.8539\n",
      "Epoch 32 | Train Loss: 0.7066 | Val Loss: 0.7936\n",
      "Epoch 33 | Train Loss: 0.6832 | Val Loss: 0.7768\n",
      "Epoch 34 | Train Loss: 0.7040 | Val Loss: 0.7841\n",
      "Epoch 35 | Train Loss: 0.7063 | Val Loss: 0.7840\n",
      "Epoch 36 | Train Loss: 0.6990 | Val Loss: 0.7818\n",
      "Epoch 37 | Train Loss: 0.7049 | Val Loss: 0.7822\n",
      "Epoch 38 | Train Loss: 0.7251 | Val Loss: 0.8101\n",
      "Epoch 39 | Train Loss: 0.6926 | Val Loss: 0.7805\n",
      "Epoch 40 | Train Loss: 0.6958 | Val Loss: 0.7871\n",
      "Epoch 41 | Train Loss: 0.6892 | Val Loss: 0.8183\n",
      "Epoch 42 | Train Loss: 0.6822 | Val Loss: 0.7821\n",
      "Epoch 43 | Train Loss: 0.6896 | Val Loss: 0.7876\n",
      "Epoch 44 | Train Loss: 0.7009 | Val Loss: 0.8670\n",
      "Epoch 45 | Train Loss: 0.7148 | Val Loss: 0.8143\n",
      "Epoch 46 | Train Loss: 0.7052 | Val Loss: 0.8163\n",
      "Epoch 47 | Train Loss: 0.7213 | Val Loss: 0.8062\n",
      "Epoch 48 | Train Loss: 0.7179 | Val Loss: 0.8037\n",
      "Epoch 49 | Train Loss: 0.6789 | Val Loss: 0.8211\n",
      "Epoch 50 | Train Loss: 0.6854 | Val Loss: 0.8143\n",
      "Fold 10 ‚ñ∂ AUC: 0.727, Balanced Acc: 0.451\n",
      "üîç Summary for hd=64, dp=0.0, lr=0.001 ‚Üí AUC: 0.7409¬±0.0402 | BalAcc: 0.4959¬±0.0310\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.0, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9166 | Val Loss: 0.8591\n",
      "Epoch 02 | Train Loss: 0.8745 | Val Loss: 0.8552\n",
      "Epoch 03 | Train Loss: 0.8632 | Val Loss: 0.8633\n",
      "Epoch 04 | Train Loss: 0.8596 | Val Loss: 0.8554\n",
      "Epoch 05 | Train Loss: 0.8669 | Val Loss: 0.8487\n",
      "Epoch 06 | Train Loss: 0.8665 | Val Loss: 0.8371\n",
      "Epoch 07 | Train Loss: 0.8542 | Val Loss: 0.8340\n",
      "Epoch 08 | Train Loss: 0.8350 | Val Loss: 0.8276\n",
      "Epoch 09 | Train Loss: 0.8551 | Val Loss: 0.8488\n",
      "Epoch 10 | Train Loss: 0.8480 | Val Loss: 0.8199\n",
      "Epoch 11 | Train Loss: 0.8293 | Val Loss: 0.8178\n",
      "Epoch 12 | Train Loss: 0.8226 | Val Loss: 0.8017\n",
      "Epoch 13 | Train Loss: 0.8085 | Val Loss: 0.7882\n",
      "Epoch 14 | Train Loss: 0.7913 | Val Loss: 0.8046\n",
      "Epoch 15 | Train Loss: 0.7936 | Val Loss: 0.7679\n",
      "Epoch 16 | Train Loss: 0.7772 | Val Loss: 0.8068\n",
      "Epoch 17 | Train Loss: 0.8184 | Val Loss: 0.7812\n",
      "Epoch 18 | Train Loss: 0.7959 | Val Loss: 0.7605\n",
      "Epoch 19 | Train Loss: 0.7722 | Val Loss: 0.7449\n",
      "Epoch 20 | Train Loss: 0.7937 | Val Loss: 0.7357\n",
      "Epoch 21 | Train Loss: 0.7558 | Val Loss: 0.7405\n",
      "Epoch 22 | Train Loss: 0.7685 | Val Loss: 0.7226\n",
      "Epoch 23 | Train Loss: 0.7744 | Val Loss: 0.7203\n",
      "Epoch 24 | Train Loss: 0.7741 | Val Loss: 0.7475\n",
      "Epoch 25 | Train Loss: 0.7740 | Val Loss: 0.7533\n",
      "Epoch 26 | Train Loss: 0.7489 | Val Loss: 0.7348\n",
      "Epoch 27 | Train Loss: 0.7604 | Val Loss: 0.7103\n",
      "Epoch 28 | Train Loss: 0.7397 | Val Loss: 0.7089\n",
      "Epoch 29 | Train Loss: 0.7332 | Val Loss: 0.7246\n",
      "Epoch 30 | Train Loss: 0.7380 | Val Loss: 0.6989\n",
      "Epoch 31 | Train Loss: 0.7584 | Val Loss: 0.7083\n",
      "Epoch 32 | Train Loss: 0.7405 | Val Loss: 0.7167\n",
      "Epoch 33 | Train Loss: 0.7624 | Val Loss: 0.7039\n",
      "Epoch 34 | Train Loss: 0.7342 | Val Loss: 0.7103\n",
      "Epoch 35 | Train Loss: 0.7296 | Val Loss: 0.6966\n",
      "Epoch 36 | Train Loss: 0.7261 | Val Loss: 0.6966\n",
      "Epoch 37 | Train Loss: 0.7358 | Val Loss: 0.7134\n",
      "Epoch 38 | Train Loss: 0.7490 | Val Loss: 0.6906\n",
      "Epoch 39 | Train Loss: 0.7406 | Val Loss: 0.7275\n",
      "Epoch 40 | Train Loss: 0.7418 | Val Loss: 0.6910\n",
      "Epoch 41 | Train Loss: 0.7401 | Val Loss: 0.6808\n",
      "Epoch 42 | Train Loss: 0.7176 | Val Loss: 0.6857\n",
      "Epoch 43 | Train Loss: 0.7227 | Val Loss: 0.7125\n",
      "Epoch 44 | Train Loss: 0.7606 | Val Loss: 0.6849\n",
      "Epoch 45 | Train Loss: 0.7604 | Val Loss: 0.7050\n",
      "Epoch 46 | Train Loss: 0.7414 | Val Loss: 0.6870\n",
      "Epoch 47 | Train Loss: 0.7392 | Val Loss: 0.6957\n",
      "Epoch 48 | Train Loss: 0.7263 | Val Loss: 0.6781\n",
      "Epoch 49 | Train Loss: 0.7098 | Val Loss: 0.6742\n",
      "Epoch 50 | Train Loss: 0.7295 | Val Loss: 0.6849\n",
      "Fold 1 ‚ñ∂ AUC: 0.790, Balanced Acc: 0.488\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.8973 | Val Loss: 0.8632\n",
      "Epoch 02 | Train Loss: 0.8807 | Val Loss: 0.8607\n",
      "Epoch 03 | Train Loss: 0.8670 | Val Loss: 0.8615\n",
      "Epoch 04 | Train Loss: 0.8689 | Val Loss: 0.8540\n",
      "Epoch 05 | Train Loss: 0.8698 | Val Loss: 0.8523\n",
      "Epoch 06 | Train Loss: 0.8573 | Val Loss: 0.8484\n",
      "Epoch 07 | Train Loss: 0.8408 | Val Loss: 0.8483\n",
      "Epoch 08 | Train Loss: 0.8615 | Val Loss: 0.8485\n",
      "Epoch 09 | Train Loss: 0.8441 | Val Loss: 0.8361\n",
      "Epoch 10 | Train Loss: 0.8514 | Val Loss: 0.8317\n",
      "Epoch 11 | Train Loss: 0.8272 | Val Loss: 0.8532\n",
      "Epoch 12 | Train Loss: 0.8395 | Val Loss: 0.8127\n",
      "Epoch 13 | Train Loss: 0.8190 | Val Loss: 0.8063\n",
      "Epoch 14 | Train Loss: 0.8249 | Val Loss: 0.8018\n",
      "Epoch 15 | Train Loss: 0.7944 | Val Loss: 0.7792\n",
      "Epoch 16 | Train Loss: 0.7854 | Val Loss: 0.7701\n",
      "Epoch 17 | Train Loss: 0.7575 | Val Loss: 0.8694\n",
      "Epoch 18 | Train Loss: 0.8201 | Val Loss: 0.8221\n",
      "Epoch 19 | Train Loss: 0.7866 | Val Loss: 0.7642\n",
      "Epoch 20 | Train Loss: 0.7736 | Val Loss: 0.7442\n",
      "Epoch 21 | Train Loss: 0.7359 | Val Loss: 0.7488\n",
      "Epoch 22 | Train Loss: 0.7434 | Val Loss: 0.7297\n",
      "Epoch 23 | Train Loss: 0.7935 | Val Loss: 0.7561\n",
      "Epoch 24 | Train Loss: 0.7720 | Val Loss: 0.7472\n",
      "Epoch 25 | Train Loss: 0.7406 | Val Loss: 0.7654\n",
      "Epoch 26 | Train Loss: 0.7478 | Val Loss: 0.7623\n",
      "Epoch 27 | Train Loss: 0.7454 | Val Loss: 0.7104\n",
      "Epoch 28 | Train Loss: 0.7343 | Val Loss: 0.7279\n",
      "Epoch 29 | Train Loss: 0.7075 | Val Loss: 0.7350\n",
      "Epoch 30 | Train Loss: 0.7479 | Val Loss: 0.7661\n",
      "Epoch 31 | Train Loss: 0.7250 | Val Loss: 0.7149\n",
      "Epoch 32 | Train Loss: 0.7183 | Val Loss: 0.7048\n",
      "Epoch 33 | Train Loss: 0.7278 | Val Loss: 0.7073\n",
      "Epoch 34 | Train Loss: 0.7215 | Val Loss: 0.7403\n",
      "Epoch 35 | Train Loss: 0.7274 | Val Loss: 0.7360\n",
      "Epoch 36 | Train Loss: 0.7424 | Val Loss: 0.7223\n",
      "Epoch 37 | Train Loss: 0.7150 | Val Loss: 0.7036\n",
      "Epoch 38 | Train Loss: 0.7181 | Val Loss: 0.7183\n",
      "Epoch 39 | Train Loss: 0.7343 | Val Loss: 0.8251\n",
      "Epoch 40 | Train Loss: 0.7417 | Val Loss: 0.6979\n",
      "Epoch 41 | Train Loss: 0.7156 | Val Loss: 0.7175\n",
      "Epoch 42 | Train Loss: 0.7358 | Val Loss: 0.7132\n",
      "Epoch 43 | Train Loss: 0.7306 | Val Loss: 0.6994\n",
      "Epoch 44 | Train Loss: 0.7154 | Val Loss: 0.7143\n",
      "Epoch 45 | Train Loss: 0.7152 | Val Loss: 0.7008\n",
      "Epoch 46 | Train Loss: 0.7404 | Val Loss: 0.7095\n",
      "Epoch 47 | Train Loss: 0.7086 | Val Loss: 0.7176\n",
      "Epoch 48 | Train Loss: 0.7201 | Val Loss: 0.7081\n",
      "Epoch 49 | Train Loss: 0.7278 | Val Loss: 0.7249\n",
      "Epoch 50 | Train Loss: 0.7250 | Val Loss: 0.7068\n",
      "Fold 2 ‚ñ∂ AUC: 0.681, Balanced Acc: 0.540\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 1.0471 | Val Loss: 0.8587\n",
      "Epoch 02 | Train Loss: 0.8744 | Val Loss: 0.8569\n",
      "Epoch 03 | Train Loss: 0.8667 | Val Loss: 0.8491\n",
      "Epoch 04 | Train Loss: 0.8822 | Val Loss: 0.8430\n",
      "Epoch 05 | Train Loss: 0.8683 | Val Loss: 0.8383\n",
      "Epoch 06 | Train Loss: 0.8461 | Val Loss: 0.8336\n",
      "Epoch 07 | Train Loss: 0.8647 | Val Loss: 0.8401\n",
      "Epoch 08 | Train Loss: 0.8476 | Val Loss: 0.8232\n",
      "Epoch 09 | Train Loss: 0.8353 | Val Loss: 0.8397\n",
      "Epoch 10 | Train Loss: 0.8762 | Val Loss: 0.8533\n",
      "Epoch 11 | Train Loss: 0.8436 | Val Loss: 0.8198\n",
      "Epoch 12 | Train Loss: 0.8409 | Val Loss: 0.8065\n",
      "Epoch 13 | Train Loss: 0.8247 | Val Loss: 0.7936\n",
      "Epoch 14 | Train Loss: 0.8054 | Val Loss: 0.7828\n",
      "Epoch 15 | Train Loss: 0.8087 | Val Loss: 0.7749\n",
      "Epoch 16 | Train Loss: 0.8000 | Val Loss: 0.7955\n",
      "Epoch 17 | Train Loss: 0.7984 | Val Loss: 0.7596\n",
      "Epoch 18 | Train Loss: 0.7949 | Val Loss: 0.7616\n",
      "Epoch 19 | Train Loss: 0.7691 | Val Loss: 0.7540\n",
      "Epoch 20 | Train Loss: 0.7892 | Val Loss: 0.8109\n",
      "Epoch 21 | Train Loss: 0.7807 | Val Loss: 0.7585\n",
      "Epoch 22 | Train Loss: 0.7833 | Val Loss: 0.7583\n",
      "Epoch 23 | Train Loss: 0.7689 | Val Loss: 0.7633\n",
      "Epoch 24 | Train Loss: 0.7791 | Val Loss: 0.7504\n",
      "Epoch 25 | Train Loss: 0.7567 | Val Loss: 0.7407\n",
      "Epoch 26 | Train Loss: 0.7489 | Val Loss: 0.7803\n",
      "Epoch 27 | Train Loss: 0.7473 | Val Loss: 0.7363\n",
      "Epoch 28 | Train Loss: 0.7469 | Val Loss: 0.7521\n",
      "Epoch 29 | Train Loss: 0.7447 | Val Loss: 0.7413\n",
      "Epoch 30 | Train Loss: 0.7569 | Val Loss: 0.7522\n",
      "Epoch 31 | Train Loss: 0.7504 | Val Loss: 0.7385\n",
      "Epoch 32 | Train Loss: 0.7437 | Val Loss: 0.7292\n",
      "Epoch 33 | Train Loss: 0.7458 | Val Loss: 0.7329\n",
      "Epoch 34 | Train Loss: 0.7335 | Val Loss: 0.7273\n",
      "Epoch 35 | Train Loss: 0.7461 | Val Loss: 0.7420\n",
      "Epoch 36 | Train Loss: 0.7426 | Val Loss: 0.7738\n",
      "Epoch 37 | Train Loss: 0.7481 | Val Loss: 0.7299\n",
      "Epoch 38 | Train Loss: 0.7383 | Val Loss: 0.7374\n",
      "Epoch 39 | Train Loss: 0.7181 | Val Loss: 0.7214\n",
      "Epoch 40 | Train Loss: 0.7435 | Val Loss: 0.7393\n",
      "Epoch 41 | Train Loss: 0.7361 | Val Loss: 0.7219\n",
      "Epoch 42 | Train Loss: 0.7403 | Val Loss: 0.7226\n",
      "Epoch 43 | Train Loss: 0.7223 | Val Loss: 0.7188\n",
      "Epoch 44 | Train Loss: 0.7584 | Val Loss: 0.7385\n",
      "Epoch 45 | Train Loss: 0.7355 | Val Loss: 0.7838\n",
      "Epoch 46 | Train Loss: 0.7451 | Val Loss: 0.7159\n",
      "Epoch 47 | Train Loss: 0.7062 | Val Loss: 0.7467\n",
      "Epoch 48 | Train Loss: 0.7360 | Val Loss: 0.7162\n",
      "Epoch 49 | Train Loss: 0.7185 | Val Loss: 0.7446\n",
      "Epoch 50 | Train Loss: 0.7154 | Val Loss: 0.7175\n",
      "Fold 3 ‚ñ∂ AUC: 0.772, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.8834 | Val Loss: 0.8737\n",
      "Epoch 02 | Train Loss: 0.8684 | Val Loss: 0.8768\n",
      "Epoch 03 | Train Loss: 0.9042 | Val Loss: 0.8622\n",
      "Epoch 04 | Train Loss: 0.8672 | Val Loss: 0.8462\n",
      "Epoch 05 | Train Loss: 0.8646 | Val Loss: 0.8478\n",
      "Epoch 06 | Train Loss: 0.8636 | Val Loss: 0.8441\n",
      "Epoch 07 | Train Loss: 0.8526 | Val Loss: 0.8340\n",
      "Epoch 08 | Train Loss: 0.8416 | Val Loss: 0.8374\n",
      "Epoch 09 | Train Loss: 0.8480 | Val Loss: 0.8147\n",
      "Epoch 10 | Train Loss: 0.8457 | Val Loss: 0.8074\n",
      "Epoch 11 | Train Loss: 0.8360 | Val Loss: 0.8057\n",
      "Epoch 12 | Train Loss: 0.8265 | Val Loss: 0.7904\n",
      "Epoch 13 | Train Loss: 0.8146 | Val Loss: 0.7866\n",
      "Epoch 14 | Train Loss: 0.8029 | Val Loss: 0.8026\n",
      "Epoch 15 | Train Loss: 0.7971 | Val Loss: 0.7832\n",
      "Epoch 16 | Train Loss: 0.7984 | Val Loss: 0.7841\n",
      "Epoch 17 | Train Loss: 0.8050 | Val Loss: 0.7852\n",
      "Epoch 18 | Train Loss: 0.8003 | Val Loss: 0.7447\n",
      "Epoch 19 | Train Loss: 0.8297 | Val Loss: 0.8181\n",
      "Epoch 20 | Train Loss: 0.7884 | Val Loss: 0.7574\n",
      "Epoch 21 | Train Loss: 0.7752 | Val Loss: 0.7343\n",
      "Epoch 22 | Train Loss: 0.7578 | Val Loss: 0.7180\n",
      "Epoch 23 | Train Loss: 0.7651 | Val Loss: 0.7284\n",
      "Epoch 24 | Train Loss: 0.7649 | Val Loss: 0.7105\n",
      "Epoch 25 | Train Loss: 0.7471 | Val Loss: 0.7162\n",
      "Epoch 26 | Train Loss: 0.7700 | Val Loss: 0.6993\n",
      "Epoch 27 | Train Loss: 0.7597 | Val Loss: 0.7708\n",
      "Epoch 28 | Train Loss: 0.7594 | Val Loss: 0.6986\n",
      "Epoch 29 | Train Loss: 0.7481 | Val Loss: 0.7055\n",
      "Epoch 30 | Train Loss: 0.7705 | Val Loss: 0.6914\n",
      "Epoch 31 | Train Loss: 0.7293 | Val Loss: 0.6843\n",
      "Epoch 32 | Train Loss: 0.7308 | Val Loss: 0.6751\n",
      "Epoch 33 | Train Loss: 0.7384 | Val Loss: 0.6773\n",
      "Epoch 34 | Train Loss: 0.7356 | Val Loss: 0.7034\n",
      "Epoch 35 | Train Loss: 0.7315 | Val Loss: 0.6751\n",
      "Epoch 36 | Train Loss: 0.7443 | Val Loss: 0.6727\n",
      "Epoch 37 | Train Loss: 0.7324 | Val Loss: 0.6711\n",
      "Epoch 38 | Train Loss: 0.7437 | Val Loss: 0.7029\n",
      "Epoch 39 | Train Loss: 0.7498 | Val Loss: 0.6828\n",
      "Epoch 40 | Train Loss: 0.7509 | Val Loss: 0.7376\n",
      "Epoch 41 | Train Loss: 0.7833 | Val Loss: 0.6853\n",
      "Epoch 42 | Train Loss: 0.7541 | Val Loss: 0.6967\n",
      "Epoch 43 | Train Loss: 0.7528 | Val Loss: 0.6814\n",
      "Epoch 44 | Train Loss: 0.7384 | Val Loss: 0.6792\n",
      "Epoch 45 | Train Loss: 0.7243 | Val Loss: 0.6817\n",
      "Epoch 46 | Train Loss: 0.7243 | Val Loss: 0.6721\n",
      "Epoch 47 | Train Loss: 0.7144 | Val Loss: 0.6672\n",
      "Epoch 48 | Train Loss: 0.7250 | Val Loss: 0.6720\n",
      "Epoch 49 | Train Loss: 0.7194 | Val Loss: 0.6600\n",
      "Epoch 50 | Train Loss: 0.7267 | Val Loss: 0.6668\n",
      "Fold 4 ‚ñ∂ AUC: 0.795, Balanced Acc: 0.553\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9534 | Val Loss: 0.9056\n",
      "Epoch 02 | Train Loss: 0.8647 | Val Loss: 0.8997\n",
      "Epoch 03 | Train Loss: 0.8650 | Val Loss: 0.8969\n",
      "Epoch 04 | Train Loss: 0.8592 | Val Loss: 0.8949\n",
      "Epoch 05 | Train Loss: 0.8671 | Val Loss: 0.8964\n",
      "Epoch 06 | Train Loss: 0.8680 | Val Loss: 0.9030\n",
      "Epoch 07 | Train Loss: 0.8590 | Val Loss: 0.8874\n",
      "Epoch 08 | Train Loss: 0.8453 | Val Loss: 0.8914\n",
      "Epoch 09 | Train Loss: 0.8478 | Val Loss: 0.8838\n",
      "Epoch 10 | Train Loss: 0.8586 | Val Loss: 0.8864\n",
      "Epoch 11 | Train Loss: 0.8467 | Val Loss: 0.8748\n",
      "Epoch 12 | Train Loss: 0.8399 | Val Loss: 0.8722\n",
      "Epoch 13 | Train Loss: 0.8375 | Val Loss: 0.8713\n",
      "Epoch 14 | Train Loss: 0.8347 | Val Loss: 0.8659\n",
      "Epoch 15 | Train Loss: 0.8174 | Val Loss: 0.8742\n",
      "Epoch 16 | Train Loss: 0.8150 | Val Loss: 0.8837\n",
      "Epoch 17 | Train Loss: 0.8182 | Val Loss: 0.8513\n",
      "Epoch 18 | Train Loss: 0.7853 | Val Loss: 0.8523\n",
      "Epoch 19 | Train Loss: 0.7852 | Val Loss: 0.8630\n",
      "Epoch 20 | Train Loss: 0.7655 | Val Loss: 0.8361\n",
      "Epoch 21 | Train Loss: 0.7899 | Val Loss: 0.8331\n",
      "Epoch 22 | Train Loss: 0.7822 | Val Loss: 0.8352\n",
      "Epoch 23 | Train Loss: 0.7716 | Val Loss: 0.8261\n",
      "Epoch 24 | Train Loss: 0.7634 | Val Loss: 0.8348\n",
      "Epoch 25 | Train Loss: 0.7636 | Val Loss: 0.8354\n",
      "Epoch 26 | Train Loss: 0.7452 | Val Loss: 0.8180\n",
      "Epoch 27 | Train Loss: 0.7555 | Val Loss: 0.8267\n",
      "Epoch 28 | Train Loss: 0.7428 | Val Loss: 0.8195\n",
      "Epoch 29 | Train Loss: 0.7363 | Val Loss: 0.8196\n",
      "Epoch 30 | Train Loss: 0.7364 | Val Loss: 0.8162\n",
      "Epoch 31 | Train Loss: 0.7455 | Val Loss: 0.8100\n",
      "Epoch 32 | Train Loss: 0.7260 | Val Loss: 0.8331\n",
      "Epoch 33 | Train Loss: 0.7400 | Val Loss: 0.8225\n",
      "Epoch 34 | Train Loss: 0.7221 | Val Loss: 0.8436\n",
      "Epoch 35 | Train Loss: 0.7479 | Val Loss: 0.8013\n",
      "Epoch 36 | Train Loss: 0.7346 | Val Loss: 0.7978\n",
      "Epoch 37 | Train Loss: 0.7317 | Val Loss: 0.7928\n",
      "Epoch 38 | Train Loss: 0.7203 | Val Loss: 0.7912\n",
      "Epoch 39 | Train Loss: 0.7113 | Val Loss: 0.8026\n",
      "Epoch 40 | Train Loss: 0.7201 | Val Loss: 0.7862\n",
      "Epoch 41 | Train Loss: 0.7180 | Val Loss: 0.8084\n",
      "Epoch 42 | Train Loss: 0.7359 | Val Loss: 0.7885\n",
      "Epoch 43 | Train Loss: 0.7370 | Val Loss: 0.8113\n",
      "Epoch 44 | Train Loss: 0.7305 | Val Loss: 0.7856\n",
      "Epoch 45 | Train Loss: 0.7335 | Val Loss: 0.7845\n",
      "Epoch 46 | Train Loss: 0.7074 | Val Loss: 0.7783\n",
      "Epoch 47 | Train Loss: 0.7080 | Val Loss: 0.7866\n",
      "Epoch 48 | Train Loss: 0.7119 | Val Loss: 0.7818\n",
      "Epoch 49 | Train Loss: 0.7165 | Val Loss: 0.7808\n",
      "Epoch 50 | Train Loss: 0.7288 | Val Loss: 0.7736\n",
      "Fold 5 ‚ñ∂ AUC: 0.743, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9312 | Val Loss: 0.9052\n",
      "Epoch 02 | Train Loss: 0.8852 | Val Loss: 0.8987\n",
      "Epoch 03 | Train Loss: 0.8657 | Val Loss: 0.8903\n",
      "Epoch 04 | Train Loss: 0.8697 | Val Loss: 0.8892\n",
      "Epoch 05 | Train Loss: 0.8508 | Val Loss: 0.8819\n",
      "Epoch 06 | Train Loss: 0.8669 | Val Loss: 0.8744\n",
      "Epoch 07 | Train Loss: 0.8393 | Val Loss: 0.8910\n",
      "Epoch 08 | Train Loss: 0.8674 | Val Loss: 0.8923\n",
      "Epoch 09 | Train Loss: 0.8397 | Val Loss: 0.8643\n",
      "Epoch 10 | Train Loss: 0.8149 | Val Loss: 0.8609\n",
      "Epoch 11 | Train Loss: 0.8044 | Val Loss: 0.8618\n",
      "Epoch 12 | Train Loss: 0.8078 | Val Loss: 0.8644\n",
      "Epoch 13 | Train Loss: 0.7966 | Val Loss: 0.8443\n",
      "Epoch 14 | Train Loss: 0.7698 | Val Loss: 0.8422\n",
      "Epoch 15 | Train Loss: 0.7625 | Val Loss: 0.8399\n",
      "Epoch 16 | Train Loss: 0.7401 | Val Loss: 0.8391\n",
      "Epoch 17 | Train Loss: 0.7670 | Val Loss: 0.8260\n",
      "Epoch 18 | Train Loss: 0.7899 | Val Loss: 0.8134\n",
      "Epoch 19 | Train Loss: 0.7520 | Val Loss: 0.8193\n",
      "Epoch 20 | Train Loss: 0.7484 | Val Loss: 0.8251\n",
      "Epoch 21 | Train Loss: 0.7513 | Val Loss: 0.8517\n",
      "Epoch 22 | Train Loss: 0.7442 | Val Loss: 0.8160\n",
      "Epoch 23 | Train Loss: 0.7248 | Val Loss: 0.8184\n",
      "Epoch 24 | Train Loss: 0.7262 | Val Loss: 0.8196\n",
      "Epoch 25 | Train Loss: 0.7167 | Val Loss: 0.8214\n",
      "Epoch 26 | Train Loss: 0.7280 | Val Loss: 0.8255\n",
      "Epoch 27 | Train Loss: 0.7031 | Val Loss: 0.8236\n",
      "Epoch 28 | Train Loss: 0.7358 | Val Loss: 0.8332\n",
      "Epoch 29 | Train Loss: 0.7239 | Val Loss: 0.8128\n",
      "Epoch 30 | Train Loss: 0.7187 | Val Loss: 0.8173\n",
      "Epoch 31 | Train Loss: 0.7203 | Val Loss: 0.8155\n",
      "Epoch 32 | Train Loss: 0.7190 | Val Loss: 0.8507\n",
      "Epoch 33 | Train Loss: 0.7172 | Val Loss: 0.8016\n",
      "Epoch 34 | Train Loss: 0.7131 | Val Loss: 0.8159\n",
      "Epoch 35 | Train Loss: 0.7074 | Val Loss: 0.8109\n",
      "Epoch 36 | Train Loss: 0.7059 | Val Loss: 0.8128\n",
      "Epoch 37 | Train Loss: 0.7054 | Val Loss: 0.8543\n",
      "Epoch 38 | Train Loss: 0.7246 | Val Loss: 0.8115\n",
      "Epoch 39 | Train Loss: 0.7186 | Val Loss: 0.8139\n",
      "Epoch 40 | Train Loss: 0.7026 | Val Loss: 0.8020\n",
      "Epoch 41 | Train Loss: 0.7068 | Val Loss: 0.8150\n",
      "Epoch 42 | Train Loss: 0.7195 | Val Loss: 0.8049\n",
      "Epoch 43 | Train Loss: 0.7130 | Val Loss: 0.7989\n",
      "Epoch 44 | Train Loss: 0.7027 | Val Loss: 0.7915\n",
      "Epoch 45 | Train Loss: 0.7035 | Val Loss: 0.8031\n",
      "Epoch 46 | Train Loss: 0.7009 | Val Loss: 0.7887\n",
      "Epoch 47 | Train Loss: 0.6983 | Val Loss: 0.7919\n",
      "Epoch 48 | Train Loss: 0.7115 | Val Loss: 0.7967\n",
      "Epoch 49 | Train Loss: 0.7000 | Val Loss: 0.8004\n",
      "Epoch 50 | Train Loss: 0.6887 | Val Loss: 0.7944\n",
      "Fold 6 ‚ñ∂ AUC: 0.749, Balanced Acc: 0.491\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9456 | Val Loss: 0.8551\n",
      "Epoch 02 | Train Loss: 0.8802 | Val Loss: 0.8493\n",
      "Epoch 03 | Train Loss: 0.8689 | Val Loss: 0.8475\n",
      "Epoch 04 | Train Loss: 0.8624 | Val Loss: 0.8457\n",
      "Epoch 05 | Train Loss: 0.8652 | Val Loss: 0.8372\n",
      "Epoch 06 | Train Loss: 0.8596 | Val Loss: 0.8387\n",
      "Epoch 07 | Train Loss: 0.8468 | Val Loss: 0.8286\n",
      "Epoch 08 | Train Loss: 0.8476 | Val Loss: 0.8199\n",
      "Epoch 09 | Train Loss: 0.8406 | Val Loss: 0.8066\n",
      "Epoch 10 | Train Loss: 0.8208 | Val Loss: 0.8042\n",
      "Epoch 11 | Train Loss: 0.8478 | Val Loss: 0.8238\n",
      "Epoch 12 | Train Loss: 0.8082 | Val Loss: 0.7869\n",
      "Epoch 13 | Train Loss: 0.8164 | Val Loss: 0.7676\n",
      "Epoch 14 | Train Loss: 0.8022 | Val Loss: 0.7789\n",
      "Epoch 15 | Train Loss: 0.7910 | Val Loss: 0.7379\n",
      "Epoch 16 | Train Loss: 0.7789 | Val Loss: 0.7615\n",
      "Epoch 17 | Train Loss: 0.7874 | Val Loss: 0.7282\n",
      "Epoch 18 | Train Loss: 0.7827 | Val Loss: 0.7113\n",
      "Epoch 19 | Train Loss: 0.7771 | Val Loss: 0.7073\n",
      "Epoch 20 | Train Loss: 0.7639 | Val Loss: 0.7068\n",
      "Epoch 21 | Train Loss: 0.7601 | Val Loss: 0.7111\n",
      "Epoch 22 | Train Loss: 0.7616 | Val Loss: 0.7209\n",
      "Epoch 23 | Train Loss: 0.7676 | Val Loss: 0.7220\n",
      "Epoch 24 | Train Loss: 0.7791 | Val Loss: 0.7182\n",
      "Epoch 25 | Train Loss: 0.7684 | Val Loss: 0.7345\n",
      "Epoch 26 | Train Loss: 0.7537 | Val Loss: 0.7357\n",
      "Epoch 27 | Train Loss: 0.7741 | Val Loss: 0.7058\n",
      "Epoch 28 | Train Loss: 0.7535 | Val Loss: 0.7005\n",
      "Epoch 29 | Train Loss: 0.7496 | Val Loss: 0.7003\n",
      "Epoch 30 | Train Loss: 0.7303 | Val Loss: 0.7041\n",
      "Epoch 31 | Train Loss: 0.7359 | Val Loss: 0.7318\n",
      "Epoch 32 | Train Loss: 0.7275 | Val Loss: 0.7089\n",
      "Epoch 33 | Train Loss: 0.7409 | Val Loss: 0.7131\n",
      "Epoch 34 | Train Loss: 0.7406 | Val Loss: 0.7077\n",
      "Epoch 35 | Train Loss: 0.7319 | Val Loss: 0.7064\n",
      "Epoch 36 | Train Loss: 0.7318 | Val Loss: 0.7059\n",
      "Epoch 37 | Train Loss: 0.7334 | Val Loss: 0.7578\n",
      "Epoch 38 | Train Loss: 0.7180 | Val Loss: 0.7975\n",
      "Epoch 39 | Train Loss: 0.7315 | Val Loss: 0.7258\n",
      "Epoch 40 | Train Loss: 0.7187 | Val Loss: 0.7125\n",
      "Epoch 41 | Train Loss: 0.7151 | Val Loss: 0.7214\n",
      "Epoch 42 | Train Loss: 0.7313 | Val Loss: 0.7304\n",
      "Epoch 43 | Train Loss: 0.7637 | Val Loss: 0.7490\n",
      "Epoch 44 | Train Loss: 0.7351 | Val Loss: 0.7384\n",
      "Epoch 45 | Train Loss: 0.7080 | Val Loss: 0.7195\n",
      "Epoch 46 | Train Loss: 0.7129 | Val Loss: 0.7234\n",
      "Epoch 47 | Train Loss: 0.7052 | Val Loss: 0.7218\n",
      "Epoch 48 | Train Loss: 0.7180 | Val Loss: 0.7265\n",
      "Epoch 49 | Train Loss: 0.7075 | Val Loss: 0.7485\n",
      "Epoch 50 | Train Loss: 0.7303 | Val Loss: 0.7349\n",
      "Fold 7 ‚ñ∂ AUC: 0.756, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9615 | Val Loss: 0.8627\n",
      "Epoch 02 | Train Loss: 0.8835 | Val Loss: 0.8531\n",
      "Epoch 03 | Train Loss: 0.8628 | Val Loss: 0.8511\n",
      "Epoch 04 | Train Loss: 0.8605 | Val Loss: 0.8491\n",
      "Epoch 05 | Train Loss: 0.8606 | Val Loss: 0.8422\n",
      "Epoch 06 | Train Loss: 0.8587 | Val Loss: 0.8411\n",
      "Epoch 07 | Train Loss: 0.8485 | Val Loss: 0.8361\n",
      "Epoch 08 | Train Loss: 0.8368 | Val Loss: 0.8318\n",
      "Epoch 09 | Train Loss: 0.8412 | Val Loss: 0.8397\n",
      "Epoch 10 | Train Loss: 0.8617 | Val Loss: 0.8224\n",
      "Epoch 11 | Train Loss: 0.8308 | Val Loss: 0.8173\n",
      "Epoch 12 | Train Loss: 0.8286 | Val Loss: 0.8118\n",
      "Epoch 13 | Train Loss: 0.8187 | Val Loss: 0.8129\n",
      "Epoch 14 | Train Loss: 0.8140 | Val Loss: 0.8041\n",
      "Epoch 15 | Train Loss: 0.8006 | Val Loss: 0.7920\n",
      "Epoch 16 | Train Loss: 0.8083 | Val Loss: 0.7799\n",
      "Epoch 17 | Train Loss: 0.7995 | Val Loss: 0.7757\n",
      "Epoch 18 | Train Loss: 0.7767 | Val Loss: 0.7854\n",
      "Epoch 19 | Train Loss: 0.8031 | Val Loss: 0.7845\n",
      "Epoch 20 | Train Loss: 0.8029 | Val Loss: 0.7689\n",
      "Epoch 21 | Train Loss: 0.7869 | Val Loss: 0.7692\n",
      "Epoch 22 | Train Loss: 0.7917 | Val Loss: 0.7609\n",
      "Epoch 23 | Train Loss: 0.7725 | Val Loss: 0.7796\n",
      "Epoch 24 | Train Loss: 0.7785 | Val Loss: 0.7608\n",
      "Epoch 25 | Train Loss: 0.7422 | Val Loss: 0.7797\n",
      "Epoch 26 | Train Loss: 0.7539 | Val Loss: 0.8154\n",
      "Epoch 27 | Train Loss: 0.7634 | Val Loss: 0.7698\n",
      "Epoch 28 | Train Loss: 0.7396 | Val Loss: 0.7662\n",
      "Epoch 29 | Train Loss: 0.7461 | Val Loss: 0.7840\n",
      "Epoch 30 | Train Loss: 0.7480 | Val Loss: 0.7705\n",
      "Epoch 31 | Train Loss: 0.7374 | Val Loss: 0.7936\n",
      "Epoch 32 | Train Loss: 0.7457 | Val Loss: 0.7754\n",
      "Epoch 33 | Train Loss: 0.7135 | Val Loss: 0.7932\n",
      "Epoch 34 | Train Loss: 0.7362 | Val Loss: 0.8166\n",
      "Epoch 35 | Train Loss: 0.7296 | Val Loss: 0.8239\n",
      "Epoch 36 | Train Loss: 0.7431 | Val Loss: 0.7928\n",
      "Epoch 37 | Train Loss: 0.7237 | Val Loss: 0.7784\n",
      "Epoch 38 | Train Loss: 0.7061 | Val Loss: 0.7838\n",
      "Epoch 39 | Train Loss: 0.7108 | Val Loss: 0.7800\n",
      "Epoch 40 | Train Loss: 0.7051 | Val Loss: 0.7855\n",
      "Epoch 41 | Train Loss: 0.7184 | Val Loss: 0.8098\n",
      "Epoch 42 | Train Loss: 0.7254 | Val Loss: 0.7837\n",
      "Epoch 43 | Train Loss: 0.7221 | Val Loss: 0.8015\n",
      "Epoch 44 | Train Loss: 0.7260 | Val Loss: 0.7815\n",
      "Epoch 45 | Train Loss: 0.7061 | Val Loss: 0.7860\n",
      "Epoch 46 | Train Loss: 0.6976 | Val Loss: 0.7894\n",
      "Epoch 47 | Train Loss: 0.7098 | Val Loss: 0.7855\n",
      "Epoch 48 | Train Loss: 0.7161 | Val Loss: 0.8462\n",
      "Epoch 49 | Train Loss: 0.7152 | Val Loss: 0.7929\n",
      "Epoch 50 | Train Loss: 0.7112 | Val Loss: 0.8476\n",
      "Fold 8 ‚ñ∂ AUC: 0.741, Balanced Acc: 0.403\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9132 | Val Loss: 0.8744\n",
      "Epoch 02 | Train Loss: 0.8751 | Val Loss: 0.8707\n",
      "Epoch 03 | Train Loss: 0.8616 | Val Loss: 0.8691\n",
      "Epoch 04 | Train Loss: 0.8522 | Val Loss: 0.8712\n",
      "Epoch 05 | Train Loss: 0.8600 | Val Loss: 0.8652\n",
      "Epoch 06 | Train Loss: 0.8587 | Val Loss: 0.8624\n",
      "Epoch 07 | Train Loss: 0.8511 | Val Loss: 0.8600\n",
      "Epoch 08 | Train Loss: 0.8545 | Val Loss: 0.8582\n",
      "Epoch 09 | Train Loss: 0.8390 | Val Loss: 0.8522\n",
      "Epoch 10 | Train Loss: 0.8265 | Val Loss: 0.8577\n",
      "Epoch 11 | Train Loss: 0.8278 | Val Loss: 0.8481\n",
      "Epoch 12 | Train Loss: 0.8004 | Val Loss: 0.8433\n",
      "Epoch 13 | Train Loss: 0.8018 | Val Loss: 0.8329\n",
      "Epoch 14 | Train Loss: 0.8032 | Val Loss: 0.8427\n",
      "Epoch 15 | Train Loss: 0.7953 | Val Loss: 0.8244\n",
      "Epoch 16 | Train Loss: 0.7852 | Val Loss: 0.8205\n",
      "Epoch 17 | Train Loss: 0.7605 | Val Loss: 0.8478\n",
      "Epoch 18 | Train Loss: 0.7418 | Val Loss: 0.8348\n",
      "Epoch 19 | Train Loss: 0.7536 | Val Loss: 0.8090\n",
      "Epoch 20 | Train Loss: 0.7380 | Val Loss: 0.8414\n",
      "Epoch 21 | Train Loss: 0.7365 | Val Loss: 0.8015\n",
      "Epoch 22 | Train Loss: 0.7364 | Val Loss: 0.8105\n",
      "Epoch 23 | Train Loss: 0.7398 | Val Loss: 0.8721\n",
      "Epoch 24 | Train Loss: 0.7367 | Val Loss: 0.8636\n",
      "Epoch 25 | Train Loss: 0.7409 | Val Loss: 0.7913\n",
      "Epoch 26 | Train Loss: 0.7387 | Val Loss: 0.7941\n",
      "Epoch 27 | Train Loss: 0.7410 | Val Loss: 0.8064\n",
      "Epoch 28 | Train Loss: 0.7388 | Val Loss: 0.7918\n",
      "Epoch 29 | Train Loss: 0.7147 | Val Loss: 0.7856\n",
      "Epoch 30 | Train Loss: 0.7151 | Val Loss: 0.7841\n",
      "Epoch 31 | Train Loss: 0.7465 | Val Loss: 0.7893\n",
      "Epoch 32 | Train Loss: 0.7513 | Val Loss: 0.7787\n",
      "Epoch 33 | Train Loss: 0.7563 | Val Loss: 0.7797\n",
      "Epoch 34 | Train Loss: 0.7181 | Val Loss: 0.7853\n",
      "Epoch 35 | Train Loss: 0.7078 | Val Loss: 0.8029\n",
      "Epoch 36 | Train Loss: 0.7260 | Val Loss: 0.7889\n",
      "Epoch 37 | Train Loss: 0.7134 | Val Loss: 0.8350\n",
      "Epoch 38 | Train Loss: 0.7319 | Val Loss: 0.7847\n",
      "Epoch 39 | Train Loss: 0.7396 | Val Loss: 0.7794\n",
      "Epoch 40 | Train Loss: 0.7040 | Val Loss: 0.7699\n",
      "Epoch 41 | Train Loss: 0.7211 | Val Loss: 0.7664\n",
      "Epoch 42 | Train Loss: 0.7340 | Val Loss: 0.7788\n",
      "Epoch 43 | Train Loss: 0.7315 | Val Loss: 0.8038\n",
      "Epoch 44 | Train Loss: 0.7125 | Val Loss: 0.7685\n",
      "Epoch 45 | Train Loss: 0.7113 | Val Loss: 0.7899\n",
      "Epoch 46 | Train Loss: 0.7028 | Val Loss: 0.7646\n",
      "Epoch 47 | Train Loss: 0.7003 | Val Loss: 0.7775\n",
      "Epoch 48 | Train Loss: 0.7287 | Val Loss: 0.7653\n",
      "Epoch 49 | Train Loss: 0.7042 | Val Loss: 0.7698\n",
      "Epoch 50 | Train Loss: 0.7166 | Val Loss: 0.7931\n",
      "Fold 9 ‚ñ∂ AUC: 0.730, Balanced Acc: 0.503\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9346 | Val Loss: 0.8697\n",
      "Epoch 02 | Train Loss: 0.8759 | Val Loss: 0.8634\n",
      "Epoch 03 | Train Loss: 0.8695 | Val Loss: 0.8666\n",
      "Epoch 04 | Train Loss: 0.8695 | Val Loss: 0.8591\n",
      "Epoch 05 | Train Loss: 0.8598 | Val Loss: 0.8567\n",
      "Epoch 06 | Train Loss: 0.8597 | Val Loss: 0.8510\n",
      "Epoch 07 | Train Loss: 0.8486 | Val Loss: 0.8457\n",
      "Epoch 08 | Train Loss: 0.8410 | Val Loss: 0.8384\n",
      "Epoch 09 | Train Loss: 0.8469 | Val Loss: 0.8374\n",
      "Epoch 10 | Train Loss: 0.8314 | Val Loss: 0.8275\n",
      "Epoch 11 | Train Loss: 0.8163 | Val Loss: 0.8150\n",
      "Epoch 12 | Train Loss: 0.8202 | Val Loss: 0.8009\n",
      "Epoch 13 | Train Loss: 0.7991 | Val Loss: 0.7906\n",
      "Epoch 14 | Train Loss: 0.7917 | Val Loss: 0.7810\n",
      "Epoch 15 | Train Loss: 0.7695 | Val Loss: 0.8469\n",
      "Epoch 16 | Train Loss: 0.8245 | Val Loss: 0.7783\n",
      "Epoch 17 | Train Loss: 0.7728 | Val Loss: 0.7852\n",
      "Epoch 18 | Train Loss: 0.7708 | Val Loss: 0.7683\n",
      "Epoch 19 | Train Loss: 0.7762 | Val Loss: 0.7926\n",
      "Epoch 20 | Train Loss: 0.7632 | Val Loss: 0.7637\n",
      "Epoch 21 | Train Loss: 0.7583 | Val Loss: 0.7619\n",
      "Epoch 22 | Train Loss: 0.7622 | Val Loss: 0.7764\n",
      "Epoch 23 | Train Loss: 0.7845 | Val Loss: 0.8214\n",
      "Epoch 24 | Train Loss: 0.7632 | Val Loss: 0.7710\n",
      "Epoch 25 | Train Loss: 0.7483 | Val Loss: 0.7568\n",
      "Epoch 26 | Train Loss: 0.7467 | Val Loss: 0.7567\n",
      "Epoch 27 | Train Loss: 0.7445 | Val Loss: 0.8437\n",
      "Epoch 28 | Train Loss: 0.7369 | Val Loss: 0.7669\n",
      "Epoch 29 | Train Loss: 0.7535 | Val Loss: 0.7927\n",
      "Epoch 30 | Train Loss: 0.7363 | Val Loss: 0.7579\n",
      "Epoch 31 | Train Loss: 0.7550 | Val Loss: 0.7666\n",
      "Epoch 32 | Train Loss: 0.7297 | Val Loss: 0.7948\n",
      "Epoch 33 | Train Loss: 0.7323 | Val Loss: 0.7617\n",
      "Epoch 34 | Train Loss: 0.7430 | Val Loss: 0.7575\n",
      "Epoch 35 | Train Loss: 0.7387 | Val Loss: 0.7682\n",
      "Epoch 36 | Train Loss: 0.7274 | Val Loss: 0.7968\n",
      "Epoch 37 | Train Loss: 0.7339 | Val Loss: 0.7632\n",
      "Epoch 38 | Train Loss: 0.7247 | Val Loss: 0.7981\n",
      "Epoch 39 | Train Loss: 0.7298 | Val Loss: 0.7645\n",
      "Epoch 40 | Train Loss: 0.7237 | Val Loss: 0.7624\n",
      "Epoch 41 | Train Loss: 0.7456 | Val Loss: 0.7618\n",
      "Epoch 42 | Train Loss: 0.7128 | Val Loss: 0.7979\n",
      "Epoch 43 | Train Loss: 0.7330 | Val Loss: 0.7695\n",
      "Epoch 44 | Train Loss: 0.7025 | Val Loss: 0.7756\n",
      "Epoch 45 | Train Loss: 0.7232 | Val Loss: 0.7877\n",
      "Epoch 46 | Train Loss: 0.7118 | Val Loss: 0.7776\n",
      "Epoch 47 | Train Loss: 0.7134 | Val Loss: 0.7664\n",
      "Epoch 48 | Train Loss: 0.7143 | Val Loss: 0.7831\n",
      "Epoch 49 | Train Loss: 0.7163 | Val Loss: 0.7836\n",
      "Epoch 50 | Train Loss: 0.7485 | Val Loss: 0.7672\n",
      "Fold 10 ‚ñ∂ AUC: 0.715, Balanced Acc: 0.469\n",
      "üîç Summary for hd=64, dp=0.0, lr=0.0005 ‚Üí AUC: 0.7473¬±0.0325 | BalAcc: 0.4868¬±0.0397\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.0, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 1.1887 | Val Loss: 1.0642\n",
      "Epoch 02 | Train Loss: 0.9838 | Val Loss: 0.9289\n",
      "Epoch 03 | Train Loss: 0.9060 | Val Loss: 0.8872\n",
      "Epoch 04 | Train Loss: 0.8775 | Val Loss: 0.8715\n",
      "Epoch 05 | Train Loss: 0.8697 | Val Loss: 0.8652\n",
      "Epoch 06 | Train Loss: 0.8637 | Val Loss: 0.8634\n",
      "Epoch 07 | Train Loss: 0.8620 | Val Loss: 0.8605\n",
      "Epoch 08 | Train Loss: 0.8661 | Val Loss: 0.8579\n",
      "Epoch 09 | Train Loss: 0.8522 | Val Loss: 0.8554\n",
      "Epoch 10 | Train Loss: 0.8592 | Val Loss: 0.8524\n",
      "Epoch 11 | Train Loss: 0.8707 | Val Loss: 0.8500\n",
      "Epoch 12 | Train Loss: 0.8446 | Val Loss: 0.8471\n",
      "Epoch 13 | Train Loss: 0.8510 | Val Loss: 0.8461\n",
      "Epoch 14 | Train Loss: 0.8506 | Val Loss: 0.8425\n",
      "Epoch 15 | Train Loss: 0.8450 | Val Loss: 0.8394\n",
      "Epoch 16 | Train Loss: 0.8344 | Val Loss: 0.8367\n",
      "Epoch 17 | Train Loss: 0.8473 | Val Loss: 0.8346\n",
      "Epoch 18 | Train Loss: 0.8312 | Val Loss: 0.8319\n",
      "Epoch 19 | Train Loss: 0.8367 | Val Loss: 0.8288\n",
      "Epoch 20 | Train Loss: 0.8422 | Val Loss: 0.8261\n",
      "Epoch 21 | Train Loss: 0.8262 | Val Loss: 0.8240\n",
      "Epoch 22 | Train Loss: 0.8225 | Val Loss: 0.8219\n",
      "Epoch 23 | Train Loss: 0.8184 | Val Loss: 0.8170\n",
      "Epoch 24 | Train Loss: 0.8167 | Val Loss: 0.8148\n",
      "Epoch 25 | Train Loss: 0.8307 | Val Loss: 0.8115\n",
      "Epoch 26 | Train Loss: 0.8091 | Val Loss: 0.8084\n",
      "Epoch 27 | Train Loss: 0.8060 | Val Loss: 0.8055\n",
      "Epoch 28 | Train Loss: 0.8009 | Val Loss: 0.8024\n",
      "Epoch 29 | Train Loss: 0.7978 | Val Loss: 0.7993\n",
      "Epoch 30 | Train Loss: 0.8108 | Val Loss: 0.7967\n",
      "Epoch 31 | Train Loss: 0.8105 | Val Loss: 0.7933\n",
      "Epoch 32 | Train Loss: 0.8035 | Val Loss: 0.7899\n",
      "Epoch 33 | Train Loss: 0.7875 | Val Loss: 0.7885\n",
      "Epoch 34 | Train Loss: 0.7910 | Val Loss: 0.7838\n",
      "Epoch 35 | Train Loss: 0.7830 | Val Loss: 0.7814\n",
      "Epoch 36 | Train Loss: 0.7940 | Val Loss: 0.7803\n",
      "Epoch 37 | Train Loss: 0.7777 | Val Loss: 0.7761\n",
      "Epoch 38 | Train Loss: 0.7887 | Val Loss: 0.7741\n",
      "Epoch 39 | Train Loss: 0.7780 | Val Loss: 0.7722\n",
      "Epoch 40 | Train Loss: 0.7745 | Val Loss: 0.7727\n",
      "Epoch 41 | Train Loss: 0.7803 | Val Loss: 0.7665\n",
      "Epoch 42 | Train Loss: 0.7710 | Val Loss: 0.7646\n",
      "Epoch 43 | Train Loss: 0.7928 | Val Loss: 0.7619\n",
      "Epoch 44 | Train Loss: 0.7725 | Val Loss: 0.7595\n",
      "Epoch 45 | Train Loss: 0.7582 | Val Loss: 0.7583\n",
      "Epoch 46 | Train Loss: 0.7706 | Val Loss: 0.7602\n",
      "Epoch 47 | Train Loss: 0.7675 | Val Loss: 0.7530\n",
      "Epoch 48 | Train Loss: 0.7783 | Val Loss: 0.7518\n",
      "Epoch 49 | Train Loss: 0.7667 | Val Loss: 0.7484\n",
      "Epoch 50 | Train Loss: 0.7592 | Val Loss: 0.7476\n",
      "Fold 1 ‚ñ∂ AUC: 0.721, Balanced Acc: 0.531\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 1.3054 | Val Loss: 1.1484\n",
      "Epoch 02 | Train Loss: 1.0594 | Val Loss: 0.9872\n",
      "Epoch 03 | Train Loss: 0.9543 | Val Loss: 0.9197\n",
      "Epoch 04 | Train Loss: 0.9064 | Val Loss: 0.8870\n",
      "Epoch 05 | Train Loss: 0.8770 | Val Loss: 0.8727\n",
      "Epoch 06 | Train Loss: 0.8646 | Val Loss: 0.8682\n",
      "Epoch 07 | Train Loss: 0.8670 | Val Loss: 0.8685\n",
      "Epoch 08 | Train Loss: 0.8601 | Val Loss: 0.8661\n",
      "Epoch 09 | Train Loss: 0.8714 | Val Loss: 0.8654\n",
      "Epoch 10 | Train Loss: 0.8739 | Val Loss: 0.8651\n",
      "Epoch 11 | Train Loss: 0.8683 | Val Loss: 0.8642\n",
      "Epoch 12 | Train Loss: 0.8570 | Val Loss: 0.8642\n",
      "Epoch 13 | Train Loss: 0.8554 | Val Loss: 0.8632\n",
      "Epoch 14 | Train Loss: 0.8706 | Val Loss: 0.8626\n",
      "Epoch 15 | Train Loss: 0.8526 | Val Loss: 0.8621\n",
      "Epoch 16 | Train Loss: 0.8736 | Val Loss: 0.8616\n",
      "Epoch 17 | Train Loss: 0.8607 | Val Loss: 0.8603\n",
      "Epoch 18 | Train Loss: 0.8591 | Val Loss: 0.8594\n",
      "Epoch 19 | Train Loss: 0.8580 | Val Loss: 0.8585\n",
      "Epoch 20 | Train Loss: 0.8621 | Val Loss: 0.8578\n",
      "Epoch 21 | Train Loss: 0.8488 | Val Loss: 0.8574\n",
      "Epoch 22 | Train Loss: 0.8489 | Val Loss: 0.8562\n",
      "Epoch 23 | Train Loss: 0.8491 | Val Loss: 0.8548\n",
      "Epoch 24 | Train Loss: 0.8575 | Val Loss: 0.8554\n",
      "Epoch 25 | Train Loss: 0.8495 | Val Loss: 0.8531\n",
      "Epoch 26 | Train Loss: 0.8391 | Val Loss: 0.8521\n",
      "Epoch 27 | Train Loss: 0.8620 | Val Loss: 0.8508\n",
      "Epoch 28 | Train Loss: 0.8513 | Val Loss: 0.8494\n",
      "Epoch 29 | Train Loss: 0.8461 | Val Loss: 0.8483\n",
      "Epoch 30 | Train Loss: 0.8447 | Val Loss: 0.8474\n",
      "Epoch 31 | Train Loss: 0.8424 | Val Loss: 0.8458\n",
      "Epoch 32 | Train Loss: 0.8404 | Val Loss: 0.8456\n",
      "Epoch 33 | Train Loss: 0.8422 | Val Loss: 0.8435\n",
      "Epoch 34 | Train Loss: 0.8260 | Val Loss: 0.8430\n",
      "Epoch 35 | Train Loss: 0.8365 | Val Loss: 0.8424\n",
      "Epoch 36 | Train Loss: 0.8284 | Val Loss: 0.8385\n",
      "Epoch 37 | Train Loss: 0.8242 | Val Loss: 0.8384\n",
      "Epoch 38 | Train Loss: 0.8301 | Val Loss: 0.8377\n",
      "Epoch 39 | Train Loss: 0.8251 | Val Loss: 0.8329\n",
      "Epoch 40 | Train Loss: 0.8529 | Val Loss: 0.8367\n",
      "Epoch 41 | Train Loss: 0.8230 | Val Loss: 0.8303\n",
      "Epoch 42 | Train Loss: 0.8187 | Val Loss: 0.8294\n",
      "Epoch 43 | Train Loss: 0.8282 | Val Loss: 0.8280\n",
      "Epoch 44 | Train Loss: 0.8133 | Val Loss: 0.8248\n",
      "Epoch 45 | Train Loss: 0.8072 | Val Loss: 0.8259\n",
      "Epoch 46 | Train Loss: 0.8399 | Val Loss: 0.8249\n",
      "Epoch 47 | Train Loss: 0.8085 | Val Loss: 0.8202\n",
      "Epoch 48 | Train Loss: 0.8149 | Val Loss: 0.8239\n",
      "Epoch 49 | Train Loss: 0.8060 | Val Loss: 0.8173\n",
      "Epoch 50 | Train Loss: 0.8082 | Val Loss: 0.8184\n",
      "Fold 2 ‚ñ∂ AUC: 0.594, Balanced Acc: 0.439\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 1.2173 | Val Loss: 1.0774\n",
      "Epoch 02 | Train Loss: 1.0135 | Val Loss: 0.9548\n",
      "Epoch 03 | Train Loss: 0.9342 | Val Loss: 0.9056\n",
      "Epoch 04 | Train Loss: 0.9012 | Val Loss: 0.8804\n",
      "Epoch 05 | Train Loss: 0.8747 | Val Loss: 0.8702\n",
      "Epoch 06 | Train Loss: 0.8760 | Val Loss: 0.8633\n",
      "Epoch 07 | Train Loss: 0.8690 | Val Loss: 0.8607\n",
      "Epoch 08 | Train Loss: 0.8686 | Val Loss: 0.8601\n",
      "Epoch 09 | Train Loss: 0.8771 | Val Loss: 0.8586\n",
      "Epoch 10 | Train Loss: 0.8609 | Val Loss: 0.8579\n",
      "Epoch 11 | Train Loss: 0.8676 | Val Loss: 0.8563\n",
      "Epoch 12 | Train Loss: 0.8613 | Val Loss: 0.8545\n",
      "Epoch 13 | Train Loss: 0.8579 | Val Loss: 0.8531\n",
      "Epoch 14 | Train Loss: 0.8701 | Val Loss: 0.8509\n",
      "Epoch 15 | Train Loss: 0.8667 | Val Loss: 0.8498\n",
      "Epoch 16 | Train Loss: 0.8551 | Val Loss: 0.8491\n",
      "Epoch 17 | Train Loss: 0.8493 | Val Loss: 0.8471\n",
      "Epoch 18 | Train Loss: 0.8623 | Val Loss: 0.8472\n",
      "Epoch 19 | Train Loss: 0.8516 | Val Loss: 0.8450\n",
      "Epoch 20 | Train Loss: 0.8515 | Val Loss: 0.8434\n",
      "Epoch 21 | Train Loss: 0.8495 | Val Loss: 0.8427\n",
      "Epoch 22 | Train Loss: 0.8509 | Val Loss: 0.8405\n",
      "Epoch 23 | Train Loss: 0.8487 | Val Loss: 0.8400\n",
      "Epoch 24 | Train Loss: 0.8476 | Val Loss: 0.8396\n",
      "Epoch 25 | Train Loss: 0.8659 | Val Loss: 0.8366\n",
      "Epoch 26 | Train Loss: 0.8566 | Val Loss: 0.8354\n",
      "Epoch 27 | Train Loss: 0.8428 | Val Loss: 0.8339\n",
      "Epoch 28 | Train Loss: 0.8547 | Val Loss: 0.8321\n",
      "Epoch 29 | Train Loss: 0.8450 | Val Loss: 0.8308\n",
      "Epoch 30 | Train Loss: 0.8363 | Val Loss: 0.8310\n",
      "Epoch 31 | Train Loss: 0.8388 | Val Loss: 0.8273\n",
      "Epoch 32 | Train Loss: 0.8339 | Val Loss: 0.8258\n",
      "Epoch 33 | Train Loss: 0.8315 | Val Loss: 0.8241\n",
      "Epoch 34 | Train Loss: 0.8326 | Val Loss: 0.8219\n",
      "Epoch 35 | Train Loss: 0.8569 | Val Loss: 0.8217\n",
      "Epoch 36 | Train Loss: 0.8369 | Val Loss: 0.8176\n",
      "Epoch 37 | Train Loss: 0.8290 | Val Loss: 0.8161\n",
      "Epoch 38 | Train Loss: 0.8275 | Val Loss: 0.8137\n",
      "Epoch 39 | Train Loss: 0.8224 | Val Loss: 0.8106\n",
      "Epoch 40 | Train Loss: 0.8225 | Val Loss: 0.8090\n",
      "Epoch 41 | Train Loss: 0.8229 | Val Loss: 0.8065\n",
      "Epoch 42 | Train Loss: 0.8075 | Val Loss: 0.8028\n",
      "Epoch 43 | Train Loss: 0.8349 | Val Loss: 0.7997\n",
      "Epoch 44 | Train Loss: 0.8202 | Val Loss: 0.8001\n",
      "Epoch 45 | Train Loss: 0.8058 | Val Loss: 0.7959\n",
      "Epoch 46 | Train Loss: 0.8168 | Val Loss: 0.7946\n",
      "Epoch 47 | Train Loss: 0.8141 | Val Loss: 0.7934\n",
      "Epoch 48 | Train Loss: 0.8175 | Val Loss: 0.7889\n",
      "Epoch 49 | Train Loss: 0.8205 | Val Loss: 0.7839\n",
      "Epoch 50 | Train Loss: 0.7983 | Val Loss: 0.7843\n",
      "Fold 3 ‚ñ∂ AUC: 0.761, Balanced Acc: 0.493\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9312 | Val Loss: 0.8818\n",
      "Epoch 02 | Train Loss: 0.8809 | Val Loss: 0.8620\n",
      "Epoch 03 | Train Loss: 0.8783 | Val Loss: 0.8583\n",
      "Epoch 04 | Train Loss: 0.8792 | Val Loss: 0.8576\n",
      "Epoch 05 | Train Loss: 0.8862 | Val Loss: 0.8576\n",
      "Epoch 06 | Train Loss: 0.8813 | Val Loss: 0.8584\n",
      "Epoch 07 | Train Loss: 0.8823 | Val Loss: 0.8574\n",
      "Epoch 08 | Train Loss: 0.8652 | Val Loss: 0.8576\n",
      "Epoch 09 | Train Loss: 0.8805 | Val Loss: 0.8567\n",
      "Epoch 10 | Train Loss: 0.8712 | Val Loss: 0.8562\n",
      "Epoch 11 | Train Loss: 0.8809 | Val Loss: 0.8554\n",
      "Epoch 12 | Train Loss: 0.8738 | Val Loss: 0.8551\n",
      "Epoch 13 | Train Loss: 0.8685 | Val Loss: 0.8549\n",
      "Epoch 14 | Train Loss: 0.8745 | Val Loss: 0.8535\n",
      "Epoch 15 | Train Loss: 0.8845 | Val Loss: 0.8524\n",
      "Epoch 16 | Train Loss: 0.8623 | Val Loss: 0.8524\n",
      "Epoch 17 | Train Loss: 0.8668 | Val Loss: 0.8523\n",
      "Epoch 18 | Train Loss: 0.8702 | Val Loss: 0.8506\n",
      "Epoch 19 | Train Loss: 0.8735 | Val Loss: 0.8492\n",
      "Epoch 20 | Train Loss: 0.8549 | Val Loss: 0.8498\n",
      "Epoch 21 | Train Loss: 0.8516 | Val Loss: 0.8472\n",
      "Epoch 22 | Train Loss: 0.8649 | Val Loss: 0.8464\n",
      "Epoch 23 | Train Loss: 0.8591 | Val Loss: 0.8470\n",
      "Epoch 24 | Train Loss: 0.8597 | Val Loss: 0.8448\n",
      "Epoch 25 | Train Loss: 0.8552 | Val Loss: 0.8434\n",
      "Epoch 26 | Train Loss: 0.8505 | Val Loss: 0.8424\n",
      "Epoch 27 | Train Loss: 0.8586 | Val Loss: 0.8407\n",
      "Epoch 28 | Train Loss: 0.8504 | Val Loss: 0.8427\n",
      "Epoch 29 | Train Loss: 0.8537 | Val Loss: 0.8390\n",
      "Epoch 30 | Train Loss: 0.8467 | Val Loss: 0.8392\n",
      "Epoch 31 | Train Loss: 0.8467 | Val Loss: 0.8366\n",
      "Epoch 32 | Train Loss: 0.8489 | Val Loss: 0.8351\n",
      "Epoch 33 | Train Loss: 0.8472 | Val Loss: 0.8337\n",
      "Epoch 34 | Train Loss: 0.8454 | Val Loss: 0.8329\n",
      "Epoch 35 | Train Loss: 0.8380 | Val Loss: 0.8316\n",
      "Epoch 36 | Train Loss: 0.8368 | Val Loss: 0.8300\n",
      "Epoch 37 | Train Loss: 0.8356 | Val Loss: 0.8276\n",
      "Epoch 38 | Train Loss: 0.8367 | Val Loss: 0.8262\n",
      "Epoch 39 | Train Loss: 0.8382 | Val Loss: 0.8239\n",
      "Epoch 40 | Train Loss: 0.8332 | Val Loss: 0.8233\n",
      "Epoch 41 | Train Loss: 0.8319 | Val Loss: 0.8203\n",
      "Epoch 42 | Train Loss: 0.8382 | Val Loss: 0.8195\n",
      "Epoch 43 | Train Loss: 0.8223 | Val Loss: 0.8182\n",
      "Epoch 44 | Train Loss: 0.8202 | Val Loss: 0.8149\n",
      "Epoch 45 | Train Loss: 0.8293 | Val Loss: 0.8123\n",
      "Epoch 46 | Train Loss: 0.8274 | Val Loss: 0.8103\n",
      "Epoch 47 | Train Loss: 0.8180 | Val Loss: 0.8075\n",
      "Epoch 48 | Train Loss: 0.8224 | Val Loss: 0.8056\n",
      "Epoch 49 | Train Loss: 0.8186 | Val Loss: 0.8025\n",
      "Epoch 50 | Train Loss: 0.8209 | Val Loss: 0.8004\n",
      "Fold 4 ‚ñ∂ AUC: 0.729, Balanced Acc: 0.426\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 1.1104 | Val Loss: 0.9892\n",
      "Epoch 02 | Train Loss: 0.9313 | Val Loss: 0.9124\n",
      "Epoch 03 | Train Loss: 0.8750 | Val Loss: 0.8989\n",
      "Epoch 04 | Train Loss: 0.8671 | Val Loss: 0.8996\n",
      "Epoch 05 | Train Loss: 0.8631 | Val Loss: 0.9002\n",
      "Epoch 06 | Train Loss: 0.8635 | Val Loss: 0.8999\n",
      "Epoch 07 | Train Loss: 0.8707 | Val Loss: 0.8998\n",
      "Epoch 08 | Train Loss: 0.8610 | Val Loss: 0.8979\n",
      "Epoch 09 | Train Loss: 0.8691 | Val Loss: 0.8960\n",
      "Epoch 10 | Train Loss: 0.8584 | Val Loss: 0.8942\n",
      "Epoch 11 | Train Loss: 0.8600 | Val Loss: 0.8938\n",
      "Epoch 12 | Train Loss: 0.8737 | Val Loss: 0.8939\n",
      "Epoch 13 | Train Loss: 0.8621 | Val Loss: 0.8912\n",
      "Epoch 14 | Train Loss: 0.8614 | Val Loss: 0.8899\n",
      "Epoch 15 | Train Loss: 0.8723 | Val Loss: 0.8895\n",
      "Epoch 16 | Train Loss: 0.8622 | Val Loss: 0.8889\n",
      "Epoch 17 | Train Loss: 0.8516 | Val Loss: 0.8907\n",
      "Epoch 18 | Train Loss: 0.8519 | Val Loss: 0.8860\n",
      "Epoch 19 | Train Loss: 0.8501 | Val Loss: 0.8869\n",
      "Epoch 20 | Train Loss: 0.8602 | Val Loss: 0.8849\n",
      "Epoch 21 | Train Loss: 0.8620 | Val Loss: 0.8860\n",
      "Epoch 22 | Train Loss: 0.8559 | Val Loss: 0.8810\n",
      "Epoch 23 | Train Loss: 0.8416 | Val Loss: 0.8806\n",
      "Epoch 24 | Train Loss: 0.8462 | Val Loss: 0.8800\n",
      "Epoch 25 | Train Loss: 0.8546 | Val Loss: 0.8792\n",
      "Epoch 26 | Train Loss: 0.8437 | Val Loss: 0.8770\n",
      "Epoch 27 | Train Loss: 0.8415 | Val Loss: 0.8765\n",
      "Epoch 28 | Train Loss: 0.8314 | Val Loss: 0.8758\n",
      "Epoch 29 | Train Loss: 0.8401 | Val Loss: 0.8741\n",
      "Epoch 30 | Train Loss: 0.8393 | Val Loss: 0.8722\n",
      "Epoch 31 | Train Loss: 0.8231 | Val Loss: 0.8706\n",
      "Epoch 32 | Train Loss: 0.8236 | Val Loss: 0.8686\n",
      "Epoch 33 | Train Loss: 0.8367 | Val Loss: 0.8690\n",
      "Epoch 34 | Train Loss: 0.8230 | Val Loss: 0.8654\n",
      "Epoch 35 | Train Loss: 0.8230 | Val Loss: 0.8623\n",
      "Epoch 36 | Train Loss: 0.8107 | Val Loss: 0.8632\n",
      "Epoch 37 | Train Loss: 0.8224 | Val Loss: 0.8628\n",
      "Epoch 38 | Train Loss: 0.8156 | Val Loss: 0.8563\n",
      "Epoch 39 | Train Loss: 0.8279 | Val Loss: 0.8563\n",
      "Epoch 40 | Train Loss: 0.8089 | Val Loss: 0.8521\n",
      "Epoch 41 | Train Loss: 0.8002 | Val Loss: 0.8508\n",
      "Epoch 42 | Train Loss: 0.8071 | Val Loss: 0.8480\n",
      "Epoch 43 | Train Loss: 0.7946 | Val Loss: 0.8465\n",
      "Epoch 44 | Train Loss: 0.8189 | Val Loss: 0.8465\n",
      "Epoch 45 | Train Loss: 0.7939 | Val Loss: 0.8415\n",
      "Epoch 46 | Train Loss: 0.7934 | Val Loss: 0.8397\n",
      "Epoch 47 | Train Loss: 0.7875 | Val Loss: 0.8375\n",
      "Epoch 48 | Train Loss: 0.7965 | Val Loss: 0.8366\n",
      "Epoch 49 | Train Loss: 0.7784 | Val Loss: 0.8361\n",
      "Epoch 50 | Train Loss: 0.7800 | Val Loss: 0.8333\n",
      "Fold 5 ‚ñ∂ AUC: 0.712, Balanced Acc: 0.386\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 1.2123 | Val Loss: 1.0921\n",
      "Epoch 02 | Train Loss: 1.0290 | Val Loss: 0.9718\n",
      "Epoch 03 | Train Loss: 0.9287 | Val Loss: 0.9227\n",
      "Epoch 04 | Train Loss: 0.9031 | Val Loss: 0.9051\n",
      "Epoch 05 | Train Loss: 0.8834 | Val Loss: 0.8980\n",
      "Epoch 06 | Train Loss: 0.8659 | Val Loss: 0.8963\n",
      "Epoch 07 | Train Loss: 0.8580 | Val Loss: 0.8965\n",
      "Epoch 08 | Train Loss: 0.8845 | Val Loss: 0.8969\n",
      "Epoch 09 | Train Loss: 0.8593 | Val Loss: 0.8944\n",
      "Epoch 10 | Train Loss: 0.8635 | Val Loss: 0.8947\n",
      "Epoch 11 | Train Loss: 0.8562 | Val Loss: 0.8937\n",
      "Epoch 12 | Train Loss: 0.8556 | Val Loss: 0.8943\n",
      "Epoch 13 | Train Loss: 0.8562 | Val Loss: 0.8926\n",
      "Epoch 14 | Train Loss: 0.8635 | Val Loss: 0.8926\n",
      "Epoch 15 | Train Loss: 0.8530 | Val Loss: 0.8918\n",
      "Epoch 16 | Train Loss: 0.8601 | Val Loss: 0.8907\n",
      "Epoch 17 | Train Loss: 0.8528 | Val Loss: 0.8908\n",
      "Epoch 18 | Train Loss: 0.8775 | Val Loss: 0.8896\n",
      "Epoch 19 | Train Loss: 0.8572 | Val Loss: 0.8871\n",
      "Epoch 20 | Train Loss: 0.8492 | Val Loss: 0.8867\n",
      "Epoch 21 | Train Loss: 0.8504 | Val Loss: 0.8872\n",
      "Epoch 22 | Train Loss: 0.8466 | Val Loss: 0.8878\n",
      "Epoch 23 | Train Loss: 0.8528 | Val Loss: 0.8864\n",
      "Epoch 24 | Train Loss: 0.8436 | Val Loss: 0.8851\n",
      "Epoch 25 | Train Loss: 0.8517 | Val Loss: 0.8843\n",
      "Epoch 26 | Train Loss: 0.8367 | Val Loss: 0.8833\n",
      "Epoch 27 | Train Loss: 0.8564 | Val Loss: 0.8840\n",
      "Epoch 28 | Train Loss: 0.8402 | Val Loss: 0.8816\n",
      "Epoch 29 | Train Loss: 0.8480 | Val Loss: 0.8806\n",
      "Epoch 30 | Train Loss: 0.8427 | Val Loss: 0.8790\n",
      "Epoch 31 | Train Loss: 0.8399 | Val Loss: 0.8793\n",
      "Epoch 32 | Train Loss: 0.8556 | Val Loss: 0.8776\n",
      "Epoch 33 | Train Loss: 0.8314 | Val Loss: 0.8766\n",
      "Epoch 34 | Train Loss: 0.8252 | Val Loss: 0.8753\n",
      "Epoch 35 | Train Loss: 0.8362 | Val Loss: 0.8752\n",
      "Epoch 36 | Train Loss: 0.8342 | Val Loss: 0.8741\n",
      "Epoch 37 | Train Loss: 0.8337 | Val Loss: 0.8719\n",
      "Epoch 38 | Train Loss: 0.8253 | Val Loss: 0.8705\n",
      "Epoch 39 | Train Loss: 0.8281 | Val Loss: 0.8692\n",
      "Epoch 40 | Train Loss: 0.8210 | Val Loss: 0.8684\n",
      "Epoch 41 | Train Loss: 0.8298 | Val Loss: 0.8672\n",
      "Epoch 42 | Train Loss: 0.8218 | Val Loss: 0.8657\n",
      "Epoch 43 | Train Loss: 0.8170 | Val Loss: 0.8649\n",
      "Epoch 44 | Train Loss: 0.8257 | Val Loss: 0.8645\n",
      "Epoch 45 | Train Loss: 0.8130 | Val Loss: 0.8612\n",
      "Epoch 46 | Train Loss: 0.8086 | Val Loss: 0.8621\n",
      "Epoch 47 | Train Loss: 0.8069 | Val Loss: 0.8594\n",
      "Epoch 48 | Train Loss: 0.8108 | Val Loss: 0.8591\n",
      "Epoch 49 | Train Loss: 0.8053 | Val Loss: 0.8580\n",
      "Epoch 50 | Train Loss: 0.8081 | Val Loss: 0.8567\n",
      "Fold 6 ‚ñ∂ AUC: 0.677, Balanced Acc: 0.430\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9255 | Val Loss: 0.8888\n",
      "Epoch 02 | Train Loss: 0.8796 | Val Loss: 0.8653\n",
      "Epoch 03 | Train Loss: 0.8695 | Val Loss: 0.8615\n",
      "Epoch 04 | Train Loss: 0.8652 | Val Loss: 0.8601\n",
      "Epoch 05 | Train Loss: 0.8684 | Val Loss: 0.8602\n",
      "Epoch 06 | Train Loss: 0.8677 | Val Loss: 0.8587\n",
      "Epoch 07 | Train Loss: 0.8656 | Val Loss: 0.8581\n",
      "Epoch 08 | Train Loss: 0.8623 | Val Loss: 0.8575\n",
      "Epoch 09 | Train Loss: 0.8624 | Val Loss: 0.8559\n",
      "Epoch 10 | Train Loss: 0.8580 | Val Loss: 0.8552\n",
      "Epoch 11 | Train Loss: 0.8571 | Val Loss: 0.8546\n",
      "Epoch 12 | Train Loss: 0.8684 | Val Loss: 0.8544\n",
      "Epoch 13 | Train Loss: 0.8586 | Val Loss: 0.8523\n",
      "Epoch 14 | Train Loss: 0.8598 | Val Loss: 0.8509\n",
      "Epoch 15 | Train Loss: 0.8604 | Val Loss: 0.8509\n",
      "Epoch 16 | Train Loss: 0.8549 | Val Loss: 0.8488\n",
      "Epoch 17 | Train Loss: 0.8629 | Val Loss: 0.8470\n",
      "Epoch 18 | Train Loss: 0.8454 | Val Loss: 0.8471\n",
      "Epoch 19 | Train Loss: 0.8487 | Val Loss: 0.8436\n",
      "Epoch 20 | Train Loss: 0.8522 | Val Loss: 0.8429\n",
      "Epoch 21 | Train Loss: 0.8376 | Val Loss: 0.8416\n",
      "Epoch 22 | Train Loss: 0.8366 | Val Loss: 0.8379\n",
      "Epoch 23 | Train Loss: 0.8502 | Val Loss: 0.8357\n",
      "Epoch 24 | Train Loss: 0.8334 | Val Loss: 0.8339\n",
      "Epoch 25 | Train Loss: 0.8510 | Val Loss: 0.8312\n",
      "Epoch 26 | Train Loss: 0.8341 | Val Loss: 0.8311\n",
      "Epoch 27 | Train Loss: 0.8490 | Val Loss: 0.8294\n",
      "Epoch 28 | Train Loss: 0.8314 | Val Loss: 0.8283\n",
      "Epoch 29 | Train Loss: 0.8254 | Val Loss: 0.8243\n",
      "Epoch 30 | Train Loss: 0.8180 | Val Loss: 0.8205\n",
      "Epoch 31 | Train Loss: 0.8135 | Val Loss: 0.8161\n",
      "Epoch 32 | Train Loss: 0.8149 | Val Loss: 0.8125\n",
      "Epoch 33 | Train Loss: 0.8149 | Val Loss: 0.8090\n",
      "Epoch 34 | Train Loss: 0.8100 | Val Loss: 0.8056\n",
      "Epoch 35 | Train Loss: 0.8014 | Val Loss: 0.8025\n",
      "Epoch 36 | Train Loss: 0.8071 | Val Loss: 0.8034\n",
      "Epoch 37 | Train Loss: 0.8015 | Val Loss: 0.7983\n",
      "Epoch 38 | Train Loss: 0.8123 | Val Loss: 0.7981\n",
      "Epoch 39 | Train Loss: 0.7976 | Val Loss: 0.7902\n",
      "Epoch 40 | Train Loss: 0.8020 | Val Loss: 0.7921\n",
      "Epoch 41 | Train Loss: 0.7894 | Val Loss: 0.7869\n",
      "Epoch 42 | Train Loss: 0.7841 | Val Loss: 0.7846\n",
      "Epoch 43 | Train Loss: 0.7788 | Val Loss: 0.7778\n",
      "Epoch 44 | Train Loss: 0.7752 | Val Loss: 0.7799\n",
      "Epoch 45 | Train Loss: 0.7863 | Val Loss: 0.7742\n",
      "Epoch 46 | Train Loss: 0.7773 | Val Loss: 0.7719\n",
      "Epoch 47 | Train Loss: 0.7675 | Val Loss: 0.7720\n",
      "Epoch 48 | Train Loss: 0.7814 | Val Loss: 0.7664\n",
      "Epoch 49 | Train Loss: 0.7688 | Val Loss: 0.7618\n",
      "Epoch 50 | Train Loss: 0.7665 | Val Loss: 0.7584\n",
      "Fold 7 ‚ñ∂ AUC: 0.759, Balanced Acc: 0.456\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 1.0184 | Val Loss: 0.9383\n",
      "Epoch 02 | Train Loss: 0.9151 | Val Loss: 0.8793\n",
      "Epoch 03 | Train Loss: 0.8854 | Val Loss: 0.8687\n",
      "Epoch 04 | Train Loss: 0.8645 | Val Loss: 0.8650\n",
      "Epoch 05 | Train Loss: 0.8593 | Val Loss: 0.8633\n",
      "Epoch 06 | Train Loss: 0.8669 | Val Loss: 0.8638\n",
      "Epoch 07 | Train Loss: 0.8567 | Val Loss: 0.8613\n",
      "Epoch 08 | Train Loss: 0.8672 | Val Loss: 0.8603\n",
      "Epoch 09 | Train Loss: 0.8619 | Val Loss: 0.8599\n",
      "Epoch 10 | Train Loss: 0.8711 | Val Loss: 0.8591\n",
      "Epoch 11 | Train Loss: 0.8555 | Val Loss: 0.8590\n",
      "Epoch 12 | Train Loss: 0.8613 | Val Loss: 0.8585\n",
      "Epoch 13 | Train Loss: 0.8589 | Val Loss: 0.8575\n",
      "Epoch 14 | Train Loss: 0.8572 | Val Loss: 0.8568\n",
      "Epoch 15 | Train Loss: 0.8581 | Val Loss: 0.8570\n",
      "Epoch 16 | Train Loss: 0.8525 | Val Loss: 0.8557\n",
      "Epoch 17 | Train Loss: 0.8524 | Val Loss: 0.8546\n",
      "Epoch 18 | Train Loss: 0.8530 | Val Loss: 0.8532\n",
      "Epoch 19 | Train Loss: 0.8481 | Val Loss: 0.8533\n",
      "Epoch 20 | Train Loss: 0.8582 | Val Loss: 0.8518\n",
      "Epoch 21 | Train Loss: 0.8524 | Val Loss: 0.8503\n",
      "Epoch 22 | Train Loss: 0.8544 | Val Loss: 0.8490\n",
      "Epoch 23 | Train Loss: 0.8533 | Val Loss: 0.8480\n",
      "Epoch 24 | Train Loss: 0.8439 | Val Loss: 0.8476\n",
      "Epoch 25 | Train Loss: 0.8474 | Val Loss: 0.8452\n",
      "Epoch 26 | Train Loss: 0.8506 | Val Loss: 0.8433\n",
      "Epoch 27 | Train Loss: 0.8423 | Val Loss: 0.8409\n",
      "Epoch 28 | Train Loss: 0.8406 | Val Loss: 0.8397\n",
      "Epoch 29 | Train Loss: 0.8283 | Val Loss: 0.8362\n",
      "Epoch 30 | Train Loss: 0.8226 | Val Loss: 0.8340\n",
      "Epoch 31 | Train Loss: 0.8348 | Val Loss: 0.8314\n",
      "Epoch 32 | Train Loss: 0.8310 | Val Loss: 0.8302\n",
      "Epoch 33 | Train Loss: 0.8233 | Val Loss: 0.8281\n",
      "Epoch 34 | Train Loss: 0.8335 | Val Loss: 0.8279\n",
      "Epoch 35 | Train Loss: 0.8367 | Val Loss: 0.8252\n",
      "Epoch 36 | Train Loss: 0.8267 | Val Loss: 0.8233\n",
      "Epoch 37 | Train Loss: 0.8186 | Val Loss: 0.8218\n",
      "Epoch 38 | Train Loss: 0.8153 | Val Loss: 0.8183\n",
      "Epoch 39 | Train Loss: 0.8262 | Val Loss: 0.8167\n",
      "Epoch 40 | Train Loss: 0.8108 | Val Loss: 0.8137\n",
      "Epoch 41 | Train Loss: 0.8137 | Val Loss: 0.8115\n",
      "Epoch 42 | Train Loss: 0.8039 | Val Loss: 0.8098\n",
      "Epoch 43 | Train Loss: 0.8079 | Val Loss: 0.8073\n",
      "Epoch 44 | Train Loss: 0.8211 | Val Loss: 0.8069\n",
      "Epoch 45 | Train Loss: 0.8122 | Val Loss: 0.8047\n",
      "Epoch 46 | Train Loss: 0.8009 | Val Loss: 0.8022\n",
      "Epoch 47 | Train Loss: 0.7962 | Val Loss: 0.8010\n",
      "Epoch 48 | Train Loss: 0.7997 | Val Loss: 0.8003\n",
      "Epoch 49 | Train Loss: 0.7836 | Val Loss: 0.7971\n",
      "Epoch 50 | Train Loss: 0.7876 | Val Loss: 0.7952\n",
      "Fold 8 ‚ñ∂ AUC: 0.702, Balanced Acc: 0.416\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 1.2514 | Val Loss: 1.1068\n",
      "Epoch 02 | Train Loss: 1.0308 | Val Loss: 0.9621\n",
      "Epoch 03 | Train Loss: 0.9204 | Val Loss: 0.9033\n",
      "Epoch 04 | Train Loss: 0.8830 | Val Loss: 0.8802\n",
      "Epoch 05 | Train Loss: 0.8715 | Val Loss: 0.8738\n",
      "Epoch 06 | Train Loss: 0.8596 | Val Loss: 0.8724\n",
      "Epoch 07 | Train Loss: 0.8718 | Val Loss: 0.8713\n",
      "Epoch 08 | Train Loss: 0.8889 | Val Loss: 0.8731\n",
      "Epoch 09 | Train Loss: 0.8635 | Val Loss: 0.8702\n",
      "Epoch 10 | Train Loss: 0.8620 | Val Loss: 0.8703\n",
      "Epoch 11 | Train Loss: 0.8624 | Val Loss: 0.8700\n",
      "Epoch 12 | Train Loss: 0.8570 | Val Loss: 0.8681\n",
      "Epoch 13 | Train Loss: 0.8587 | Val Loss: 0.8678\n",
      "Epoch 14 | Train Loss: 0.8531 | Val Loss: 0.8669\n",
      "Epoch 15 | Train Loss: 0.8514 | Val Loss: 0.8662\n",
      "Epoch 16 | Train Loss: 0.8739 | Val Loss: 0.8658\n",
      "Epoch 17 | Train Loss: 0.8633 | Val Loss: 0.8661\n",
      "Epoch 18 | Train Loss: 0.8548 | Val Loss: 0.8648\n",
      "Epoch 19 | Train Loss: 0.8582 | Val Loss: 0.8635\n",
      "Epoch 20 | Train Loss: 0.8510 | Val Loss: 0.8634\n",
      "Epoch 21 | Train Loss: 0.8603 | Val Loss: 0.8616\n",
      "Epoch 22 | Train Loss: 0.8563 | Val Loss: 0.8612\n",
      "Epoch 23 | Train Loss: 0.8527 | Val Loss: 0.8615\n",
      "Epoch 24 | Train Loss: 0.8520 | Val Loss: 0.8595\n",
      "Epoch 25 | Train Loss: 0.8390 | Val Loss: 0.8590\n",
      "Epoch 26 | Train Loss: 0.8428 | Val Loss: 0.8577\n",
      "Epoch 27 | Train Loss: 0.8402 | Val Loss: 0.8567\n",
      "Epoch 28 | Train Loss: 0.8364 | Val Loss: 0.8552\n",
      "Epoch 29 | Train Loss: 0.8309 | Val Loss: 0.8544\n",
      "Epoch 30 | Train Loss: 0.8324 | Val Loss: 0.8532\n",
      "Epoch 31 | Train Loss: 0.8375 | Val Loss: 0.8518\n",
      "Epoch 32 | Train Loss: 0.8418 | Val Loss: 0.8505\n",
      "Epoch 33 | Train Loss: 0.8244 | Val Loss: 0.8496\n",
      "Epoch 34 | Train Loss: 0.8380 | Val Loss: 0.8482\n",
      "Epoch 35 | Train Loss: 0.8319 | Val Loss: 0.8481\n",
      "Epoch 36 | Train Loss: 0.8164 | Val Loss: 0.8465\n",
      "Epoch 37 | Train Loss: 0.8228 | Val Loss: 0.8498\n",
      "Epoch 38 | Train Loss: 0.8149 | Val Loss: 0.8439\n",
      "Epoch 39 | Train Loss: 0.8262 | Val Loss: 0.8422\n",
      "Epoch 40 | Train Loss: 0.8197 | Val Loss: 0.8404\n",
      "Epoch 41 | Train Loss: 0.8087 | Val Loss: 0.8396\n",
      "Epoch 42 | Train Loss: 0.8083 | Val Loss: 0.8380\n",
      "Epoch 43 | Train Loss: 0.8197 | Val Loss: 0.8370\n",
      "Epoch 44 | Train Loss: 0.8113 | Val Loss: 0.8353\n",
      "Epoch 45 | Train Loss: 0.8064 | Val Loss: 0.8345\n",
      "Epoch 46 | Train Loss: 0.8010 | Val Loss: 0.8324\n",
      "Epoch 47 | Train Loss: 0.7988 | Val Loss: 0.8331\n",
      "Epoch 48 | Train Loss: 0.8045 | Val Loss: 0.8324\n",
      "Epoch 49 | Train Loss: 0.7972 | Val Loss: 0.8290\n",
      "Epoch 50 | Train Loss: 0.8029 | Val Loss: 0.8360\n",
      "Fold 9 ‚ñ∂ AUC: 0.665, Balanced Acc: 0.420\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 1.1490 | Val Loss: 1.0373\n",
      "Epoch 02 | Train Loss: 0.9703 | Val Loss: 0.9252\n",
      "Epoch 03 | Train Loss: 0.9155 | Val Loss: 0.8858\n",
      "Epoch 04 | Train Loss: 0.8754 | Val Loss: 0.8702\n",
      "Epoch 05 | Train Loss: 0.8611 | Val Loss: 0.8662\n",
      "Epoch 06 | Train Loss: 0.8599 | Val Loss: 0.8639\n",
      "Epoch 07 | Train Loss: 0.8572 | Val Loss: 0.8638\n",
      "Epoch 08 | Train Loss: 0.8539 | Val Loss: 0.8616\n",
      "Epoch 09 | Train Loss: 0.8513 | Val Loss: 0.8599\n",
      "Epoch 10 | Train Loss: 0.8525 | Val Loss: 0.8612\n",
      "Epoch 11 | Train Loss: 0.8624 | Val Loss: 0.8592\n",
      "Epoch 12 | Train Loss: 0.8583 | Val Loss: 0.8589\n",
      "Epoch 13 | Train Loss: 0.8544 | Val Loss: 0.8569\n",
      "Epoch 14 | Train Loss: 0.8482 | Val Loss: 0.8561\n",
      "Epoch 15 | Train Loss: 0.8476 | Val Loss: 0.8565\n",
      "Epoch 16 | Train Loss: 0.8524 | Val Loss: 0.8550\n",
      "Epoch 17 | Train Loss: 0.8566 | Val Loss: 0.8547\n",
      "Epoch 18 | Train Loss: 0.8473 | Val Loss: 0.8526\n",
      "Epoch 19 | Train Loss: 0.8441 | Val Loss: 0.8539\n",
      "Epoch 20 | Train Loss: 0.8393 | Val Loss: 0.8525\n",
      "Epoch 21 | Train Loss: 0.8564 | Val Loss: 0.8523\n",
      "Epoch 22 | Train Loss: 0.8495 | Val Loss: 0.8493\n",
      "Epoch 23 | Train Loss: 0.8467 | Val Loss: 0.8502\n",
      "Epoch 24 | Train Loss: 0.8451 | Val Loss: 0.8475\n",
      "Epoch 25 | Train Loss: 0.8438 | Val Loss: 0.8484\n",
      "Epoch 26 | Train Loss: 0.8431 | Val Loss: 0.8454\n",
      "Epoch 27 | Train Loss: 0.8421 | Val Loss: 0.8447\n",
      "Epoch 28 | Train Loss: 0.8383 | Val Loss: 0.8435\n",
      "Epoch 29 | Train Loss: 0.8395 | Val Loss: 0.8426\n",
      "Epoch 30 | Train Loss: 0.8523 | Val Loss: 0.8446\n",
      "Epoch 31 | Train Loss: 0.8428 | Val Loss: 0.8398\n",
      "Epoch 32 | Train Loss: 0.8429 | Val Loss: 0.8402\n",
      "Epoch 33 | Train Loss: 0.8304 | Val Loss: 0.8389\n",
      "Epoch 34 | Train Loss: 0.8290 | Val Loss: 0.8406\n",
      "Epoch 35 | Train Loss: 0.8392 | Val Loss: 0.8348\n",
      "Epoch 36 | Train Loss: 0.8433 | Val Loss: 0.8358\n",
      "Epoch 37 | Train Loss: 0.8413 | Val Loss: 0.8341\n",
      "Epoch 38 | Train Loss: 0.8365 | Val Loss: 0.8319\n",
      "Epoch 39 | Train Loss: 0.8261 | Val Loss: 0.8329\n",
      "Epoch 40 | Train Loss: 0.8269 | Val Loss: 0.8290\n",
      "Epoch 41 | Train Loss: 0.8397 | Val Loss: 0.8279\n",
      "Epoch 42 | Train Loss: 0.8304 | Val Loss: 0.8271\n",
      "Epoch 43 | Train Loss: 0.8326 | Val Loss: 0.8237\n",
      "Epoch 44 | Train Loss: 0.8194 | Val Loss: 0.8230\n",
      "Epoch 45 | Train Loss: 0.8223 | Val Loss: 0.8217\n",
      "Epoch 46 | Train Loss: 0.8252 | Val Loss: 0.8210\n",
      "Epoch 47 | Train Loss: 0.8151 | Val Loss: 0.8210\n",
      "Epoch 48 | Train Loss: 0.8258 | Val Loss: 0.8168\n",
      "Epoch 49 | Train Loss: 0.8123 | Val Loss: 0.8194\n",
      "Epoch 50 | Train Loss: 0.8134 | Val Loss: 0.8140\n",
      "Fold 10 ‚ñ∂ AUC: 0.749, Balanced Acc: 0.404\n",
      "üîç Summary for hd=64, dp=0.0, lr=0.0001 ‚Üí AUC: 0.7068¬±0.0487 | BalAcc: 0.4399¬±0.0410\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.2, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9539 | Val Loss: 0.8760\n",
      "Epoch 02 | Train Loss: 0.8681 | Val Loss: 0.8672\n",
      "Epoch 03 | Train Loss: 0.8655 | Val Loss: 0.8603\n",
      "Epoch 04 | Train Loss: 0.8706 | Val Loss: 0.8589\n",
      "Epoch 05 | Train Loss: 0.8655 | Val Loss: 0.8535\n",
      "Epoch 06 | Train Loss: 0.8634 | Val Loss: 0.8536\n",
      "Epoch 07 | Train Loss: 0.8567 | Val Loss: 0.8543\n",
      "Epoch 08 | Train Loss: 0.8621 | Val Loss: 0.8441\n",
      "Epoch 09 | Train Loss: 0.8598 | Val Loss: 0.8225\n",
      "Epoch 10 | Train Loss: 0.8445 | Val Loss: 0.8907\n",
      "Epoch 11 | Train Loss: 0.8652 | Val Loss: 0.8489\n",
      "Epoch 12 | Train Loss: 0.8505 | Val Loss: 0.8281\n",
      "Epoch 13 | Train Loss: 0.8205 | Val Loss: 0.7891\n",
      "Epoch 14 | Train Loss: 0.7806 | Val Loss: 0.7644\n",
      "Epoch 15 | Train Loss: 0.7700 | Val Loss: 0.7769\n",
      "Epoch 16 | Train Loss: 0.7749 | Val Loss: 0.7417\n",
      "Epoch 17 | Train Loss: 0.7697 | Val Loss: 0.7428\n",
      "Epoch 18 | Train Loss: 0.7706 | Val Loss: 0.7464\n",
      "Epoch 19 | Train Loss: 0.7776 | Val Loss: 0.7286\n",
      "Epoch 20 | Train Loss: 0.7659 | Val Loss: 0.7273\n",
      "Epoch 21 | Train Loss: 0.7640 | Val Loss: 0.7162\n",
      "Epoch 22 | Train Loss: 0.7791 | Val Loss: 0.7372\n",
      "Epoch 23 | Train Loss: 0.7571 | Val Loss: 0.7132\n",
      "Epoch 24 | Train Loss: 0.7550 | Val Loss: 0.7507\n",
      "Epoch 25 | Train Loss: 0.7453 | Val Loss: 0.7065\n",
      "Epoch 26 | Train Loss: 0.7491 | Val Loss: 0.6988\n",
      "Epoch 27 | Train Loss: 0.7371 | Val Loss: 0.7001\n",
      "Epoch 28 | Train Loss: 0.7458 | Val Loss: 0.6933\n",
      "Epoch 29 | Train Loss: 0.7530 | Val Loss: 0.7044\n",
      "Epoch 30 | Train Loss: 0.7659 | Val Loss: 0.7273\n",
      "Epoch 31 | Train Loss: 0.7582 | Val Loss: 0.6954\n",
      "Epoch 32 | Train Loss: 0.7512 | Val Loss: 0.7080\n",
      "Epoch 33 | Train Loss: 0.7419 | Val Loss: 0.7015\n",
      "Epoch 34 | Train Loss: 0.7479 | Val Loss: 0.6918\n",
      "Epoch 35 | Train Loss: 0.7391 | Val Loss: 0.6875\n",
      "Epoch 36 | Train Loss: 0.7273 | Val Loss: 0.6851\n",
      "Epoch 37 | Train Loss: 0.7468 | Val Loss: 0.6833\n",
      "Epoch 38 | Train Loss: 0.7285 | Val Loss: 0.6869\n",
      "Epoch 39 | Train Loss: 0.7462 | Val Loss: 0.6866\n",
      "Epoch 40 | Train Loss: 0.7336 | Val Loss: 0.7369\n",
      "Epoch 41 | Train Loss: 0.7562 | Val Loss: 0.6845\n",
      "Epoch 42 | Train Loss: 0.7324 | Val Loss: 0.6868\n",
      "Epoch 43 | Train Loss: 0.7238 | Val Loss: 0.6896\n",
      "Epoch 44 | Train Loss: 0.7452 | Val Loss: 0.7199\n",
      "Epoch 45 | Train Loss: 0.7638 | Val Loss: 0.6872\n",
      "Epoch 46 | Train Loss: 0.7203 | Val Loss: 0.6887\n",
      "Epoch 47 | Train Loss: 0.7465 | Val Loss: 0.6799\n",
      "Epoch 48 | Train Loss: 0.7418 | Val Loss: 0.6958\n",
      "Epoch 49 | Train Loss: 0.7321 | Val Loss: 0.6942\n",
      "Epoch 50 | Train Loss: 0.7106 | Val Loss: 0.6891\n",
      "Fold 1 ‚ñ∂ AUC: 0.790, Balanced Acc: 0.510\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9408 | Val Loss: 0.8646\n",
      "Epoch 02 | Train Loss: 0.8805 | Val Loss: 0.8609\n",
      "Epoch 03 | Train Loss: 0.8714 | Val Loss: 0.8572\n",
      "Epoch 04 | Train Loss: 0.8693 | Val Loss: 0.8544\n",
      "Epoch 05 | Train Loss: 0.8783 | Val Loss: 0.8551\n",
      "Epoch 06 | Train Loss: 0.8700 | Val Loss: 0.8441\n",
      "Epoch 07 | Train Loss: 0.8436 | Val Loss: 0.8334\n",
      "Epoch 08 | Train Loss: 0.8404 | Val Loss: 0.8164\n",
      "Epoch 09 | Train Loss: 0.8040 | Val Loss: 0.8115\n",
      "Epoch 10 | Train Loss: 0.8095 | Val Loss: 0.7824\n",
      "Epoch 11 | Train Loss: 0.7980 | Val Loss: 0.8119\n",
      "Epoch 12 | Train Loss: 0.7767 | Val Loss: 0.7767\n",
      "Epoch 13 | Train Loss: 0.7825 | Val Loss: 0.7524\n",
      "Epoch 14 | Train Loss: 0.7521 | Val Loss: 0.7631\n",
      "Epoch 15 | Train Loss: 0.7636 | Val Loss: 0.7646\n",
      "Epoch 16 | Train Loss: 0.7733 | Val Loss: 0.7396\n",
      "Epoch 17 | Train Loss: 0.7595 | Val Loss: 0.8217\n",
      "Epoch 18 | Train Loss: 0.8244 | Val Loss: 0.7481\n",
      "Epoch 19 | Train Loss: 0.7872 | Val Loss: 0.7591\n",
      "Epoch 20 | Train Loss: 0.7672 | Val Loss: 0.7777\n",
      "Epoch 21 | Train Loss: 0.7618 | Val Loss: 0.7483\n",
      "Epoch 22 | Train Loss: 0.7624 | Val Loss: 0.7924\n",
      "Epoch 23 | Train Loss: 0.7649 | Val Loss: 0.7943\n",
      "Epoch 24 | Train Loss: 0.7623 | Val Loss: 0.7606\n",
      "Epoch 25 | Train Loss: 0.7514 | Val Loss: 0.7372\n",
      "Epoch 26 | Train Loss: 0.7500 | Val Loss: 0.7497\n",
      "Epoch 27 | Train Loss: 0.7428 | Val Loss: 0.8027\n",
      "Epoch 28 | Train Loss: 0.7397 | Val Loss: 0.7314\n",
      "Epoch 29 | Train Loss: 0.7552 | Val Loss: 0.7438\n",
      "Epoch 30 | Train Loss: 0.7353 | Val Loss: 0.7399\n",
      "Epoch 31 | Train Loss: 0.7554 | Val Loss: 0.7283\n",
      "Epoch 32 | Train Loss: 0.7863 | Val Loss: 0.7851\n",
      "Epoch 33 | Train Loss: 0.7408 | Val Loss: 0.7692\n",
      "Epoch 34 | Train Loss: 0.7392 | Val Loss: 0.7366\n",
      "Epoch 35 | Train Loss: 0.7584 | Val Loss: 0.7662\n",
      "Epoch 36 | Train Loss: 0.7424 | Val Loss: 0.7927\n",
      "Epoch 37 | Train Loss: 0.7530 | Val Loss: 0.7371\n",
      "Epoch 38 | Train Loss: 0.7434 | Val Loss: 0.7184\n",
      "Epoch 39 | Train Loss: 0.7147 | Val Loss: 0.7968\n",
      "Epoch 40 | Train Loss: 0.7439 | Val Loss: 0.7171\n",
      "Epoch 41 | Train Loss: 0.7272 | Val Loss: 0.7589\n",
      "Epoch 42 | Train Loss: 0.7342 | Val Loss: 0.7496\n",
      "Epoch 43 | Train Loss: 0.7228 | Val Loss: 0.7115\n",
      "Epoch 44 | Train Loss: 0.7587 | Val Loss: 0.7767\n",
      "Epoch 45 | Train Loss: 0.7382 | Val Loss: 0.7498\n",
      "Epoch 46 | Train Loss: 0.7584 | Val Loss: 0.7351\n",
      "Epoch 47 | Train Loss: 0.7184 | Val Loss: 0.7463\n",
      "Epoch 48 | Train Loss: 0.7159 | Val Loss: 0.7295\n",
      "Epoch 49 | Train Loss: 0.7340 | Val Loss: 0.7089\n",
      "Epoch 50 | Train Loss: 0.7185 | Val Loss: 0.7793\n",
      "Fold 2 ‚ñ∂ AUC: 0.682, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9490 | Val Loss: 0.8973\n",
      "Epoch 02 | Train Loss: 0.8890 | Val Loss: 0.8715\n",
      "Epoch 03 | Train Loss: 0.8939 | Val Loss: 0.8585\n",
      "Epoch 04 | Train Loss: 0.8700 | Val Loss: 0.8630\n",
      "Epoch 05 | Train Loss: 0.8691 | Val Loss: 0.8487\n",
      "Epoch 06 | Train Loss: 0.8573 | Val Loss: 0.8348\n",
      "Epoch 07 | Train Loss: 0.8458 | Val Loss: 0.8206\n",
      "Epoch 08 | Train Loss: 0.8427 | Val Loss: 0.8547\n",
      "Epoch 09 | Train Loss: 0.8402 | Val Loss: 0.7790\n",
      "Epoch 10 | Train Loss: 0.8037 | Val Loss: 0.7593\n",
      "Epoch 11 | Train Loss: 0.8356 | Val Loss: 0.7551\n",
      "Epoch 12 | Train Loss: 0.7874 | Val Loss: 0.7875\n",
      "Epoch 13 | Train Loss: 0.7608 | Val Loss: 0.7499\n",
      "Epoch 14 | Train Loss: 0.7885 | Val Loss: 0.7535\n",
      "Epoch 15 | Train Loss: 0.7679 | Val Loss: 0.7511\n",
      "Epoch 16 | Train Loss: 0.7553 | Val Loss: 0.7308\n",
      "Epoch 17 | Train Loss: 0.7368 | Val Loss: 0.7345\n",
      "Epoch 18 | Train Loss: 0.7560 | Val Loss: 0.7266\n",
      "Epoch 19 | Train Loss: 0.7469 | Val Loss: 0.7541\n",
      "Epoch 20 | Train Loss: 0.7684 | Val Loss: 0.8014\n",
      "Epoch 21 | Train Loss: 0.7723 | Val Loss: 0.7913\n",
      "Epoch 22 | Train Loss: 0.7758 | Val Loss: 0.7371\n",
      "Epoch 23 | Train Loss: 0.7366 | Val Loss: 0.7365\n",
      "Epoch 24 | Train Loss: 0.7415 | Val Loss: 0.7304\n",
      "Epoch 25 | Train Loss: 0.7225 | Val Loss: 0.7447\n",
      "Epoch 26 | Train Loss: 0.7344 | Val Loss: 0.7580\n",
      "Epoch 27 | Train Loss: 0.7512 | Val Loss: 0.7208\n",
      "Epoch 28 | Train Loss: 0.7476 | Val Loss: 0.7257\n",
      "Epoch 29 | Train Loss: 0.7376 | Val Loss: 0.7346\n",
      "Epoch 30 | Train Loss: 0.7314 | Val Loss: 0.7150\n",
      "Epoch 31 | Train Loss: 0.7667 | Val Loss: 0.7195\n",
      "Epoch 32 | Train Loss: 0.7287 | Val Loss: 0.7173\n",
      "Epoch 33 | Train Loss: 0.7503 | Val Loss: 0.7418\n",
      "Epoch 34 | Train Loss: 0.7170 | Val Loss: 0.7239\n",
      "Epoch 35 | Train Loss: 0.7375 | Val Loss: 0.7240\n",
      "Epoch 36 | Train Loss: 0.7314 | Val Loss: 0.7368\n",
      "Epoch 37 | Train Loss: 0.7159 | Val Loss: 0.7176\n",
      "Epoch 38 | Train Loss: 0.7362 | Val Loss: 0.7106\n",
      "Epoch 39 | Train Loss: 0.7364 | Val Loss: 0.7502\n",
      "Epoch 40 | Train Loss: 0.7405 | Val Loss: 0.7140\n",
      "Epoch 41 | Train Loss: 0.7300 | Val Loss: 0.7144\n",
      "Epoch 42 | Train Loss: 0.7280 | Val Loss: 0.7182\n",
      "Epoch 43 | Train Loss: 0.7372 | Val Loss: 0.7133\n",
      "Epoch 44 | Train Loss: 0.7195 | Val Loss: 0.7129\n",
      "Epoch 45 | Train Loss: 0.7189 | Val Loss: 0.7153\n",
      "Epoch 46 | Train Loss: 0.7313 | Val Loss: 0.7126\n",
      "Epoch 47 | Train Loss: 0.7278 | Val Loss: 0.7323\n",
      "Epoch 48 | Train Loss: 0.7446 | Val Loss: 0.7245\n",
      "Epoch 49 | Train Loss: 0.7289 | Val Loss: 0.7157\n",
      "Epoch 50 | Train Loss: 0.7144 | Val Loss: 0.7125\n",
      "Fold 3 ‚ñ∂ AUC: 0.770, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9081 | Val Loss: 0.8687\n",
      "Epoch 02 | Train Loss: 0.8735 | Val Loss: 0.8601\n",
      "Epoch 03 | Train Loss: 0.8819 | Val Loss: 0.8632\n",
      "Epoch 04 | Train Loss: 0.8537 | Val Loss: 0.8560\n",
      "Epoch 05 | Train Loss: 0.8663 | Val Loss: 0.8316\n",
      "Epoch 06 | Train Loss: 0.8442 | Val Loss: 0.8407\n",
      "Epoch 07 | Train Loss: 0.8424 | Val Loss: 0.8043\n",
      "Epoch 08 | Train Loss: 0.8120 | Val Loss: 0.8266\n",
      "Epoch 09 | Train Loss: 0.8226 | Val Loss: 0.7922\n",
      "Epoch 10 | Train Loss: 0.8007 | Val Loss: 0.7477\n",
      "Epoch 11 | Train Loss: 0.7775 | Val Loss: 0.7922\n",
      "Epoch 12 | Train Loss: 0.7798 | Val Loss: 0.7216\n",
      "Epoch 13 | Train Loss: 0.7939 | Val Loss: 0.7334\n",
      "Epoch 14 | Train Loss: 0.7821 | Val Loss: 0.7312\n",
      "Epoch 15 | Train Loss: 0.7643 | Val Loss: 0.7046\n",
      "Epoch 16 | Train Loss: 0.7974 | Val Loss: 0.7029\n",
      "Epoch 17 | Train Loss: 0.7900 | Val Loss: 0.7023\n",
      "Epoch 18 | Train Loss: 0.7720 | Val Loss: 0.7081\n",
      "Epoch 19 | Train Loss: 0.7527 | Val Loss: 0.6980\n",
      "Epoch 20 | Train Loss: 0.7776 | Val Loss: 0.7002\n",
      "Epoch 21 | Train Loss: 0.7652 | Val Loss: 0.7050\n",
      "Epoch 22 | Train Loss: 0.7539 | Val Loss: 0.6985\n",
      "Epoch 23 | Train Loss: 0.7773 | Val Loss: 0.6982\n",
      "Epoch 24 | Train Loss: 0.7415 | Val Loss: 0.6828\n",
      "Epoch 25 | Train Loss: 0.7781 | Val Loss: 0.6875\n",
      "Epoch 26 | Train Loss: 0.7459 | Val Loss: 0.6884\n",
      "Epoch 27 | Train Loss: 0.7569 | Val Loss: 0.6844\n",
      "Epoch 28 | Train Loss: 0.7481 | Val Loss: 0.6793\n",
      "Epoch 29 | Train Loss: 0.7664 | Val Loss: 0.6746\n",
      "Epoch 30 | Train Loss: 0.7517 | Val Loss: 0.6820\n",
      "Epoch 31 | Train Loss: 0.7703 | Val Loss: 0.6772\n",
      "Epoch 32 | Train Loss: 0.7552 | Val Loss: 0.6892\n",
      "Epoch 33 | Train Loss: 0.7425 | Val Loss: 0.7094\n",
      "Epoch 34 | Train Loss: 0.7450 | Val Loss: 0.6793\n",
      "Epoch 35 | Train Loss: 0.7366 | Val Loss: 0.6742\n",
      "Epoch 36 | Train Loss: 0.7712 | Val Loss: 0.6746\n",
      "Epoch 37 | Train Loss: 0.7278 | Val Loss: 0.6659\n",
      "Epoch 38 | Train Loss: 0.7337 | Val Loss: 0.7662\n",
      "Epoch 39 | Train Loss: 0.7810 | Val Loss: 0.7241\n",
      "Epoch 40 | Train Loss: 0.7723 | Val Loss: 0.6821\n",
      "Epoch 41 | Train Loss: 0.7465 | Val Loss: 0.6653\n",
      "Epoch 42 | Train Loss: 0.7236 | Val Loss: 0.6694\n",
      "Epoch 43 | Train Loss: 0.7408 | Val Loss: 0.6796\n",
      "Epoch 44 | Train Loss: 0.7389 | Val Loss: 0.6764\n",
      "Epoch 45 | Train Loss: 0.7487 | Val Loss: 0.6670\n",
      "Epoch 46 | Train Loss: 0.7361 | Val Loss: 0.6583\n",
      "Epoch 47 | Train Loss: 0.7172 | Val Loss: 0.6725\n",
      "Epoch 48 | Train Loss: 0.7290 | Val Loss: 0.6829\n",
      "Epoch 49 | Train Loss: 0.7241 | Val Loss: 0.6686\n",
      "Epoch 50 | Train Loss: 0.7333 | Val Loss: 0.6729\n",
      "Fold 4 ‚ñ∂ AUC: 0.787, Balanced Acc: 0.528\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.8997 | Val Loss: 0.8951\n",
      "Epoch 02 | Train Loss: 0.8797 | Val Loss: 0.8905\n",
      "Epoch 03 | Train Loss: 0.8668 | Val Loss: 0.8884\n",
      "Epoch 04 | Train Loss: 0.8680 | Val Loss: 0.8903\n",
      "Epoch 05 | Train Loss: 0.8557 | Val Loss: 0.8804\n",
      "Epoch 06 | Train Loss: 0.8614 | Val Loss: 0.8805\n",
      "Epoch 07 | Train Loss: 0.8371 | Val Loss: 0.8896\n",
      "Epoch 08 | Train Loss: 0.8446 | Val Loss: 0.8680\n",
      "Epoch 09 | Train Loss: 0.8389 | Val Loss: 0.8662\n",
      "Epoch 10 | Train Loss: 0.8230 | Val Loss: 0.8647\n",
      "Epoch 11 | Train Loss: 0.8001 | Val Loss: 0.8332\n",
      "Epoch 12 | Train Loss: 0.7734 | Val Loss: 0.8282\n",
      "Epoch 13 | Train Loss: 0.7845 | Val Loss: 0.8690\n",
      "Epoch 14 | Train Loss: 0.7729 | Val Loss: 0.8215\n",
      "Epoch 15 | Train Loss: 0.7478 | Val Loss: 0.8219\n",
      "Epoch 16 | Train Loss: 0.7367 | Val Loss: 0.8250\n",
      "Epoch 17 | Train Loss: 0.7655 | Val Loss: 0.8271\n",
      "Epoch 18 | Train Loss: 0.7675 | Val Loss: 0.8402\n",
      "Epoch 19 | Train Loss: 0.7420 | Val Loss: 0.8193\n",
      "Epoch 20 | Train Loss: 0.7597 | Val Loss: 0.8287\n",
      "Epoch 21 | Train Loss: 0.7556 | Val Loss: 0.8087\n",
      "Epoch 22 | Train Loss: 0.7323 | Val Loss: 0.8072\n",
      "Epoch 23 | Train Loss: 0.7198 | Val Loss: 0.8123\n",
      "Epoch 24 | Train Loss: 0.7421 | Val Loss: 0.8064\n",
      "Epoch 25 | Train Loss: 0.7287 | Val Loss: 0.8108\n",
      "Epoch 26 | Train Loss: 0.7119 | Val Loss: 0.8470\n",
      "Epoch 27 | Train Loss: 0.7423 | Val Loss: 0.8029\n",
      "Epoch 28 | Train Loss: 0.7304 | Val Loss: 0.8134\n",
      "Epoch 29 | Train Loss: 0.7111 | Val Loss: 0.8161\n",
      "Epoch 30 | Train Loss: 0.7241 | Val Loss: 0.7997\n",
      "Epoch 31 | Train Loss: 0.7468 | Val Loss: 0.8109\n",
      "Epoch 32 | Train Loss: 0.7243 | Val Loss: 0.7989\n",
      "Epoch 33 | Train Loss: 0.7215 | Val Loss: 0.8018\n",
      "Epoch 34 | Train Loss: 0.7289 | Val Loss: 0.8127\n",
      "Epoch 35 | Train Loss: 0.7235 | Val Loss: 0.7932\n",
      "Epoch 36 | Train Loss: 0.7218 | Val Loss: 0.7979\n",
      "Epoch 37 | Train Loss: 0.7201 | Val Loss: 0.7851\n",
      "Epoch 38 | Train Loss: 0.7157 | Val Loss: 0.7926\n",
      "Epoch 39 | Train Loss: 0.7246 | Val Loss: 0.8017\n",
      "Epoch 40 | Train Loss: 0.7037 | Val Loss: 0.7923\n",
      "Epoch 41 | Train Loss: 0.7325 | Val Loss: 0.8015\n",
      "Epoch 42 | Train Loss: 0.7418 | Val Loss: 0.7823\n",
      "Epoch 43 | Train Loss: 0.7155 | Val Loss: 0.7984\n",
      "Epoch 44 | Train Loss: 0.7025 | Val Loss: 0.7975\n",
      "Epoch 45 | Train Loss: 0.6930 | Val Loss: 0.7982\n",
      "Epoch 46 | Train Loss: 0.7143 | Val Loss: 0.7877\n",
      "Epoch 47 | Train Loss: 0.7324 | Val Loss: 0.7920\n",
      "Epoch 48 | Train Loss: 0.7210 | Val Loss: 0.7983\n",
      "Epoch 49 | Train Loss: 0.7066 | Val Loss: 0.8151\n",
      "Epoch 50 | Train Loss: 0.7430 | Val Loss: 0.8071\n",
      "Fold 5 ‚ñ∂ AUC: 0.731, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9685 | Val Loss: 0.9578\n",
      "Epoch 02 | Train Loss: 0.8784 | Val Loss: 0.9004\n",
      "Epoch 03 | Train Loss: 0.8632 | Val Loss: 0.8959\n",
      "Epoch 04 | Train Loss: 0.8755 | Val Loss: 0.8940\n",
      "Epoch 05 | Train Loss: 0.8433 | Val Loss: 0.8781\n",
      "Epoch 06 | Train Loss: 0.8515 | Val Loss: 0.9064\n",
      "Epoch 07 | Train Loss: 0.8862 | Val Loss: 0.8811\n",
      "Epoch 08 | Train Loss: 0.8193 | Val Loss: 0.8513\n",
      "Epoch 09 | Train Loss: 0.8123 | Val Loss: 0.8570\n",
      "Epoch 10 | Train Loss: 0.8187 | Val Loss: 0.8523\n",
      "Epoch 11 | Train Loss: 0.7899 | Val Loss: 0.8236\n",
      "Epoch 12 | Train Loss: 0.7804 | Val Loss: 0.8233\n",
      "Epoch 13 | Train Loss: 0.7929 | Val Loss: 0.8371\n",
      "Epoch 14 | Train Loss: 0.7942 | Val Loss: 0.8214\n",
      "Epoch 15 | Train Loss: 0.7606 | Val Loss: 0.8252\n",
      "Epoch 16 | Train Loss: 0.7556 | Val Loss: 0.8191\n",
      "Epoch 17 | Train Loss: 0.7641 | Val Loss: 0.8197\n",
      "Epoch 18 | Train Loss: 0.7571 | Val Loss: 0.8362\n",
      "Epoch 19 | Train Loss: 0.7703 | Val Loss: 0.8383\n",
      "Epoch 20 | Train Loss: 0.7607 | Val Loss: 0.8049\n",
      "Epoch 21 | Train Loss: 0.7816 | Val Loss: 0.8102\n",
      "Epoch 22 | Train Loss: 0.7557 | Val Loss: 0.8198\n",
      "Epoch 23 | Train Loss: 0.7576 | Val Loss: 0.8158\n",
      "Epoch 24 | Train Loss: 0.7414 | Val Loss: 0.8069\n",
      "Epoch 25 | Train Loss: 0.7585 | Val Loss: 0.8126\n",
      "Epoch 26 | Train Loss: 0.7419 | Val Loss: 0.8036\n",
      "Epoch 27 | Train Loss: 0.7358 | Val Loss: 0.8257\n",
      "Epoch 28 | Train Loss: 0.7560 | Val Loss: 0.8186\n",
      "Epoch 29 | Train Loss: 0.7568 | Val Loss: 0.8331\n",
      "Epoch 30 | Train Loss: 0.7481 | Val Loss: 0.8054\n",
      "Epoch 31 | Train Loss: 0.7297 | Val Loss: 0.8100\n",
      "Epoch 32 | Train Loss: 0.7199 | Val Loss: 0.8162\n",
      "Epoch 33 | Train Loss: 0.7318 | Val Loss: 0.8127\n",
      "Epoch 34 | Train Loss: 0.7317 | Val Loss: 0.8045\n",
      "Epoch 35 | Train Loss: 0.7220 | Val Loss: 0.8220\n",
      "Epoch 36 | Train Loss: 0.7119 | Val Loss: 0.8230\n",
      "Epoch 37 | Train Loss: 0.7186 | Val Loss: 0.8193\n",
      "Epoch 38 | Train Loss: 0.7233 | Val Loss: 0.8184\n",
      "Epoch 39 | Train Loss: 0.7296 | Val Loss: 0.8390\n",
      "Epoch 40 | Train Loss: 0.7048 | Val Loss: 0.8164\n",
      "Epoch 41 | Train Loss: 0.7212 | Val Loss: 0.8169\n",
      "Epoch 42 | Train Loss: 0.7213 | Val Loss: 0.8275\n",
      "Epoch 43 | Train Loss: 0.7201 | Val Loss: 0.8105\n",
      "Epoch 44 | Train Loss: 0.7244 | Val Loss: 0.8206\n",
      "Epoch 45 | Train Loss: 0.6956 | Val Loss: 0.8404\n",
      "Epoch 46 | Train Loss: 0.7274 | Val Loss: 0.8139\n",
      "Epoch 47 | Train Loss: 0.7167 | Val Loss: 0.8044\n",
      "Epoch 48 | Train Loss: 0.7092 | Val Loss: 0.8265\n",
      "Epoch 49 | Train Loss: 0.7178 | Val Loss: 0.8112\n",
      "Epoch 50 | Train Loss: 0.6999 | Val Loss: 0.8547\n",
      "Fold 6 ‚ñ∂ AUC: 0.731, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9071 | Val Loss: 0.8646\n",
      "Epoch 02 | Train Loss: 0.8740 | Val Loss: 0.8614\n",
      "Epoch 03 | Train Loss: 0.8804 | Val Loss: 0.8353\n",
      "Epoch 04 | Train Loss: 0.8589 | Val Loss: 0.8232\n",
      "Epoch 05 | Train Loss: 0.8401 | Val Loss: 0.8009\n",
      "Epoch 06 | Train Loss: 0.8347 | Val Loss: 0.7896\n",
      "Epoch 07 | Train Loss: 0.8256 | Val Loss: 0.7768\n",
      "Epoch 08 | Train Loss: 0.8282 | Val Loss: 0.7853\n",
      "Epoch 09 | Train Loss: 0.8113 | Val Loss: 0.7573\n",
      "Epoch 10 | Train Loss: 0.7873 | Val Loss: 0.7328\n",
      "Epoch 11 | Train Loss: 0.7855 | Val Loss: 0.7479\n",
      "Epoch 12 | Train Loss: 0.8087 | Val Loss: 0.8035\n",
      "Epoch 13 | Train Loss: 0.7937 | Val Loss: 0.7545\n",
      "Epoch 14 | Train Loss: 0.7636 | Val Loss: 0.7147\n",
      "Epoch 15 | Train Loss: 0.7766 | Val Loss: 0.7158\n",
      "Epoch 16 | Train Loss: 0.7692 | Val Loss: 0.7176\n",
      "Epoch 17 | Train Loss: 0.7657 | Val Loss: 0.7187\n",
      "Epoch 18 | Train Loss: 0.7391 | Val Loss: 0.7173\n",
      "Epoch 19 | Train Loss: 0.7657 | Val Loss: 0.7171\n",
      "Epoch 20 | Train Loss: 0.7866 | Val Loss: 0.7740\n",
      "Epoch 21 | Train Loss: 0.7625 | Val Loss: 0.7202\n",
      "Epoch 22 | Train Loss: 0.7405 | Val Loss: 0.7068\n",
      "Epoch 23 | Train Loss: 0.7417 | Val Loss: 0.7211\n",
      "Epoch 24 | Train Loss: 0.7395 | Val Loss: 0.7286\n",
      "Epoch 25 | Train Loss: 0.7405 | Val Loss: 0.7156\n",
      "Epoch 26 | Train Loss: 0.7550 | Val Loss: 0.7287\n",
      "Epoch 27 | Train Loss: 0.7279 | Val Loss: 0.7220\n",
      "Epoch 28 | Train Loss: 0.7335 | Val Loss: 0.7356\n",
      "Epoch 29 | Train Loss: 0.7207 | Val Loss: 0.7180\n",
      "Epoch 30 | Train Loss: 0.7368 | Val Loss: 0.7269\n",
      "Epoch 31 | Train Loss: 0.7356 | Val Loss: 0.7280\n",
      "Epoch 32 | Train Loss: 0.7257 | Val Loss: 0.7424\n",
      "Epoch 33 | Train Loss: 0.7564 | Val Loss: 0.7505\n",
      "Epoch 34 | Train Loss: 0.7229 | Val Loss: 0.7337\n",
      "Epoch 35 | Train Loss: 0.7430 | Val Loss: 0.7185\n",
      "Epoch 36 | Train Loss: 0.7153 | Val Loss: 0.7231\n",
      "Epoch 37 | Train Loss: 0.7237 | Val Loss: 0.7176\n",
      "Epoch 38 | Train Loss: 0.7162 | Val Loss: 0.7315\n",
      "Epoch 39 | Train Loss: 0.7396 | Val Loss: 0.7231\n",
      "Epoch 40 | Train Loss: 0.7344 | Val Loss: 0.7331\n",
      "Epoch 41 | Train Loss: 0.7383 | Val Loss: 0.7198\n",
      "Epoch 42 | Train Loss: 0.7224 | Val Loss: 0.7391\n",
      "Epoch 43 | Train Loss: 0.7412 | Val Loss: 0.7438\n",
      "Epoch 44 | Train Loss: 0.7405 | Val Loss: 0.7319\n",
      "Epoch 45 | Train Loss: 0.7155 | Val Loss: 0.7270\n",
      "Epoch 46 | Train Loss: 0.7441 | Val Loss: 0.7310\n",
      "Epoch 47 | Train Loss: 0.7287 | Val Loss: 0.7276\n",
      "Epoch 48 | Train Loss: 0.7285 | Val Loss: 0.7292\n",
      "Epoch 49 | Train Loss: 0.7258 | Val Loss: 0.7874\n",
      "Epoch 50 | Train Loss: 0.7345 | Val Loss: 0.7379\n",
      "Fold 7 ‚ñ∂ AUC: 0.732, Balanced Acc: 0.510\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9089 | Val Loss: 0.8887\n",
      "Epoch 02 | Train Loss: 0.8942 | Val Loss: 0.8732\n",
      "Epoch 03 | Train Loss: 0.8718 | Val Loss: 0.8722\n",
      "Epoch 04 | Train Loss: 0.8516 | Val Loss: 0.8737\n",
      "Epoch 05 | Train Loss: 0.8621 | Val Loss: 0.8651\n",
      "Epoch 06 | Train Loss: 0.8813 | Val Loss: 0.8566\n",
      "Epoch 07 | Train Loss: 0.8654 | Val Loss: 0.8662\n",
      "Epoch 08 | Train Loss: 0.8574 | Val Loss: 0.8347\n",
      "Epoch 09 | Train Loss: 0.8623 | Val Loss: 0.8306\n",
      "Epoch 10 | Train Loss: 0.8193 | Val Loss: 0.8070\n",
      "Epoch 11 | Train Loss: 0.7849 | Val Loss: 0.7951\n",
      "Epoch 12 | Train Loss: 0.8220 | Val Loss: 0.7961\n",
      "Epoch 13 | Train Loss: 0.8085 | Val Loss: 0.8014\n",
      "Epoch 14 | Train Loss: 0.7759 | Val Loss: 0.7876\n",
      "Epoch 15 | Train Loss: 0.7605 | Val Loss: 0.8685\n",
      "Epoch 16 | Train Loss: 0.7607 | Val Loss: 0.7997\n",
      "Epoch 17 | Train Loss: 0.7874 | Val Loss: 0.7987\n",
      "Epoch 18 | Train Loss: 0.7740 | Val Loss: 0.8271\n",
      "Epoch 19 | Train Loss: 0.7439 | Val Loss: 0.8211\n",
      "Epoch 20 | Train Loss: 0.7604 | Val Loss: 0.7917\n",
      "Epoch 21 | Train Loss: 0.7515 | Val Loss: 0.7825\n",
      "Epoch 22 | Train Loss: 0.7389 | Val Loss: 0.8173\n",
      "Epoch 23 | Train Loss: 0.7241 | Val Loss: 0.7965\n",
      "Epoch 24 | Train Loss: 0.7427 | Val Loss: 0.7888\n",
      "Epoch 25 | Train Loss: 0.7424 | Val Loss: 0.8085\n",
      "Epoch 26 | Train Loss: 0.7441 | Val Loss: 0.7979\n",
      "Epoch 27 | Train Loss: 0.7270 | Val Loss: 0.7812\n",
      "Epoch 28 | Train Loss: 0.7401 | Val Loss: 0.7906\n",
      "Epoch 29 | Train Loss: 0.7356 | Val Loss: 0.7955\n",
      "Epoch 30 | Train Loss: 0.7627 | Val Loss: 0.7882\n",
      "Epoch 31 | Train Loss: 0.7574 | Val Loss: 0.8107\n",
      "Epoch 32 | Train Loss: 0.7205 | Val Loss: 0.7864\n",
      "Epoch 33 | Train Loss: 0.7187 | Val Loss: 0.7914\n",
      "Epoch 34 | Train Loss: 0.7121 | Val Loss: 0.8074\n",
      "Epoch 35 | Train Loss: 0.7276 | Val Loss: 0.7947\n",
      "Epoch 36 | Train Loss: 0.7172 | Val Loss: 0.7878\n",
      "Epoch 37 | Train Loss: 0.7232 | Val Loss: 0.7894\n",
      "Epoch 38 | Train Loss: 0.7230 | Val Loss: 0.8017\n",
      "Epoch 39 | Train Loss: 0.7232 | Val Loss: 0.7849\n",
      "Epoch 40 | Train Loss: 0.7136 | Val Loss: 0.7889\n",
      "Epoch 41 | Train Loss: 0.7530 | Val Loss: 0.7874\n",
      "Epoch 42 | Train Loss: 0.7539 | Val Loss: 0.7926\n",
      "Epoch 43 | Train Loss: 0.7343 | Val Loss: 0.8014\n",
      "Epoch 44 | Train Loss: 0.7193 | Val Loss: 0.7927\n",
      "Epoch 45 | Train Loss: 0.7099 | Val Loss: 0.7917\n",
      "Epoch 46 | Train Loss: 0.7285 | Val Loss: 0.7933\n",
      "Epoch 47 | Train Loss: 0.7020 | Val Loss: 0.7960\n",
      "Epoch 48 | Train Loss: 0.7025 | Val Loss: 0.7997\n",
      "Epoch 49 | Train Loss: 0.7133 | Val Loss: 0.8123\n",
      "Epoch 50 | Train Loss: 0.7161 | Val Loss: 0.7884\n",
      "Fold 8 ‚ñ∂ AUC: 0.720, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9392 | Val Loss: 0.8862\n",
      "Epoch 02 | Train Loss: 0.8762 | Val Loss: 0.8778\n",
      "Epoch 03 | Train Loss: 0.8666 | Val Loss: 0.8682\n",
      "Epoch 04 | Train Loss: 0.8640 | Val Loss: 0.8661\n",
      "Epoch 05 | Train Loss: 0.8584 | Val Loss: 0.8743\n",
      "Epoch 06 | Train Loss: 0.8605 | Val Loss: 0.8967\n",
      "Epoch 07 | Train Loss: 0.8574 | Val Loss: 0.8559\n",
      "Epoch 08 | Train Loss: 0.8362 | Val Loss: 0.8529\n",
      "Epoch 09 | Train Loss: 0.8267 | Val Loss: 0.8406\n",
      "Epoch 10 | Train Loss: 0.8111 | Val Loss: 0.8378\n",
      "Epoch 11 | Train Loss: 0.8114 | Val Loss: 0.8255\n",
      "Epoch 12 | Train Loss: 0.7816 | Val Loss: 0.8202\n",
      "Epoch 13 | Train Loss: 0.7767 | Val Loss: 0.9033\n",
      "Epoch 14 | Train Loss: 0.8203 | Val Loss: 0.8980\n",
      "Epoch 15 | Train Loss: 0.7789 | Val Loss: 0.8117\n",
      "Epoch 16 | Train Loss: 0.7757 | Val Loss: 0.8436\n",
      "Epoch 17 | Train Loss: 0.7703 | Val Loss: 0.7974\n",
      "Epoch 18 | Train Loss: 0.7464 | Val Loss: 0.8093\n",
      "Epoch 19 | Train Loss: 0.7467 | Val Loss: 0.8329\n",
      "Epoch 20 | Train Loss: 0.7519 | Val Loss: 0.8028\n",
      "Epoch 21 | Train Loss: 0.7470 | Val Loss: 0.8176\n",
      "Epoch 22 | Train Loss: 0.7752 | Val Loss: 0.7976\n",
      "Epoch 23 | Train Loss: 0.7533 | Val Loss: 0.7896\n",
      "Epoch 24 | Train Loss: 0.7558 | Val Loss: 0.8169\n",
      "Epoch 25 | Train Loss: 0.7438 | Val Loss: 0.7940\n",
      "Epoch 26 | Train Loss: 0.7633 | Val Loss: 0.8565\n",
      "Epoch 27 | Train Loss: 0.7461 | Val Loss: 0.7876\n",
      "Epoch 28 | Train Loss: 0.7436 | Val Loss: 0.8070\n",
      "Epoch 29 | Train Loss: 0.7316 | Val Loss: 0.7945\n",
      "Epoch 30 | Train Loss: 0.7275 | Val Loss: 0.7947\n",
      "Epoch 31 | Train Loss: 0.7332 | Val Loss: 0.7979\n",
      "Epoch 32 | Train Loss: 0.7307 | Val Loss: 0.7971\n",
      "Epoch 33 | Train Loss: 0.7278 | Val Loss: 0.7844\n",
      "Epoch 34 | Train Loss: 0.7453 | Val Loss: 0.7748\n",
      "Epoch 35 | Train Loss: 0.7430 | Val Loss: 0.7876\n",
      "Epoch 36 | Train Loss: 0.7536 | Val Loss: 0.7730\n",
      "Epoch 37 | Train Loss: 0.7225 | Val Loss: 0.7914\n",
      "Epoch 38 | Train Loss: 0.7241 | Val Loss: 0.7689\n",
      "Epoch 39 | Train Loss: 0.7256 | Val Loss: 0.7812\n",
      "Epoch 40 | Train Loss: 0.7191 | Val Loss: 0.7730\n",
      "Epoch 41 | Train Loss: 0.7215 | Val Loss: 0.8062\n",
      "Epoch 42 | Train Loss: 0.7404 | Val Loss: 0.7641\n",
      "Epoch 43 | Train Loss: 0.7138 | Val Loss: 0.7748\n",
      "Epoch 44 | Train Loss: 0.7450 | Val Loss: 0.7731\n",
      "Epoch 45 | Train Loss: 0.7073 | Val Loss: 0.7679\n",
      "Epoch 46 | Train Loss: 0.7182 | Val Loss: 0.7723\n",
      "Epoch 47 | Train Loss: 0.7356 | Val Loss: 0.7945\n",
      "Epoch 48 | Train Loss: 0.7406 | Val Loss: 0.7843\n",
      "Epoch 49 | Train Loss: 0.7033 | Val Loss: 0.7612\n",
      "Epoch 50 | Train Loss: 0.7128 | Val Loss: 0.7915\n",
      "Fold 9 ‚ñ∂ AUC: 0.738, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9013 | Val Loss: 0.8682\n",
      "Epoch 02 | Train Loss: 0.8689 | Val Loss: 0.8746\n",
      "Epoch 03 | Train Loss: 0.8597 | Val Loss: 0.8533\n",
      "Epoch 04 | Train Loss: 0.8622 | Val Loss: 0.8629\n",
      "Epoch 05 | Train Loss: 0.8492 | Val Loss: 0.8381\n",
      "Epoch 06 | Train Loss: 0.8414 | Val Loss: 0.8510\n",
      "Epoch 07 | Train Loss: 0.8303 | Val Loss: 0.8353\n",
      "Epoch 08 | Train Loss: 0.8226 | Val Loss: 0.8029\n",
      "Epoch 09 | Train Loss: 0.7975 | Val Loss: 0.8366\n",
      "Epoch 10 | Train Loss: 0.8029 | Val Loss: 0.7821\n",
      "Epoch 11 | Train Loss: 0.7965 | Val Loss: 0.7684\n",
      "Epoch 12 | Train Loss: 0.7780 | Val Loss: 0.7719\n",
      "Epoch 13 | Train Loss: 0.7676 | Val Loss: 0.7666\n",
      "Epoch 14 | Train Loss: 0.7652 | Val Loss: 0.7674\n",
      "Epoch 15 | Train Loss: 0.7562 | Val Loss: 0.7711\n",
      "Epoch 16 | Train Loss: 0.7654 | Val Loss: 0.7703\n",
      "Epoch 17 | Train Loss: 0.7363 | Val Loss: 0.7860\n",
      "Epoch 18 | Train Loss: 0.7482 | Val Loss: 0.7660\n",
      "Epoch 19 | Train Loss: 0.7299 | Val Loss: 0.9363\n",
      "Epoch 20 | Train Loss: 0.7604 | Val Loss: 0.7813\n",
      "Epoch 21 | Train Loss: 0.7426 | Val Loss: 0.7719\n",
      "Epoch 22 | Train Loss: 0.7412 | Val Loss: 0.7626\n",
      "Epoch 23 | Train Loss: 0.7428 | Val Loss: 0.7879\n",
      "Epoch 24 | Train Loss: 0.7310 | Val Loss: 0.8451\n",
      "Epoch 25 | Train Loss: 0.7440 | Val Loss: 0.7761\n",
      "Epoch 26 | Train Loss: 0.7324 | Val Loss: 0.7619\n",
      "Epoch 27 | Train Loss: 0.7204 | Val Loss: 0.7846\n",
      "Epoch 28 | Train Loss: 0.7189 | Val Loss: 0.7789\n",
      "Epoch 29 | Train Loss: 0.7293 | Val Loss: 0.7791\n",
      "Epoch 30 | Train Loss: 0.7198 | Val Loss: 0.7693\n",
      "Epoch 31 | Train Loss: 0.7099 | Val Loss: 0.7949\n",
      "Epoch 32 | Train Loss: 0.7317 | Val Loss: 0.7804\n",
      "Epoch 33 | Train Loss: 0.7217 | Val Loss: 0.7691\n",
      "Epoch 34 | Train Loss: 0.7062 | Val Loss: 0.7946\n",
      "Epoch 35 | Train Loss: 0.7094 | Val Loss: 0.7775\n",
      "Epoch 36 | Train Loss: 0.7040 | Val Loss: 0.8022\n",
      "Epoch 37 | Train Loss: 0.7193 | Val Loss: 0.8227\n",
      "Epoch 38 | Train Loss: 0.7106 | Val Loss: 0.7682\n",
      "Epoch 39 | Train Loss: 0.7211 | Val Loss: 0.7719\n",
      "Epoch 40 | Train Loss: 0.7433 | Val Loss: 0.7753\n",
      "Epoch 41 | Train Loss: 0.7261 | Val Loss: 0.8133\n",
      "Epoch 42 | Train Loss: 0.7519 | Val Loss: 0.8420\n",
      "Epoch 43 | Train Loss: 0.7027 | Val Loss: 0.7677\n",
      "Epoch 44 | Train Loss: 0.7241 | Val Loss: 0.7755\n",
      "Epoch 45 | Train Loss: 0.7147 | Val Loss: 0.7929\n",
      "Epoch 46 | Train Loss: 0.7112 | Val Loss: 0.8026\n",
      "Epoch 47 | Train Loss: 0.7180 | Val Loss: 0.8106\n",
      "Epoch 48 | Train Loss: 0.7154 | Val Loss: 0.7723\n",
      "Epoch 49 | Train Loss: 0.6991 | Val Loss: 0.8038\n",
      "Epoch 50 | Train Loss: 0.6888 | Val Loss: 0.7898\n",
      "Fold 10 ‚ñ∂ AUC: 0.724, Balanced Acc: 0.451\n",
      "üîç Summary for hd=64, dp=0.2, lr=0.001 ‚Üí AUC: 0.7405¬±0.0314 | BalAcc: 0.4814¬±0.0448\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.2, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9280 | Val Loss: 0.8562\n",
      "Epoch 02 | Train Loss: 0.8737 | Val Loss: 0.8601\n",
      "Epoch 03 | Train Loss: 0.8673 | Val Loss: 0.8499\n",
      "Epoch 04 | Train Loss: 0.8533 | Val Loss: 0.8401\n",
      "Epoch 05 | Train Loss: 0.8709 | Val Loss: 0.8316\n",
      "Epoch 06 | Train Loss: 0.8533 | Val Loss: 0.8286\n",
      "Epoch 07 | Train Loss: 0.8239 | Val Loss: 0.8469\n",
      "Epoch 08 | Train Loss: 0.8268 | Val Loss: 0.8077\n",
      "Epoch 09 | Train Loss: 0.8274 | Val Loss: 0.8020\n",
      "Epoch 10 | Train Loss: 0.7998 | Val Loss: 0.7776\n",
      "Epoch 11 | Train Loss: 0.7863 | Val Loss: 0.8064\n",
      "Epoch 12 | Train Loss: 0.8250 | Val Loss: 0.7996\n",
      "Epoch 13 | Train Loss: 0.7929 | Val Loss: 0.7796\n",
      "Epoch 14 | Train Loss: 0.7879 | Val Loss: 0.7611\n",
      "Epoch 15 | Train Loss: 0.7834 | Val Loss: 0.7579\n",
      "Epoch 16 | Train Loss: 0.7621 | Val Loss: 0.7429\n",
      "Epoch 17 | Train Loss: 0.7853 | Val Loss: 0.7342\n",
      "Epoch 18 | Train Loss: 0.7652 | Val Loss: 0.7421\n",
      "Epoch 19 | Train Loss: 0.7651 | Val Loss: 0.7252\n",
      "Epoch 20 | Train Loss: 0.7571 | Val Loss: 0.7252\n",
      "Epoch 21 | Train Loss: 0.7565 | Val Loss: 0.7588\n",
      "Epoch 22 | Train Loss: 0.7780 | Val Loss: 0.7228\n",
      "Epoch 23 | Train Loss: 0.7743 | Val Loss: 0.7233\n",
      "Epoch 24 | Train Loss: 0.7526 | Val Loss: 0.7177\n",
      "Epoch 25 | Train Loss: 0.7369 | Val Loss: 0.7106\n",
      "Epoch 26 | Train Loss: 0.7525 | Val Loss: 0.7209\n",
      "Epoch 27 | Train Loss: 0.7522 | Val Loss: 0.7213\n",
      "Epoch 28 | Train Loss: 0.7544 | Val Loss: 0.7191\n",
      "Epoch 29 | Train Loss: 0.7411 | Val Loss: 0.7040\n",
      "Epoch 30 | Train Loss: 0.7431 | Val Loss: 0.7188\n",
      "Epoch 31 | Train Loss: 0.7475 | Val Loss: 0.7015\n",
      "Epoch 32 | Train Loss: 0.7423 | Val Loss: 0.7011\n",
      "Epoch 33 | Train Loss: 0.7492 | Val Loss: 0.7075\n",
      "Epoch 34 | Train Loss: 0.7639 | Val Loss: 0.6973\n",
      "Epoch 35 | Train Loss: 0.7318 | Val Loss: 0.6955\n",
      "Epoch 36 | Train Loss: 0.7611 | Val Loss: 0.6945\n",
      "Epoch 37 | Train Loss: 0.7306 | Val Loss: 0.7047\n",
      "Epoch 38 | Train Loss: 0.7452 | Val Loss: 0.6898\n",
      "Epoch 39 | Train Loss: 0.7316 | Val Loss: 0.6959\n",
      "Epoch 40 | Train Loss: 0.7354 | Val Loss: 0.6893\n",
      "Epoch 41 | Train Loss: 0.7510 | Val Loss: 0.6882\n",
      "Epoch 42 | Train Loss: 0.7444 | Val Loss: 0.7057\n",
      "Epoch 43 | Train Loss: 0.7248 | Val Loss: 0.7023\n",
      "Epoch 44 | Train Loss: 0.7419 | Val Loss: 0.7514\n",
      "Epoch 45 | Train Loss: 0.7604 | Val Loss: 0.6949\n",
      "Epoch 46 | Train Loss: 0.7401 | Val Loss: 0.6881\n",
      "Epoch 47 | Train Loss: 0.7402 | Val Loss: 0.6967\n",
      "Epoch 48 | Train Loss: 0.7206 | Val Loss: 0.6881\n",
      "Epoch 49 | Train Loss: 0.7179 | Val Loss: 0.6855\n",
      "Epoch 50 | Train Loss: 0.7371 | Val Loss: 0.7203\n",
      "Fold 1 ‚ñ∂ AUC: 0.769, Balanced Acc: 0.507\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9442 | Val Loss: 0.8891\n",
      "Epoch 02 | Train Loss: 0.9003 | Val Loss: 0.8668\n",
      "Epoch 03 | Train Loss: 0.8772 | Val Loss: 0.8704\n",
      "Epoch 04 | Train Loss: 0.8621 | Val Loss: 0.8620\n",
      "Epoch 05 | Train Loss: 0.8630 | Val Loss: 0.8578\n",
      "Epoch 06 | Train Loss: 0.8643 | Val Loss: 0.8518\n",
      "Epoch 07 | Train Loss: 0.8565 | Val Loss: 0.8434\n",
      "Epoch 08 | Train Loss: 0.8648 | Val Loss: 0.8378\n",
      "Epoch 09 | Train Loss: 0.8374 | Val Loss: 0.8269\n",
      "Epoch 10 | Train Loss: 0.8183 | Val Loss: 0.8113\n",
      "Epoch 11 | Train Loss: 0.8183 | Val Loss: 0.8004\n",
      "Epoch 12 | Train Loss: 0.8135 | Val Loss: 0.8059\n",
      "Epoch 13 | Train Loss: 0.8074 | Val Loss: 0.7948\n",
      "Epoch 14 | Train Loss: 0.7810 | Val Loss: 0.7734\n",
      "Epoch 15 | Train Loss: 0.7894 | Val Loss: 0.7765\n",
      "Epoch 16 | Train Loss: 0.7741 | Val Loss: 0.7560\n",
      "Epoch 17 | Train Loss: 0.7590 | Val Loss: 0.7568\n",
      "Epoch 18 | Train Loss: 0.7501 | Val Loss: 0.7548\n",
      "Epoch 19 | Train Loss: 0.7472 | Val Loss: 0.7344\n",
      "Epoch 20 | Train Loss: 0.7578 | Val Loss: 0.7259\n",
      "Epoch 21 | Train Loss: 0.7702 | Val Loss: 0.7321\n",
      "Epoch 22 | Train Loss: 0.7418 | Val Loss: 0.7194\n",
      "Epoch 23 | Train Loss: 0.7571 | Val Loss: 0.7175\n",
      "Epoch 24 | Train Loss: 0.7468 | Val Loss: 0.7391\n",
      "Epoch 25 | Train Loss: 0.7548 | Val Loss: 0.7089\n",
      "Epoch 26 | Train Loss: 0.7272 | Val Loss: 0.7522\n",
      "Epoch 27 | Train Loss: 0.7514 | Val Loss: 0.7095\n",
      "Epoch 28 | Train Loss: 0.7408 | Val Loss: 0.7283\n",
      "Epoch 29 | Train Loss: 0.7521 | Val Loss: 0.7159\n",
      "Epoch 30 | Train Loss: 0.7387 | Val Loss: 0.7004\n",
      "Epoch 31 | Train Loss: 0.7291 | Val Loss: 0.7179\n",
      "Epoch 32 | Train Loss: 0.7375 | Val Loss: 0.7043\n",
      "Epoch 33 | Train Loss: 0.7357 | Val Loss: 0.7012\n",
      "Epoch 34 | Train Loss: 0.7334 | Val Loss: 0.7214\n",
      "Epoch 35 | Train Loss: 0.7280 | Val Loss: 0.7297\n",
      "Epoch 36 | Train Loss: 0.7294 | Val Loss: 0.7301\n",
      "Epoch 37 | Train Loss: 0.7358 | Val Loss: 0.7080\n",
      "Epoch 38 | Train Loss: 0.7170 | Val Loss: 0.6973\n",
      "Epoch 39 | Train Loss: 0.7269 | Val Loss: 0.7003\n",
      "Epoch 40 | Train Loss: 0.7391 | Val Loss: 0.7211\n",
      "Epoch 41 | Train Loss: 0.7193 | Val Loss: 0.6986\n",
      "Epoch 42 | Train Loss: 0.7198 | Val Loss: 0.7441\n",
      "Epoch 43 | Train Loss: 0.7108 | Val Loss: 0.7010\n",
      "Epoch 44 | Train Loss: 0.7349 | Val Loss: 0.7028\n",
      "Epoch 45 | Train Loss: 0.7208 | Val Loss: 0.6997\n",
      "Epoch 46 | Train Loss: 0.7167 | Val Loss: 0.7275\n",
      "Epoch 47 | Train Loss: 0.7147 | Val Loss: 0.6948\n",
      "Epoch 48 | Train Loss: 0.7382 | Val Loss: 0.6961\n",
      "Epoch 49 | Train Loss: 0.7317 | Val Loss: 0.7933\n",
      "Epoch 50 | Train Loss: 0.7260 | Val Loss: 0.7193\n",
      "Fold 2 ‚ñ∂ AUC: 0.676, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9040 | Val Loss: 0.8834\n",
      "Epoch 02 | Train Loss: 0.8969 | Val Loss: 0.8719\n",
      "Epoch 03 | Train Loss: 0.8946 | Val Loss: 0.8688\n",
      "Epoch 04 | Train Loss: 0.8892 | Val Loss: 0.8643\n",
      "Epoch 05 | Train Loss: 0.8765 | Val Loss: 0.8602\n",
      "Epoch 06 | Train Loss: 0.8659 | Val Loss: 0.8540\n",
      "Epoch 07 | Train Loss: 0.8574 | Val Loss: 0.8552\n",
      "Epoch 08 | Train Loss: 0.8578 | Val Loss: 0.8410\n",
      "Epoch 09 | Train Loss: 0.8463 | Val Loss: 0.8382\n",
      "Epoch 10 | Train Loss: 0.8430 | Val Loss: 0.8183\n",
      "Epoch 11 | Train Loss: 0.8346 | Val Loss: 0.8072\n",
      "Epoch 12 | Train Loss: 0.8242 | Val Loss: 0.7956\n",
      "Epoch 13 | Train Loss: 0.8247 | Val Loss: 0.8224\n",
      "Epoch 14 | Train Loss: 0.7969 | Val Loss: 0.7889\n",
      "Epoch 15 | Train Loss: 0.7926 | Val Loss: 0.7827\n",
      "Epoch 16 | Train Loss: 0.7792 | Val Loss: 0.7607\n",
      "Epoch 17 | Train Loss: 0.7807 | Val Loss: 0.7573\n",
      "Epoch 18 | Train Loss: 0.7768 | Val Loss: 0.7594\n",
      "Epoch 19 | Train Loss: 0.7744 | Val Loss: 0.7531\n",
      "Epoch 20 | Train Loss: 0.7733 | Val Loss: 0.7495\n",
      "Epoch 21 | Train Loss: 0.7796 | Val Loss: 0.7482\n",
      "Epoch 22 | Train Loss: 0.7654 | Val Loss: 0.8031\n",
      "Epoch 23 | Train Loss: 0.7822 | Val Loss: 0.7993\n",
      "Epoch 24 | Train Loss: 0.7577 | Val Loss: 0.7535\n",
      "Epoch 25 | Train Loss: 0.7482 | Val Loss: 0.7523\n",
      "Epoch 26 | Train Loss: 0.7780 | Val Loss: 0.7616\n",
      "Epoch 27 | Train Loss: 0.7568 | Val Loss: 0.7500\n",
      "Epoch 28 | Train Loss: 0.7506 | Val Loss: 0.7472\n",
      "Epoch 29 | Train Loss: 0.7336 | Val Loss: 0.7592\n",
      "Epoch 30 | Train Loss: 0.7352 | Val Loss: 0.7599\n",
      "Epoch 31 | Train Loss: 0.7723 | Val Loss: 0.7405\n",
      "Epoch 32 | Train Loss: 0.7592 | Val Loss: 0.7626\n",
      "Epoch 33 | Train Loss: 0.7412 | Val Loss: 0.7500\n",
      "Epoch 34 | Train Loss: 0.7791 | Val Loss: 0.7351\n",
      "Epoch 35 | Train Loss: 0.7384 | Val Loss: 0.7567\n",
      "Epoch 36 | Train Loss: 0.7480 | Val Loss: 0.7670\n",
      "Epoch 37 | Train Loss: 0.7385 | Val Loss: 0.7417\n",
      "Epoch 38 | Train Loss: 0.7508 | Val Loss: 0.7588\n",
      "Epoch 39 | Train Loss: 0.7300 | Val Loss: 0.7291\n",
      "Epoch 40 | Train Loss: 0.7520 | Val Loss: 0.7333\n",
      "Epoch 41 | Train Loss: 0.7528 | Val Loss: 0.8168\n",
      "Epoch 42 | Train Loss: 0.7693 | Val Loss: 0.7457\n",
      "Epoch 43 | Train Loss: 0.7350 | Val Loss: 0.7541\n",
      "Epoch 44 | Train Loss: 0.7539 | Val Loss: 0.7343\n",
      "Epoch 45 | Train Loss: 0.7329 | Val Loss: 0.7269\n",
      "Epoch 46 | Train Loss: 0.7374 | Val Loss: 0.7580\n",
      "Epoch 47 | Train Loss: 0.7668 | Val Loss: 0.7345\n",
      "Epoch 48 | Train Loss: 0.7374 | Val Loss: 0.7272\n",
      "Epoch 49 | Train Loss: 0.7375 | Val Loss: 0.7603\n",
      "Epoch 50 | Train Loss: 0.7603 | Val Loss: 0.7253\n",
      "Fold 3 ‚ñ∂ AUC: 0.764, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9525 | Val Loss: 0.8640\n",
      "Epoch 02 | Train Loss: 0.8792 | Val Loss: 0.8569\n",
      "Epoch 03 | Train Loss: 0.8712 | Val Loss: 0.8577\n",
      "Epoch 04 | Train Loss: 0.8633 | Val Loss: 0.8548\n",
      "Epoch 05 | Train Loss: 0.8656 | Val Loss: 0.8521\n",
      "Epoch 06 | Train Loss: 0.8595 | Val Loss: 0.8490\n",
      "Epoch 07 | Train Loss: 0.8567 | Val Loss: 0.8448\n",
      "Epoch 08 | Train Loss: 0.8579 | Val Loss: 0.8387\n",
      "Epoch 09 | Train Loss: 0.8547 | Val Loss: 0.8429\n",
      "Epoch 10 | Train Loss: 0.8501 | Val Loss: 0.8267\n",
      "Epoch 11 | Train Loss: 0.8374 | Val Loss: 0.8195\n",
      "Epoch 12 | Train Loss: 0.8348 | Val Loss: 0.8185\n",
      "Epoch 13 | Train Loss: 0.8328 | Val Loss: 0.8003\n",
      "Epoch 14 | Train Loss: 0.8309 | Val Loss: 0.7895\n",
      "Epoch 15 | Train Loss: 0.8248 | Val Loss: 0.8123\n",
      "Epoch 16 | Train Loss: 0.8393 | Val Loss: 0.8010\n",
      "Epoch 17 | Train Loss: 0.7828 | Val Loss: 0.7750\n",
      "Epoch 18 | Train Loss: 0.7912 | Val Loss: 0.8004\n",
      "Epoch 19 | Train Loss: 0.8050 | Val Loss: 0.7411\n",
      "Epoch 20 | Train Loss: 0.7889 | Val Loss: 0.7326\n",
      "Epoch 21 | Train Loss: 0.7752 | Val Loss: 0.7228\n",
      "Epoch 22 | Train Loss: 0.7692 | Val Loss: 0.7178\n",
      "Epoch 23 | Train Loss: 0.7607 | Val Loss: 0.7125\n",
      "Epoch 24 | Train Loss: 0.7770 | Val Loss: 0.7037\n",
      "Epoch 25 | Train Loss: 0.7524 | Val Loss: 0.7007\n",
      "Epoch 26 | Train Loss: 0.7514 | Val Loss: 0.6967\n",
      "Epoch 27 | Train Loss: 0.7507 | Val Loss: 0.6903\n",
      "Epoch 28 | Train Loss: 0.7552 | Val Loss: 0.6900\n",
      "Epoch 29 | Train Loss: 0.7580 | Val Loss: 0.6894\n",
      "Epoch 30 | Train Loss: 0.7526 | Val Loss: 0.6889\n",
      "Epoch 31 | Train Loss: 0.7251 | Val Loss: 0.6830\n",
      "Epoch 32 | Train Loss: 0.7509 | Val Loss: 0.6782\n",
      "Epoch 33 | Train Loss: 0.7571 | Val Loss: 0.6888\n",
      "Epoch 34 | Train Loss: 0.7365 | Val Loss: 0.6815\n",
      "Epoch 35 | Train Loss: 0.7525 | Val Loss: 0.6730\n",
      "Epoch 36 | Train Loss: 0.7379 | Val Loss: 0.6932\n",
      "Epoch 37 | Train Loss: 0.7312 | Val Loss: 0.6736\n",
      "Epoch 38 | Train Loss: 0.7357 | Val Loss: 0.6676\n",
      "Epoch 39 | Train Loss: 0.7427 | Val Loss: 0.6667\n",
      "Epoch 40 | Train Loss: 0.7303 | Val Loss: 0.6668\n",
      "Epoch 41 | Train Loss: 0.7210 | Val Loss: 0.6658\n",
      "Epoch 42 | Train Loss: 0.7334 | Val Loss: 0.6664\n",
      "Epoch 43 | Train Loss: 0.7281 | Val Loss: 0.6830\n",
      "Epoch 44 | Train Loss: 0.7244 | Val Loss: 0.6735\n",
      "Epoch 45 | Train Loss: 0.7265 | Val Loss: 0.6677\n",
      "Epoch 46 | Train Loss: 0.7457 | Val Loss: 0.6786\n",
      "Epoch 47 | Train Loss: 0.7701 | Val Loss: 0.6890\n",
      "Epoch 48 | Train Loss: 0.7429 | Val Loss: 0.6782\n",
      "Epoch 49 | Train Loss: 0.7185 | Val Loss: 0.6737\n",
      "Epoch 50 | Train Loss: 0.7172 | Val Loss: 0.6644\n",
      "Fold 4 ‚ñ∂ AUC: 0.796, Balanced Acc: 0.553\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9379 | Val Loss: 0.9076\n",
      "Epoch 02 | Train Loss: 0.8803 | Val Loss: 0.9004\n",
      "Epoch 03 | Train Loss: 0.8773 | Val Loss: 0.8892\n",
      "Epoch 04 | Train Loss: 0.8541 | Val Loss: 0.8860\n",
      "Epoch 05 | Train Loss: 0.8612 | Val Loss: 0.8890\n",
      "Epoch 06 | Train Loss: 0.8525 | Val Loss: 0.8755\n",
      "Epoch 07 | Train Loss: 0.8573 | Val Loss: 0.8725\n",
      "Epoch 08 | Train Loss: 0.8533 | Val Loss: 0.8670\n",
      "Epoch 09 | Train Loss: 0.8257 | Val Loss: 0.8611\n",
      "Epoch 10 | Train Loss: 0.8227 | Val Loss: 0.8484\n",
      "Epoch 11 | Train Loss: 0.8013 | Val Loss: 0.8455\n",
      "Epoch 12 | Train Loss: 0.7832 | Val Loss: 0.8555\n",
      "Epoch 13 | Train Loss: 0.7943 | Val Loss: 0.8565\n",
      "Epoch 14 | Train Loss: 0.7984 | Val Loss: 0.8622\n",
      "Epoch 15 | Train Loss: 0.7869 | Val Loss: 0.8283\n",
      "Epoch 16 | Train Loss: 0.7578 | Val Loss: 0.8324\n",
      "Epoch 17 | Train Loss: 0.7597 | Val Loss: 0.8332\n",
      "Epoch 18 | Train Loss: 0.7476 | Val Loss: 0.8472\n",
      "Epoch 19 | Train Loss: 0.7708 | Val Loss: 0.8258\n",
      "Epoch 20 | Train Loss: 0.7607 | Val Loss: 0.8246\n",
      "Epoch 21 | Train Loss: 0.7389 | Val Loss: 0.8227\n",
      "Epoch 22 | Train Loss: 0.7745 | Val Loss: 0.8241\n",
      "Epoch 23 | Train Loss: 0.7479 | Val Loss: 0.8177\n",
      "Epoch 24 | Train Loss: 0.7662 | Val Loss: 0.8166\n",
      "Epoch 25 | Train Loss: 0.7411 | Val Loss: 0.8143\n",
      "Epoch 26 | Train Loss: 0.7390 | Val Loss: 0.8178\n",
      "Epoch 27 | Train Loss: 0.7572 | Val Loss: 0.8168\n",
      "Epoch 28 | Train Loss: 0.7424 | Val Loss: 0.8235\n",
      "Epoch 29 | Train Loss: 0.7504 | Val Loss: 0.8106\n",
      "Epoch 30 | Train Loss: 0.7259 | Val Loss: 0.8102\n",
      "Epoch 31 | Train Loss: 0.7357 | Val Loss: 0.8069\n",
      "Epoch 32 | Train Loss: 0.7411 | Val Loss: 0.8195\n",
      "Epoch 33 | Train Loss: 0.7207 | Val Loss: 0.8381\n",
      "Epoch 34 | Train Loss: 0.7548 | Val Loss: 0.8163\n",
      "Epoch 35 | Train Loss: 0.7593 | Val Loss: 0.8072\n",
      "Epoch 36 | Train Loss: 0.7312 | Val Loss: 0.8031\n",
      "Epoch 37 | Train Loss: 0.7128 | Val Loss: 0.8043\n",
      "Epoch 38 | Train Loss: 0.7244 | Val Loss: 0.8123\n",
      "Epoch 39 | Train Loss: 0.7268 | Val Loss: 0.8039\n",
      "Epoch 40 | Train Loss: 0.7290 | Val Loss: 0.8015\n",
      "Epoch 41 | Train Loss: 0.7408 | Val Loss: 0.8095\n",
      "Epoch 42 | Train Loss: 0.7438 | Val Loss: 0.8213\n",
      "Epoch 43 | Train Loss: 0.7347 | Val Loss: 0.7952\n",
      "Epoch 44 | Train Loss: 0.7300 | Val Loss: 0.8154\n",
      "Epoch 45 | Train Loss: 0.7106 | Val Loss: 0.8200\n",
      "Epoch 46 | Train Loss: 0.7145 | Val Loss: 0.8008\n",
      "Epoch 47 | Train Loss: 0.7056 | Val Loss: 0.8203\n",
      "Epoch 48 | Train Loss: 0.7252 | Val Loss: 0.7958\n",
      "Epoch 49 | Train Loss: 0.7248 | Val Loss: 0.7933\n",
      "Epoch 50 | Train Loss: 0.7073 | Val Loss: 0.7974\n",
      "Fold 5 ‚ñ∂ AUC: 0.734, Balanced Acc: 0.490\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9039 | Val Loss: 0.9259\n",
      "Epoch 02 | Train Loss: 0.8725 | Val Loss: 0.8950\n",
      "Epoch 03 | Train Loss: 0.8773 | Val Loss: 0.8964\n",
      "Epoch 04 | Train Loss: 0.8818 | Val Loss: 0.8936\n",
      "Epoch 05 | Train Loss: 0.8560 | Val Loss: 0.8903\n",
      "Epoch 06 | Train Loss: 0.8662 | Val Loss: 0.9005\n",
      "Epoch 07 | Train Loss: 0.8614 | Val Loss: 0.8857\n",
      "Epoch 08 | Train Loss: 0.8460 | Val Loss: 0.8803\n",
      "Epoch 09 | Train Loss: 0.8376 | Val Loss: 0.8832\n",
      "Epoch 10 | Train Loss: 0.8411 | Val Loss: 0.8743\n",
      "Epoch 11 | Train Loss: 0.8415 | Val Loss: 0.8546\n",
      "Epoch 12 | Train Loss: 0.8349 | Val Loss: 0.8598\n",
      "Epoch 13 | Train Loss: 0.8141 | Val Loss: 0.8419\n",
      "Epoch 14 | Train Loss: 0.8064 | Val Loss: 0.8560\n",
      "Epoch 15 | Train Loss: 0.7714 | Val Loss: 0.8590\n",
      "Epoch 16 | Train Loss: 0.7701 | Val Loss: 0.8624\n",
      "Epoch 17 | Train Loss: 0.7716 | Val Loss: 0.8396\n",
      "Epoch 18 | Train Loss: 0.7689 | Val Loss: 0.8726\n",
      "Epoch 19 | Train Loss: 0.7995 | Val Loss: 0.8589\n",
      "Epoch 20 | Train Loss: 0.7667 | Val Loss: 0.8186\n",
      "Epoch 21 | Train Loss: 0.7769 | Val Loss: 0.8725\n",
      "Epoch 22 | Train Loss: 0.7794 | Val Loss: 0.8172\n",
      "Epoch 23 | Train Loss: 0.7907 | Val Loss: 0.8390\n",
      "Epoch 24 | Train Loss: 0.7681 | Val Loss: 0.8148\n",
      "Epoch 25 | Train Loss: 0.7537 | Val Loss: 0.8170\n",
      "Epoch 26 | Train Loss: 0.7476 | Val Loss: 0.8159\n",
      "Epoch 27 | Train Loss: 0.7245 | Val Loss: 0.8272\n",
      "Epoch 28 | Train Loss: 0.7322 | Val Loss: 0.8284\n",
      "Epoch 29 | Train Loss: 0.7571 | Val Loss: 0.8265\n",
      "Epoch 30 | Train Loss: 0.7314 | Val Loss: 0.8159\n",
      "Epoch 31 | Train Loss: 0.7382 | Val Loss: 0.8295\n",
      "Epoch 32 | Train Loss: 0.7247 | Val Loss: 0.8216\n",
      "Epoch 33 | Train Loss: 0.7265 | Val Loss: 0.8188\n",
      "Epoch 34 | Train Loss: 0.7288 | Val Loss: 0.8240\n",
      "Epoch 35 | Train Loss: 0.7350 | Val Loss: 0.8244\n",
      "Epoch 36 | Train Loss: 0.7244 | Val Loss: 0.8461\n",
      "Epoch 37 | Train Loss: 0.7540 | Val Loss: 0.8289\n",
      "Epoch 38 | Train Loss: 0.7407 | Val Loss: 0.8181\n",
      "Epoch 39 | Train Loss: 0.7360 | Val Loss: 0.8170\n",
      "Epoch 40 | Train Loss: 0.7551 | Val Loss: 0.8214\n",
      "Epoch 41 | Train Loss: 0.7302 | Val Loss: 0.8178\n",
      "Epoch 42 | Train Loss: 0.7204 | Val Loss: 0.8143\n",
      "Epoch 43 | Train Loss: 0.7243 | Val Loss: 0.8206\n",
      "Epoch 44 | Train Loss: 0.7128 | Val Loss: 0.8263\n",
      "Epoch 45 | Train Loss: 0.7157 | Val Loss: 0.8272\n",
      "Epoch 46 | Train Loss: 0.7098 | Val Loss: 0.8195\n",
      "Epoch 47 | Train Loss: 0.7130 | Val Loss: 0.8245\n",
      "Epoch 48 | Train Loss: 0.7125 | Val Loss: 0.8284\n",
      "Epoch 49 | Train Loss: 0.7328 | Val Loss: 0.8351\n",
      "Epoch 50 | Train Loss: 0.7686 | Val Loss: 0.8811\n",
      "Fold 6 ‚ñ∂ AUC: 0.728, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 1.0276 | Val Loss: 0.8851\n",
      "Epoch 02 | Train Loss: 0.8977 | Val Loss: 0.8595\n",
      "Epoch 03 | Train Loss: 0.8733 | Val Loss: 0.8586\n",
      "Epoch 04 | Train Loss: 0.8772 | Val Loss: 0.8565\n",
      "Epoch 05 | Train Loss: 0.8780 | Val Loss: 0.8573\n",
      "Epoch 06 | Train Loss: 0.8581 | Val Loss: 0.8505\n",
      "Epoch 07 | Train Loss: 0.8672 | Val Loss: 0.8465\n",
      "Epoch 08 | Train Loss: 0.8688 | Val Loss: 0.8397\n",
      "Epoch 09 | Train Loss: 0.8615 | Val Loss: 0.8340\n",
      "Epoch 10 | Train Loss: 0.8571 | Val Loss: 0.8381\n",
      "Epoch 11 | Train Loss: 0.8579 | Val Loss: 0.8293\n",
      "Epoch 12 | Train Loss: 0.8487 | Val Loss: 0.8234\n",
      "Epoch 13 | Train Loss: 0.8404 | Val Loss: 0.8099\n",
      "Epoch 14 | Train Loss: 0.8204 | Val Loss: 0.7932\n",
      "Epoch 15 | Train Loss: 0.8231 | Val Loss: 0.7794\n",
      "Epoch 16 | Train Loss: 0.8082 | Val Loss: 0.7632\n",
      "Epoch 17 | Train Loss: 0.8299 | Val Loss: 0.7533\n",
      "Epoch 18 | Train Loss: 0.8023 | Val Loss: 0.7505\n",
      "Epoch 19 | Train Loss: 0.7958 | Val Loss: 0.7400\n",
      "Epoch 20 | Train Loss: 0.7725 | Val Loss: 0.7270\n",
      "Epoch 21 | Train Loss: 0.7829 | Val Loss: 0.7445\n",
      "Epoch 22 | Train Loss: 0.7809 | Val Loss: 0.7307\n",
      "Epoch 23 | Train Loss: 0.7714 | Val Loss: 0.7165\n",
      "Epoch 24 | Train Loss: 0.7765 | Val Loss: 0.7147\n",
      "Epoch 25 | Train Loss: 0.7637 | Val Loss: 0.7178\n",
      "Epoch 26 | Train Loss: 0.7627 | Val Loss: 0.7107\n",
      "Epoch 27 | Train Loss: 0.7658 | Val Loss: 0.7912\n",
      "Epoch 28 | Train Loss: 0.7904 | Val Loss: 0.7175\n",
      "Epoch 29 | Train Loss: 0.7802 | Val Loss: 0.7210\n",
      "Epoch 30 | Train Loss: 0.7443 | Val Loss: 0.7196\n",
      "Epoch 31 | Train Loss: 0.7590 | Val Loss: 0.7054\n",
      "Epoch 32 | Train Loss: 0.7548 | Val Loss: 0.7110\n",
      "Epoch 33 | Train Loss: 0.7585 | Val Loss: 0.7120\n",
      "Epoch 34 | Train Loss: 0.7445 | Val Loss: 0.7206\n",
      "Epoch 35 | Train Loss: 0.7645 | Val Loss: 0.7123\n",
      "Epoch 36 | Train Loss: 0.7286 | Val Loss: 0.7078\n",
      "Epoch 37 | Train Loss: 0.7325 | Val Loss: 0.7213\n",
      "Epoch 38 | Train Loss: 0.7311 | Val Loss: 0.7146\n",
      "Epoch 39 | Train Loss: 0.7499 | Val Loss: 0.7135\n",
      "Epoch 40 | Train Loss: 0.7559 | Val Loss: 0.7387\n",
      "Epoch 41 | Train Loss: 0.7290 | Val Loss: 0.7251\n",
      "Epoch 42 | Train Loss: 0.7262 | Val Loss: 0.7456\n",
      "Epoch 43 | Train Loss: 0.7471 | Val Loss: 0.7317\n",
      "Epoch 44 | Train Loss: 0.7200 | Val Loss: 0.7276\n",
      "Epoch 45 | Train Loss: 0.7129 | Val Loss: 0.7362\n",
      "Epoch 46 | Train Loss: 0.7303 | Val Loss: 0.7492\n",
      "Epoch 47 | Train Loss: 0.7463 | Val Loss: 0.7356\n",
      "Epoch 48 | Train Loss: 0.7158 | Val Loss: 0.7312\n",
      "Epoch 49 | Train Loss: 0.7418 | Val Loss: 0.7355\n",
      "Epoch 50 | Train Loss: 0.7331 | Val Loss: 0.7414\n",
      "Fold 7 ‚ñ∂ AUC: 0.748, Balanced Acc: 0.462\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9011 | Val Loss: 0.8710\n",
      "Epoch 02 | Train Loss: 0.8728 | Val Loss: 0.8699\n",
      "Epoch 03 | Train Loss: 0.8723 | Val Loss: 0.8644\n",
      "Epoch 04 | Train Loss: 0.8586 | Val Loss: 0.8613\n",
      "Epoch 05 | Train Loss: 0.8495 | Val Loss: 0.8539\n",
      "Epoch 06 | Train Loss: 0.8559 | Val Loss: 0.8499\n",
      "Epoch 07 | Train Loss: 0.8483 | Val Loss: 0.8425\n",
      "Epoch 08 | Train Loss: 0.8371 | Val Loss: 0.8381\n",
      "Epoch 09 | Train Loss: 0.8333 | Val Loss: 0.8338\n",
      "Epoch 10 | Train Loss: 0.8251 | Val Loss: 0.8207\n",
      "Epoch 11 | Train Loss: 0.7997 | Val Loss: 0.8445\n",
      "Epoch 12 | Train Loss: 0.8151 | Val Loss: 0.8061\n",
      "Epoch 13 | Train Loss: 0.7867 | Val Loss: 0.8011\n",
      "Epoch 14 | Train Loss: 0.7822 | Val Loss: 0.8018\n",
      "Epoch 15 | Train Loss: 0.7660 | Val Loss: 0.8092\n",
      "Epoch 16 | Train Loss: 0.7777 | Val Loss: 0.8215\n",
      "Epoch 17 | Train Loss: 0.7878 | Val Loss: 0.8286\n",
      "Epoch 18 | Train Loss: 0.7797 | Val Loss: 0.8606\n",
      "Epoch 19 | Train Loss: 0.7937 | Val Loss: 0.8076\n",
      "Epoch 20 | Train Loss: 0.7786 | Val Loss: 0.8123\n",
      "Epoch 21 | Train Loss: 0.7407 | Val Loss: 0.8049\n",
      "Epoch 22 | Train Loss: 0.7398 | Val Loss: 0.8059\n",
      "Epoch 23 | Train Loss: 0.7553 | Val Loss: 0.8075\n",
      "Epoch 24 | Train Loss: 0.7390 | Val Loss: 0.8068\n",
      "Epoch 25 | Train Loss: 0.7525 | Val Loss: 0.8036\n",
      "Epoch 26 | Train Loss: 0.7396 | Val Loss: 0.8396\n",
      "Epoch 27 | Train Loss: 0.7781 | Val Loss: 0.8715\n",
      "Epoch 28 | Train Loss: 0.7647 | Val Loss: 0.7963\n",
      "Epoch 29 | Train Loss: 0.7477 | Val Loss: 0.7983\n",
      "Epoch 30 | Train Loss: 0.7344 | Val Loss: 0.8053\n",
      "Epoch 31 | Train Loss: 0.7362 | Val Loss: 0.8204\n",
      "Epoch 32 | Train Loss: 0.7531 | Val Loss: 0.8018\n",
      "Epoch 33 | Train Loss: 0.7474 | Val Loss: 0.8163\n",
      "Epoch 34 | Train Loss: 0.7271 | Val Loss: 0.8004\n",
      "Epoch 35 | Train Loss: 0.7325 | Val Loss: 0.8168\n",
      "Epoch 36 | Train Loss: 0.7586 | Val Loss: 0.8079\n",
      "Epoch 37 | Train Loss: 0.7233 | Val Loss: 0.7993\n",
      "Epoch 38 | Train Loss: 0.7247 | Val Loss: 0.8077\n",
      "Epoch 39 | Train Loss: 0.7361 | Val Loss: 0.8205\n",
      "Epoch 40 | Train Loss: 0.7488 | Val Loss: 0.8088\n",
      "Epoch 41 | Train Loss: 0.7319 | Val Loss: 0.8085\n",
      "Epoch 42 | Train Loss: 0.7118 | Val Loss: 0.8053\n",
      "Epoch 43 | Train Loss: 0.7351 | Val Loss: 0.8027\n",
      "Epoch 44 | Train Loss: 0.7230 | Val Loss: 0.8033\n",
      "Epoch 45 | Train Loss: 0.7205 | Val Loss: 0.8059\n",
      "Epoch 46 | Train Loss: 0.7304 | Val Loss: 0.8145\n",
      "Epoch 47 | Train Loss: 0.7325 | Val Loss: 0.8060\n",
      "Epoch 48 | Train Loss: 0.7081 | Val Loss: 0.7925\n",
      "Epoch 49 | Train Loss: 0.7122 | Val Loss: 0.8035\n",
      "Epoch 50 | Train Loss: 0.7073 | Val Loss: 0.8025\n",
      "Fold 8 ‚ñ∂ AUC: 0.708, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9718 | Val Loss: 0.8817\n",
      "Epoch 02 | Train Loss: 0.8836 | Val Loss: 0.8854\n",
      "Epoch 03 | Train Loss: 0.8855 | Val Loss: 0.8764\n",
      "Epoch 04 | Train Loss: 0.8699 | Val Loss: 0.8705\n",
      "Epoch 05 | Train Loss: 0.8570 | Val Loss: 0.8676\n",
      "Epoch 06 | Train Loss: 0.8648 | Val Loss: 0.8697\n",
      "Epoch 07 | Train Loss: 0.8535 | Val Loss: 0.8631\n",
      "Epoch 08 | Train Loss: 0.8676 | Val Loss: 0.8619\n",
      "Epoch 09 | Train Loss: 0.8609 | Val Loss: 0.8604\n",
      "Epoch 10 | Train Loss: 0.8421 | Val Loss: 0.8724\n",
      "Epoch 11 | Train Loss: 0.8406 | Val Loss: 0.8642\n",
      "Epoch 12 | Train Loss: 0.8577 | Val Loss: 0.8526\n",
      "Epoch 13 | Train Loss: 0.8262 | Val Loss: 0.8549\n",
      "Epoch 14 | Train Loss: 0.8305 | Val Loss: 0.8461\n",
      "Epoch 15 | Train Loss: 0.8233 | Val Loss: 0.8434\n",
      "Epoch 16 | Train Loss: 0.8004 | Val Loss: 0.8679\n",
      "Epoch 17 | Train Loss: 0.8339 | Val Loss: 0.8447\n",
      "Epoch 18 | Train Loss: 0.8065 | Val Loss: 0.8295\n",
      "Epoch 19 | Train Loss: 0.7778 | Val Loss: 0.8260\n",
      "Epoch 20 | Train Loss: 0.7839 | Val Loss: 0.8438\n",
      "Epoch 21 | Train Loss: 0.7762 | Val Loss: 0.8185\n",
      "Epoch 22 | Train Loss: 0.7720 | Val Loss: 0.8429\n",
      "Epoch 23 | Train Loss: 0.7939 | Val Loss: 0.8175\n",
      "Epoch 24 | Train Loss: 0.7559 | Val Loss: 0.8091\n",
      "Epoch 25 | Train Loss: 0.7526 | Val Loss: 0.8057\n",
      "Epoch 26 | Train Loss: 0.7556 | Val Loss: 0.8261\n",
      "Epoch 27 | Train Loss: 0.7699 | Val Loss: 0.8251\n",
      "Epoch 28 | Train Loss: 0.7690 | Val Loss: 0.8034\n",
      "Epoch 29 | Train Loss: 0.7682 | Val Loss: 0.8051\n",
      "Epoch 30 | Train Loss: 0.7603 | Val Loss: 0.8014\n",
      "Epoch 31 | Train Loss: 0.7389 | Val Loss: 0.7902\n",
      "Epoch 32 | Train Loss: 0.7748 | Val Loss: 0.7967\n",
      "Epoch 33 | Train Loss: 0.7401 | Val Loss: 0.7896\n",
      "Epoch 34 | Train Loss: 0.7438 | Val Loss: 0.7926\n",
      "Epoch 35 | Train Loss: 0.7272 | Val Loss: 0.7890\n",
      "Epoch 36 | Train Loss: 0.7641 | Val Loss: 0.7997\n",
      "Epoch 37 | Train Loss: 0.7229 | Val Loss: 0.7978\n",
      "Epoch 38 | Train Loss: 0.7391 | Val Loss: 0.7867\n",
      "Epoch 39 | Train Loss: 0.7355 | Val Loss: 0.7836\n",
      "Epoch 40 | Train Loss: 0.7435 | Val Loss: 0.7840\n",
      "Epoch 41 | Train Loss: 0.7262 | Val Loss: 0.7756\n",
      "Epoch 42 | Train Loss: 0.7330 | Val Loss: 0.7736\n",
      "Epoch 43 | Train Loss: 0.7430 | Val Loss: 0.7741\n",
      "Epoch 44 | Train Loss: 0.7587 | Val Loss: 0.8010\n",
      "Epoch 45 | Train Loss: 0.7211 | Val Loss: 0.7742\n",
      "Epoch 46 | Train Loss: 0.7382 | Val Loss: 0.8181\n",
      "Epoch 47 | Train Loss: 0.7528 | Val Loss: 0.7954\n",
      "Epoch 48 | Train Loss: 0.7380 | Val Loss: 0.7654\n",
      "Epoch 49 | Train Loss: 0.7244 | Val Loss: 0.7662\n",
      "Epoch 50 | Train Loss: 0.7285 | Val Loss: 0.7745\n",
      "Fold 9 ‚ñ∂ AUC: 0.712, Balanced Acc: 0.486\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9391 | Val Loss: 0.8735\n",
      "Epoch 02 | Train Loss: 0.8845 | Val Loss: 0.8720\n",
      "Epoch 03 | Train Loss: 0.8672 | Val Loss: 0.8643\n",
      "Epoch 04 | Train Loss: 0.8649 | Val Loss: 0.8595\n",
      "Epoch 05 | Train Loss: 0.8580 | Val Loss: 0.8587\n",
      "Epoch 06 | Train Loss: 0.8872 | Val Loss: 0.8554\n",
      "Epoch 07 | Train Loss: 0.8655 | Val Loss: 0.8483\n",
      "Epoch 08 | Train Loss: 0.8475 | Val Loss: 0.8390\n",
      "Epoch 09 | Train Loss: 0.8419 | Val Loss: 0.8313\n",
      "Epoch 10 | Train Loss: 0.8356 | Val Loss: 0.8271\n",
      "Epoch 11 | Train Loss: 0.8199 | Val Loss: 0.8240\n",
      "Epoch 12 | Train Loss: 0.8479 | Val Loss: 0.8113\n",
      "Epoch 13 | Train Loss: 0.8291 | Val Loss: 0.8476\n",
      "Epoch 14 | Train Loss: 0.8124 | Val Loss: 0.7898\n",
      "Epoch 15 | Train Loss: 0.7978 | Val Loss: 0.7867\n",
      "Epoch 16 | Train Loss: 0.7801 | Val Loss: 0.7862\n",
      "Epoch 17 | Train Loss: 0.7955 | Val Loss: 0.7739\n",
      "Epoch 18 | Train Loss: 0.7890 | Val Loss: 0.7690\n",
      "Epoch 19 | Train Loss: 0.7591 | Val Loss: 0.7647\n",
      "Epoch 20 | Train Loss: 0.7664 | Val Loss: 0.7684\n",
      "Epoch 21 | Train Loss: 0.7694 | Val Loss: 0.7758\n",
      "Epoch 22 | Train Loss: 0.7661 | Val Loss: 0.7603\n",
      "Epoch 23 | Train Loss: 0.7558 | Val Loss: 0.7580\n",
      "Epoch 24 | Train Loss: 0.7650 | Val Loss: 0.7636\n",
      "Epoch 25 | Train Loss: 0.7576 | Val Loss: 0.8656\n",
      "Epoch 26 | Train Loss: 0.7598 | Val Loss: 0.7700\n",
      "Epoch 27 | Train Loss: 0.7516 | Val Loss: 0.7764\n",
      "Epoch 28 | Train Loss: 0.7406 | Val Loss: 0.7638\n",
      "Epoch 29 | Train Loss: 0.7372 | Val Loss: 0.8039\n",
      "Epoch 30 | Train Loss: 0.7463 | Val Loss: 0.7675\n",
      "Epoch 31 | Train Loss: 0.7343 | Val Loss: 0.7771\n",
      "Epoch 32 | Train Loss: 0.7216 | Val Loss: 0.7639\n",
      "Epoch 33 | Train Loss: 0.7353 | Val Loss: 0.7584\n",
      "Epoch 34 | Train Loss: 0.7327 | Val Loss: 0.7636\n",
      "Epoch 35 | Train Loss: 0.7628 | Val Loss: 0.7748\n",
      "Epoch 36 | Train Loss: 0.7201 | Val Loss: 0.8493\n",
      "Epoch 37 | Train Loss: 0.7616 | Val Loss: 0.7629\n",
      "Epoch 38 | Train Loss: 0.7374 | Val Loss: 0.7689\n",
      "Epoch 39 | Train Loss: 0.7348 | Val Loss: 0.7689\n",
      "Epoch 40 | Train Loss: 0.7243 | Val Loss: 0.7904\n",
      "Epoch 41 | Train Loss: 0.7222 | Val Loss: 0.7865\n",
      "Epoch 42 | Train Loss: 0.7324 | Val Loss: 0.7649\n",
      "Epoch 43 | Train Loss: 0.7354 | Val Loss: 0.7622\n",
      "Epoch 44 | Train Loss: 0.7278 | Val Loss: 0.8287\n",
      "Epoch 45 | Train Loss: 0.7342 | Val Loss: 0.7680\n",
      "Epoch 46 | Train Loss: 0.7165 | Val Loss: 0.7631\n",
      "Epoch 47 | Train Loss: 0.7086 | Val Loss: 0.7800\n",
      "Epoch 48 | Train Loss: 0.7192 | Val Loss: 0.7648\n",
      "Epoch 49 | Train Loss: 0.7150 | Val Loss: 0.7865\n",
      "Epoch 50 | Train Loss: 0.7212 | Val Loss: 0.7716\n",
      "Fold 10 ‚ñ∂ AUC: 0.727, Balanced Acc: 0.451\n",
      "üîç Summary for hd=64, dp=0.2, lr=0.0005 ‚Üí AUC: 0.7361¬±0.0327 | BalAcc: 0.4820¬±0.0474\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.2, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 1.0154 | Val Loss: 0.9393\n",
      "Epoch 02 | Train Loss: 0.9188 | Val Loss: 0.8875\n",
      "Epoch 03 | Train Loss: 0.8854 | Val Loss: 0.8691\n",
      "Epoch 04 | Train Loss: 0.8750 | Val Loss: 0.8643\n",
      "Epoch 05 | Train Loss: 0.8701 | Val Loss: 0.8648\n",
      "Epoch 06 | Train Loss: 0.8662 | Val Loss: 0.8633\n",
      "Epoch 07 | Train Loss: 0.8636 | Val Loss: 0.8615\n",
      "Epoch 08 | Train Loss: 0.8635 | Val Loss: 0.8610\n",
      "Epoch 09 | Train Loss: 0.8643 | Val Loss: 0.8596\n",
      "Epoch 10 | Train Loss: 0.8598 | Val Loss: 0.8591\n",
      "Epoch 11 | Train Loss: 0.8636 | Val Loss: 0.8605\n",
      "Epoch 12 | Train Loss: 0.8664 | Val Loss: 0.8573\n",
      "Epoch 13 | Train Loss: 0.8625 | Val Loss: 0.8578\n",
      "Epoch 14 | Train Loss: 0.8675 | Val Loss: 0.8560\n",
      "Epoch 15 | Train Loss: 0.8660 | Val Loss: 0.8551\n",
      "Epoch 16 | Train Loss: 0.8861 | Val Loss: 0.8555\n",
      "Epoch 17 | Train Loss: 0.8578 | Val Loss: 0.8547\n",
      "Epoch 18 | Train Loss: 0.8552 | Val Loss: 0.8533\n",
      "Epoch 19 | Train Loss: 0.8629 | Val Loss: 0.8517\n",
      "Epoch 20 | Train Loss: 0.8660 | Val Loss: 0.8515\n",
      "Epoch 21 | Train Loss: 0.8534 | Val Loss: 0.8500\n",
      "Epoch 22 | Train Loss: 0.8449 | Val Loss: 0.8490\n",
      "Epoch 23 | Train Loss: 0.8626 | Val Loss: 0.8484\n",
      "Epoch 24 | Train Loss: 0.8487 | Val Loss: 0.8469\n",
      "Epoch 25 | Train Loss: 0.8463 | Val Loss: 0.8468\n",
      "Epoch 26 | Train Loss: 0.8449 | Val Loss: 0.8445\n",
      "Epoch 27 | Train Loss: 0.8522 | Val Loss: 0.8430\n",
      "Epoch 28 | Train Loss: 0.8526 | Val Loss: 0.8412\n",
      "Epoch 29 | Train Loss: 0.8464 | Val Loss: 0.8397\n",
      "Epoch 30 | Train Loss: 0.8458 | Val Loss: 0.8429\n",
      "Epoch 31 | Train Loss: 0.8432 | Val Loss: 0.8395\n",
      "Epoch 32 | Train Loss: 0.8510 | Val Loss: 0.8371\n",
      "Epoch 33 | Train Loss: 0.8392 | Val Loss: 0.8350\n",
      "Epoch 34 | Train Loss: 0.8381 | Val Loss: 0.8328\n",
      "Epoch 35 | Train Loss: 0.8435 | Val Loss: 0.8316\n",
      "Epoch 36 | Train Loss: 0.8277 | Val Loss: 0.8301\n",
      "Epoch 37 | Train Loss: 0.8444 | Val Loss: 0.8308\n",
      "Epoch 38 | Train Loss: 0.8354 | Val Loss: 0.8278\n",
      "Epoch 39 | Train Loss: 0.8503 | Val Loss: 0.8245\n",
      "Epoch 40 | Train Loss: 0.8363 | Val Loss: 0.8228\n",
      "Epoch 41 | Train Loss: 0.8374 | Val Loss: 0.8212\n",
      "Epoch 42 | Train Loss: 0.8320 | Val Loss: 0.8189\n",
      "Epoch 43 | Train Loss: 0.8309 | Val Loss: 0.8163\n",
      "Epoch 44 | Train Loss: 0.8204 | Val Loss: 0.8139\n",
      "Epoch 45 | Train Loss: 0.8293 | Val Loss: 0.8122\n",
      "Epoch 46 | Train Loss: 0.8143 | Val Loss: 0.8099\n",
      "Epoch 47 | Train Loss: 0.8132 | Val Loss: 0.8080\n",
      "Epoch 48 | Train Loss: 0.8151 | Val Loss: 0.8051\n",
      "Epoch 49 | Train Loss: 0.8084 | Val Loss: 0.8032\n",
      "Epoch 50 | Train Loss: 0.8063 | Val Loss: 0.8012\n",
      "Fold 1 ‚ñ∂ AUC: 0.755, Balanced Acc: 0.440\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 1.0683 | Val Loss: 0.9570\n",
      "Epoch 02 | Train Loss: 0.9257 | Val Loss: 0.8837\n",
      "Epoch 03 | Train Loss: 0.8827 | Val Loss: 0.8666\n",
      "Epoch 04 | Train Loss: 0.8695 | Val Loss: 0.8633\n",
      "Epoch 05 | Train Loss: 0.8798 | Val Loss: 0.8623\n",
      "Epoch 06 | Train Loss: 0.8688 | Val Loss: 0.8618\n",
      "Epoch 07 | Train Loss: 0.8798 | Val Loss: 0.8614\n",
      "Epoch 08 | Train Loss: 0.8696 | Val Loss: 0.8609\n",
      "Epoch 09 | Train Loss: 0.8742 | Val Loss: 0.8604\n",
      "Epoch 10 | Train Loss: 0.8614 | Val Loss: 0.8599\n",
      "Epoch 11 | Train Loss: 0.8708 | Val Loss: 0.8597\n",
      "Epoch 12 | Train Loss: 0.8633 | Val Loss: 0.8593\n",
      "Epoch 13 | Train Loss: 0.8693 | Val Loss: 0.8589\n",
      "Epoch 14 | Train Loss: 0.8562 | Val Loss: 0.8584\n",
      "Epoch 15 | Train Loss: 0.8618 | Val Loss: 0.8580\n",
      "Epoch 16 | Train Loss: 0.8737 | Val Loss: 0.8579\n",
      "Epoch 17 | Train Loss: 0.8599 | Val Loss: 0.8580\n",
      "Epoch 18 | Train Loss: 0.8630 | Val Loss: 0.8571\n",
      "Epoch 19 | Train Loss: 0.8691 | Val Loss: 0.8567\n",
      "Epoch 20 | Train Loss: 0.8614 | Val Loss: 0.8560\n",
      "Epoch 21 | Train Loss: 0.8582 | Val Loss: 0.8578\n",
      "Epoch 22 | Train Loss: 0.8727 | Val Loss: 0.8551\n",
      "Epoch 23 | Train Loss: 0.8614 | Val Loss: 0.8543\n",
      "Epoch 24 | Train Loss: 0.8520 | Val Loss: 0.8536\n",
      "Epoch 25 | Train Loss: 0.8635 | Val Loss: 0.8563\n",
      "Epoch 26 | Train Loss: 0.8572 | Val Loss: 0.8534\n",
      "Epoch 27 | Train Loss: 0.8728 | Val Loss: 0.8519\n",
      "Epoch 28 | Train Loss: 0.8553 | Val Loss: 0.8513\n",
      "Epoch 29 | Train Loss: 0.8451 | Val Loss: 0.8520\n",
      "Epoch 30 | Train Loss: 0.8511 | Val Loss: 0.8491\n",
      "Epoch 31 | Train Loss: 0.8633 | Val Loss: 0.8491\n",
      "Epoch 32 | Train Loss: 0.8482 | Val Loss: 0.8477\n",
      "Epoch 33 | Train Loss: 0.8450 | Val Loss: 0.8474\n",
      "Epoch 34 | Train Loss: 0.8546 | Val Loss: 0.8459\n",
      "Epoch 35 | Train Loss: 0.8564 | Val Loss: 0.8455\n",
      "Epoch 36 | Train Loss: 0.8411 | Val Loss: 0.8447\n",
      "Epoch 37 | Train Loss: 0.8486 | Val Loss: 0.8433\n",
      "Epoch 38 | Train Loss: 0.8447 | Val Loss: 0.8417\n",
      "Epoch 39 | Train Loss: 0.8454 | Val Loss: 0.8404\n",
      "Epoch 40 | Train Loss: 0.8530 | Val Loss: 0.8400\n",
      "Epoch 41 | Train Loss: 0.8534 | Val Loss: 0.8385\n",
      "Epoch 42 | Train Loss: 0.8448 | Val Loss: 0.8395\n",
      "Epoch 43 | Train Loss: 0.8419 | Val Loss: 0.8354\n",
      "Epoch 44 | Train Loss: 0.8303 | Val Loss: 0.8339\n",
      "Epoch 45 | Train Loss: 0.8434 | Val Loss: 0.8339\n",
      "Epoch 46 | Train Loss: 0.8493 | Val Loss: 0.8328\n",
      "Epoch 47 | Train Loss: 0.8278 | Val Loss: 0.8293\n",
      "Epoch 48 | Train Loss: 0.8534 | Val Loss: 0.8306\n",
      "Epoch 49 | Train Loss: 0.8398 | Val Loss: 0.8265\n",
      "Epoch 50 | Train Loss: 0.8280 | Val Loss: 0.8283\n",
      "Fold 2 ‚ñ∂ AUC: 0.674, Balanced Acc: 0.368\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 1.1918 | Val Loss: 1.0596\n",
      "Epoch 02 | Train Loss: 0.9976 | Val Loss: 0.9405\n",
      "Epoch 03 | Train Loss: 0.9147 | Val Loss: 0.8836\n",
      "Epoch 04 | Train Loss: 0.8715 | Val Loss: 0.8633\n",
      "Epoch 05 | Train Loss: 0.8692 | Val Loss: 0.8574\n",
      "Epoch 06 | Train Loss: 0.8645 | Val Loss: 0.8559\n",
      "Epoch 07 | Train Loss: 0.8569 | Val Loss: 0.8550\n",
      "Epoch 08 | Train Loss: 0.8623 | Val Loss: 0.8546\n",
      "Epoch 09 | Train Loss: 0.8611 | Val Loss: 0.8535\n",
      "Epoch 10 | Train Loss: 0.8594 | Val Loss: 0.8524\n",
      "Epoch 11 | Train Loss: 0.8773 | Val Loss: 0.8514\n",
      "Epoch 12 | Train Loss: 0.8733 | Val Loss: 0.8512\n",
      "Epoch 13 | Train Loss: 0.8577 | Val Loss: 0.8497\n",
      "Epoch 14 | Train Loss: 0.8572 | Val Loss: 0.8482\n",
      "Epoch 15 | Train Loss: 0.8712 | Val Loss: 0.8465\n",
      "Epoch 16 | Train Loss: 0.8540 | Val Loss: 0.8469\n",
      "Epoch 17 | Train Loss: 0.8526 | Val Loss: 0.8442\n",
      "Epoch 18 | Train Loss: 0.8625 | Val Loss: 0.8433\n",
      "Epoch 19 | Train Loss: 0.8586 | Val Loss: 0.8419\n",
      "Epoch 20 | Train Loss: 0.8584 | Val Loss: 0.8403\n",
      "Epoch 21 | Train Loss: 0.8502 | Val Loss: 0.8397\n",
      "Epoch 22 | Train Loss: 0.8419 | Val Loss: 0.8385\n",
      "Epoch 23 | Train Loss: 0.8455 | Val Loss: 0.8349\n",
      "Epoch 24 | Train Loss: 0.8545 | Val Loss: 0.8335\n",
      "Epoch 25 | Train Loss: 0.8426 | Val Loss: 0.8323\n",
      "Epoch 26 | Train Loss: 0.8386 | Val Loss: 0.8316\n",
      "Epoch 27 | Train Loss: 0.8567 | Val Loss: 0.8289\n",
      "Epoch 28 | Train Loss: 0.8390 | Val Loss: 0.8293\n",
      "Epoch 29 | Train Loss: 0.8312 | Val Loss: 0.8261\n",
      "Epoch 30 | Train Loss: 0.8446 | Val Loss: 0.8267\n",
      "Epoch 31 | Train Loss: 0.8294 | Val Loss: 0.8242\n",
      "Epoch 32 | Train Loss: 0.8368 | Val Loss: 0.8209\n",
      "Epoch 33 | Train Loss: 0.8325 | Val Loss: 0.8214\n",
      "Epoch 34 | Train Loss: 0.8349 | Val Loss: 0.8180\n",
      "Epoch 35 | Train Loss: 0.8460 | Val Loss: 0.8159\n",
      "Epoch 36 | Train Loss: 0.8355 | Val Loss: 0.8187\n",
      "Epoch 37 | Train Loss: 0.8361 | Val Loss: 0.8134\n",
      "Epoch 38 | Train Loss: 0.8275 | Val Loss: 0.8141\n",
      "Epoch 39 | Train Loss: 0.8316 | Val Loss: 0.8101\n",
      "Epoch 40 | Train Loss: 0.8183 | Val Loss: 0.8090\n",
      "Epoch 41 | Train Loss: 0.8224 | Val Loss: 0.8047\n",
      "Epoch 42 | Train Loss: 0.8209 | Val Loss: 0.8058\n",
      "Epoch 43 | Train Loss: 0.8090 | Val Loss: 0.8013\n",
      "Epoch 44 | Train Loss: 0.8150 | Val Loss: 0.8014\n",
      "Epoch 45 | Train Loss: 0.8170 | Val Loss: 0.7969\n",
      "Epoch 46 | Train Loss: 0.8141 | Val Loss: 0.7979\n",
      "Epoch 47 | Train Loss: 0.8100 | Val Loss: 0.7943\n",
      "Epoch 48 | Train Loss: 0.8130 | Val Loss: 0.7940\n",
      "Epoch 49 | Train Loss: 0.8082 | Val Loss: 0.7901\n",
      "Epoch 50 | Train Loss: 0.8162 | Val Loss: 0.7923\n",
      "Fold 3 ‚ñ∂ AUC: 0.768, Balanced Acc: 0.484\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 1.2735 | Val Loss: 1.1679\n",
      "Epoch 02 | Train Loss: 1.1161 | Val Loss: 1.0503\n",
      "Epoch 03 | Train Loss: 1.0137 | Val Loss: 0.9635\n",
      "Epoch 04 | Train Loss: 0.9444 | Val Loss: 0.9089\n",
      "Epoch 05 | Train Loss: 0.8978 | Val Loss: 0.8716\n",
      "Epoch 06 | Train Loss: 0.8832 | Val Loss: 0.8539\n",
      "Epoch 07 | Train Loss: 0.8746 | Val Loss: 0.8458\n",
      "Epoch 08 | Train Loss: 0.8655 | Val Loss: 0.8429\n",
      "Epoch 09 | Train Loss: 0.8687 | Val Loss: 0.8418\n",
      "Epoch 10 | Train Loss: 0.8760 | Val Loss: 0.8405\n",
      "Epoch 11 | Train Loss: 0.8711 | Val Loss: 0.8410\n",
      "Epoch 12 | Train Loss: 0.8621 | Val Loss: 0.8395\n",
      "Epoch 13 | Train Loss: 0.8641 | Val Loss: 0.8381\n",
      "Epoch 14 | Train Loss: 0.8543 | Val Loss: 0.8366\n",
      "Epoch 15 | Train Loss: 0.8664 | Val Loss: 0.8349\n",
      "Epoch 16 | Train Loss: 0.8561 | Val Loss: 0.8349\n",
      "Epoch 17 | Train Loss: 0.8864 | Val Loss: 0.8327\n",
      "Epoch 18 | Train Loss: 0.8603 | Val Loss: 0.8336\n",
      "Epoch 19 | Train Loss: 0.8678 | Val Loss: 0.8319\n",
      "Epoch 20 | Train Loss: 0.8632 | Val Loss: 0.8321\n",
      "Epoch 21 | Train Loss: 0.8484 | Val Loss: 0.8296\n",
      "Epoch 22 | Train Loss: 0.8597 | Val Loss: 0.8283\n",
      "Epoch 23 | Train Loss: 0.8646 | Val Loss: 0.8263\n",
      "Epoch 24 | Train Loss: 0.8678 | Val Loss: 0.8261\n",
      "Epoch 25 | Train Loss: 0.8593 | Val Loss: 0.8249\n",
      "Epoch 26 | Train Loss: 0.8506 | Val Loss: 0.8256\n",
      "Epoch 27 | Train Loss: 0.8426 | Val Loss: 0.8231\n",
      "Epoch 28 | Train Loss: 0.8533 | Val Loss: 0.8209\n",
      "Epoch 29 | Train Loss: 0.8475 | Val Loss: 0.8206\n",
      "Epoch 30 | Train Loss: 0.8442 | Val Loss: 0.8187\n",
      "Epoch 31 | Train Loss: 0.8373 | Val Loss: 0.8176\n",
      "Epoch 32 | Train Loss: 0.8342 | Val Loss: 0.8168\n",
      "Epoch 33 | Train Loss: 0.8489 | Val Loss: 0.8145\n",
      "Epoch 34 | Train Loss: 0.8371 | Val Loss: 0.8137\n",
      "Epoch 35 | Train Loss: 0.8317 | Val Loss: 0.8117\n",
      "Epoch 36 | Train Loss: 0.8281 | Val Loss: 0.8093\n",
      "Epoch 37 | Train Loss: 0.8299 | Val Loss: 0.8074\n",
      "Epoch 38 | Train Loss: 0.8451 | Val Loss: 0.8061\n",
      "Epoch 39 | Train Loss: 0.8483 | Val Loss: 0.8045\n",
      "Epoch 40 | Train Loss: 0.8259 | Val Loss: 0.8046\n",
      "Epoch 41 | Train Loss: 0.8351 | Val Loss: 0.8017\n",
      "Epoch 42 | Train Loss: 0.8327 | Val Loss: 0.7992\n",
      "Epoch 43 | Train Loss: 0.8421 | Val Loss: 0.7969\n",
      "Epoch 44 | Train Loss: 0.8208 | Val Loss: 0.7972\n",
      "Epoch 45 | Train Loss: 0.8203 | Val Loss: 0.7931\n",
      "Epoch 46 | Train Loss: 0.8265 | Val Loss: 0.7931\n",
      "Epoch 47 | Train Loss: 0.8097 | Val Loss: 0.7903\n",
      "Epoch 48 | Train Loss: 0.8235 | Val Loss: 0.7868\n",
      "Epoch 49 | Train Loss: 0.8228 | Val Loss: 0.7845\n",
      "Epoch 50 | Train Loss: 0.8075 | Val Loss: 0.7825\n",
      "Fold 4 ‚ñ∂ AUC: 0.847, Balanced Acc: 0.443\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 1.1630 | Val Loss: 1.0512\n",
      "Epoch 02 | Train Loss: 0.9924 | Val Loss: 0.9570\n",
      "Epoch 03 | Train Loss: 0.9142 | Val Loss: 0.9128\n",
      "Epoch 04 | Train Loss: 0.8784 | Val Loss: 0.8982\n",
      "Epoch 05 | Train Loss: 0.8714 | Val Loss: 0.8964\n",
      "Epoch 06 | Train Loss: 0.8595 | Val Loss: 0.8965\n",
      "Epoch 07 | Train Loss: 0.8609 | Val Loss: 0.8971\n",
      "Epoch 08 | Train Loss: 0.8582 | Val Loss: 0.8977\n",
      "Epoch 09 | Train Loss: 0.8604 | Val Loss: 0.8967\n",
      "Epoch 10 | Train Loss: 0.8609 | Val Loss: 0.8971\n",
      "Epoch 11 | Train Loss: 0.8564 | Val Loss: 0.8960\n",
      "Epoch 12 | Train Loss: 0.8704 | Val Loss: 0.8947\n",
      "Epoch 13 | Train Loss: 0.8737 | Val Loss: 0.8938\n",
      "Epoch 14 | Train Loss: 0.8530 | Val Loss: 0.8921\n",
      "Epoch 15 | Train Loss: 0.8572 | Val Loss: 0.8906\n",
      "Epoch 16 | Train Loss: 0.8598 | Val Loss: 0.8898\n",
      "Epoch 17 | Train Loss: 0.8674 | Val Loss: 0.8895\n",
      "Epoch 18 | Train Loss: 0.8619 | Val Loss: 0.8877\n",
      "Epoch 19 | Train Loss: 0.8491 | Val Loss: 0.8857\n",
      "Epoch 20 | Train Loss: 0.8517 | Val Loss: 0.8856\n",
      "Epoch 21 | Train Loss: 0.8479 | Val Loss: 0.8849\n",
      "Epoch 22 | Train Loss: 0.8481 | Val Loss: 0.8847\n",
      "Epoch 23 | Train Loss: 0.8548 | Val Loss: 0.8842\n",
      "Epoch 24 | Train Loss: 0.8445 | Val Loss: 0.8830\n",
      "Epoch 25 | Train Loss: 0.8597 | Val Loss: 0.8819\n",
      "Epoch 26 | Train Loss: 0.8453 | Val Loss: 0.8796\n",
      "Epoch 27 | Train Loss: 0.8600 | Val Loss: 0.8786\n",
      "Epoch 28 | Train Loss: 0.8398 | Val Loss: 0.8789\n",
      "Epoch 29 | Train Loss: 0.8568 | Val Loss: 0.8772\n",
      "Epoch 30 | Train Loss: 0.8461 | Val Loss: 0.8755\n",
      "Epoch 31 | Train Loss: 0.8458 | Val Loss: 0.8743\n",
      "Epoch 32 | Train Loss: 0.8290 | Val Loss: 0.8740\n",
      "Epoch 33 | Train Loss: 0.8462 | Val Loss: 0.8728\n",
      "Epoch 34 | Train Loss: 0.8418 | Val Loss: 0.8699\n",
      "Epoch 35 | Train Loss: 0.8310 | Val Loss: 0.8685\n",
      "Epoch 36 | Train Loss: 0.8222 | Val Loss: 0.8662\n",
      "Epoch 37 | Train Loss: 0.8307 | Val Loss: 0.8647\n",
      "Epoch 38 | Train Loss: 0.8337 | Val Loss: 0.8633\n",
      "Epoch 39 | Train Loss: 0.8166 | Val Loss: 0.8617\n",
      "Epoch 40 | Train Loss: 0.8152 | Val Loss: 0.8597\n",
      "Epoch 41 | Train Loss: 0.8233 | Val Loss: 0.8575\n",
      "Epoch 42 | Train Loss: 0.8439 | Val Loss: 0.8551\n",
      "Epoch 43 | Train Loss: 0.8062 | Val Loss: 0.8518\n",
      "Epoch 44 | Train Loss: 0.8167 | Val Loss: 0.8498\n",
      "Epoch 45 | Train Loss: 0.8251 | Val Loss: 0.8476\n",
      "Epoch 46 | Train Loss: 0.8006 | Val Loss: 0.8445\n",
      "Epoch 47 | Train Loss: 0.8057 | Val Loss: 0.8439\n",
      "Epoch 48 | Train Loss: 0.8093 | Val Loss: 0.8413\n",
      "Epoch 49 | Train Loss: 0.8051 | Val Loss: 0.8379\n",
      "Epoch 50 | Train Loss: 0.7838 | Val Loss: 0.8355\n",
      "Fold 5 ‚ñ∂ AUC: 0.710, Balanced Acc: 0.369\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 1.1521 | Val Loss: 1.0351\n",
      "Epoch 02 | Train Loss: 0.9735 | Val Loss: 0.9309\n",
      "Epoch 03 | Train Loss: 0.8911 | Val Loss: 0.8999\n",
      "Epoch 04 | Train Loss: 0.8760 | Val Loss: 0.8975\n",
      "Epoch 05 | Train Loss: 0.8810 | Val Loss: 0.9006\n",
      "Epoch 06 | Train Loss: 0.8690 | Val Loss: 0.8985\n",
      "Epoch 07 | Train Loss: 0.8654 | Val Loss: 0.8984\n",
      "Epoch 08 | Train Loss: 0.8596 | Val Loss: 0.8978\n",
      "Epoch 09 | Train Loss: 0.8666 | Val Loss: 0.8974\n",
      "Epoch 10 | Train Loss: 0.8625 | Val Loss: 0.8957\n",
      "Epoch 11 | Train Loss: 0.8665 | Val Loss: 0.8956\n",
      "Epoch 12 | Train Loss: 0.8593 | Val Loss: 0.8972\n",
      "Epoch 13 | Train Loss: 0.8667 | Val Loss: 0.8951\n",
      "Epoch 14 | Train Loss: 0.8747 | Val Loss: 0.8947\n",
      "Epoch 15 | Train Loss: 0.8599 | Val Loss: 0.8952\n",
      "Epoch 16 | Train Loss: 0.8559 | Val Loss: 0.8919\n",
      "Epoch 17 | Train Loss: 0.8578 | Val Loss: 0.8909\n",
      "Epoch 18 | Train Loss: 0.8759 | Val Loss: 0.8911\n",
      "Epoch 19 | Train Loss: 0.8566 | Val Loss: 0.8931\n",
      "Epoch 20 | Train Loss: 0.8544 | Val Loss: 0.8893\n",
      "Epoch 21 | Train Loss: 0.8752 | Val Loss: 0.8910\n",
      "Epoch 22 | Train Loss: 0.8735 | Val Loss: 0.8903\n",
      "Epoch 23 | Train Loss: 0.8623 | Val Loss: 0.8866\n",
      "Epoch 24 | Train Loss: 0.8532 | Val Loss: 0.8860\n",
      "Epoch 25 | Train Loss: 0.8450 | Val Loss: 0.8855\n",
      "Epoch 26 | Train Loss: 0.8497 | Val Loss: 0.8860\n",
      "Epoch 27 | Train Loss: 0.8520 | Val Loss: 0.8860\n",
      "Epoch 28 | Train Loss: 0.8365 | Val Loss: 0.8866\n",
      "Epoch 29 | Train Loss: 0.8605 | Val Loss: 0.8837\n",
      "Epoch 30 | Train Loss: 0.8547 | Val Loss: 0.8822\n",
      "Epoch 31 | Train Loss: 0.8363 | Val Loss: 0.8822\n",
      "Epoch 32 | Train Loss: 0.8632 | Val Loss: 0.8819\n",
      "Epoch 33 | Train Loss: 0.8465 | Val Loss: 0.8794\n",
      "Epoch 34 | Train Loss: 0.8396 | Val Loss: 0.8785\n",
      "Epoch 35 | Train Loss: 0.8385 | Val Loss: 0.8816\n",
      "Epoch 36 | Train Loss: 0.8304 | Val Loss: 0.8786\n",
      "Epoch 37 | Train Loss: 0.8342 | Val Loss: 0.8754\n",
      "Epoch 38 | Train Loss: 0.8371 | Val Loss: 0.8726\n",
      "Epoch 39 | Train Loss: 0.8282 | Val Loss: 0.8715\n",
      "Epoch 40 | Train Loss: 0.8243 | Val Loss: 0.8757\n",
      "Epoch 41 | Train Loss: 0.8246 | Val Loss: 0.8707\n",
      "Epoch 42 | Train Loss: 0.8183 | Val Loss: 0.8695\n",
      "Epoch 43 | Train Loss: 0.8098 | Val Loss: 0.8698\n",
      "Epoch 44 | Train Loss: 0.8193 | Val Loss: 0.8660\n",
      "Epoch 45 | Train Loss: 0.8261 | Val Loss: 0.8655\n",
      "Epoch 46 | Train Loss: 0.8102 | Val Loss: 0.8628\n",
      "Epoch 47 | Train Loss: 0.8293 | Val Loss: 0.8621\n",
      "Epoch 48 | Train Loss: 0.8106 | Val Loss: 0.8597\n",
      "Epoch 49 | Train Loss: 0.8097 | Val Loss: 0.8596\n",
      "Epoch 50 | Train Loss: 0.8043 | Val Loss: 0.8596\n",
      "Fold 6 ‚ñ∂ AUC: 0.673, Balanced Acc: 0.430\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9526 | Val Loss: 0.8886\n",
      "Epoch 02 | Train Loss: 0.8876 | Val Loss: 0.8543\n",
      "Epoch 03 | Train Loss: 0.8701 | Val Loss: 0.8436\n",
      "Epoch 04 | Train Loss: 0.8750 | Val Loss: 0.8402\n",
      "Epoch 05 | Train Loss: 0.8552 | Val Loss: 0.8402\n",
      "Epoch 06 | Train Loss: 0.8605 | Val Loss: 0.8376\n",
      "Epoch 07 | Train Loss: 0.8605 | Val Loss: 0.8358\n",
      "Epoch 08 | Train Loss: 0.8633 | Val Loss: 0.8367\n",
      "Epoch 09 | Train Loss: 0.8685 | Val Loss: 0.8339\n",
      "Epoch 10 | Train Loss: 0.8617 | Val Loss: 0.8330\n",
      "Epoch 11 | Train Loss: 0.8529 | Val Loss: 0.8326\n",
      "Epoch 12 | Train Loss: 0.8610 | Val Loss: 0.8309\n",
      "Epoch 13 | Train Loss: 0.8652 | Val Loss: 0.8287\n",
      "Epoch 14 | Train Loss: 0.8465 | Val Loss: 0.8280\n",
      "Epoch 15 | Train Loss: 0.8473 | Val Loss: 0.8268\n",
      "Epoch 16 | Train Loss: 0.8517 | Val Loss: 0.8241\n",
      "Epoch 17 | Train Loss: 0.8452 | Val Loss: 0.8243\n",
      "Epoch 18 | Train Loss: 0.8444 | Val Loss: 0.8207\n",
      "Epoch 19 | Train Loss: 0.8473 | Val Loss: 0.8218\n",
      "Epoch 20 | Train Loss: 0.8611 | Val Loss: 0.8178\n",
      "Epoch 21 | Train Loss: 0.8439 | Val Loss: 0.8164\n",
      "Epoch 22 | Train Loss: 0.8353 | Val Loss: 0.8165\n",
      "Epoch 23 | Train Loss: 0.8393 | Val Loss: 0.8124\n",
      "Epoch 24 | Train Loss: 0.8257 | Val Loss: 0.8103\n",
      "Epoch 25 | Train Loss: 0.8270 | Val Loss: 0.8074\n",
      "Epoch 26 | Train Loss: 0.8287 | Val Loss: 0.8043\n",
      "Epoch 27 | Train Loss: 0.8306 | Val Loss: 0.8023\n",
      "Epoch 28 | Train Loss: 0.8273 | Val Loss: 0.8003\n",
      "Epoch 29 | Train Loss: 0.8244 | Val Loss: 0.7975\n",
      "Epoch 30 | Train Loss: 0.8310 | Val Loss: 0.7962\n",
      "Epoch 31 | Train Loss: 0.8461 | Val Loss: 0.7934\n",
      "Epoch 32 | Train Loss: 0.8194 | Val Loss: 0.7918\n",
      "Epoch 33 | Train Loss: 0.8142 | Val Loss: 0.7904\n",
      "Epoch 34 | Train Loss: 0.8080 | Val Loss: 0.7888\n",
      "Epoch 35 | Train Loss: 0.8171 | Val Loss: 0.7838\n",
      "Epoch 36 | Train Loss: 0.8096 | Val Loss: 0.7817\n",
      "Epoch 37 | Train Loss: 0.8132 | Val Loss: 0.7798\n",
      "Epoch 38 | Train Loss: 0.8014 | Val Loss: 0.7765\n",
      "Epoch 39 | Train Loss: 0.8067 | Val Loss: 0.7742\n",
      "Epoch 40 | Train Loss: 0.8066 | Val Loss: 0.7715\n",
      "Epoch 41 | Train Loss: 0.8170 | Val Loss: 0.7699\n",
      "Epoch 42 | Train Loss: 0.7966 | Val Loss: 0.7680\n",
      "Epoch 43 | Train Loss: 0.8088 | Val Loss: 0.7667\n",
      "Epoch 44 | Train Loss: 0.8110 | Val Loss: 0.7643\n",
      "Epoch 45 | Train Loss: 0.8140 | Val Loss: 0.7615\n",
      "Epoch 46 | Train Loss: 0.7825 | Val Loss: 0.7595\n",
      "Epoch 47 | Train Loss: 0.7886 | Val Loss: 0.7587\n",
      "Epoch 48 | Train Loss: 0.8025 | Val Loss: 0.7559\n",
      "Epoch 49 | Train Loss: 0.7911 | Val Loss: 0.7542\n",
      "Epoch 50 | Train Loss: 0.7928 | Val Loss: 0.7523\n",
      "Fold 7 ‚ñ∂ AUC: 0.800, Balanced Acc: 0.511\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 1.0201 | Val Loss: 0.9433\n",
      "Epoch 02 | Train Loss: 0.9177 | Val Loss: 0.8908\n",
      "Epoch 03 | Train Loss: 0.8798 | Val Loss: 0.8702\n",
      "Epoch 04 | Train Loss: 0.8842 | Val Loss: 0.8622\n",
      "Epoch 05 | Train Loss: 0.8583 | Val Loss: 0.8606\n",
      "Epoch 06 | Train Loss: 0.8658 | Val Loss: 0.8618\n",
      "Epoch 07 | Train Loss: 0.8814 | Val Loss: 0.8608\n",
      "Epoch 08 | Train Loss: 0.8633 | Val Loss: 0.8570\n",
      "Epoch 09 | Train Loss: 0.8678 | Val Loss: 0.8576\n",
      "Epoch 10 | Train Loss: 0.8678 | Val Loss: 0.8572\n",
      "Epoch 11 | Train Loss: 0.8540 | Val Loss: 0.8544\n",
      "Epoch 12 | Train Loss: 0.8559 | Val Loss: 0.8548\n",
      "Epoch 13 | Train Loss: 0.8651 | Val Loss: 0.8524\n",
      "Epoch 14 | Train Loss: 0.8741 | Val Loss: 0.8541\n",
      "Epoch 15 | Train Loss: 0.8640 | Val Loss: 0.8506\n",
      "Epoch 16 | Train Loss: 0.8495 | Val Loss: 0.8494\n",
      "Epoch 17 | Train Loss: 0.8656 | Val Loss: 0.8489\n",
      "Epoch 18 | Train Loss: 0.8636 | Val Loss: 0.8484\n",
      "Epoch 19 | Train Loss: 0.8580 | Val Loss: 0.8463\n",
      "Epoch 20 | Train Loss: 0.8464 | Val Loss: 0.8464\n",
      "Epoch 21 | Train Loss: 0.8468 | Val Loss: 0.8434\n",
      "Epoch 22 | Train Loss: 0.8538 | Val Loss: 0.8453\n",
      "Epoch 23 | Train Loss: 0.8452 | Val Loss: 0.8408\n",
      "Epoch 24 | Train Loss: 0.8396 | Val Loss: 0.8403\n",
      "Epoch 25 | Train Loss: 0.8484 | Val Loss: 0.8377\n",
      "Epoch 26 | Train Loss: 0.8461 | Val Loss: 0.8358\n",
      "Epoch 27 | Train Loss: 0.8377 | Val Loss: 0.8354\n",
      "Epoch 28 | Train Loss: 0.8383 | Val Loss: 0.8342\n",
      "Epoch 29 | Train Loss: 0.8395 | Val Loss: 0.8312\n",
      "Epoch 30 | Train Loss: 0.8337 | Val Loss: 0.8309\n",
      "Epoch 31 | Train Loss: 0.8410 | Val Loss: 0.8277\n",
      "Epoch 32 | Train Loss: 0.8338 | Val Loss: 0.8253\n",
      "Epoch 33 | Train Loss: 0.8296 | Val Loss: 0.8240\n",
      "Epoch 34 | Train Loss: 0.8441 | Val Loss: 0.8218\n",
      "Epoch 35 | Train Loss: 0.8180 | Val Loss: 0.8191\n",
      "Epoch 36 | Train Loss: 0.8259 | Val Loss: 0.8164\n",
      "Epoch 37 | Train Loss: 0.8265 | Val Loss: 0.8140\n",
      "Epoch 38 | Train Loss: 0.8185 | Val Loss: 0.8131\n",
      "Epoch 39 | Train Loss: 0.8196 | Val Loss: 0.8103\n",
      "Epoch 40 | Train Loss: 0.8135 | Val Loss: 0.8102\n",
      "Epoch 41 | Train Loss: 0.8133 | Val Loss: 0.8053\n",
      "Epoch 42 | Train Loss: 0.8000 | Val Loss: 0.8059\n",
      "Epoch 43 | Train Loss: 0.8070 | Val Loss: 0.8013\n",
      "Epoch 44 | Train Loss: 0.8060 | Val Loss: 0.7991\n",
      "Epoch 45 | Train Loss: 0.8020 | Val Loss: 0.7969\n",
      "Epoch 46 | Train Loss: 0.7916 | Val Loss: 0.7958\n",
      "Epoch 47 | Train Loss: 0.7931 | Val Loss: 0.7931\n",
      "Epoch 48 | Train Loss: 0.8006 | Val Loss: 0.7908\n",
      "Epoch 49 | Train Loss: 0.7863 | Val Loss: 0.7924\n",
      "Epoch 50 | Train Loss: 0.7899 | Val Loss: 0.7884\n",
      "Fold 8 ‚ñ∂ AUC: 0.702, Balanced Acc: 0.434\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 1.0613 | Val Loss: 0.9989\n",
      "Epoch 02 | Train Loss: 0.9570 | Val Loss: 0.9297\n",
      "Epoch 03 | Train Loss: 0.9171 | Val Loss: 0.8940\n",
      "Epoch 04 | Train Loss: 0.8773 | Val Loss: 0.8800\n",
      "Epoch 05 | Train Loss: 0.8815 | Val Loss: 0.8732\n",
      "Epoch 06 | Train Loss: 0.8685 | Val Loss: 0.8703\n",
      "Epoch 07 | Train Loss: 0.8804 | Val Loss: 0.8692\n",
      "Epoch 08 | Train Loss: 0.8639 | Val Loss: 0.8685\n",
      "Epoch 09 | Train Loss: 0.8782 | Val Loss: 0.8693\n",
      "Epoch 10 | Train Loss: 0.8742 | Val Loss: 0.8680\n",
      "Epoch 11 | Train Loss: 0.8737 | Val Loss: 0.8677\n",
      "Epoch 12 | Train Loss: 0.8686 | Val Loss: 0.8665\n",
      "Epoch 13 | Train Loss: 0.8638 | Val Loss: 0.8668\n",
      "Epoch 14 | Train Loss: 0.8734 | Val Loss: 0.8654\n",
      "Epoch 15 | Train Loss: 0.8703 | Val Loss: 0.8655\n",
      "Epoch 16 | Train Loss: 0.8651 | Val Loss: 0.8683\n",
      "Epoch 17 | Train Loss: 0.8512 | Val Loss: 0.8646\n",
      "Epoch 18 | Train Loss: 0.8559 | Val Loss: 0.8633\n",
      "Epoch 19 | Train Loss: 0.8481 | Val Loss: 0.8644\n",
      "Epoch 20 | Train Loss: 0.8518 | Val Loss: 0.8619\n",
      "Epoch 21 | Train Loss: 0.8523 | Val Loss: 0.8618\n",
      "Epoch 22 | Train Loss: 0.8769 | Val Loss: 0.8623\n",
      "Epoch 23 | Train Loss: 0.8608 | Val Loss: 0.8628\n",
      "Epoch 24 | Train Loss: 0.8453 | Val Loss: 0.8622\n",
      "Epoch 25 | Train Loss: 0.8444 | Val Loss: 0.8586\n",
      "Epoch 26 | Train Loss: 0.8586 | Val Loss: 0.8585\n",
      "Epoch 27 | Train Loss: 0.8494 | Val Loss: 0.8570\n",
      "Epoch 28 | Train Loss: 0.8547 | Val Loss: 0.8560\n",
      "Epoch 29 | Train Loss: 0.8423 | Val Loss: 0.8556\n",
      "Epoch 30 | Train Loss: 0.8472 | Val Loss: 0.8539\n",
      "Epoch 31 | Train Loss: 0.8468 | Val Loss: 0.8534\n",
      "Epoch 32 | Train Loss: 0.8421 | Val Loss: 0.8525\n",
      "Epoch 33 | Train Loss: 0.8344 | Val Loss: 0.8515\n",
      "Epoch 34 | Train Loss: 0.8314 | Val Loss: 0.8512\n",
      "Epoch 35 | Train Loss: 0.8468 | Val Loss: 0.8488\n",
      "Epoch 36 | Train Loss: 0.8316 | Val Loss: 0.8480\n",
      "Epoch 37 | Train Loss: 0.8334 | Val Loss: 0.8472\n",
      "Epoch 38 | Train Loss: 0.8250 | Val Loss: 0.8462\n",
      "Epoch 39 | Train Loss: 0.8182 | Val Loss: 0.8452\n",
      "Epoch 40 | Train Loss: 0.8314 | Val Loss: 0.8469\n",
      "Epoch 41 | Train Loss: 0.8305 | Val Loss: 0.8425\n",
      "Epoch 42 | Train Loss: 0.8100 | Val Loss: 0.8417\n",
      "Epoch 43 | Train Loss: 0.8335 | Val Loss: 0.8392\n",
      "Epoch 44 | Train Loss: 0.8133 | Val Loss: 0.8387\n",
      "Epoch 45 | Train Loss: 0.8176 | Val Loss: 0.8371\n",
      "Epoch 46 | Train Loss: 0.8079 | Val Loss: 0.8362\n",
      "Epoch 47 | Train Loss: 0.8168 | Val Loss: 0.8377\n",
      "Epoch 48 | Train Loss: 0.8075 | Val Loss: 0.8321\n",
      "Epoch 49 | Train Loss: 0.8053 | Val Loss: 0.8316\n",
      "Epoch 50 | Train Loss: 0.8066 | Val Loss: 0.8292\n",
      "Fold 9 ‚ñ∂ AUC: 0.667, Balanced Acc: 0.394\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 1.3507 | Val Loss: 1.1643\n",
      "Epoch 02 | Train Loss: 1.0805 | Val Loss: 0.9931\n",
      "Epoch 03 | Train Loss: 0.9670 | Val Loss: 0.9241\n",
      "Epoch 04 | Train Loss: 0.9083 | Val Loss: 0.8894\n",
      "Epoch 05 | Train Loss: 0.8827 | Val Loss: 0.8759\n",
      "Epoch 06 | Train Loss: 0.8682 | Val Loss: 0.8707\n",
      "Epoch 07 | Train Loss: 0.8698 | Val Loss: 0.8692\n",
      "Epoch 08 | Train Loss: 0.8799 | Val Loss: 0.8659\n",
      "Epoch 09 | Train Loss: 0.8693 | Val Loss: 0.8649\n",
      "Epoch 10 | Train Loss: 0.8722 | Val Loss: 0.8651\n",
      "Epoch 11 | Train Loss: 0.8654 | Val Loss: 0.8624\n",
      "Epoch 12 | Train Loss: 0.8683 | Val Loss: 0.8614\n",
      "Epoch 13 | Train Loss: 0.8820 | Val Loss: 0.8608\n",
      "Epoch 14 | Train Loss: 0.8711 | Val Loss: 0.8595\n",
      "Epoch 15 | Train Loss: 0.8633 | Val Loss: 0.8571\n",
      "Epoch 16 | Train Loss: 0.8661 | Val Loss: 0.8580\n",
      "Epoch 17 | Train Loss: 0.8596 | Val Loss: 0.8553\n",
      "Epoch 18 | Train Loss: 0.8616 | Val Loss: 0.8540\n",
      "Epoch 19 | Train Loss: 0.8493 | Val Loss: 0.8524\n",
      "Epoch 20 | Train Loss: 0.8579 | Val Loss: 0.8532\n",
      "Epoch 21 | Train Loss: 0.8650 | Val Loss: 0.8497\n",
      "Epoch 22 | Train Loss: 0.8626 | Val Loss: 0.8508\n",
      "Epoch 23 | Train Loss: 0.8560 | Val Loss: 0.8468\n",
      "Epoch 24 | Train Loss: 0.8516 | Val Loss: 0.8481\n",
      "Epoch 25 | Train Loss: 0.8494 | Val Loss: 0.8450\n",
      "Epoch 26 | Train Loss: 0.8429 | Val Loss: 0.8451\n",
      "Epoch 27 | Train Loss: 0.8440 | Val Loss: 0.8418\n",
      "Epoch 28 | Train Loss: 0.8465 | Val Loss: 0.8421\n",
      "Epoch 29 | Train Loss: 0.8507 | Val Loss: 0.8396\n",
      "Epoch 30 | Train Loss: 0.8445 | Val Loss: 0.8374\n",
      "Epoch 31 | Train Loss: 0.8489 | Val Loss: 0.8421\n",
      "Epoch 32 | Train Loss: 0.8464 | Val Loss: 0.8360\n",
      "Epoch 33 | Train Loss: 0.8430 | Val Loss: 0.8399\n",
      "Epoch 34 | Train Loss: 0.8396 | Val Loss: 0.8318\n",
      "Epoch 35 | Train Loss: 0.8450 | Val Loss: 0.8347\n",
      "Epoch 36 | Train Loss: 0.8495 | Val Loss: 0.8283\n",
      "Epoch 37 | Train Loss: 0.8436 | Val Loss: 0.8267\n",
      "Epoch 38 | Train Loss: 0.8275 | Val Loss: 0.8257\n",
      "Epoch 39 | Train Loss: 0.8386 | Val Loss: 0.8241\n",
      "Epoch 40 | Train Loss: 0.8248 | Val Loss: 0.8239\n",
      "Epoch 41 | Train Loss: 0.8184 | Val Loss: 0.8227\n",
      "Epoch 42 | Train Loss: 0.8310 | Val Loss: 0.8200\n",
      "Epoch 43 | Train Loss: 0.8418 | Val Loss: 0.8182\n",
      "Epoch 44 | Train Loss: 0.8260 | Val Loss: 0.8138\n",
      "Epoch 45 | Train Loss: 0.8214 | Val Loss: 0.8157\n",
      "Epoch 46 | Train Loss: 0.8177 | Val Loss: 0.8133\n",
      "Epoch 47 | Train Loss: 0.8198 | Val Loss: 0.8092\n",
      "Epoch 48 | Train Loss: 0.8110 | Val Loss: 0.8098\n",
      "Epoch 49 | Train Loss: 0.8063 | Val Loss: 0.8085\n",
      "Epoch 50 | Train Loss: 0.8112 | Val Loss: 0.8023\n",
      "Fold 10 ‚ñ∂ AUC: 0.717, Balanced Acc: 0.439\n",
      "üîç Summary for hd=64, dp=0.2, lr=0.0001 ‚Üí AUC: 0.7312¬±0.0567 | BalAcc: 0.4313¬±0.0433\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.4, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9871 | Val Loss: 0.8734\n",
      "Epoch 02 | Train Loss: 0.8776 | Val Loss: 0.8549\n",
      "Epoch 03 | Train Loss: 0.8924 | Val Loss: 0.8577\n",
      "Epoch 04 | Train Loss: 0.8624 | Val Loss: 0.8527\n",
      "Epoch 05 | Train Loss: 0.8605 | Val Loss: 0.8491\n",
      "Epoch 06 | Train Loss: 0.8718 | Val Loss: 0.8446\n",
      "Epoch 07 | Train Loss: 0.8501 | Val Loss: 0.8349\n",
      "Epoch 08 | Train Loss: 0.8627 | Val Loss: 0.8255\n",
      "Epoch 09 | Train Loss: 0.8496 | Val Loss: 0.8547\n",
      "Epoch 10 | Train Loss: 0.8541 | Val Loss: 0.8142\n",
      "Epoch 11 | Train Loss: 0.8377 | Val Loss: 0.8028\n",
      "Epoch 12 | Train Loss: 0.8350 | Val Loss: 0.8134\n",
      "Epoch 13 | Train Loss: 0.8134 | Val Loss: 0.7958\n",
      "Epoch 14 | Train Loss: 0.7966 | Val Loss: 0.7685\n",
      "Epoch 15 | Train Loss: 0.7962 | Val Loss: 0.7625\n",
      "Epoch 16 | Train Loss: 0.7644 | Val Loss: 0.7432\n",
      "Epoch 17 | Train Loss: 0.7840 | Val Loss: 0.7383\n",
      "Epoch 18 | Train Loss: 0.7975 | Val Loss: 0.7305\n",
      "Epoch 19 | Train Loss: 0.7695 | Val Loss: 0.7298\n",
      "Epoch 20 | Train Loss: 0.7940 | Val Loss: 0.7310\n",
      "Epoch 21 | Train Loss: 0.7796 | Val Loss: 0.7555\n",
      "Epoch 22 | Train Loss: 0.7821 | Val Loss: 0.7269\n",
      "Epoch 23 | Train Loss: 0.7707 | Val Loss: 0.7245\n",
      "Epoch 24 | Train Loss: 0.7503 | Val Loss: 0.7240\n",
      "Epoch 25 | Train Loss: 0.7531 | Val Loss: 0.7227\n",
      "Epoch 26 | Train Loss: 0.7702 | Val Loss: 0.7222\n",
      "Epoch 27 | Train Loss: 0.7983 | Val Loss: 0.7316\n",
      "Epoch 28 | Train Loss: 0.7664 | Val Loss: 0.7098\n",
      "Epoch 29 | Train Loss: 0.7529 | Val Loss: 0.7002\n",
      "Epoch 30 | Train Loss: 0.7662 | Val Loss: 0.7160\n",
      "Epoch 31 | Train Loss: 0.7306 | Val Loss: 0.7007\n",
      "Epoch 32 | Train Loss: 0.7261 | Val Loss: 0.7056\n",
      "Epoch 33 | Train Loss: 0.7547 | Val Loss: 0.6974\n",
      "Epoch 34 | Train Loss: 0.7552 | Val Loss: 0.6946\n",
      "Epoch 35 | Train Loss: 0.7594 | Val Loss: 0.7046\n",
      "Epoch 36 | Train Loss: 0.7530 | Val Loss: 0.6998\n",
      "Epoch 37 | Train Loss: 0.7336 | Val Loss: 0.6956\n",
      "Epoch 38 | Train Loss: 0.7459 | Val Loss: 0.6955\n",
      "Epoch 39 | Train Loss: 0.7274 | Val Loss: 0.7020\n",
      "Epoch 40 | Train Loss: 0.7350 | Val Loss: 0.7077\n",
      "Epoch 41 | Train Loss: 0.7773 | Val Loss: 0.6958\n",
      "Epoch 42 | Train Loss: 0.7644 | Val Loss: 0.7236\n",
      "Epoch 43 | Train Loss: 0.7698 | Val Loss: 0.7049\n",
      "Epoch 44 | Train Loss: 0.7414 | Val Loss: 0.6913\n",
      "Epoch 45 | Train Loss: 0.7197 | Val Loss: 0.6932\n",
      "Epoch 46 | Train Loss: 0.7339 | Val Loss: 0.6962\n",
      "Epoch 47 | Train Loss: 0.7399 | Val Loss: 0.6956\n",
      "Epoch 48 | Train Loss: 0.7428 | Val Loss: 0.6945\n",
      "Epoch 49 | Train Loss: 0.7498 | Val Loss: 0.6951\n",
      "Epoch 50 | Train Loss: 0.7351 | Val Loss: 0.7316\n",
      "Fold 1 ‚ñ∂ AUC: 0.768, Balanced Acc: 0.484\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9917 | Val Loss: 0.8697\n",
      "Epoch 02 | Train Loss: 0.8819 | Val Loss: 0.8665\n",
      "Epoch 03 | Train Loss: 0.8713 | Val Loss: 0.8572\n",
      "Epoch 04 | Train Loss: 0.8731 | Val Loss: 0.8664\n",
      "Epoch 05 | Train Loss: 0.8781 | Val Loss: 0.8459\n",
      "Epoch 06 | Train Loss: 0.8511 | Val Loss: 0.8348\n",
      "Epoch 07 | Train Loss: 0.8582 | Val Loss: 0.8244\n",
      "Epoch 08 | Train Loss: 0.8261 | Val Loss: 0.8050\n",
      "Epoch 09 | Train Loss: 0.8113 | Val Loss: 0.7807\n",
      "Epoch 10 | Train Loss: 0.7981 | Val Loss: 0.7874\n",
      "Epoch 11 | Train Loss: 0.7763 | Val Loss: 0.7583\n",
      "Epoch 12 | Train Loss: 0.7921 | Val Loss: 0.7475\n",
      "Epoch 13 | Train Loss: 0.7657 | Val Loss: 0.7435\n",
      "Epoch 14 | Train Loss: 0.8120 | Val Loss: 0.7370\n",
      "Epoch 15 | Train Loss: 0.8026 | Val Loss: 0.7491\n",
      "Epoch 16 | Train Loss: 0.7651 | Val Loss: 0.7496\n",
      "Epoch 17 | Train Loss: 0.7566 | Val Loss: 0.7629\n",
      "Epoch 18 | Train Loss: 0.7616 | Val Loss: 0.7394\n",
      "Epoch 19 | Train Loss: 0.7833 | Val Loss: 0.7317\n",
      "Epoch 20 | Train Loss: 0.7519 | Val Loss: 0.7356\n",
      "Epoch 21 | Train Loss: 0.7633 | Val Loss: 0.7335\n",
      "Epoch 22 | Train Loss: 0.7428 | Val Loss: 0.7487\n",
      "Epoch 23 | Train Loss: 0.7664 | Val Loss: 0.7435\n",
      "Epoch 24 | Train Loss: 0.7357 | Val Loss: 0.7242\n",
      "Epoch 25 | Train Loss: 0.7711 | Val Loss: 0.7524\n",
      "Epoch 26 | Train Loss: 0.7270 | Val Loss: 0.7616\n",
      "Epoch 27 | Train Loss: 0.7444 | Val Loss: 0.7281\n",
      "Epoch 28 | Train Loss: 0.7847 | Val Loss: 0.8388\n",
      "Epoch 29 | Train Loss: 0.7652 | Val Loss: 0.7327\n",
      "Epoch 30 | Train Loss: 0.7489 | Val Loss: 0.7319\n",
      "Epoch 31 | Train Loss: 0.7290 | Val Loss: 0.7298\n",
      "Epoch 32 | Train Loss: 0.7545 | Val Loss: 0.7200\n",
      "Epoch 33 | Train Loss: 0.7663 | Val Loss: 0.7256\n",
      "Epoch 34 | Train Loss: 0.7494 | Val Loss: 0.8033\n",
      "Epoch 35 | Train Loss: 0.7441 | Val Loss: 0.7229\n",
      "Epoch 36 | Train Loss: 0.7433 | Val Loss: 0.7933\n",
      "Epoch 37 | Train Loss: 0.7291 | Val Loss: 0.7544\n",
      "Epoch 38 | Train Loss: 0.7372 | Val Loss: 0.7179\n",
      "Epoch 39 | Train Loss: 0.7335 | Val Loss: 0.7161\n",
      "Epoch 40 | Train Loss: 0.7423 | Val Loss: 0.7573\n",
      "Epoch 41 | Train Loss: 0.7518 | Val Loss: 0.7712\n",
      "Epoch 42 | Train Loss: 0.7324 | Val Loss: 0.7709\n",
      "Epoch 43 | Train Loss: 0.7713 | Val Loss: 0.7281\n",
      "Epoch 44 | Train Loss: 0.7431 | Val Loss: 0.7393\n",
      "Epoch 45 | Train Loss: 0.7329 | Val Loss: 0.7936\n",
      "Epoch 46 | Train Loss: 0.7630 | Val Loss: 0.7215\n",
      "Epoch 47 | Train Loss: 0.7215 | Val Loss: 0.7323\n",
      "Epoch 48 | Train Loss: 0.7281 | Val Loss: 0.7321\n",
      "Epoch 49 | Train Loss: 0.7262 | Val Loss: 0.7576\n",
      "Epoch 50 | Train Loss: 0.7231 | Val Loss: 0.7079\n",
      "Fold 2 ‚ñ∂ AUC: 0.692, Balanced Acc: 0.553\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.8892 | Val Loss: 0.9212\n",
      "Epoch 02 | Train Loss: 0.8732 | Val Loss: 0.8552\n",
      "Epoch 03 | Train Loss: 0.8656 | Val Loss: 0.8471\n",
      "Epoch 04 | Train Loss: 0.8507 | Val Loss: 0.8351\n",
      "Epoch 05 | Train Loss: 0.8419 | Val Loss: 0.8198\n",
      "Epoch 06 | Train Loss: 0.8534 | Val Loss: 0.7970\n",
      "Epoch 07 | Train Loss: 0.8234 | Val Loss: 0.7796\n",
      "Epoch 08 | Train Loss: 0.8041 | Val Loss: 0.7812\n",
      "Epoch 09 | Train Loss: 0.8213 | Val Loss: 0.7866\n",
      "Epoch 10 | Train Loss: 0.7819 | Val Loss: 0.7807\n",
      "Epoch 11 | Train Loss: 0.7944 | Val Loss: 0.7506\n",
      "Epoch 12 | Train Loss: 0.7638 | Val Loss: 0.8021\n",
      "Epoch 13 | Train Loss: 0.8013 | Val Loss: 0.7749\n",
      "Epoch 14 | Train Loss: 0.7718 | Val Loss: 0.7430\n",
      "Epoch 15 | Train Loss: 0.7769 | Val Loss: 0.7459\n",
      "Epoch 16 | Train Loss: 0.7671 | Val Loss: 0.7640\n",
      "Epoch 17 | Train Loss: 0.7626 | Val Loss: 0.7616\n",
      "Epoch 18 | Train Loss: 0.7467 | Val Loss: 0.7800\n",
      "Epoch 19 | Train Loss: 0.7569 | Val Loss: 0.7399\n",
      "Epoch 20 | Train Loss: 0.7584 | Val Loss: 0.7382\n",
      "Epoch 21 | Train Loss: 0.7514 | Val Loss: 0.7382\n",
      "Epoch 22 | Train Loss: 0.7540 | Val Loss: 0.7514\n",
      "Epoch 23 | Train Loss: 0.7612 | Val Loss: 0.7952\n",
      "Epoch 24 | Train Loss: 0.7365 | Val Loss: 0.7282\n",
      "Epoch 25 | Train Loss: 0.7453 | Val Loss: 0.7409\n",
      "Epoch 26 | Train Loss: 0.7276 | Val Loss: 0.7260\n",
      "Epoch 27 | Train Loss: 0.7356 | Val Loss: 0.7245\n",
      "Epoch 28 | Train Loss: 0.7509 | Val Loss: 0.7363\n",
      "Epoch 29 | Train Loss: 0.7559 | Val Loss: 0.7256\n",
      "Epoch 30 | Train Loss: 0.7207 | Val Loss: 0.7282\n",
      "Epoch 31 | Train Loss: 0.7433 | Val Loss: 0.7170\n",
      "Epoch 32 | Train Loss: 0.7206 | Val Loss: 0.7163\n",
      "Epoch 33 | Train Loss: 0.7112 | Val Loss: 0.7145\n",
      "Epoch 34 | Train Loss: 0.7301 | Val Loss: 0.7178\n",
      "Epoch 35 | Train Loss: 0.7337 | Val Loss: 0.7406\n",
      "Epoch 36 | Train Loss: 0.7116 | Val Loss: 0.7237\n",
      "Epoch 37 | Train Loss: 0.7402 | Val Loss: 0.7202\n",
      "Epoch 38 | Train Loss: 0.7351 | Val Loss: 0.7519\n",
      "Epoch 39 | Train Loss: 0.7233 | Val Loss: 0.7221\n",
      "Epoch 40 | Train Loss: 0.7348 | Val Loss: 0.7152\n",
      "Epoch 41 | Train Loss: 0.7145 | Val Loss: 0.7127\n",
      "Epoch 42 | Train Loss: 0.7367 | Val Loss: 0.7134\n",
      "Epoch 43 | Train Loss: 0.7287 | Val Loss: 0.7240\n",
      "Epoch 44 | Train Loss: 0.7080 | Val Loss: 0.7093\n",
      "Epoch 45 | Train Loss: 0.7260 | Val Loss: 0.7390\n",
      "Epoch 46 | Train Loss: 0.7537 | Val Loss: 0.7114\n",
      "Epoch 47 | Train Loss: 0.7252 | Val Loss: 0.7129\n",
      "Epoch 48 | Train Loss: 0.7244 | Val Loss: 0.7126\n",
      "Epoch 49 | Train Loss: 0.7257 | Val Loss: 0.7065\n",
      "Epoch 50 | Train Loss: 0.7104 | Val Loss: 0.7042\n",
      "Fold 3 ‚ñ∂ AUC: 0.780, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 1.0212 | Val Loss: 0.8637\n",
      "Epoch 02 | Train Loss: 0.8888 | Val Loss: 0.8599\n",
      "Epoch 03 | Train Loss: 0.8942 | Val Loss: 0.8568\n",
      "Epoch 04 | Train Loss: 0.8792 | Val Loss: 0.8566\n",
      "Epoch 05 | Train Loss: 0.8850 | Val Loss: 0.8451\n",
      "Epoch 06 | Train Loss: 0.8696 | Val Loss: 0.8479\n",
      "Epoch 07 | Train Loss: 0.8445 | Val Loss: 0.8455\n",
      "Epoch 08 | Train Loss: 0.8651 | Val Loss: 0.8273\n",
      "Epoch 09 | Train Loss: 0.8374 | Val Loss: 0.8166\n",
      "Epoch 10 | Train Loss: 0.8440 | Val Loss: 0.7923\n",
      "Epoch 11 | Train Loss: 0.8262 | Val Loss: 0.7771\n",
      "Epoch 12 | Train Loss: 0.8258 | Val Loss: 0.8113\n",
      "Epoch 13 | Train Loss: 0.8080 | Val Loss: 0.7725\n",
      "Epoch 14 | Train Loss: 0.7866 | Val Loss: 0.7400\n",
      "Epoch 15 | Train Loss: 0.7964 | Val Loss: 0.7369\n",
      "Epoch 16 | Train Loss: 0.7938 | Val Loss: 0.7180\n",
      "Epoch 17 | Train Loss: 0.7751 | Val Loss: 0.7141\n",
      "Epoch 18 | Train Loss: 0.7684 | Val Loss: 0.7107\n",
      "Epoch 19 | Train Loss: 0.7781 | Val Loss: 0.7100\n",
      "Epoch 20 | Train Loss: 0.7728 | Val Loss: 0.7162\n",
      "Epoch 21 | Train Loss: 0.8022 | Val Loss: 0.7353\n",
      "Epoch 22 | Train Loss: 0.8160 | Val Loss: 0.7452\n",
      "Epoch 23 | Train Loss: 0.7887 | Val Loss: 0.7115\n",
      "Epoch 24 | Train Loss: 0.7773 | Val Loss: 0.7034\n",
      "Epoch 25 | Train Loss: 0.7550 | Val Loss: 0.7009\n",
      "Epoch 26 | Train Loss: 0.7628 | Val Loss: 0.6979\n",
      "Epoch 27 | Train Loss: 0.7665 | Val Loss: 0.6960\n",
      "Epoch 28 | Train Loss: 0.7479 | Val Loss: 0.6961\n",
      "Epoch 29 | Train Loss: 0.7850 | Val Loss: 0.6882\n",
      "Epoch 30 | Train Loss: 0.7549 | Val Loss: 0.7341\n",
      "Epoch 31 | Train Loss: 0.7759 | Val Loss: 0.7143\n",
      "Epoch 32 | Train Loss: 0.7620 | Val Loss: 0.6841\n",
      "Epoch 33 | Train Loss: 0.7604 | Val Loss: 0.6952\n",
      "Epoch 34 | Train Loss: 0.7619 | Val Loss: 0.6990\n",
      "Epoch 35 | Train Loss: 0.7506 | Val Loss: 0.6846\n",
      "Epoch 36 | Train Loss: 0.7419 | Val Loss: 0.6763\n",
      "Epoch 37 | Train Loss: 0.7465 | Val Loss: 0.6712\n",
      "Epoch 38 | Train Loss: 0.7645 | Val Loss: 0.6768\n",
      "Epoch 39 | Train Loss: 0.7527 | Val Loss: 0.6858\n",
      "Epoch 40 | Train Loss: 0.7396 | Val Loss: 0.6731\n",
      "Epoch 41 | Train Loss: 0.7634 | Val Loss: 0.7141\n",
      "Epoch 42 | Train Loss: 0.7422 | Val Loss: 0.6929\n",
      "Epoch 43 | Train Loss: 0.7468 | Val Loss: 0.6796\n",
      "Epoch 44 | Train Loss: 0.7323 | Val Loss: 0.6768\n",
      "Epoch 45 | Train Loss: 0.7457 | Val Loss: 0.6673\n",
      "Epoch 46 | Train Loss: 0.7313 | Val Loss: 0.6690\n",
      "Epoch 47 | Train Loss: 0.7325 | Val Loss: 0.6692\n",
      "Epoch 48 | Train Loss: 0.7619 | Val Loss: 0.6728\n",
      "Epoch 49 | Train Loss: 0.7472 | Val Loss: 0.6810\n",
      "Epoch 50 | Train Loss: 0.7351 | Val Loss: 0.6742\n",
      "Fold 4 ‚ñ∂ AUC: 0.782, Balanced Acc: 0.553\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.8987 | Val Loss: 0.8883\n",
      "Epoch 02 | Train Loss: 0.8628 | Val Loss: 0.8822\n",
      "Epoch 03 | Train Loss: 0.8728 | Val Loss: 0.8754\n",
      "Epoch 04 | Train Loss: 0.8430 | Val Loss: 0.8696\n",
      "Epoch 05 | Train Loss: 0.8381 | Val Loss: 0.8841\n",
      "Epoch 06 | Train Loss: 0.8242 | Val Loss: 0.8565\n",
      "Epoch 07 | Train Loss: 0.8053 | Val Loss: 0.9782\n",
      "Epoch 08 | Train Loss: 0.8660 | Val Loss: 0.8469\n",
      "Epoch 09 | Train Loss: 0.8062 | Val Loss: 0.8345\n",
      "Epoch 10 | Train Loss: 0.7860 | Val Loss: 0.8266\n",
      "Epoch 11 | Train Loss: 0.7785 | Val Loss: 0.8406\n",
      "Epoch 12 | Train Loss: 0.7869 | Val Loss: 0.8728\n",
      "Epoch 13 | Train Loss: 0.8066 | Val Loss: 0.8232\n",
      "Epoch 14 | Train Loss: 0.7992 | Val Loss: 0.8387\n",
      "Epoch 15 | Train Loss: 0.7611 | Val Loss: 0.8257\n",
      "Epoch 16 | Train Loss: 0.7580 | Val Loss: 0.8561\n",
      "Epoch 17 | Train Loss: 0.7734 | Val Loss: 0.8210\n",
      "Epoch 18 | Train Loss: 0.7495 | Val Loss: 0.8178\n",
      "Epoch 19 | Train Loss: 0.7513 | Val Loss: 0.8303\n",
      "Epoch 20 | Train Loss: 0.7872 | Val Loss: 0.8240\n",
      "Epoch 21 | Train Loss: 0.7434 | Val Loss: 0.8213\n",
      "Epoch 22 | Train Loss: 0.7484 | Val Loss: 0.8195\n",
      "Epoch 23 | Train Loss: 0.7420 | Val Loss: 0.8121\n",
      "Epoch 24 | Train Loss: 0.7603 | Val Loss: 0.8074\n",
      "Epoch 25 | Train Loss: 0.7398 | Val Loss: 0.8025\n",
      "Epoch 26 | Train Loss: 0.7278 | Val Loss: 0.8074\n",
      "Epoch 27 | Train Loss: 0.7255 | Val Loss: 0.8115\n",
      "Epoch 28 | Train Loss: 0.7447 | Val Loss: 0.7985\n",
      "Epoch 29 | Train Loss: 0.7377 | Val Loss: 0.7961\n",
      "Epoch 30 | Train Loss: 0.7268 | Val Loss: 0.7950\n",
      "Epoch 31 | Train Loss: 0.7178 | Val Loss: 0.7899\n",
      "Epoch 32 | Train Loss: 0.7071 | Val Loss: 0.7872\n",
      "Epoch 33 | Train Loss: 0.7255 | Val Loss: 0.8076\n",
      "Epoch 34 | Train Loss: 0.7407 | Val Loss: 0.7956\n",
      "Epoch 35 | Train Loss: 0.7348 | Val Loss: 0.7907\n",
      "Epoch 36 | Train Loss: 0.7286 | Val Loss: 0.7863\n",
      "Epoch 37 | Train Loss: 0.7297 | Val Loss: 0.7913\n",
      "Epoch 38 | Train Loss: 0.7218 | Val Loss: 0.8099\n",
      "Epoch 39 | Train Loss: 0.7402 | Val Loss: 0.7953\n",
      "Epoch 40 | Train Loss: 0.7114 | Val Loss: 0.7838\n",
      "Epoch 41 | Train Loss: 0.7267 | Val Loss: 0.7926\n",
      "Epoch 42 | Train Loss: 0.7427 | Val Loss: 0.7793\n",
      "Epoch 43 | Train Loss: 0.7093 | Val Loss: 0.8025\n",
      "Epoch 44 | Train Loss: 0.7356 | Val Loss: 0.8088\n",
      "Epoch 45 | Train Loss: 0.7288 | Val Loss: 0.7899\n",
      "Epoch 46 | Train Loss: 0.7297 | Val Loss: 0.8112\n",
      "Epoch 47 | Train Loss: 0.7313 | Val Loss: 0.8002\n",
      "Epoch 48 | Train Loss: 0.7219 | Val Loss: 0.8080\n",
      "Epoch 49 | Train Loss: 0.7262 | Val Loss: 0.8065\n",
      "Epoch 50 | Train Loss: 0.7114 | Val Loss: 0.7959\n",
      "Fold 5 ‚ñ∂ AUC: 0.730, Balanced Acc: 0.466\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9221 | Val Loss: 0.9288\n",
      "Epoch 02 | Train Loss: 0.8782 | Val Loss: 0.9032\n",
      "Epoch 03 | Train Loss: 0.8586 | Val Loss: 0.8889\n",
      "Epoch 04 | Train Loss: 0.8579 | Val Loss: 0.8872\n",
      "Epoch 05 | Train Loss: 0.8461 | Val Loss: 0.8904\n",
      "Epoch 06 | Train Loss: 0.8319 | Val Loss: 0.8724\n",
      "Epoch 07 | Train Loss: 0.8604 | Val Loss: 0.8596\n",
      "Epoch 08 | Train Loss: 0.8441 | Val Loss: 0.8480\n",
      "Epoch 09 | Train Loss: 0.8140 | Val Loss: 0.8414\n",
      "Epoch 10 | Train Loss: 0.8121 | Val Loss: 0.8274\n",
      "Epoch 11 | Train Loss: 0.7996 | Val Loss: 0.8246\n",
      "Epoch 12 | Train Loss: 0.7718 | Val Loss: 0.8116\n",
      "Epoch 13 | Train Loss: 0.7998 | Val Loss: 0.7997\n",
      "Epoch 14 | Train Loss: 0.7657 | Val Loss: 0.8063\n",
      "Epoch 15 | Train Loss: 0.7684 | Val Loss: 0.7998\n",
      "Epoch 16 | Train Loss: 0.7562 | Val Loss: 0.8067\n",
      "Epoch 17 | Train Loss: 0.7573 | Val Loss: 0.8227\n",
      "Epoch 18 | Train Loss: 0.7647 | Val Loss: 0.8154\n",
      "Epoch 19 | Train Loss: 0.7455 | Val Loss: 0.8087\n",
      "Epoch 20 | Train Loss: 0.7450 | Val Loss: 0.8290\n",
      "Epoch 21 | Train Loss: 0.7632 | Val Loss: 0.8074\n",
      "Epoch 22 | Train Loss: 0.7449 | Val Loss: 0.8024\n",
      "Epoch 23 | Train Loss: 0.7534 | Val Loss: 0.8447\n",
      "Epoch 24 | Train Loss: 0.7939 | Val Loss: 0.8139\n",
      "Epoch 25 | Train Loss: 0.7591 | Val Loss: 0.8263\n",
      "Epoch 26 | Train Loss: 0.7561 | Val Loss: 0.7990\n",
      "Epoch 27 | Train Loss: 0.7416 | Val Loss: 0.8183\n",
      "Epoch 28 | Train Loss: 0.7351 | Val Loss: 0.8004\n",
      "Epoch 29 | Train Loss: 0.7449 | Val Loss: 0.8073\n",
      "Epoch 30 | Train Loss: 0.7459 | Val Loss: 0.8081\n",
      "Epoch 31 | Train Loss: 0.7133 | Val Loss: 0.8478\n",
      "Epoch 32 | Train Loss: 0.7801 | Val Loss: 0.8083\n",
      "Epoch 33 | Train Loss: 0.7334 | Val Loss: 0.8030\n",
      "Epoch 34 | Train Loss: 0.7347 | Val Loss: 0.8065\n",
      "Epoch 35 | Train Loss: 0.7517 | Val Loss: 0.8115\n",
      "Epoch 36 | Train Loss: 0.7334 | Val Loss: 0.8268\n",
      "Epoch 37 | Train Loss: 0.7643 | Val Loss: 0.8071\n",
      "Epoch 38 | Train Loss: 0.7573 | Val Loss: 0.8092\n",
      "Epoch 39 | Train Loss: 0.7311 | Val Loss: 0.8192\n",
      "Epoch 40 | Train Loss: 0.7402 | Val Loss: 0.8026\n",
      "Epoch 41 | Train Loss: 0.7327 | Val Loss: 0.8452\n",
      "Epoch 42 | Train Loss: 0.7586 | Val Loss: 0.8089\n",
      "Epoch 43 | Train Loss: 0.7434 | Val Loss: 0.8088\n",
      "Epoch 44 | Train Loss: 0.7346 | Val Loss: 0.8154\n",
      "Epoch 45 | Train Loss: 0.7585 | Val Loss: 0.8085\n",
      "Epoch 46 | Train Loss: 0.7354 | Val Loss: 0.8051\n",
      "Epoch 47 | Train Loss: 0.7147 | Val Loss: 0.8113\n",
      "Epoch 48 | Train Loss: 0.7374 | Val Loss: 0.8356\n",
      "Epoch 49 | Train Loss: 0.7326 | Val Loss: 0.8109\n",
      "Epoch 50 | Train Loss: 0.7163 | Val Loss: 0.8142\n",
      "Fold 6 ‚ñ∂ AUC: 0.736, Balanced Acc: 0.491\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9307 | Val Loss: 0.8854\n",
      "Epoch 02 | Train Loss: 0.8736 | Val Loss: 0.8537\n",
      "Epoch 03 | Train Loss: 0.8939 | Val Loss: 0.8460\n",
      "Epoch 04 | Train Loss: 0.8658 | Val Loss: 0.8655\n",
      "Epoch 05 | Train Loss: 0.8739 | Val Loss: 0.8406\n",
      "Epoch 06 | Train Loss: 0.8519 | Val Loss: 0.8245\n",
      "Epoch 07 | Train Loss: 0.8569 | Val Loss: 0.7947\n",
      "Epoch 08 | Train Loss: 0.8253 | Val Loss: 0.7627\n",
      "Epoch 09 | Train Loss: 0.8151 | Val Loss: 0.7550\n",
      "Epoch 10 | Train Loss: 0.8241 | Val Loss: 0.7488\n",
      "Epoch 11 | Train Loss: 0.8444 | Val Loss: 0.8530\n",
      "Epoch 12 | Train Loss: 0.8147 | Val Loss: 0.7469\n",
      "Epoch 13 | Train Loss: 0.7884 | Val Loss: 0.7174\n",
      "Epoch 14 | Train Loss: 0.7812 | Val Loss: 0.7241\n",
      "Epoch 15 | Train Loss: 0.7596 | Val Loss: 0.7391\n",
      "Epoch 16 | Train Loss: 0.7898 | Val Loss: 0.6965\n",
      "Epoch 17 | Train Loss: 0.7697 | Val Loss: 0.6926\n",
      "Epoch 18 | Train Loss: 0.7755 | Val Loss: 0.7021\n",
      "Epoch 19 | Train Loss: 0.7462 | Val Loss: 0.7088\n",
      "Epoch 20 | Train Loss: 0.7525 | Val Loss: 0.7006\n",
      "Epoch 21 | Train Loss: 0.7815 | Val Loss: 0.7544\n",
      "Epoch 22 | Train Loss: 0.7794 | Val Loss: 0.7118\n",
      "Epoch 23 | Train Loss: 0.7305 | Val Loss: 0.7011\n",
      "Epoch 24 | Train Loss: 0.7807 | Val Loss: 0.7040\n",
      "Epoch 25 | Train Loss: 0.7438 | Val Loss: 0.7047\n",
      "Epoch 26 | Train Loss: 0.7464 | Val Loss: 0.7126\n",
      "Epoch 27 | Train Loss: 0.7306 | Val Loss: 0.7125\n",
      "Epoch 28 | Train Loss: 0.7446 | Val Loss: 0.7240\n",
      "Epoch 29 | Train Loss: 0.7487 | Val Loss: 0.7288\n",
      "Epoch 30 | Train Loss: 0.7477 | Val Loss: 0.7139\n",
      "Epoch 31 | Train Loss: 0.7361 | Val Loss: 0.7187\n",
      "Epoch 32 | Train Loss: 0.7314 | Val Loss: 0.7207\n",
      "Epoch 33 | Train Loss: 0.7416 | Val Loss: 0.7216\n",
      "Epoch 34 | Train Loss: 0.7640 | Val Loss: 0.7542\n",
      "Epoch 35 | Train Loss: 0.7573 | Val Loss: 0.7209\n",
      "Epoch 36 | Train Loss: 0.7559 | Val Loss: 0.7109\n",
      "Epoch 37 | Train Loss: 0.7471 | Val Loss: 0.7117\n",
      "Epoch 38 | Train Loss: 0.7382 | Val Loss: 0.7300\n",
      "Epoch 39 | Train Loss: 0.7202 | Val Loss: 0.7243\n",
      "Epoch 40 | Train Loss: 0.7286 | Val Loss: 0.7309\n",
      "Epoch 41 | Train Loss: 0.7565 | Val Loss: 0.8039\n",
      "Epoch 42 | Train Loss: 0.7748 | Val Loss: 0.7350\n",
      "Epoch 43 | Train Loss: 0.7276 | Val Loss: 0.7201\n",
      "Epoch 44 | Train Loss: 0.7153 | Val Loss: 0.7116\n",
      "Epoch 45 | Train Loss: 0.7317 | Val Loss: 0.7270\n",
      "Epoch 46 | Train Loss: 0.7647 | Val Loss: 0.7196\n",
      "Epoch 47 | Train Loss: 0.7335 | Val Loss: 0.7256\n",
      "Epoch 48 | Train Loss: 0.7198 | Val Loss: 0.7158\n",
      "Epoch 49 | Train Loss: 0.7190 | Val Loss: 0.7280\n",
      "Epoch 50 | Train Loss: 0.7257 | Val Loss: 0.7213\n",
      "Fold 7 ‚ñ∂ AUC: 0.754, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9246 | Val Loss: 0.8785\n",
      "Epoch 02 | Train Loss: 0.8894 | Val Loss: 0.8734\n",
      "Epoch 03 | Train Loss: 0.8824 | Val Loss: 0.8536\n",
      "Epoch 04 | Train Loss: 0.8731 | Val Loss: 0.8610\n",
      "Epoch 05 | Train Loss: 0.8552 | Val Loss: 0.8418\n",
      "Epoch 06 | Train Loss: 0.8380 | Val Loss: 0.8361\n",
      "Epoch 07 | Train Loss: 0.8538 | Val Loss: 0.8111\n",
      "Epoch 08 | Train Loss: 0.8140 | Val Loss: 0.7911\n",
      "Epoch 09 | Train Loss: 0.8145 | Val Loss: 0.8035\n",
      "Epoch 10 | Train Loss: 0.7901 | Val Loss: 0.8136\n",
      "Epoch 11 | Train Loss: 0.8311 | Val Loss: 0.8050\n",
      "Epoch 12 | Train Loss: 0.7766 | Val Loss: 0.7730\n",
      "Epoch 13 | Train Loss: 0.7763 | Val Loss: 0.7627\n",
      "Epoch 14 | Train Loss: 0.7786 | Val Loss: 0.7775\n",
      "Epoch 15 | Train Loss: 0.7874 | Val Loss: 0.7829\n",
      "Epoch 16 | Train Loss: 0.7416 | Val Loss: 0.7660\n",
      "Epoch 17 | Train Loss: 0.7434 | Val Loss: 0.7787\n",
      "Epoch 18 | Train Loss: 0.7639 | Val Loss: 0.7992\n",
      "Epoch 19 | Train Loss: 0.7840 | Val Loss: 0.7705\n",
      "Epoch 20 | Train Loss: 0.7748 | Val Loss: 0.7936\n",
      "Epoch 21 | Train Loss: 0.7552 | Val Loss: 0.7837\n",
      "Epoch 22 | Train Loss: 0.7652 | Val Loss: 0.8096\n",
      "Epoch 23 | Train Loss: 0.7345 | Val Loss: 0.7732\n",
      "Epoch 24 | Train Loss: 0.7492 | Val Loss: 0.7810\n",
      "Epoch 25 | Train Loss: 0.7181 | Val Loss: 0.7799\n",
      "Epoch 26 | Train Loss: 0.7307 | Val Loss: 0.7757\n",
      "Epoch 27 | Train Loss: 0.7165 | Val Loss: 0.7779\n",
      "Epoch 28 | Train Loss: 0.7301 | Val Loss: 0.7787\n",
      "Epoch 29 | Train Loss: 0.7147 | Val Loss: 0.8070\n",
      "Epoch 30 | Train Loss: 0.7327 | Val Loss: 0.7776\n",
      "Epoch 31 | Train Loss: 0.7179 | Val Loss: 0.7820\n",
      "Epoch 32 | Train Loss: 0.7049 | Val Loss: 0.7909\n",
      "Epoch 33 | Train Loss: 0.7273 | Val Loss: 0.7897\n",
      "Epoch 34 | Train Loss: 0.7115 | Val Loss: 0.8054\n",
      "Epoch 35 | Train Loss: 0.7376 | Val Loss: 0.8149\n",
      "Epoch 36 | Train Loss: 0.7802 | Val Loss: 0.7826\n",
      "Epoch 37 | Train Loss: 0.7661 | Val Loss: 0.8103\n",
      "Epoch 38 | Train Loss: 0.7400 | Val Loss: 0.7818\n",
      "Epoch 39 | Train Loss: 0.7166 | Val Loss: 0.7866\n",
      "Epoch 40 | Train Loss: 0.7243 | Val Loss: 0.7844\n",
      "Epoch 41 | Train Loss: 0.7172 | Val Loss: 0.7766\n",
      "Epoch 42 | Train Loss: 0.6868 | Val Loss: 0.7875\n",
      "Epoch 43 | Train Loss: 0.7427 | Val Loss: 0.7924\n",
      "Epoch 44 | Train Loss: 0.7035 | Val Loss: 0.7981\n",
      "Epoch 45 | Train Loss: 0.7170 | Val Loss: 0.7871\n",
      "Epoch 46 | Train Loss: 0.6866 | Val Loss: 0.7781\n",
      "Epoch 47 | Train Loss: 0.7029 | Val Loss: 0.7975\n",
      "Epoch 48 | Train Loss: 0.7326 | Val Loss: 0.7844\n",
      "Epoch 49 | Train Loss: 0.7377 | Val Loss: 0.8032\n",
      "Epoch 50 | Train Loss: 0.7670 | Val Loss: 0.7828\n",
      "Fold 8 ‚ñ∂ AUC: 0.719, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9606 | Val Loss: 0.8751\n",
      "Epoch 02 | Train Loss: 0.8805 | Val Loss: 0.8884\n",
      "Epoch 03 | Train Loss: 0.8662 | Val Loss: 0.8701\n",
      "Epoch 04 | Train Loss: 0.8852 | Val Loss: 0.8940\n",
      "Epoch 05 | Train Loss: 0.8593 | Val Loss: 0.8678\n",
      "Epoch 06 | Train Loss: 0.8614 | Val Loss: 0.8563\n",
      "Epoch 07 | Train Loss: 0.8405 | Val Loss: 0.8525\n",
      "Epoch 08 | Train Loss: 0.8358 | Val Loss: 0.8600\n",
      "Epoch 09 | Train Loss: 0.8473 | Val Loss: 0.8857\n",
      "Epoch 10 | Train Loss: 0.8268 | Val Loss: 0.8343\n",
      "Epoch 11 | Train Loss: 0.8169 | Val Loss: 0.8156\n",
      "Epoch 12 | Train Loss: 0.7712 | Val Loss: 0.8216\n",
      "Epoch 13 | Train Loss: 0.7858 | Val Loss: 0.8752\n",
      "Epoch 14 | Train Loss: 0.7876 | Val Loss: 0.7996\n",
      "Epoch 15 | Train Loss: 0.7772 | Val Loss: 0.7839\n",
      "Epoch 16 | Train Loss: 0.7596 | Val Loss: 0.7855\n",
      "Epoch 17 | Train Loss: 0.7479 | Val Loss: 0.7943\n",
      "Epoch 18 | Train Loss: 0.7696 | Val Loss: 0.8036\n",
      "Epoch 19 | Train Loss: 0.7779 | Val Loss: 0.7693\n",
      "Epoch 20 | Train Loss: 0.7429 | Val Loss: 0.8146\n",
      "Epoch 21 | Train Loss: 0.7719 | Val Loss: 0.7637\n",
      "Epoch 22 | Train Loss: 0.7460 | Val Loss: 0.7587\n",
      "Epoch 23 | Train Loss: 0.8096 | Val Loss: 0.7602\n",
      "Epoch 24 | Train Loss: 0.7730 | Val Loss: 0.7927\n",
      "Epoch 25 | Train Loss: 0.7319 | Val Loss: 0.7561\n",
      "Epoch 26 | Train Loss: 0.7361 | Val Loss: 0.8028\n",
      "Epoch 27 | Train Loss: 0.7380 | Val Loss: 0.7524\n",
      "Epoch 28 | Train Loss: 0.7399 | Val Loss: 0.7502\n",
      "Epoch 29 | Train Loss: 0.7595 | Val Loss: 0.7990\n",
      "Epoch 30 | Train Loss: 0.7661 | Val Loss: 0.7635\n",
      "Epoch 31 | Train Loss: 0.7440 | Val Loss: 0.7697\n",
      "Epoch 32 | Train Loss: 0.7276 | Val Loss: 0.7800\n",
      "Epoch 33 | Train Loss: 0.7674 | Val Loss: 0.7505\n",
      "Epoch 34 | Train Loss: 0.7447 | Val Loss: 0.7400\n",
      "Epoch 35 | Train Loss: 0.7313 | Val Loss: 0.7549\n",
      "Epoch 36 | Train Loss: 0.7098 | Val Loss: 0.7582\n",
      "Epoch 37 | Train Loss: 0.7256 | Val Loss: 0.7798\n",
      "Epoch 38 | Train Loss: 0.7226 | Val Loss: 0.7404\n",
      "Epoch 39 | Train Loss: 0.7268 | Val Loss: 0.7484\n",
      "Epoch 40 | Train Loss: 0.7276 | Val Loss: 0.7943\n",
      "Epoch 41 | Train Loss: 0.7368 | Val Loss: 0.7477\n",
      "Epoch 42 | Train Loss: 0.7324 | Val Loss: 0.7387\n",
      "Epoch 43 | Train Loss: 0.7365 | Val Loss: 0.8134\n",
      "Epoch 44 | Train Loss: 0.7745 | Val Loss: 0.7389\n",
      "Epoch 45 | Train Loss: 0.7289 | Val Loss: 0.7457\n",
      "Epoch 46 | Train Loss: 0.7346 | Val Loss: 0.7448\n",
      "Epoch 47 | Train Loss: 0.7187 | Val Loss: 0.7527\n",
      "Epoch 48 | Train Loss: 0.7241 | Val Loss: 0.7583\n",
      "Epoch 49 | Train Loss: 0.7250 | Val Loss: 0.7495\n",
      "Epoch 50 | Train Loss: 0.7130 | Val Loss: 0.7486\n",
      "Fold 9 ‚ñ∂ AUC: 0.775, Balanced Acc: 0.499\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9026 | Val Loss: 0.8749\n",
      "Epoch 02 | Train Loss: 0.8835 | Val Loss: 0.8734\n",
      "Epoch 03 | Train Loss: 0.8743 | Val Loss: 0.8616\n",
      "Epoch 04 | Train Loss: 0.8742 | Val Loss: 0.8533\n",
      "Epoch 05 | Train Loss: 0.8566 | Val Loss: 0.8524\n",
      "Epoch 06 | Train Loss: 0.8592 | Val Loss: 0.8439\n",
      "Epoch 07 | Train Loss: 0.8536 | Val Loss: 0.8508\n",
      "Epoch 08 | Train Loss: 0.8398 | Val Loss: 0.8232\n",
      "Epoch 09 | Train Loss: 0.8121 | Val Loss: 0.8052\n",
      "Epoch 10 | Train Loss: 0.8118 | Val Loss: 0.8026\n",
      "Epoch 11 | Train Loss: 0.8018 | Val Loss: 0.7885\n",
      "Epoch 12 | Train Loss: 0.8134 | Val Loss: 0.7775\n",
      "Epoch 13 | Train Loss: 0.8348 | Val Loss: 0.7903\n",
      "Epoch 14 | Train Loss: 0.7848 | Val Loss: 0.7905\n",
      "Epoch 15 | Train Loss: 0.7807 | Val Loss: 0.7705\n",
      "Epoch 16 | Train Loss: 0.7643 | Val Loss: 0.7703\n",
      "Epoch 17 | Train Loss: 0.8102 | Val Loss: 0.8079\n",
      "Epoch 18 | Train Loss: 0.8034 | Val Loss: 0.7834\n",
      "Epoch 19 | Train Loss: 0.7907 | Val Loss: 0.8499\n",
      "Epoch 20 | Train Loss: 0.7637 | Val Loss: 0.7760\n",
      "Epoch 21 | Train Loss: 0.7700 | Val Loss: 0.7830\n",
      "Epoch 22 | Train Loss: 0.7687 | Val Loss: 0.7916\n",
      "Epoch 23 | Train Loss: 0.7522 | Val Loss: 0.7769\n",
      "Epoch 24 | Train Loss: 0.7507 | Val Loss: 0.7709\n",
      "Epoch 25 | Train Loss: 0.7547 | Val Loss: 0.7846\n",
      "Epoch 26 | Train Loss: 0.7498 | Val Loss: 0.7992\n",
      "Epoch 27 | Train Loss: 0.7471 | Val Loss: 0.7807\n",
      "Epoch 28 | Train Loss: 0.7508 | Val Loss: 0.7718\n",
      "Epoch 29 | Train Loss: 0.7324 | Val Loss: 0.7671\n",
      "Epoch 30 | Train Loss: 0.7748 | Val Loss: 0.7721\n",
      "Epoch 31 | Train Loss: 0.7566 | Val Loss: 0.7783\n",
      "Epoch 32 | Train Loss: 0.7171 | Val Loss: 0.8200\n",
      "Epoch 33 | Train Loss: 0.7636 | Val Loss: 0.7713\n",
      "Epoch 34 | Train Loss: 0.7293 | Val Loss: 0.7745\n",
      "Epoch 35 | Train Loss: 0.7485 | Val Loss: 0.7772\n",
      "Epoch 36 | Train Loss: 0.7273 | Val Loss: 0.7766\n",
      "Epoch 37 | Train Loss: 0.7376 | Val Loss: 0.7732\n",
      "Epoch 38 | Train Loss: 0.7325 | Val Loss: 0.7789\n",
      "Epoch 39 | Train Loss: 0.7624 | Val Loss: 0.8033\n",
      "Epoch 40 | Train Loss: 0.7109 | Val Loss: 0.7756\n",
      "Epoch 41 | Train Loss: 0.7318 | Val Loss: 0.8013\n",
      "Epoch 42 | Train Loss: 0.7200 | Val Loss: 0.7847\n",
      "Epoch 43 | Train Loss: 0.7327 | Val Loss: 0.7766\n",
      "Epoch 44 | Train Loss: 0.7466 | Val Loss: 0.7861\n",
      "Epoch 45 | Train Loss: 0.7305 | Val Loss: 0.7899\n",
      "Epoch 46 | Train Loss: 0.7329 | Val Loss: 0.8243\n",
      "Epoch 47 | Train Loss: 0.7203 | Val Loss: 0.7763\n",
      "Epoch 48 | Train Loss: 0.7349 | Val Loss: 0.7703\n",
      "Epoch 49 | Train Loss: 0.7452 | Val Loss: 0.8036\n",
      "Epoch 50 | Train Loss: 0.7603 | Val Loss: 0.7785\n",
      "Fold 10 ‚ñ∂ AUC: 0.709, Balanced Acc: 0.469\n",
      "üîç Summary for hd=64, dp=0.4, lr=0.001 ‚Üí AUC: 0.7445¬±0.0302 | BalAcc: 0.4874¬±0.0422\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.4, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.8995 | Val Loss: 0.8661\n",
      "Epoch 02 | Train Loss: 0.9022 | Val Loss: 0.8584\n",
      "Epoch 03 | Train Loss: 0.8736 | Val Loss: 0.8554\n",
      "Epoch 04 | Train Loss: 0.8676 | Val Loss: 0.8462\n",
      "Epoch 05 | Train Loss: 0.8551 | Val Loss: 0.8449\n",
      "Epoch 06 | Train Loss: 0.8614 | Val Loss: 0.8600\n",
      "Epoch 07 | Train Loss: 0.8652 | Val Loss: 0.8366\n",
      "Epoch 08 | Train Loss: 0.8462 | Val Loss: 0.8359\n",
      "Epoch 09 | Train Loss: 0.8517 | Val Loss: 0.8362\n",
      "Epoch 10 | Train Loss: 0.8445 | Val Loss: 0.8179\n",
      "Epoch 11 | Train Loss: 0.8357 | Val Loss: 0.8080\n",
      "Epoch 12 | Train Loss: 0.8187 | Val Loss: 0.7935\n",
      "Epoch 13 | Train Loss: 0.8080 | Val Loss: 0.7949\n",
      "Epoch 14 | Train Loss: 0.8412 | Val Loss: 0.7791\n",
      "Epoch 15 | Train Loss: 0.7976 | Val Loss: 0.7758\n",
      "Epoch 16 | Train Loss: 0.8139 | Val Loss: 0.7556\n",
      "Epoch 17 | Train Loss: 0.7817 | Val Loss: 0.7490\n",
      "Epoch 18 | Train Loss: 0.7557 | Val Loss: 0.7783\n",
      "Epoch 19 | Train Loss: 0.8050 | Val Loss: 0.7340\n",
      "Epoch 20 | Train Loss: 0.7755 | Val Loss: 0.7575\n",
      "Epoch 21 | Train Loss: 0.7802 | Val Loss: 0.7272\n",
      "Epoch 22 | Train Loss: 0.7641 | Val Loss: 0.7201\n",
      "Epoch 23 | Train Loss: 0.7691 | Val Loss: 0.7402\n",
      "Epoch 24 | Train Loss: 0.7854 | Val Loss: 0.7213\n",
      "Epoch 25 | Train Loss: 0.7548 | Val Loss: 0.7156\n",
      "Epoch 26 | Train Loss: 0.7591 | Val Loss: 0.7893\n",
      "Epoch 27 | Train Loss: 0.7666 | Val Loss: 0.7154\n",
      "Epoch 28 | Train Loss: 0.7630 | Val Loss: 0.7295\n",
      "Epoch 29 | Train Loss: 0.7564 | Val Loss: 0.7153\n",
      "Epoch 30 | Train Loss: 0.7390 | Val Loss: 0.7603\n",
      "Epoch 31 | Train Loss: 0.7674 | Val Loss: 0.7050\n",
      "Epoch 32 | Train Loss: 0.7533 | Val Loss: 0.7049\n",
      "Epoch 33 | Train Loss: 0.7598 | Val Loss: 0.7291\n",
      "Epoch 34 | Train Loss: 0.7514 | Val Loss: 0.7096\n",
      "Epoch 35 | Train Loss: 0.7652 | Val Loss: 0.6991\n",
      "Epoch 36 | Train Loss: 0.7494 | Val Loss: 0.7080\n",
      "Epoch 37 | Train Loss: 0.7337 | Val Loss: 0.7033\n",
      "Epoch 38 | Train Loss: 0.7464 | Val Loss: 0.7108\n",
      "Epoch 39 | Train Loss: 0.7219 | Val Loss: 0.6983\n",
      "Epoch 40 | Train Loss: 0.7516 | Val Loss: 0.7017\n",
      "Epoch 41 | Train Loss: 0.7682 | Val Loss: 0.7324\n",
      "Epoch 42 | Train Loss: 0.7341 | Val Loss: 0.7009\n",
      "Epoch 43 | Train Loss: 0.7527 | Val Loss: 0.7953\n",
      "Epoch 44 | Train Loss: 0.7886 | Val Loss: 0.7146\n",
      "Epoch 45 | Train Loss: 0.7731 | Val Loss: 0.7023\n",
      "Epoch 46 | Train Loss: 0.7485 | Val Loss: 0.6993\n",
      "Epoch 47 | Train Loss: 0.7259 | Val Loss: 0.6981\n",
      "Epoch 48 | Train Loss: 0.7580 | Val Loss: 0.6990\n",
      "Epoch 49 | Train Loss: 0.7288 | Val Loss: 0.6971\n",
      "Epoch 50 | Train Loss: 0.7405 | Val Loss: 0.7004\n",
      "Fold 1 ‚ñ∂ AUC: 0.766, Balanced Acc: 0.505\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9037 | Val Loss: 0.8651\n",
      "Epoch 02 | Train Loss: 0.8911 | Val Loss: 0.8609\n",
      "Epoch 03 | Train Loss: 0.8770 | Val Loss: 0.8558\n",
      "Epoch 04 | Train Loss: 0.8734 | Val Loss: 0.8492\n",
      "Epoch 05 | Train Loss: 0.8598 | Val Loss: 0.8505\n",
      "Epoch 06 | Train Loss: 0.8583 | Val Loss: 0.8513\n",
      "Epoch 07 | Train Loss: 0.8545 | Val Loss: 0.8366\n",
      "Epoch 08 | Train Loss: 0.8476 | Val Loss: 0.8325\n",
      "Epoch 09 | Train Loss: 0.8561 | Val Loss: 0.8269\n",
      "Epoch 10 | Train Loss: 0.8382 | Val Loss: 0.8669\n",
      "Epoch 11 | Train Loss: 0.8640 | Val Loss: 0.8194\n",
      "Epoch 12 | Train Loss: 0.8267 | Val Loss: 0.8094\n",
      "Epoch 13 | Train Loss: 0.8253 | Val Loss: 0.8115\n",
      "Epoch 14 | Train Loss: 0.8170 | Val Loss: 0.8138\n",
      "Epoch 15 | Train Loss: 0.8119 | Val Loss: 0.7993\n",
      "Epoch 16 | Train Loss: 0.8080 | Val Loss: 0.7841\n",
      "Epoch 17 | Train Loss: 0.7830 | Val Loss: 0.7731\n",
      "Epoch 18 | Train Loss: 0.7777 | Val Loss: 0.7608\n",
      "Epoch 19 | Train Loss: 0.7740 | Val Loss: 0.7599\n",
      "Epoch 20 | Train Loss: 0.7884 | Val Loss: 0.7564\n",
      "Epoch 21 | Train Loss: 0.8009 | Val Loss: 0.7617\n",
      "Epoch 22 | Train Loss: 0.7837 | Val Loss: 0.7484\n",
      "Epoch 23 | Train Loss: 0.7456 | Val Loss: 0.7405\n",
      "Epoch 24 | Train Loss: 0.7576 | Val Loss: 0.7642\n",
      "Epoch 25 | Train Loss: 0.7582 | Val Loss: 0.7707\n",
      "Epoch 26 | Train Loss: 0.7915 | Val Loss: 0.7428\n",
      "Epoch 27 | Train Loss: 0.7723 | Val Loss: 0.7414\n",
      "Epoch 28 | Train Loss: 0.7737 | Val Loss: 0.7298\n",
      "Epoch 29 | Train Loss: 0.7672 | Val Loss: 0.7756\n",
      "Epoch 30 | Train Loss: 0.7567 | Val Loss: 0.7476\n",
      "Epoch 31 | Train Loss: 0.7564 | Val Loss: 0.7235\n",
      "Epoch 32 | Train Loss: 0.7531 | Val Loss: 0.7555\n",
      "Epoch 33 | Train Loss: 0.7568 | Val Loss: 0.7199\n",
      "Epoch 34 | Train Loss: 0.7514 | Val Loss: 0.7185\n",
      "Epoch 35 | Train Loss: 0.7694 | Val Loss: 0.7142\n",
      "Epoch 36 | Train Loss: 0.7510 | Val Loss: 0.7780\n",
      "Epoch 37 | Train Loss: 0.7516 | Val Loss: 0.7222\n",
      "Epoch 38 | Train Loss: 0.7333 | Val Loss: 0.7136\n",
      "Epoch 39 | Train Loss: 0.7433 | Val Loss: 0.7210\n",
      "Epoch 40 | Train Loss: 0.7291 | Val Loss: 0.7252\n",
      "Epoch 41 | Train Loss: 0.7070 | Val Loss: 0.7655\n",
      "Epoch 42 | Train Loss: 0.7408 | Val Loss: 0.7095\n",
      "Epoch 43 | Train Loss: 0.7084 | Val Loss: 0.8152\n",
      "Epoch 44 | Train Loss: 0.7597 | Val Loss: 0.7197\n",
      "Epoch 45 | Train Loss: 0.7360 | Val Loss: 0.7117\n",
      "Epoch 46 | Train Loss: 0.7489 | Val Loss: 0.7120\n",
      "Epoch 47 | Train Loss: 0.7321 | Val Loss: 0.7164\n",
      "Epoch 48 | Train Loss: 0.7303 | Val Loss: 0.7556\n",
      "Epoch 49 | Train Loss: 0.7248 | Val Loss: 0.7606\n",
      "Epoch 50 | Train Loss: 0.7463 | Val Loss: 0.7076\n",
      "Fold 2 ‚ñ∂ AUC: 0.679, Balanced Acc: 0.540\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 1.0456 | Val Loss: 0.8859\n",
      "Epoch 02 | Train Loss: 0.8918 | Val Loss: 0.8657\n",
      "Epoch 03 | Train Loss: 0.8795 | Val Loss: 0.8619\n",
      "Epoch 04 | Train Loss: 0.8907 | Val Loss: 0.8608\n",
      "Epoch 05 | Train Loss: 0.8705 | Val Loss: 0.8627\n",
      "Epoch 06 | Train Loss: 0.8620 | Val Loss: 0.8519\n",
      "Epoch 07 | Train Loss: 0.8600 | Val Loss: 0.8461\n",
      "Epoch 08 | Train Loss: 0.8636 | Val Loss: 0.8464\n",
      "Epoch 09 | Train Loss: 0.8574 | Val Loss: 0.8337\n",
      "Epoch 10 | Train Loss: 0.8476 | Val Loss: 0.8226\n",
      "Epoch 11 | Train Loss: 0.8330 | Val Loss: 0.8201\n",
      "Epoch 12 | Train Loss: 0.8232 | Val Loss: 0.7933\n",
      "Epoch 13 | Train Loss: 0.8174 | Val Loss: 0.7892\n",
      "Epoch 14 | Train Loss: 0.8243 | Val Loss: 0.8503\n",
      "Epoch 15 | Train Loss: 0.8328 | Val Loss: 0.7903\n",
      "Epoch 16 | Train Loss: 0.8100 | Val Loss: 0.7785\n",
      "Epoch 17 | Train Loss: 0.7952 | Val Loss: 0.8005\n",
      "Epoch 18 | Train Loss: 0.7804 | Val Loss: 0.7617\n",
      "Epoch 19 | Train Loss: 0.7872 | Val Loss: 0.7654\n",
      "Epoch 20 | Train Loss: 0.7809 | Val Loss: 0.7833\n",
      "Epoch 21 | Train Loss: 0.7747 | Val Loss: 0.7644\n",
      "Epoch 22 | Train Loss: 0.7765 | Val Loss: 0.7453\n",
      "Epoch 23 | Train Loss: 0.7643 | Val Loss: 0.8083\n",
      "Epoch 24 | Train Loss: 0.7569 | Val Loss: 0.7466\n",
      "Epoch 25 | Train Loss: 0.8022 | Val Loss: 0.7479\n",
      "Epoch 26 | Train Loss: 0.7721 | Val Loss: 0.7706\n",
      "Epoch 27 | Train Loss: 0.7676 | Val Loss: 0.7515\n",
      "Epoch 28 | Train Loss: 0.7330 | Val Loss: 0.7422\n",
      "Epoch 29 | Train Loss: 0.7412 | Val Loss: 0.7438\n",
      "Epoch 30 | Train Loss: 0.7760 | Val Loss: 0.7520\n",
      "Epoch 31 | Train Loss: 0.7619 | Val Loss: 0.7447\n",
      "Epoch 32 | Train Loss: 0.7682 | Val Loss: 0.7420\n",
      "Epoch 33 | Train Loss: 0.7485 | Val Loss: 0.7597\n",
      "Epoch 34 | Train Loss: 0.7632 | Val Loss: 0.7395\n",
      "Epoch 35 | Train Loss: 0.7436 | Val Loss: 0.7621\n",
      "Epoch 36 | Train Loss: 0.7506 | Val Loss: 0.7360\n",
      "Epoch 37 | Train Loss: 0.7509 | Val Loss: 0.7401\n",
      "Epoch 38 | Train Loss: 0.7443 | Val Loss: 0.7406\n",
      "Epoch 39 | Train Loss: 0.7515 | Val Loss: 0.7352\n",
      "Epoch 40 | Train Loss: 0.7369 | Val Loss: 0.7314\n",
      "Epoch 41 | Train Loss: 0.7535 | Val Loss: 0.7729\n",
      "Epoch 42 | Train Loss: 0.7537 | Val Loss: 0.7410\n",
      "Epoch 43 | Train Loss: 0.7541 | Val Loss: 0.7393\n",
      "Epoch 44 | Train Loss: 0.7335 | Val Loss: 0.7470\n",
      "Epoch 45 | Train Loss: 0.7333 | Val Loss: 0.7282\n",
      "Epoch 46 | Train Loss: 0.7404 | Val Loss: 0.7505\n",
      "Epoch 47 | Train Loss: 0.7556 | Val Loss: 0.7277\n",
      "Epoch 48 | Train Loss: 0.7446 | Val Loss: 0.7309\n",
      "Epoch 49 | Train Loss: 0.7402 | Val Loss: 0.7355\n",
      "Epoch 50 | Train Loss: 0.7200 | Val Loss: 0.7341\n",
      "Fold 3 ‚ñ∂ AUC: 0.759, Balanced Acc: 0.497\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9449 | Val Loss: 0.8648\n",
      "Epoch 02 | Train Loss: 0.8745 | Val Loss: 0.8604\n",
      "Epoch 03 | Train Loss: 0.8808 | Val Loss: 0.8612\n",
      "Epoch 04 | Train Loss: 0.8628 | Val Loss: 0.8588\n",
      "Epoch 05 | Train Loss: 0.8708 | Val Loss: 0.8568\n",
      "Epoch 06 | Train Loss: 0.8665 | Val Loss: 0.8552\n",
      "Epoch 07 | Train Loss: 0.8672 | Val Loss: 0.8576\n",
      "Epoch 08 | Train Loss: 0.8593 | Val Loss: 0.8537\n",
      "Epoch 09 | Train Loss: 0.8766 | Val Loss: 0.8552\n",
      "Epoch 10 | Train Loss: 0.8706 | Val Loss: 0.8521\n",
      "Epoch 11 | Train Loss: 0.8783 | Val Loss: 0.8421\n",
      "Epoch 12 | Train Loss: 0.8604 | Val Loss: 0.8412\n",
      "Epoch 13 | Train Loss: 0.8458 | Val Loss: 0.8328\n",
      "Epoch 14 | Train Loss: 0.8411 | Val Loss: 0.8309\n",
      "Epoch 15 | Train Loss: 0.8622 | Val Loss: 0.8187\n",
      "Epoch 16 | Train Loss: 0.8602 | Val Loss: 0.8527\n",
      "Epoch 17 | Train Loss: 0.8533 | Val Loss: 0.8426\n",
      "Epoch 18 | Train Loss: 0.8303 | Val Loss: 0.8080\n",
      "Epoch 19 | Train Loss: 0.8329 | Val Loss: 0.8054\n",
      "Epoch 20 | Train Loss: 0.8101 | Val Loss: 0.7822\n",
      "Epoch 21 | Train Loss: 0.7911 | Val Loss: 0.7679\n",
      "Epoch 22 | Train Loss: 0.8056 | Val Loss: 0.7755\n",
      "Epoch 23 | Train Loss: 0.7906 | Val Loss: 0.7549\n",
      "Epoch 24 | Train Loss: 0.7968 | Val Loss: 0.7490\n",
      "Epoch 25 | Train Loss: 0.7837 | Val Loss: 0.7321\n",
      "Epoch 26 | Train Loss: 0.7759 | Val Loss: 0.7356\n",
      "Epoch 27 | Train Loss: 0.7699 | Val Loss: 0.7309\n",
      "Epoch 28 | Train Loss: 0.7656 | Val Loss: 0.7110\n",
      "Epoch 29 | Train Loss: 0.7575 | Val Loss: 0.7094\n",
      "Epoch 30 | Train Loss: 0.7692 | Val Loss: 0.7104\n",
      "Epoch 31 | Train Loss: 0.7818 | Val Loss: 0.7028\n",
      "Epoch 32 | Train Loss: 0.7618 | Val Loss: 0.6923\n",
      "Epoch 33 | Train Loss: 0.7549 | Val Loss: 0.6875\n",
      "Epoch 34 | Train Loss: 0.7424 | Val Loss: 0.6888\n",
      "Epoch 35 | Train Loss: 0.7258 | Val Loss: 0.6808\n",
      "Epoch 36 | Train Loss: 0.7583 | Val Loss: 0.6819\n",
      "Epoch 37 | Train Loss: 0.7516 | Val Loss: 0.7092\n",
      "Epoch 38 | Train Loss: 0.7567 | Val Loss: 0.6786\n",
      "Epoch 39 | Train Loss: 0.7648 | Val Loss: 0.6934\n",
      "Epoch 40 | Train Loss: 0.7487 | Val Loss: 0.7031\n",
      "Epoch 41 | Train Loss: 0.7817 | Val Loss: 0.6848\n",
      "Epoch 42 | Train Loss: 0.7476 | Val Loss: 0.6864\n",
      "Epoch 43 | Train Loss: 0.7363 | Val Loss: 0.6726\n",
      "Epoch 44 | Train Loss: 0.7654 | Val Loss: 0.6859\n",
      "Epoch 45 | Train Loss: 0.7383 | Val Loss: 0.6778\n",
      "Epoch 46 | Train Loss: 0.7416 | Val Loss: 0.6745\n",
      "Epoch 47 | Train Loss: 0.7578 | Val Loss: 0.6726\n",
      "Epoch 48 | Train Loss: 0.7710 | Val Loss: 0.6772\n",
      "Epoch 49 | Train Loss: 0.7510 | Val Loss: 0.6763\n",
      "Epoch 50 | Train Loss: 0.7431 | Val Loss: 0.6711\n",
      "Fold 4 ‚ñ∂ AUC: 0.787, Balanced Acc: 0.553\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 1.0041 | Val Loss: 0.9040\n",
      "Epoch 02 | Train Loss: 0.8854 | Val Loss: 0.9064\n",
      "Epoch 03 | Train Loss: 0.8645 | Val Loss: 0.8971\n",
      "Epoch 04 | Train Loss: 0.8770 | Val Loss: 0.9110\n",
      "Epoch 05 | Train Loss: 0.8634 | Val Loss: 0.8919\n",
      "Epoch 06 | Train Loss: 0.8627 | Val Loss: 0.8899\n",
      "Epoch 07 | Train Loss: 0.8710 | Val Loss: 0.8913\n",
      "Epoch 08 | Train Loss: 0.8674 | Val Loss: 0.8815\n",
      "Epoch 09 | Train Loss: 0.8536 | Val Loss: 0.8779\n",
      "Epoch 10 | Train Loss: 0.8344 | Val Loss: 0.8818\n",
      "Epoch 11 | Train Loss: 0.8544 | Val Loss: 0.8681\n",
      "Epoch 12 | Train Loss: 0.8418 | Val Loss: 0.8728\n",
      "Epoch 13 | Train Loss: 0.8418 | Val Loss: 0.8833\n",
      "Epoch 14 | Train Loss: 0.8089 | Val Loss: 0.8531\n",
      "Epoch 15 | Train Loss: 0.8007 | Val Loss: 0.8509\n",
      "Epoch 16 | Train Loss: 0.7984 | Val Loss: 0.8585\n",
      "Epoch 17 | Train Loss: 0.8176 | Val Loss: 0.8417\n",
      "Epoch 18 | Train Loss: 0.7959 | Val Loss: 0.8478\n",
      "Epoch 19 | Train Loss: 0.7764 | Val Loss: 0.8426\n",
      "Epoch 20 | Train Loss: 0.7984 | Val Loss: 0.8372\n",
      "Epoch 21 | Train Loss: 0.7679 | Val Loss: 0.8418\n",
      "Epoch 22 | Train Loss: 0.7704 | Val Loss: 0.8336\n",
      "Epoch 23 | Train Loss: 0.7889 | Val Loss: 0.8441\n",
      "Epoch 24 | Train Loss: 0.7719 | Val Loss: 0.8342\n",
      "Epoch 25 | Train Loss: 0.7440 | Val Loss: 0.8347\n",
      "Epoch 26 | Train Loss: 0.7522 | Val Loss: 0.8369\n",
      "Epoch 27 | Train Loss: 0.7433 | Val Loss: 0.8439\n",
      "Epoch 28 | Train Loss: 0.7675 | Val Loss: 0.8344\n",
      "Epoch 29 | Train Loss: 0.7920 | Val Loss: 0.8527\n",
      "Epoch 30 | Train Loss: 0.7661 | Val Loss: 0.8306\n",
      "Epoch 31 | Train Loss: 0.7386 | Val Loss: 0.8252\n",
      "Epoch 32 | Train Loss: 0.7510 | Val Loss: 0.8267\n",
      "Epoch 33 | Train Loss: 0.7513 | Val Loss: 0.8496\n",
      "Epoch 34 | Train Loss: 0.7813 | Val Loss: 0.8264\n",
      "Epoch 35 | Train Loss: 0.7587 | Val Loss: 0.8249\n",
      "Epoch 36 | Train Loss: 0.7412 | Val Loss: 0.8219\n",
      "Epoch 37 | Train Loss: 0.7334 | Val Loss: 0.8831\n",
      "Epoch 38 | Train Loss: 0.7659 | Val Loss: 0.8275\n",
      "Epoch 39 | Train Loss: 0.7534 | Val Loss: 0.8323\n",
      "Epoch 40 | Train Loss: 0.7395 | Val Loss: 0.8364\n",
      "Epoch 41 | Train Loss: 0.7400 | Val Loss: 0.8225\n",
      "Epoch 42 | Train Loss: 0.7432 | Val Loss: 0.8231\n",
      "Epoch 43 | Train Loss: 0.7465 | Val Loss: 0.8195\n",
      "Epoch 44 | Train Loss: 0.7451 | Val Loss: 0.8135\n",
      "Epoch 45 | Train Loss: 0.7410 | Val Loss: 0.8129\n",
      "Epoch 46 | Train Loss: 0.7530 | Val Loss: 0.8131\n",
      "Epoch 47 | Train Loss: 0.7380 | Val Loss: 0.8141\n",
      "Epoch 48 | Train Loss: 0.7505 | Val Loss: 0.8067\n",
      "Epoch 49 | Train Loss: 0.7156 | Val Loss: 0.8090\n",
      "Epoch 50 | Train Loss: 0.7309 | Val Loss: 0.8124\n",
      "Fold 5 ‚ñ∂ AUC: 0.717, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9052 | Val Loss: 0.9025\n",
      "Epoch 02 | Train Loss: 0.8798 | Val Loss: 0.9088\n",
      "Epoch 03 | Train Loss: 0.8720 | Val Loss: 0.8911\n",
      "Epoch 04 | Train Loss: 0.8702 | Val Loss: 0.8894\n",
      "Epoch 05 | Train Loss: 0.8641 | Val Loss: 0.8856\n",
      "Epoch 06 | Train Loss: 0.8469 | Val Loss: 0.8858\n",
      "Epoch 07 | Train Loss: 0.8552 | Val Loss: 0.8831\n",
      "Epoch 08 | Train Loss: 0.8496 | Val Loss: 0.8733\n",
      "Epoch 09 | Train Loss: 0.8396 | Val Loss: 0.8682\n",
      "Epoch 10 | Train Loss: 0.8441 | Val Loss: 0.8728\n",
      "Epoch 11 | Train Loss: 0.8282 | Val Loss: 0.8688\n",
      "Epoch 12 | Train Loss: 0.8132 | Val Loss: 0.8485\n",
      "Epoch 13 | Train Loss: 0.8330 | Val Loss: 0.8434\n",
      "Epoch 14 | Train Loss: 0.7832 | Val Loss: 0.8391\n",
      "Epoch 15 | Train Loss: 0.7924 | Val Loss: 0.8581\n",
      "Epoch 16 | Train Loss: 0.7921 | Val Loss: 0.8325\n",
      "Epoch 17 | Train Loss: 0.7825 | Val Loss: 0.8301\n",
      "Epoch 18 | Train Loss: 0.7710 | Val Loss: 0.8291\n",
      "Epoch 19 | Train Loss: 0.7838 | Val Loss: 0.8266\n",
      "Epoch 20 | Train Loss: 0.7745 | Val Loss: 0.8303\n",
      "Epoch 21 | Train Loss: 0.7735 | Val Loss: 0.8194\n",
      "Epoch 22 | Train Loss: 0.7521 | Val Loss: 0.8177\n",
      "Epoch 23 | Train Loss: 0.7686 | Val Loss: 0.8193\n",
      "Epoch 24 | Train Loss: 0.7572 | Val Loss: 0.8264\n",
      "Epoch 25 | Train Loss: 0.7496 | Val Loss: 0.8173\n",
      "Epoch 26 | Train Loss: 0.7470 | Val Loss: 0.8479\n",
      "Epoch 27 | Train Loss: 0.7793 | Val Loss: 0.8342\n",
      "Epoch 28 | Train Loss: 0.7461 | Val Loss: 0.8482\n",
      "Epoch 29 | Train Loss: 0.7602 | Val Loss: 0.8296\n",
      "Epoch 30 | Train Loss: 0.7368 | Val Loss: 0.8140\n",
      "Epoch 31 | Train Loss: 0.7529 | Val Loss: 0.8201\n",
      "Epoch 32 | Train Loss: 0.7485 | Val Loss: 0.8326\n",
      "Epoch 33 | Train Loss: 0.7390 | Val Loss: 0.8231\n",
      "Epoch 34 | Train Loss: 0.7579 | Val Loss: 0.8106\n",
      "Epoch 35 | Train Loss: 0.7413 | Val Loss: 0.8147\n",
      "Epoch 36 | Train Loss: 0.7559 | Val Loss: 0.8133\n",
      "Epoch 37 | Train Loss: 0.7491 | Val Loss: 0.8181\n",
      "Epoch 38 | Train Loss: 0.7850 | Val Loss: 0.8092\n",
      "Epoch 39 | Train Loss: 0.7513 | Val Loss: 0.8047\n",
      "Epoch 40 | Train Loss: 0.7374 | Val Loss: 0.8115\n",
      "Epoch 41 | Train Loss: 0.7290 | Val Loss: 0.8253\n",
      "Epoch 42 | Train Loss: 0.7408 | Val Loss: 0.8476\n",
      "Epoch 43 | Train Loss: 0.7722 | Val Loss: 0.8067\n",
      "Epoch 44 | Train Loss: 0.7473 | Val Loss: 0.8114\n",
      "Epoch 45 | Train Loss: 0.7416 | Val Loss: 0.8092\n",
      "Epoch 46 | Train Loss: 0.7245 | Val Loss: 0.8146\n",
      "Epoch 47 | Train Loss: 0.7218 | Val Loss: 0.8148\n",
      "Epoch 48 | Train Loss: 0.7587 | Val Loss: 0.8098\n",
      "Epoch 49 | Train Loss: 0.7386 | Val Loss: 0.8087\n",
      "Epoch 50 | Train Loss: 0.7465 | Val Loss: 0.8160\n",
      "Fold 6 ‚ñ∂ AUC: 0.743, Balanced Acc: 0.486\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9147 | Val Loss: 0.8665\n",
      "Epoch 02 | Train Loss: 0.8700 | Val Loss: 0.8607\n",
      "Epoch 03 | Train Loss: 0.8808 | Val Loss: 0.8562\n",
      "Epoch 04 | Train Loss: 0.8613 | Val Loss: 0.8546\n",
      "Epoch 05 | Train Loss: 0.8689 | Val Loss: 0.8483\n",
      "Epoch 06 | Train Loss: 0.8728 | Val Loss: 0.8475\n",
      "Epoch 07 | Train Loss: 0.8735 | Val Loss: 0.8505\n",
      "Epoch 08 | Train Loss: 0.8778 | Val Loss: 0.8489\n",
      "Epoch 09 | Train Loss: 0.8539 | Val Loss: 0.8394\n",
      "Epoch 10 | Train Loss: 0.8515 | Val Loss: 0.8270\n",
      "Epoch 11 | Train Loss: 0.8513 | Val Loss: 0.8204\n",
      "Epoch 12 | Train Loss: 0.8420 | Val Loss: 0.8133\n",
      "Epoch 13 | Train Loss: 0.8332 | Val Loss: 0.8009\n",
      "Epoch 14 | Train Loss: 0.8112 | Val Loss: 0.7833\n",
      "Epoch 15 | Train Loss: 0.8196 | Val Loss: 0.7779\n",
      "Epoch 16 | Train Loss: 0.8120 | Val Loss: 0.7682\n",
      "Epoch 17 | Train Loss: 0.8009 | Val Loss: 0.7763\n",
      "Epoch 18 | Train Loss: 0.7929 | Val Loss: 0.7533\n",
      "Epoch 19 | Train Loss: 0.7692 | Val Loss: 0.7585\n",
      "Epoch 20 | Train Loss: 0.7876 | Val Loss: 0.7412\n",
      "Epoch 21 | Train Loss: 0.7899 | Val Loss: 0.7340\n",
      "Epoch 22 | Train Loss: 0.7610 | Val Loss: 0.8290\n",
      "Epoch 23 | Train Loss: 0.8006 | Val Loss: 0.7584\n",
      "Epoch 24 | Train Loss: 0.7924 | Val Loss: 0.8186\n",
      "Epoch 25 | Train Loss: 0.8054 | Val Loss: 0.7571\n",
      "Epoch 26 | Train Loss: 0.7543 | Val Loss: 0.7310\n",
      "Epoch 27 | Train Loss: 0.7668 | Val Loss: 0.7368\n",
      "Epoch 28 | Train Loss: 0.7690 | Val Loss: 0.7201\n",
      "Epoch 29 | Train Loss: 0.7500 | Val Loss: 0.7297\n",
      "Epoch 30 | Train Loss: 0.7556 | Val Loss: 0.7263\n",
      "Epoch 31 | Train Loss: 0.7583 | Val Loss: 0.7301\n",
      "Epoch 32 | Train Loss: 0.7586 | Val Loss: 0.7387\n",
      "Epoch 33 | Train Loss: 0.7467 | Val Loss: 0.7358\n",
      "Epoch 34 | Train Loss: 0.7555 | Val Loss: 0.7222\n",
      "Epoch 35 | Train Loss: 0.7484 | Val Loss: 0.7431\n",
      "Epoch 36 | Train Loss: 0.7502 | Val Loss: 0.7431\n",
      "Epoch 37 | Train Loss: 0.7698 | Val Loss: 0.7286\n",
      "Epoch 38 | Train Loss: 0.7602 | Val Loss: 0.7548\n",
      "Epoch 39 | Train Loss: 0.7385 | Val Loss: 0.7244\n",
      "Epoch 40 | Train Loss: 0.7490 | Val Loss: 0.7337\n",
      "Epoch 41 | Train Loss: 0.7391 | Val Loss: 0.7513\n",
      "Epoch 42 | Train Loss: 0.7381 | Val Loss: 0.7374\n",
      "Epoch 43 | Train Loss: 0.7203 | Val Loss: 0.7659\n",
      "Epoch 44 | Train Loss: 0.7248 | Val Loss: 0.7316\n",
      "Epoch 45 | Train Loss: 0.7266 | Val Loss: 0.7454\n",
      "Epoch 46 | Train Loss: 0.7424 | Val Loss: 0.7456\n",
      "Epoch 47 | Train Loss: 0.7449 | Val Loss: 0.7318\n",
      "Epoch 48 | Train Loss: 0.7320 | Val Loss: 0.7424\n",
      "Epoch 49 | Train Loss: 0.7375 | Val Loss: 0.7260\n",
      "Epoch 50 | Train Loss: 0.7239 | Val Loss: 0.7342\n",
      "Fold 7 ‚ñ∂ AUC: 0.756, Balanced Acc: 0.462\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9429 | Val Loss: 0.8745\n",
      "Epoch 02 | Train Loss: 0.8734 | Val Loss: 0.8686\n",
      "Epoch 03 | Train Loss: 0.8611 | Val Loss: 0.8699\n",
      "Epoch 04 | Train Loss: 0.8689 | Val Loss: 0.8817\n",
      "Epoch 05 | Train Loss: 0.8696 | Val Loss: 0.8605\n",
      "Epoch 06 | Train Loss: 0.8668 | Val Loss: 0.8519\n",
      "Epoch 07 | Train Loss: 0.8449 | Val Loss: 0.8462\n",
      "Epoch 08 | Train Loss: 0.8481 | Val Loss: 0.8328\n",
      "Epoch 09 | Train Loss: 0.8214 | Val Loss: 0.8469\n",
      "Epoch 10 | Train Loss: 0.8334 | Val Loss: 0.8433\n",
      "Epoch 11 | Train Loss: 0.8287 | Val Loss: 0.8152\n",
      "Epoch 12 | Train Loss: 0.8379 | Val Loss: 0.8341\n",
      "Epoch 13 | Train Loss: 0.8205 | Val Loss: 0.8021\n",
      "Epoch 14 | Train Loss: 0.7903 | Val Loss: 0.8253\n",
      "Epoch 15 | Train Loss: 0.7946 | Val Loss: 0.7848\n",
      "Epoch 16 | Train Loss: 0.7816 | Val Loss: 0.8136\n",
      "Epoch 17 | Train Loss: 0.8071 | Val Loss: 0.8308\n",
      "Epoch 18 | Train Loss: 0.7926 | Val Loss: 0.7802\n",
      "Epoch 19 | Train Loss: 0.7735 | Val Loss: 0.7822\n",
      "Epoch 20 | Train Loss: 0.7613 | Val Loss: 0.7944\n",
      "Epoch 21 | Train Loss: 0.7716 | Val Loss: 0.8053\n",
      "Epoch 22 | Train Loss: 0.7653 | Val Loss: 0.7834\n",
      "Epoch 23 | Train Loss: 0.7419 | Val Loss: 0.7851\n",
      "Epoch 24 | Train Loss: 0.7430 | Val Loss: 0.7896\n",
      "Epoch 25 | Train Loss: 0.7665 | Val Loss: 0.7866\n",
      "Epoch 26 | Train Loss: 0.7377 | Val Loss: 0.7893\n",
      "Epoch 27 | Train Loss: 0.7437 | Val Loss: 0.7894\n",
      "Epoch 28 | Train Loss: 0.7546 | Val Loss: 0.8008\n",
      "Epoch 29 | Train Loss: 0.7603 | Val Loss: 0.8196\n",
      "Epoch 30 | Train Loss: 0.7670 | Val Loss: 0.7931\n",
      "Epoch 31 | Train Loss: 0.7653 | Val Loss: 0.7901\n",
      "Epoch 32 | Train Loss: 0.7310 | Val Loss: 0.7985\n",
      "Epoch 33 | Train Loss: 0.7320 | Val Loss: 0.7941\n",
      "Epoch 34 | Train Loss: 0.7342 | Val Loss: 0.7977\n",
      "Epoch 35 | Train Loss: 0.7297 | Val Loss: 0.7963\n",
      "Epoch 36 | Train Loss: 0.7150 | Val Loss: 0.7940\n",
      "Epoch 37 | Train Loss: 0.7437 | Val Loss: 0.7974\n",
      "Epoch 38 | Train Loss: 0.7286 | Val Loss: 0.7897\n",
      "Epoch 39 | Train Loss: 0.7311 | Val Loss: 0.7921\n",
      "Epoch 40 | Train Loss: 0.7128 | Val Loss: 0.7961\n",
      "Epoch 41 | Train Loss: 0.7253 | Val Loss: 0.7917\n",
      "Epoch 42 | Train Loss: 0.7411 | Val Loss: 0.7966\n",
      "Epoch 43 | Train Loss: 0.7261 | Val Loss: 0.8203\n",
      "Epoch 44 | Train Loss: 0.7604 | Val Loss: 0.8238\n",
      "Epoch 45 | Train Loss: 0.7538 | Val Loss: 0.8155\n",
      "Epoch 46 | Train Loss: 0.7358 | Val Loss: 0.7897\n",
      "Epoch 47 | Train Loss: 0.7301 | Val Loss: 0.8105\n",
      "Epoch 48 | Train Loss: 0.7398 | Val Loss: 0.7947\n",
      "Epoch 49 | Train Loss: 0.7281 | Val Loss: 0.8019\n",
      "Epoch 50 | Train Loss: 0.7180 | Val Loss: 0.7947\n",
      "Fold 8 ‚ñ∂ AUC: 0.720, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9019 | Val Loss: 0.8885\n",
      "Epoch 02 | Train Loss: 0.8991 | Val Loss: 0.8898\n",
      "Epoch 03 | Train Loss: 0.8799 | Val Loss: 0.8759\n",
      "Epoch 04 | Train Loss: 0.8778 | Val Loss: 0.8733\n",
      "Epoch 05 | Train Loss: 0.8603 | Val Loss: 0.8690\n",
      "Epoch 06 | Train Loss: 0.8650 | Val Loss: 0.8710\n",
      "Epoch 07 | Train Loss: 0.8642 | Val Loss: 0.8640\n",
      "Epoch 08 | Train Loss: 0.8687 | Val Loss: 0.8647\n",
      "Epoch 09 | Train Loss: 0.8515 | Val Loss: 0.8579\n",
      "Epoch 10 | Train Loss: 0.8507 | Val Loss: 0.8549\n",
      "Epoch 11 | Train Loss: 0.8360 | Val Loss: 0.8575\n",
      "Epoch 12 | Train Loss: 0.8318 | Val Loss: 0.8438\n",
      "Epoch 13 | Train Loss: 0.8373 | Val Loss: 0.8898\n",
      "Epoch 14 | Train Loss: 0.8439 | Val Loss: 0.8501\n",
      "Epoch 15 | Train Loss: 0.8275 | Val Loss: 0.8315\n",
      "Epoch 16 | Train Loss: 0.8041 | Val Loss: 0.8391\n",
      "Epoch 17 | Train Loss: 0.8025 | Val Loss: 0.8266\n",
      "Epoch 18 | Train Loss: 0.7927 | Val Loss: 0.8191\n",
      "Epoch 19 | Train Loss: 0.7861 | Val Loss: 0.8191\n",
      "Epoch 20 | Train Loss: 0.7800 | Val Loss: 0.8192\n",
      "Epoch 21 | Train Loss: 0.7951 | Val Loss: 0.8169\n",
      "Epoch 22 | Train Loss: 0.7686 | Val Loss: 0.8063\n",
      "Epoch 23 | Train Loss: 0.7830 | Val Loss: 0.8087\n",
      "Epoch 24 | Train Loss: 0.7803 | Val Loss: 0.8030\n",
      "Epoch 25 | Train Loss: 0.7755 | Val Loss: 0.8540\n",
      "Epoch 26 | Train Loss: 0.7823 | Val Loss: 0.7912\n",
      "Epoch 27 | Train Loss: 0.7467 | Val Loss: 0.7951\n",
      "Epoch 28 | Train Loss: 0.7549 | Val Loss: 0.7862\n",
      "Epoch 29 | Train Loss: 0.7633 | Val Loss: 0.7908\n",
      "Epoch 30 | Train Loss: 0.7556 | Val Loss: 0.8153\n",
      "Epoch 31 | Train Loss: 0.7554 | Val Loss: 0.7923\n",
      "Epoch 32 | Train Loss: 0.7467 | Val Loss: 0.7877\n",
      "Epoch 33 | Train Loss: 0.7380 | Val Loss: 0.8155\n",
      "Epoch 34 | Train Loss: 0.7564 | Val Loss: 0.7890\n",
      "Epoch 35 | Train Loss: 0.7636 | Val Loss: 0.7952\n",
      "Epoch 36 | Train Loss: 0.7541 | Val Loss: 0.8045\n",
      "Epoch 37 | Train Loss: 0.7414 | Val Loss: 0.7836\n",
      "Epoch 38 | Train Loss: 0.7547 | Val Loss: 0.7834\n",
      "Epoch 39 | Train Loss: 0.7459 | Val Loss: 0.7823\n",
      "Epoch 40 | Train Loss: 0.7763 | Val Loss: 0.7749\n",
      "Epoch 41 | Train Loss: 0.7675 | Val Loss: 0.8445\n",
      "Epoch 42 | Train Loss: 0.7622 | Val Loss: 0.7694\n",
      "Epoch 43 | Train Loss: 0.7542 | Val Loss: 0.7756\n",
      "Epoch 44 | Train Loss: 0.7268 | Val Loss: 0.7747\n",
      "Epoch 45 | Train Loss: 0.7419 | Val Loss: 0.7665\n",
      "Epoch 46 | Train Loss: 0.7309 | Val Loss: 0.7859\n",
      "Epoch 47 | Train Loss: 0.7292 | Val Loss: 0.7702\n",
      "Epoch 48 | Train Loss: 0.7399 | Val Loss: 0.7710\n",
      "Epoch 49 | Train Loss: 0.7411 | Val Loss: 0.7694\n",
      "Epoch 50 | Train Loss: 0.7427 | Val Loss: 0.7666\n",
      "Fold 9 ‚ñ∂ AUC: 0.713, Balanced Acc: 0.486\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9369 | Val Loss: 0.8813\n",
      "Epoch 02 | Train Loss: 0.8771 | Val Loss: 0.8780\n",
      "Epoch 03 | Train Loss: 0.8776 | Val Loss: 0.8729\n",
      "Epoch 04 | Train Loss: 0.8655 | Val Loss: 0.8698\n",
      "Epoch 05 | Train Loss: 0.8734 | Val Loss: 0.8630\n",
      "Epoch 06 | Train Loss: 0.8602 | Val Loss: 0.8583\n",
      "Epoch 07 | Train Loss: 0.8653 | Val Loss: 0.8558\n",
      "Epoch 08 | Train Loss: 0.8496 | Val Loss: 0.8532\n",
      "Epoch 09 | Train Loss: 0.8504 | Val Loss: 0.8428\n",
      "Epoch 10 | Train Loss: 0.8417 | Val Loss: 0.8431\n",
      "Epoch 11 | Train Loss: 0.8482 | Val Loss: 0.8251\n",
      "Epoch 12 | Train Loss: 0.8308 | Val Loss: 0.8159\n",
      "Epoch 13 | Train Loss: 0.8280 | Val Loss: 0.8076\n",
      "Epoch 14 | Train Loss: 0.8005 | Val Loss: 0.7946\n",
      "Epoch 15 | Train Loss: 0.7990 | Val Loss: 0.7854\n",
      "Epoch 16 | Train Loss: 0.7956 | Val Loss: 0.7812\n",
      "Epoch 17 | Train Loss: 0.7757 | Val Loss: 0.7994\n",
      "Epoch 18 | Train Loss: 0.7614 | Val Loss: 0.7934\n",
      "Epoch 19 | Train Loss: 0.7852 | Val Loss: 0.7615\n",
      "Epoch 20 | Train Loss: 0.7724 | Val Loss: 0.7866\n",
      "Epoch 21 | Train Loss: 0.7574 | Val Loss: 0.7905\n",
      "Epoch 22 | Train Loss: 0.7550 | Val Loss: 0.7616\n",
      "Epoch 23 | Train Loss: 0.7525 | Val Loss: 0.7672\n",
      "Epoch 24 | Train Loss: 0.7724 | Val Loss: 0.7585\n",
      "Epoch 25 | Train Loss: 0.7572 | Val Loss: 0.8063\n",
      "Epoch 26 | Train Loss: 0.7448 | Val Loss: 0.7819\n",
      "Epoch 27 | Train Loss: 0.7695 | Val Loss: 0.7790\n",
      "Epoch 28 | Train Loss: 0.7939 | Val Loss: 0.7780\n",
      "Epoch 29 | Train Loss: 0.7370 | Val Loss: 0.8056\n",
      "Epoch 30 | Train Loss: 0.7491 | Val Loss: 0.7628\n",
      "Epoch 31 | Train Loss: 0.7464 | Val Loss: 0.8061\n",
      "Epoch 32 | Train Loss: 0.7480 | Val Loss: 0.7662\n",
      "Epoch 33 | Train Loss: 0.7434 | Val Loss: 0.7793\n",
      "Epoch 34 | Train Loss: 0.7385 | Val Loss: 0.7919\n",
      "Epoch 35 | Train Loss: 0.7381 | Val Loss: 0.7728\n",
      "Epoch 36 | Train Loss: 0.7238 | Val Loss: 0.7781\n",
      "Epoch 37 | Train Loss: 0.7271 | Val Loss: 0.7651\n",
      "Epoch 38 | Train Loss: 0.7510 | Val Loss: 0.7759\n",
      "Epoch 39 | Train Loss: 0.7395 | Val Loss: 0.7887\n",
      "Epoch 40 | Train Loss: 0.7184 | Val Loss: 0.7672\n",
      "Epoch 41 | Train Loss: 0.7409 | Val Loss: 0.7655\n",
      "Epoch 42 | Train Loss: 0.7158 | Val Loss: 0.8105\n",
      "Epoch 43 | Train Loss: 0.7348 | Val Loss: 0.7939\n",
      "Epoch 44 | Train Loss: 0.7287 | Val Loss: 0.7642\n",
      "Epoch 45 | Train Loss: 0.7478 | Val Loss: 0.7664\n",
      "Epoch 46 | Train Loss: 0.7380 | Val Loss: 0.7762\n",
      "Epoch 47 | Train Loss: 0.7232 | Val Loss: 0.7861\n",
      "Epoch 48 | Train Loss: 0.7415 | Val Loss: 0.7822\n",
      "Epoch 49 | Train Loss: 0.7337 | Val Loss: 0.7871\n",
      "Epoch 50 | Train Loss: 0.7203 | Val Loss: 0.7686\n",
      "Fold 10 ‚ñ∂ AUC: 0.704, Balanced Acc: 0.477\n",
      "üîç Summary for hd=64, dp=0.4, lr=0.0005 ‚Üí AUC: 0.7343¬±0.0313 | BalAcc: 0.4894¬±0.0371\n",
      "\n",
      "üîß Config: hidden_dim=64, dropout=0.4, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9338 | Val Loss: 0.9033\n",
      "Epoch 02 | Train Loss: 0.8959 | Val Loss: 0.8760\n",
      "Epoch 03 | Train Loss: 0.8902 | Val Loss: 0.8662\n",
      "Epoch 04 | Train Loss: 0.8712 | Val Loss: 0.8632\n",
      "Epoch 05 | Train Loss: 0.8924 | Val Loss: 0.8617\n",
      "Epoch 06 | Train Loss: 0.8722 | Val Loss: 0.8607\n",
      "Epoch 07 | Train Loss: 0.8760 | Val Loss: 0.8604\n",
      "Epoch 08 | Train Loss: 0.8690 | Val Loss: 0.8586\n",
      "Epoch 09 | Train Loss: 0.8801 | Val Loss: 0.8574\n",
      "Epoch 10 | Train Loss: 0.8788 | Val Loss: 0.8564\n",
      "Epoch 11 | Train Loss: 0.8605 | Val Loss: 0.8554\n",
      "Epoch 12 | Train Loss: 0.8690 | Val Loss: 0.8546\n",
      "Epoch 13 | Train Loss: 0.8646 | Val Loss: 0.8534\n",
      "Epoch 14 | Train Loss: 0.8801 | Val Loss: 0.8529\n",
      "Epoch 15 | Train Loss: 0.8764 | Val Loss: 0.8525\n",
      "Epoch 16 | Train Loss: 0.8712 | Val Loss: 0.8520\n",
      "Epoch 17 | Train Loss: 0.8699 | Val Loss: 0.8502\n",
      "Epoch 18 | Train Loss: 0.8529 | Val Loss: 0.8496\n",
      "Epoch 19 | Train Loss: 0.8628 | Val Loss: 0.8481\n",
      "Epoch 20 | Train Loss: 0.8564 | Val Loss: 0.8469\n",
      "Epoch 21 | Train Loss: 0.8533 | Val Loss: 0.8458\n",
      "Epoch 22 | Train Loss: 0.8605 | Val Loss: 0.8447\n",
      "Epoch 23 | Train Loss: 0.8593 | Val Loss: 0.8437\n",
      "Epoch 24 | Train Loss: 0.8636 | Val Loss: 0.8416\n",
      "Epoch 25 | Train Loss: 0.8486 | Val Loss: 0.8410\n",
      "Epoch 26 | Train Loss: 0.8484 | Val Loss: 0.8379\n",
      "Epoch 27 | Train Loss: 0.8583 | Val Loss: 0.8362\n",
      "Epoch 28 | Train Loss: 0.8495 | Val Loss: 0.8352\n",
      "Epoch 29 | Train Loss: 0.8515 | Val Loss: 0.8350\n",
      "Epoch 30 | Train Loss: 0.8494 | Val Loss: 0.8368\n",
      "Epoch 31 | Train Loss: 0.8552 | Val Loss: 0.8315\n",
      "Epoch 32 | Train Loss: 0.8512 | Val Loss: 0.8297\n",
      "Epoch 33 | Train Loss: 0.8445 | Val Loss: 0.8311\n",
      "Epoch 34 | Train Loss: 0.8398 | Val Loss: 0.8291\n",
      "Epoch 35 | Train Loss: 0.8430 | Val Loss: 0.8257\n",
      "Epoch 36 | Train Loss: 0.8319 | Val Loss: 0.8246\n",
      "Epoch 37 | Train Loss: 0.8330 | Val Loss: 0.8228\n",
      "Epoch 38 | Train Loss: 0.8412 | Val Loss: 0.8218\n",
      "Epoch 39 | Train Loss: 0.8381 | Val Loss: 0.8200\n",
      "Epoch 40 | Train Loss: 0.8263 | Val Loss: 0.8193\n",
      "Epoch 41 | Train Loss: 0.8523 | Val Loss: 0.8178\n",
      "Epoch 42 | Train Loss: 0.8379 | Val Loss: 0.8201\n",
      "Epoch 43 | Train Loss: 0.8321 | Val Loss: 0.8150\n",
      "Epoch 44 | Train Loss: 0.8316 | Val Loss: 0.8143\n",
      "Epoch 45 | Train Loss: 0.8171 | Val Loss: 0.8134\n",
      "Epoch 46 | Train Loss: 0.8348 | Val Loss: 0.8100\n",
      "Epoch 47 | Train Loss: 0.8230 | Val Loss: 0.8086\n",
      "Epoch 48 | Train Loss: 0.8319 | Val Loss: 0.8073\n",
      "Epoch 49 | Train Loss: 0.8306 | Val Loss: 0.8048\n",
      "Epoch 50 | Train Loss: 0.8185 | Val Loss: 0.8040\n",
      "Fold 1 ‚ñ∂ AUC: 0.767, Balanced Acc: 0.443\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 1.0202 | Val Loss: 0.9488\n",
      "Epoch 02 | Train Loss: 0.9193 | Val Loss: 0.8838\n",
      "Epoch 03 | Train Loss: 0.8912 | Val Loss: 0.8722\n",
      "Epoch 04 | Train Loss: 0.8801 | Val Loss: 0.8712\n",
      "Epoch 05 | Train Loss: 0.8721 | Val Loss: 0.8685\n",
      "Epoch 06 | Train Loss: 0.8699 | Val Loss: 0.8676\n",
      "Epoch 07 | Train Loss: 0.8790 | Val Loss: 0.8675\n",
      "Epoch 08 | Train Loss: 0.8712 | Val Loss: 0.8683\n",
      "Epoch 09 | Train Loss: 0.8816 | Val Loss: 0.8666\n",
      "Epoch 10 | Train Loss: 0.8691 | Val Loss: 0.8669\n",
      "Epoch 11 | Train Loss: 0.8822 | Val Loss: 0.8654\n",
      "Epoch 12 | Train Loss: 0.8639 | Val Loss: 0.8647\n",
      "Epoch 13 | Train Loss: 0.8786 | Val Loss: 0.8648\n",
      "Epoch 14 | Train Loss: 0.8722 | Val Loss: 0.8648\n",
      "Epoch 15 | Train Loss: 0.8567 | Val Loss: 0.8627\n",
      "Epoch 16 | Train Loss: 0.8623 | Val Loss: 0.8621\n",
      "Epoch 17 | Train Loss: 0.8727 | Val Loss: 0.8624\n",
      "Epoch 18 | Train Loss: 0.8695 | Val Loss: 0.8614\n",
      "Epoch 19 | Train Loss: 0.8566 | Val Loss: 0.8605\n",
      "Epoch 20 | Train Loss: 0.8745 | Val Loss: 0.8612\n",
      "Epoch 21 | Train Loss: 0.8519 | Val Loss: 0.8589\n",
      "Epoch 22 | Train Loss: 0.8719 | Val Loss: 0.8584\n",
      "Epoch 23 | Train Loss: 0.8795 | Val Loss: 0.8582\n",
      "Epoch 24 | Train Loss: 0.8725 | Val Loss: 0.8571\n",
      "Epoch 25 | Train Loss: 0.8642 | Val Loss: 0.8563\n",
      "Epoch 26 | Train Loss: 0.8695 | Val Loss: 0.8592\n",
      "Epoch 27 | Train Loss: 0.8718 | Val Loss: 0.8531\n",
      "Epoch 28 | Train Loss: 0.8559 | Val Loss: 0.8522\n",
      "Epoch 29 | Train Loss: 0.8542 | Val Loss: 0.8513\n",
      "Epoch 30 | Train Loss: 0.8680 | Val Loss: 0.8506\n",
      "Epoch 31 | Train Loss: 0.8492 | Val Loss: 0.8525\n",
      "Epoch 32 | Train Loss: 0.8555 | Val Loss: 0.8489\n",
      "Epoch 33 | Train Loss: 0.8547 | Val Loss: 0.8480\n",
      "Epoch 34 | Train Loss: 0.8469 | Val Loss: 0.8460\n",
      "Epoch 35 | Train Loss: 0.8695 | Val Loss: 0.8451\n",
      "Epoch 36 | Train Loss: 0.8631 | Val Loss: 0.8456\n",
      "Epoch 37 | Train Loss: 0.8459 | Val Loss: 0.8450\n",
      "Epoch 38 | Train Loss: 0.8453 | Val Loss: 0.8424\n",
      "Epoch 39 | Train Loss: 0.8437 | Val Loss: 0.8406\n",
      "Epoch 40 | Train Loss: 0.8338 | Val Loss: 0.8393\n",
      "Epoch 41 | Train Loss: 0.8424 | Val Loss: 0.8378\n",
      "Epoch 42 | Train Loss: 0.8385 | Val Loss: 0.8374\n",
      "Epoch 43 | Train Loss: 0.8462 | Val Loss: 0.8353\n",
      "Epoch 44 | Train Loss: 0.8382 | Val Loss: 0.8340\n",
      "Epoch 45 | Train Loss: 0.8502 | Val Loss: 0.8344\n",
      "Epoch 46 | Train Loss: 0.8262 | Val Loss: 0.8325\n",
      "Epoch 47 | Train Loss: 0.8350 | Val Loss: 0.8293\n",
      "Epoch 48 | Train Loss: 0.8338 | Val Loss: 0.8280\n",
      "Epoch 49 | Train Loss: 0.8227 | Val Loss: 0.8270\n",
      "Epoch 50 | Train Loss: 0.8372 | Val Loss: 0.8259\n",
      "Fold 2 ‚ñ∂ AUC: 0.629, Balanced Acc: 0.421\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9868 | Val Loss: 0.9239\n",
      "Epoch 02 | Train Loss: 0.9136 | Val Loss: 0.8811\n",
      "Epoch 03 | Train Loss: 0.8953 | Val Loss: 0.8691\n",
      "Epoch 04 | Train Loss: 0.8712 | Val Loss: 0.8662\n",
      "Epoch 05 | Train Loss: 0.8768 | Val Loss: 0.8646\n",
      "Epoch 06 | Train Loss: 0.8686 | Val Loss: 0.8638\n",
      "Epoch 07 | Train Loss: 0.8755 | Val Loss: 0.8628\n",
      "Epoch 08 | Train Loss: 0.8696 | Val Loss: 0.8619\n",
      "Epoch 09 | Train Loss: 0.8633 | Val Loss: 0.8607\n",
      "Epoch 10 | Train Loss: 0.8632 | Val Loss: 0.8601\n",
      "Epoch 11 | Train Loss: 0.8669 | Val Loss: 0.8588\n",
      "Epoch 12 | Train Loss: 0.8862 | Val Loss: 0.8582\n",
      "Epoch 13 | Train Loss: 0.8583 | Val Loss: 0.8571\n",
      "Epoch 14 | Train Loss: 0.8543 | Val Loss: 0.8552\n",
      "Epoch 15 | Train Loss: 0.8681 | Val Loss: 0.8544\n",
      "Epoch 16 | Train Loss: 0.8664 | Val Loss: 0.8532\n",
      "Epoch 17 | Train Loss: 0.8584 | Val Loss: 0.8529\n",
      "Epoch 18 | Train Loss: 0.8606 | Val Loss: 0.8511\n",
      "Epoch 19 | Train Loss: 0.8803 | Val Loss: 0.8494\n",
      "Epoch 20 | Train Loss: 0.8618 | Val Loss: 0.8492\n",
      "Epoch 21 | Train Loss: 0.8701 | Val Loss: 0.8470\n",
      "Epoch 22 | Train Loss: 0.8611 | Val Loss: 0.8463\n",
      "Epoch 23 | Train Loss: 0.8621 | Val Loss: 0.8438\n",
      "Epoch 24 | Train Loss: 0.8675 | Val Loss: 0.8428\n",
      "Epoch 25 | Train Loss: 0.8522 | Val Loss: 0.8416\n",
      "Epoch 26 | Train Loss: 0.8511 | Val Loss: 0.8400\n",
      "Epoch 27 | Train Loss: 0.8492 | Val Loss: 0.8374\n",
      "Epoch 28 | Train Loss: 0.8586 | Val Loss: 0.8354\n",
      "Epoch 29 | Train Loss: 0.8692 | Val Loss: 0.8352\n",
      "Epoch 30 | Train Loss: 0.8498 | Val Loss: 0.8329\n",
      "Epoch 31 | Train Loss: 0.8406 | Val Loss: 0.8323\n",
      "Epoch 32 | Train Loss: 0.8570 | Val Loss: 0.8309\n",
      "Epoch 33 | Train Loss: 0.8450 | Val Loss: 0.8270\n",
      "Epoch 34 | Train Loss: 0.8575 | Val Loss: 0.8260\n",
      "Epoch 35 | Train Loss: 0.8366 | Val Loss: 0.8233\n",
      "Epoch 36 | Train Loss: 0.8401 | Val Loss: 0.8220\n",
      "Epoch 37 | Train Loss: 0.8329 | Val Loss: 0.8176\n",
      "Epoch 38 | Train Loss: 0.8385 | Val Loss: 0.8168\n",
      "Epoch 39 | Train Loss: 0.8409 | Val Loss: 0.8141\n",
      "Epoch 40 | Train Loss: 0.8231 | Val Loss: 0.8112\n",
      "Epoch 41 | Train Loss: 0.8427 | Val Loss: 0.8093\n",
      "Epoch 42 | Train Loss: 0.8230 | Val Loss: 0.8070\n",
      "Epoch 43 | Train Loss: 0.8347 | Val Loss: 0.8035\n",
      "Epoch 44 | Train Loss: 0.8204 | Val Loss: 0.8005\n",
      "Epoch 45 | Train Loss: 0.8342 | Val Loss: 0.7970\n",
      "Epoch 46 | Train Loss: 0.8209 | Val Loss: 0.7949\n",
      "Epoch 47 | Train Loss: 0.8245 | Val Loss: 0.7987\n",
      "Epoch 48 | Train Loss: 0.8367 | Val Loss: 0.7898\n",
      "Epoch 49 | Train Loss: 0.8217 | Val Loss: 0.7880\n",
      "Epoch 50 | Train Loss: 0.8254 | Val Loss: 0.7859\n",
      "Fold 3 ‚ñ∂ AUC: 0.759, Balanced Acc: 0.488\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 1.1029 | Val Loss: 0.9918\n",
      "Epoch 02 | Train Loss: 0.9507 | Val Loss: 0.9008\n",
      "Epoch 03 | Train Loss: 0.8990 | Val Loss: 0.8652\n",
      "Epoch 04 | Train Loss: 0.8803 | Val Loss: 0.8536\n",
      "Epoch 05 | Train Loss: 0.8892 | Val Loss: 0.8500\n",
      "Epoch 06 | Train Loss: 0.8717 | Val Loss: 0.8488\n",
      "Epoch 07 | Train Loss: 0.8663 | Val Loss: 0.8479\n",
      "Epoch 08 | Train Loss: 0.8637 | Val Loss: 0.8468\n",
      "Epoch 09 | Train Loss: 0.8645 | Val Loss: 0.8453\n",
      "Epoch 10 | Train Loss: 0.8834 | Val Loss: 0.8441\n",
      "Epoch 11 | Train Loss: 0.8741 | Val Loss: 0.8441\n",
      "Epoch 12 | Train Loss: 0.8662 | Val Loss: 0.8426\n",
      "Epoch 13 | Train Loss: 0.8680 | Val Loss: 0.8410\n",
      "Epoch 14 | Train Loss: 0.8637 | Val Loss: 0.8396\n",
      "Epoch 15 | Train Loss: 0.8710 | Val Loss: 0.8378\n",
      "Epoch 16 | Train Loss: 0.8593 | Val Loss: 0.8370\n",
      "Epoch 17 | Train Loss: 0.8637 | Val Loss: 0.8361\n",
      "Epoch 18 | Train Loss: 0.8687 | Val Loss: 0.8337\n",
      "Epoch 19 | Train Loss: 0.8539 | Val Loss: 0.8328\n",
      "Epoch 20 | Train Loss: 0.8711 | Val Loss: 0.8322\n",
      "Epoch 21 | Train Loss: 0.8720 | Val Loss: 0.8305\n",
      "Epoch 22 | Train Loss: 0.8603 | Val Loss: 0.8298\n",
      "Epoch 23 | Train Loss: 0.8667 | Val Loss: 0.8273\n",
      "Epoch 24 | Train Loss: 0.8506 | Val Loss: 0.8262\n",
      "Epoch 25 | Train Loss: 0.8397 | Val Loss: 0.8242\n",
      "Epoch 26 | Train Loss: 0.8397 | Val Loss: 0.8230\n",
      "Epoch 27 | Train Loss: 0.8613 | Val Loss: 0.8212\n",
      "Epoch 28 | Train Loss: 0.8574 | Val Loss: 0.8200\n",
      "Epoch 29 | Train Loss: 0.8455 | Val Loss: 0.8190\n",
      "Epoch 30 | Train Loss: 0.8496 | Val Loss: 0.8173\n",
      "Epoch 31 | Train Loss: 0.8425 | Val Loss: 0.8170\n",
      "Epoch 32 | Train Loss: 0.8369 | Val Loss: 0.8130\n",
      "Epoch 33 | Train Loss: 0.8455 | Val Loss: 0.8124\n",
      "Epoch 34 | Train Loss: 0.8455 | Val Loss: 0.8100\n",
      "Epoch 35 | Train Loss: 0.8272 | Val Loss: 0.8096\n",
      "Epoch 36 | Train Loss: 0.8484 | Val Loss: 0.8068\n",
      "Epoch 37 | Train Loss: 0.8252 | Val Loss: 0.8068\n",
      "Epoch 38 | Train Loss: 0.8313 | Val Loss: 0.8036\n",
      "Epoch 39 | Train Loss: 0.8333 | Val Loss: 0.8019\n",
      "Epoch 40 | Train Loss: 0.8255 | Val Loss: 0.7999\n",
      "Epoch 41 | Train Loss: 0.8381 | Val Loss: 0.7987\n",
      "Epoch 42 | Train Loss: 0.8294 | Val Loss: 0.7980\n",
      "Epoch 43 | Train Loss: 0.8173 | Val Loss: 0.7955\n",
      "Epoch 44 | Train Loss: 0.8317 | Val Loss: 0.7945\n",
      "Epoch 45 | Train Loss: 0.8286 | Val Loss: 0.7919\n",
      "Epoch 46 | Train Loss: 0.8266 | Val Loss: 0.7908\n",
      "Epoch 47 | Train Loss: 0.8105 | Val Loss: 0.7889\n",
      "Epoch 48 | Train Loss: 0.8007 | Val Loss: 0.7859\n",
      "Epoch 49 | Train Loss: 0.8176 | Val Loss: 0.7845\n",
      "Epoch 50 | Train Loss: 0.8104 | Val Loss: 0.7830\n",
      "Fold 4 ‚ñ∂ AUC: 0.802, Balanced Acc: 0.453\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9969 | Val Loss: 0.9494\n",
      "Epoch 02 | Train Loss: 0.9172 | Val Loss: 0.9079\n",
      "Epoch 03 | Train Loss: 0.8837 | Val Loss: 0.8970\n",
      "Epoch 04 | Train Loss: 0.8771 | Val Loss: 0.8952\n",
      "Epoch 05 | Train Loss: 0.8650 | Val Loss: 0.8956\n",
      "Epoch 06 | Train Loss: 0.8679 | Val Loss: 0.8959\n",
      "Epoch 07 | Train Loss: 0.8602 | Val Loss: 0.8969\n",
      "Epoch 08 | Train Loss: 0.8609 | Val Loss: 0.8945\n",
      "Epoch 09 | Train Loss: 0.8591 | Val Loss: 0.8942\n",
      "Epoch 10 | Train Loss: 0.8595 | Val Loss: 0.8946\n",
      "Epoch 11 | Train Loss: 0.8712 | Val Loss: 0.8921\n",
      "Epoch 12 | Train Loss: 0.8726 | Val Loss: 0.8917\n",
      "Epoch 13 | Train Loss: 0.8810 | Val Loss: 0.8912\n",
      "Epoch 14 | Train Loss: 0.8607 | Val Loss: 0.8885\n",
      "Epoch 15 | Train Loss: 0.8727 | Val Loss: 0.8883\n",
      "Epoch 16 | Train Loss: 0.8672 | Val Loss: 0.8886\n",
      "Epoch 17 | Train Loss: 0.8447 | Val Loss: 0.8869\n",
      "Epoch 18 | Train Loss: 0.8664 | Val Loss: 0.8865\n",
      "Epoch 19 | Train Loss: 0.8527 | Val Loss: 0.8871\n",
      "Epoch 20 | Train Loss: 0.8550 | Val Loss: 0.8837\n",
      "Epoch 21 | Train Loss: 0.8473 | Val Loss: 0.8839\n",
      "Epoch 22 | Train Loss: 0.8531 | Val Loss: 0.8856\n",
      "Epoch 23 | Train Loss: 0.8494 | Val Loss: 0.8831\n",
      "Epoch 24 | Train Loss: 0.8484 | Val Loss: 0.8835\n",
      "Epoch 25 | Train Loss: 0.8644 | Val Loss: 0.8811\n",
      "Epoch 26 | Train Loss: 0.8418 | Val Loss: 0.8784\n",
      "Epoch 27 | Train Loss: 0.8544 | Val Loss: 0.8778\n",
      "Epoch 28 | Train Loss: 0.8357 | Val Loss: 0.8746\n",
      "Epoch 29 | Train Loss: 0.8434 | Val Loss: 0.8735\n",
      "Epoch 30 | Train Loss: 0.8402 | Val Loss: 0.8748\n",
      "Epoch 31 | Train Loss: 0.8373 | Val Loss: 0.8732\n",
      "Epoch 32 | Train Loss: 0.8420 | Val Loss: 0.8702\n",
      "Epoch 33 | Train Loss: 0.8397 | Val Loss: 0.8676\n",
      "Epoch 34 | Train Loss: 0.8386 | Val Loss: 0.8668\n",
      "Epoch 35 | Train Loss: 0.8279 | Val Loss: 0.8648\n",
      "Epoch 36 | Train Loss: 0.8301 | Val Loss: 0.8642\n",
      "Epoch 37 | Train Loss: 0.8423 | Val Loss: 0.8621\n",
      "Epoch 38 | Train Loss: 0.8202 | Val Loss: 0.8575\n",
      "Epoch 39 | Train Loss: 0.8184 | Val Loss: 0.8557\n",
      "Epoch 40 | Train Loss: 0.8361 | Val Loss: 0.8544\n",
      "Epoch 41 | Train Loss: 0.8113 | Val Loss: 0.8553\n",
      "Epoch 42 | Train Loss: 0.8070 | Val Loss: 0.8512\n",
      "Epoch 43 | Train Loss: 0.8184 | Val Loss: 0.8496\n",
      "Epoch 44 | Train Loss: 0.8111 | Val Loss: 0.8489\n",
      "Epoch 45 | Train Loss: 0.8133 | Val Loss: 0.8444\n",
      "Epoch 46 | Train Loss: 0.7973 | Val Loss: 0.8454\n",
      "Epoch 47 | Train Loss: 0.8154 | Val Loss: 0.8414\n",
      "Epoch 48 | Train Loss: 0.8046 | Val Loss: 0.8398\n",
      "Epoch 49 | Train Loss: 0.8010 | Val Loss: 0.8352\n",
      "Epoch 50 | Train Loss: 0.8052 | Val Loss: 0.8362\n",
      "Fold 5 ‚ñ∂ AUC: 0.690, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 1.2059 | Val Loss: 1.0677\n",
      "Epoch 02 | Train Loss: 1.0130 | Val Loss: 0.9572\n",
      "Epoch 03 | Train Loss: 0.9228 | Val Loss: 0.9176\n",
      "Epoch 04 | Train Loss: 0.8998 | Val Loss: 0.9058\n",
      "Epoch 05 | Train Loss: 0.8912 | Val Loss: 0.9052\n",
      "Epoch 06 | Train Loss: 0.8884 | Val Loss: 0.9056\n",
      "Epoch 07 | Train Loss: 0.8664 | Val Loss: 0.9056\n",
      "Epoch 08 | Train Loss: 0.8709 | Val Loss: 0.9057\n",
      "Epoch 09 | Train Loss: 0.8632 | Val Loss: 0.9059\n",
      "Epoch 10 | Train Loss: 0.8800 | Val Loss: 0.9064\n",
      "Epoch 11 | Train Loss: 0.8777 | Val Loss: 0.9047\n",
      "Epoch 12 | Train Loss: 0.8637 | Val Loss: 0.9045\n",
      "Epoch 13 | Train Loss: 0.8705 | Val Loss: 0.9038\n",
      "Epoch 14 | Train Loss: 0.8723 | Val Loss: 0.9031\n",
      "Epoch 15 | Train Loss: 0.8645 | Val Loss: 0.9026\n",
      "Epoch 16 | Train Loss: 0.8611 | Val Loss: 0.9022\n",
      "Epoch 17 | Train Loss: 0.8513 | Val Loss: 0.9024\n",
      "Epoch 18 | Train Loss: 0.8635 | Val Loss: 0.9025\n",
      "Epoch 19 | Train Loss: 0.8743 | Val Loss: 0.9011\n",
      "Epoch 20 | Train Loss: 0.8605 | Val Loss: 0.8998\n",
      "Epoch 21 | Train Loss: 0.8558 | Val Loss: 0.8986\n",
      "Epoch 22 | Train Loss: 0.8636 | Val Loss: 0.8979\n",
      "Epoch 23 | Train Loss: 0.8784 | Val Loss: 0.8983\n",
      "Epoch 24 | Train Loss: 0.8576 | Val Loss: 0.8979\n",
      "Epoch 25 | Train Loss: 0.8547 | Val Loss: 0.8971\n",
      "Epoch 26 | Train Loss: 0.8642 | Val Loss: 0.8966\n",
      "Epoch 27 | Train Loss: 0.8454 | Val Loss: 0.8986\n",
      "Epoch 28 | Train Loss: 0.8489 | Val Loss: 0.8950\n",
      "Epoch 29 | Train Loss: 0.8471 | Val Loss: 0.8939\n",
      "Epoch 30 | Train Loss: 0.8554 | Val Loss: 0.8949\n",
      "Epoch 31 | Train Loss: 0.8437 | Val Loss: 0.8921\n",
      "Epoch 32 | Train Loss: 0.8611 | Val Loss: 0.8912\n",
      "Epoch 33 | Train Loss: 0.8377 | Val Loss: 0.8897\n",
      "Epoch 34 | Train Loss: 0.8545 | Val Loss: 0.8887\n",
      "Epoch 35 | Train Loss: 0.8380 | Val Loss: 0.8869\n",
      "Epoch 36 | Train Loss: 0.8492 | Val Loss: 0.8861\n",
      "Epoch 37 | Train Loss: 0.8344 | Val Loss: 0.8872\n",
      "Epoch 38 | Train Loss: 0.8389 | Val Loss: 0.8840\n",
      "Epoch 39 | Train Loss: 0.8457 | Val Loss: 0.8855\n",
      "Epoch 40 | Train Loss: 0.8403 | Val Loss: 0.8822\n",
      "Epoch 41 | Train Loss: 0.8262 | Val Loss: 0.8835\n",
      "Epoch 42 | Train Loss: 0.8367 | Val Loss: 0.8809\n",
      "Epoch 43 | Train Loss: 0.8386 | Val Loss: 0.8794\n",
      "Epoch 44 | Train Loss: 0.8197 | Val Loss: 0.8804\n",
      "Epoch 45 | Train Loss: 0.8394 | Val Loss: 0.8796\n",
      "Epoch 46 | Train Loss: 0.8195 | Val Loss: 0.8769\n",
      "Epoch 47 | Train Loss: 0.8162 | Val Loss: 0.8773\n",
      "Epoch 48 | Train Loss: 0.8236 | Val Loss: 0.8734\n",
      "Epoch 49 | Train Loss: 0.8079 | Val Loss: 0.8762\n",
      "Epoch 50 | Train Loss: 0.8143 | Val Loss: 0.8762\n",
      "Fold 6 ‚ñ∂ AUC: 0.617, Balanced Acc: 0.449\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 1.0465 | Val Loss: 0.9657\n",
      "Epoch 02 | Train Loss: 0.9463 | Val Loss: 0.9024\n",
      "Epoch 03 | Train Loss: 0.9006 | Val Loss: 0.8724\n",
      "Epoch 04 | Train Loss: 0.8744 | Val Loss: 0.8597\n",
      "Epoch 05 | Train Loss: 0.8720 | Val Loss: 0.8555\n",
      "Epoch 06 | Train Loss: 0.8766 | Val Loss: 0.8535\n",
      "Epoch 07 | Train Loss: 0.8634 | Val Loss: 0.8517\n",
      "Epoch 08 | Train Loss: 0.8747 | Val Loss: 0.8508\n",
      "Epoch 09 | Train Loss: 0.8549 | Val Loss: 0.8498\n",
      "Epoch 10 | Train Loss: 0.8703 | Val Loss: 0.8497\n",
      "Epoch 11 | Train Loss: 0.8572 | Val Loss: 0.8475\n",
      "Epoch 12 | Train Loss: 0.8584 | Val Loss: 0.8459\n",
      "Epoch 13 | Train Loss: 0.8598 | Val Loss: 0.8438\n",
      "Epoch 14 | Train Loss: 0.8628 | Val Loss: 0.8422\n",
      "Epoch 15 | Train Loss: 0.8539 | Val Loss: 0.8413\n",
      "Epoch 16 | Train Loss: 0.8558 | Val Loss: 0.8402\n",
      "Epoch 17 | Train Loss: 0.8493 | Val Loss: 0.8388\n",
      "Epoch 18 | Train Loss: 0.8517 | Val Loss: 0.8376\n",
      "Epoch 19 | Train Loss: 0.8590 | Val Loss: 0.8357\n",
      "Epoch 20 | Train Loss: 0.8443 | Val Loss: 0.8341\n",
      "Epoch 21 | Train Loss: 0.8460 | Val Loss: 0.8323\n",
      "Epoch 22 | Train Loss: 0.8472 | Val Loss: 0.8314\n",
      "Epoch 23 | Train Loss: 0.8436 | Val Loss: 0.8293\n",
      "Epoch 24 | Train Loss: 0.8429 | Val Loss: 0.8274\n",
      "Epoch 25 | Train Loss: 0.8360 | Val Loss: 0.8257\n",
      "Epoch 26 | Train Loss: 0.8430 | Val Loss: 0.8239\n",
      "Epoch 27 | Train Loss: 0.8429 | Val Loss: 0.8231\n",
      "Epoch 28 | Train Loss: 0.8389 | Val Loss: 0.8217\n",
      "Epoch 29 | Train Loss: 0.8418 | Val Loss: 0.8183\n",
      "Epoch 30 | Train Loss: 0.8542 | Val Loss: 0.8172\n",
      "Epoch 31 | Train Loss: 0.8394 | Val Loss: 0.8141\n",
      "Epoch 32 | Train Loss: 0.8317 | Val Loss: 0.8122\n",
      "Epoch 33 | Train Loss: 0.8450 | Val Loss: 0.8093\n",
      "Epoch 34 | Train Loss: 0.8366 | Val Loss: 0.8096\n",
      "Epoch 35 | Train Loss: 0.8423 | Val Loss: 0.8052\n",
      "Epoch 36 | Train Loss: 0.8306 | Val Loss: 0.8031\n",
      "Epoch 37 | Train Loss: 0.8348 | Val Loss: 0.8006\n",
      "Epoch 38 | Train Loss: 0.8278 | Val Loss: 0.7988\n",
      "Epoch 39 | Train Loss: 0.8259 | Val Loss: 0.7984\n",
      "Epoch 40 | Train Loss: 0.8092 | Val Loss: 0.7927\n",
      "Epoch 41 | Train Loss: 0.8144 | Val Loss: 0.7897\n",
      "Epoch 42 | Train Loss: 0.8098 | Val Loss: 0.7870\n",
      "Epoch 43 | Train Loss: 0.8253 | Val Loss: 0.7837\n",
      "Epoch 44 | Train Loss: 0.8105 | Val Loss: 0.7812\n",
      "Epoch 45 | Train Loss: 0.8080 | Val Loss: 0.7788\n",
      "Epoch 46 | Train Loss: 0.8088 | Val Loss: 0.7770\n",
      "Epoch 47 | Train Loss: 0.8113 | Val Loss: 0.7747\n",
      "Epoch 48 | Train Loss: 0.7981 | Val Loss: 0.7717\n",
      "Epoch 49 | Train Loss: 0.7916 | Val Loss: 0.7725\n",
      "Epoch 50 | Train Loss: 0.7983 | Val Loss: 0.7648\n",
      "Fold 7 ‚ñ∂ AUC: 0.816, Balanced Acc: 0.500\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9769 | Val Loss: 0.9185\n",
      "Epoch 02 | Train Loss: 0.9048 | Val Loss: 0.8854\n",
      "Epoch 03 | Train Loss: 0.8803 | Val Loss: 0.8713\n",
      "Epoch 04 | Train Loss: 0.8860 | Val Loss: 0.8681\n",
      "Epoch 05 | Train Loss: 0.8675 | Val Loss: 0.8670\n",
      "Epoch 06 | Train Loss: 0.8637 | Val Loss: 0.8667\n",
      "Epoch 07 | Train Loss: 0.8755 | Val Loss: 0.8665\n",
      "Epoch 08 | Train Loss: 0.8652 | Val Loss: 0.8642\n",
      "Epoch 09 | Train Loss: 0.8784 | Val Loss: 0.8629\n",
      "Epoch 10 | Train Loss: 0.8755 | Val Loss: 0.8640\n",
      "Epoch 11 | Train Loss: 0.8666 | Val Loss: 0.8611\n",
      "Epoch 12 | Train Loss: 0.8729 | Val Loss: 0.8617\n",
      "Epoch 13 | Train Loss: 0.8784 | Val Loss: 0.8592\n",
      "Epoch 14 | Train Loss: 0.8631 | Val Loss: 0.8591\n",
      "Epoch 15 | Train Loss: 0.8680 | Val Loss: 0.8573\n",
      "Epoch 16 | Train Loss: 0.8636 | Val Loss: 0.8562\n",
      "Epoch 17 | Train Loss: 0.8597 | Val Loss: 0.8548\n",
      "Epoch 18 | Train Loss: 0.8514 | Val Loss: 0.8560\n",
      "Epoch 19 | Train Loss: 0.8653 | Val Loss: 0.8522\n",
      "Epoch 20 | Train Loss: 0.8701 | Val Loss: 0.8529\n",
      "Epoch 21 | Train Loss: 0.8689 | Val Loss: 0.8503\n",
      "Epoch 22 | Train Loss: 0.8585 | Val Loss: 0.8498\n",
      "Epoch 23 | Train Loss: 0.8462 | Val Loss: 0.8483\n",
      "Epoch 24 | Train Loss: 0.8691 | Val Loss: 0.8484\n",
      "Epoch 25 | Train Loss: 0.8556 | Val Loss: 0.8467\n",
      "Epoch 26 | Train Loss: 0.8477 | Val Loss: 0.8446\n",
      "Epoch 27 | Train Loss: 0.8474 | Val Loss: 0.8435\n",
      "Epoch 28 | Train Loss: 0.8576 | Val Loss: 0.8416\n",
      "Epoch 29 | Train Loss: 0.8531 | Val Loss: 0.8412\n",
      "Epoch 30 | Train Loss: 0.8535 | Val Loss: 0.8404\n",
      "Epoch 31 | Train Loss: 0.8442 | Val Loss: 0.8376\n",
      "Epoch 32 | Train Loss: 0.8504 | Val Loss: 0.8357\n",
      "Epoch 33 | Train Loss: 0.8508 | Val Loss: 0.8334\n",
      "Epoch 34 | Train Loss: 0.8609 | Val Loss: 0.8332\n",
      "Epoch 35 | Train Loss: 0.8416 | Val Loss: 0.8310\n",
      "Epoch 36 | Train Loss: 0.8376 | Val Loss: 0.8289\n",
      "Epoch 37 | Train Loss: 0.8483 | Val Loss: 0.8280\n",
      "Epoch 38 | Train Loss: 0.8427 | Val Loss: 0.8262\n",
      "Epoch 39 | Train Loss: 0.8402 | Val Loss: 0.8256\n",
      "Epoch 40 | Train Loss: 0.8308 | Val Loss: 0.8223\n",
      "Epoch 41 | Train Loss: 0.8344 | Val Loss: 0.8193\n",
      "Epoch 42 | Train Loss: 0.8317 | Val Loss: 0.8184\n",
      "Epoch 43 | Train Loss: 0.8272 | Val Loss: 0.8168\n",
      "Epoch 44 | Train Loss: 0.8343 | Val Loss: 0.8141\n",
      "Epoch 45 | Train Loss: 0.8175 | Val Loss: 0.8126\n",
      "Epoch 46 | Train Loss: 0.8332 | Val Loss: 0.8115\n",
      "Epoch 47 | Train Loss: 0.8272 | Val Loss: 0.8108\n",
      "Epoch 48 | Train Loss: 0.8160 | Val Loss: 0.8074\n",
      "Epoch 49 | Train Loss: 0.8183 | Val Loss: 0.8064\n",
      "Epoch 50 | Train Loss: 0.8326 | Val Loss: 0.8049\n",
      "Fold 8 ‚ñ∂ AUC: 0.733, Balanced Acc: 0.408\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9735 | Val Loss: 0.9284\n",
      "Epoch 02 | Train Loss: 0.8911 | Val Loss: 0.8902\n",
      "Epoch 03 | Train Loss: 0.8867 | Val Loss: 0.8778\n",
      "Epoch 04 | Train Loss: 0.8769 | Val Loss: 0.8749\n",
      "Epoch 05 | Train Loss: 0.8760 | Val Loss: 0.8739\n",
      "Epoch 06 | Train Loss: 0.8692 | Val Loss: 0.8736\n",
      "Epoch 07 | Train Loss: 0.8716 | Val Loss: 0.8718\n",
      "Epoch 08 | Train Loss: 0.8686 | Val Loss: 0.8710\n",
      "Epoch 09 | Train Loss: 0.8616 | Val Loss: 0.8700\n",
      "Epoch 10 | Train Loss: 0.8558 | Val Loss: 0.8700\n",
      "Epoch 11 | Train Loss: 0.8818 | Val Loss: 0.8687\n",
      "Epoch 12 | Train Loss: 0.8758 | Val Loss: 0.8678\n",
      "Epoch 13 | Train Loss: 0.8668 | Val Loss: 0.8695\n",
      "Epoch 14 | Train Loss: 0.8576 | Val Loss: 0.8673\n",
      "Epoch 15 | Train Loss: 0.8635 | Val Loss: 0.8649\n",
      "Epoch 16 | Train Loss: 0.8543 | Val Loss: 0.8634\n",
      "Epoch 17 | Train Loss: 0.8638 | Val Loss: 0.8629\n",
      "Epoch 18 | Train Loss: 0.8469 | Val Loss: 0.8617\n",
      "Epoch 19 | Train Loss: 0.8536 | Val Loss: 0.8622\n",
      "Epoch 20 | Train Loss: 0.8494 | Val Loss: 0.8603\n",
      "Epoch 21 | Train Loss: 0.8474 | Val Loss: 0.8592\n",
      "Epoch 22 | Train Loss: 0.8639 | Val Loss: 0.8590\n",
      "Epoch 23 | Train Loss: 0.8652 | Val Loss: 0.8576\n",
      "Epoch 24 | Train Loss: 0.8533 | Val Loss: 0.8586\n",
      "Epoch 25 | Train Loss: 0.8557 | Val Loss: 0.8571\n",
      "Epoch 26 | Train Loss: 0.8437 | Val Loss: 0.8557\n",
      "Epoch 27 | Train Loss: 0.8508 | Val Loss: 0.8541\n",
      "Epoch 28 | Train Loss: 0.8491 | Val Loss: 0.8536\n",
      "Epoch 29 | Train Loss: 0.8279 | Val Loss: 0.8509\n",
      "Epoch 30 | Train Loss: 0.8362 | Val Loss: 0.8500\n",
      "Epoch 31 | Train Loss: 0.8401 | Val Loss: 0.8481\n",
      "Epoch 32 | Train Loss: 0.8237 | Val Loss: 0.8474\n",
      "Epoch 33 | Train Loss: 0.8373 | Val Loss: 0.8454\n",
      "Epoch 34 | Train Loss: 0.8370 | Val Loss: 0.8439\n",
      "Epoch 35 | Train Loss: 0.8280 | Val Loss: 0.8424\n",
      "Epoch 36 | Train Loss: 0.8252 | Val Loss: 0.8410\n",
      "Epoch 37 | Train Loss: 0.8194 | Val Loss: 0.8438\n",
      "Epoch 38 | Train Loss: 0.8065 | Val Loss: 0.8387\n",
      "Epoch 39 | Train Loss: 0.8060 | Val Loss: 0.8389\n",
      "Epoch 40 | Train Loss: 0.8173 | Val Loss: 0.8378\n",
      "Epoch 41 | Train Loss: 0.8097 | Val Loss: 0.8380\n",
      "Epoch 42 | Train Loss: 0.8130 | Val Loss: 0.8346\n",
      "Epoch 43 | Train Loss: 0.8207 | Val Loss: 0.8325\n",
      "Epoch 44 | Train Loss: 0.8168 | Val Loss: 0.8326\n",
      "Epoch 45 | Train Loss: 0.8251 | Val Loss: 0.8336\n",
      "Epoch 46 | Train Loss: 0.8033 | Val Loss: 0.8260\n",
      "Epoch 47 | Train Loss: 0.8254 | Val Loss: 0.8351\n",
      "Epoch 48 | Train Loss: 0.8004 | Val Loss: 0.8247\n",
      "Epoch 49 | Train Loss: 0.7904 | Val Loss: 0.8221\n",
      "Epoch 50 | Train Loss: 0.8078 | Val Loss: 0.8203\n",
      "Fold 9 ‚ñ∂ AUC: 0.672, Balanced Acc: 0.437\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 1.5765 | Val Loss: 1.2960\n",
      "Epoch 02 | Train Loss: 1.1691 | Val Loss: 1.0371\n",
      "Epoch 03 | Train Loss: 0.9981 | Val Loss: 0.9433\n",
      "Epoch 04 | Train Loss: 0.9342 | Val Loss: 0.9022\n",
      "Epoch 05 | Train Loss: 0.8944 | Val Loss: 0.8843\n",
      "Epoch 06 | Train Loss: 0.8883 | Val Loss: 0.8761\n",
      "Epoch 07 | Train Loss: 0.8752 | Val Loss: 0.8726\n",
      "Epoch 08 | Train Loss: 0.8781 | Val Loss: 0.8703\n",
      "Epoch 09 | Train Loss: 0.8648 | Val Loss: 0.8690\n",
      "Epoch 10 | Train Loss: 0.8674 | Val Loss: 0.8699\n",
      "Epoch 11 | Train Loss: 0.8670 | Val Loss: 0.8696\n",
      "Epoch 12 | Train Loss: 0.8776 | Val Loss: 0.8687\n",
      "Epoch 13 | Train Loss: 0.8752 | Val Loss: 0.8671\n",
      "Epoch 14 | Train Loss: 0.8677 | Val Loss: 0.8674\n",
      "Epoch 15 | Train Loss: 0.8759 | Val Loss: 0.8664\n",
      "Epoch 16 | Train Loss: 0.8700 | Val Loss: 0.8649\n",
      "Epoch 17 | Train Loss: 0.8764 | Val Loss: 0.8650\n",
      "Epoch 18 | Train Loss: 0.8539 | Val Loss: 0.8641\n",
      "Epoch 19 | Train Loss: 0.8774 | Val Loss: 0.8634\n",
      "Epoch 20 | Train Loss: 0.8944 | Val Loss: 0.8628\n",
      "Epoch 21 | Train Loss: 0.8669 | Val Loss: 0.8613\n",
      "Epoch 22 | Train Loss: 0.8626 | Val Loss: 0.8603\n",
      "Epoch 23 | Train Loss: 0.8806 | Val Loss: 0.8604\n",
      "Epoch 24 | Train Loss: 0.8631 | Val Loss: 0.8589\n",
      "Epoch 25 | Train Loss: 0.8500 | Val Loss: 0.8579\n",
      "Epoch 26 | Train Loss: 0.8640 | Val Loss: 0.8575\n",
      "Epoch 27 | Train Loss: 0.8556 | Val Loss: 0.8576\n",
      "Epoch 28 | Train Loss: 0.8630 | Val Loss: 0.8558\n",
      "Epoch 29 | Train Loss: 0.8441 | Val Loss: 0.8550\n",
      "Epoch 30 | Train Loss: 0.8592 | Val Loss: 0.8563\n",
      "Epoch 31 | Train Loss: 0.8774 | Val Loss: 0.8533\n",
      "Epoch 32 | Train Loss: 0.8638 | Val Loss: 0.8521\n",
      "Epoch 33 | Train Loss: 0.8551 | Val Loss: 0.8515\n",
      "Epoch 34 | Train Loss: 0.8507 | Val Loss: 0.8515\n",
      "Epoch 35 | Train Loss: 0.8627 | Val Loss: 0.8495\n",
      "Epoch 36 | Train Loss: 0.8570 | Val Loss: 0.8475\n",
      "Epoch 37 | Train Loss: 0.8494 | Val Loss: 0.8461\n",
      "Epoch 38 | Train Loss: 0.8497 | Val Loss: 0.8444\n",
      "Epoch 39 | Train Loss: 0.8476 | Val Loss: 0.8436\n",
      "Epoch 40 | Train Loss: 0.8414 | Val Loss: 0.8428\n",
      "Epoch 41 | Train Loss: 0.8430 | Val Loss: 0.8418\n",
      "Epoch 42 | Train Loss: 0.8422 | Val Loss: 0.8401\n",
      "Epoch 43 | Train Loss: 0.8396 | Val Loss: 0.8386\n",
      "Epoch 44 | Train Loss: 0.8429 | Val Loss: 0.8368\n",
      "Epoch 45 | Train Loss: 0.8320 | Val Loss: 0.8344\n",
      "Epoch 46 | Train Loss: 0.8505 | Val Loss: 0.8325\n",
      "Epoch 47 | Train Loss: 0.8378 | Val Loss: 0.8310\n",
      "Epoch 48 | Train Loss: 0.8428 | Val Loss: 0.8284\n",
      "Epoch 49 | Train Loss: 0.8246 | Val Loss: 0.8266\n",
      "Epoch 50 | Train Loss: 0.8399 | Val Loss: 0.8248\n",
      "Fold 10 ‚ñ∂ AUC: 0.703, Balanced Acc: 0.404\n",
      "üîç Summary for hd=64, dp=0.4, lr=0.0001 ‚Üí AUC: 0.7187¬±0.0649 | BalAcc: 0.4462¬±0.0298\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.0, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9582 | Val Loss: 0.8874\n",
      "Epoch 02 | Train Loss: 0.8932 | Val Loss: 0.8696\n",
      "Epoch 03 | Train Loss: 0.8775 | Val Loss: 0.8515\n",
      "Epoch 04 | Train Loss: 0.8725 | Val Loss: 0.8460\n",
      "Epoch 05 | Train Loss: 0.8474 | Val Loss: 0.8245\n",
      "Epoch 06 | Train Loss: 0.8418 | Val Loss: 0.8123\n",
      "Epoch 07 | Train Loss: 0.8070 | Val Loss: 0.7897\n",
      "Epoch 08 | Train Loss: 0.7852 | Val Loss: 0.7636\n",
      "Epoch 09 | Train Loss: 0.7876 | Val Loss: 0.7375\n",
      "Epoch 10 | Train Loss: 0.7648 | Val Loss: 0.7228\n",
      "Epoch 11 | Train Loss: 0.7710 | Val Loss: 0.7294\n",
      "Epoch 12 | Train Loss: 0.7497 | Val Loss: 0.7781\n",
      "Epoch 13 | Train Loss: 0.7934 | Val Loss: 0.7487\n",
      "Epoch 14 | Train Loss: 0.7670 | Val Loss: 0.7097\n",
      "Epoch 15 | Train Loss: 0.7776 | Val Loss: 0.7158\n",
      "Epoch 16 | Train Loss: 0.7433 | Val Loss: 0.7193\n",
      "Epoch 17 | Train Loss: 0.7628 | Val Loss: 0.7004\n",
      "Epoch 18 | Train Loss: 0.7553 | Val Loss: 0.7012\n",
      "Epoch 19 | Train Loss: 0.7333 | Val Loss: 0.7151\n",
      "Epoch 20 | Train Loss: 0.7634 | Val Loss: 0.7022\n",
      "Epoch 21 | Train Loss: 0.7463 | Val Loss: 0.6922\n",
      "Epoch 22 | Train Loss: 0.7257 | Val Loss: 0.6844\n",
      "Epoch 23 | Train Loss: 0.7318 | Val Loss: 0.7018\n",
      "Epoch 24 | Train Loss: 0.7419 | Val Loss: 0.7050\n",
      "Epoch 25 | Train Loss: 0.7264 | Val Loss: 0.6807\n",
      "Epoch 26 | Train Loss: 0.7209 | Val Loss: 0.6851\n",
      "Epoch 27 | Train Loss: 0.7400 | Val Loss: 0.6806\n",
      "Epoch 28 | Train Loss: 0.7368 | Val Loss: 0.7117\n",
      "Epoch 29 | Train Loss: 0.7491 | Val Loss: 0.6927\n",
      "Epoch 30 | Train Loss: 0.7488 | Val Loss: 0.6835\n",
      "Epoch 31 | Train Loss: 0.7508 | Val Loss: 0.7441\n",
      "Epoch 32 | Train Loss: 0.7585 | Val Loss: 0.6924\n",
      "Epoch 33 | Train Loss: 0.7368 | Val Loss: 0.7104\n",
      "Epoch 34 | Train Loss: 0.7492 | Val Loss: 0.6912\n",
      "Epoch 35 | Train Loss: 0.7382 | Val Loss: 0.6894\n",
      "Epoch 36 | Train Loss: 0.7332 | Val Loss: 0.6862\n",
      "Epoch 37 | Train Loss: 0.7305 | Val Loss: 0.6966\n",
      "Epoch 38 | Train Loss: 0.7152 | Val Loss: 0.6918\n",
      "Epoch 39 | Train Loss: 0.7407 | Val Loss: 0.6890\n",
      "Epoch 40 | Train Loss: 0.7314 | Val Loss: 0.6946\n",
      "Epoch 41 | Train Loss: 0.7086 | Val Loss: 0.6978\n",
      "Epoch 42 | Train Loss: 0.7044 | Val Loss: 0.7171\n",
      "Epoch 43 | Train Loss: 0.7039 | Val Loss: 0.6933\n",
      "Epoch 44 | Train Loss: 0.7107 | Val Loss: 0.7307\n",
      "Epoch 45 | Train Loss: 0.7137 | Val Loss: 0.7150\n",
      "Epoch 46 | Train Loss: 0.7047 | Val Loss: 0.7078\n",
      "Epoch 47 | Train Loss: 0.7314 | Val Loss: 0.7214\n",
      "Epoch 48 | Train Loss: 0.7177 | Val Loss: 0.7279\n",
      "Epoch 49 | Train Loss: 0.7196 | Val Loss: 0.7242\n",
      "Epoch 50 | Train Loss: 0.7263 | Val Loss: 0.7239\n",
      "Fold 1 ‚ñ∂ AUC: 0.783, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.8981 | Val Loss: 0.8946\n",
      "Epoch 02 | Train Loss: 0.8835 | Val Loss: 0.8502\n",
      "Epoch 03 | Train Loss: 0.8654 | Val Loss: 0.8570\n",
      "Epoch 04 | Train Loss: 0.8767 | Val Loss: 0.8406\n",
      "Epoch 05 | Train Loss: 0.8439 | Val Loss: 0.8572\n",
      "Epoch 06 | Train Loss: 0.8607 | Val Loss: 0.8220\n",
      "Epoch 07 | Train Loss: 0.8095 | Val Loss: 0.8929\n",
      "Epoch 08 | Train Loss: 0.8081 | Val Loss: 0.8043\n",
      "Epoch 09 | Train Loss: 0.7843 | Val Loss: 0.7648\n",
      "Epoch 10 | Train Loss: 0.7829 | Val Loss: 0.7505\n",
      "Epoch 11 | Train Loss: 0.7608 | Val Loss: 0.7652\n",
      "Epoch 12 | Train Loss: 0.7720 | Val Loss: 0.7349\n",
      "Epoch 13 | Train Loss: 0.7535 | Val Loss: 0.7444\n",
      "Epoch 14 | Train Loss: 0.7758 | Val Loss: 0.7376\n",
      "Epoch 15 | Train Loss: 0.7735 | Val Loss: 0.7490\n",
      "Epoch 16 | Train Loss: 0.7744 | Val Loss: 0.7849\n",
      "Epoch 17 | Train Loss: 0.7406 | Val Loss: 0.7635\n",
      "Epoch 18 | Train Loss: 0.7350 | Val Loss: 0.7253\n",
      "Epoch 19 | Train Loss: 0.7347 | Val Loss: 0.7430\n",
      "Epoch 20 | Train Loss: 0.7472 | Val Loss: 0.8271\n",
      "Epoch 21 | Train Loss: 0.7298 | Val Loss: 0.7207\n",
      "Epoch 22 | Train Loss: 0.7357 | Val Loss: 0.7581\n",
      "Epoch 23 | Train Loss: 0.7249 | Val Loss: 0.7743\n",
      "Epoch 24 | Train Loss: 0.7366 | Val Loss: 0.7748\n",
      "Epoch 25 | Train Loss: 0.7450 | Val Loss: 0.6949\n",
      "Epoch 26 | Train Loss: 0.7567 | Val Loss: 0.8162\n",
      "Epoch 27 | Train Loss: 0.7386 | Val Loss: 0.8411\n",
      "Epoch 28 | Train Loss: 0.7547 | Val Loss: 0.7684\n",
      "Epoch 29 | Train Loss: 0.7426 | Val Loss: 0.7499\n",
      "Epoch 30 | Train Loss: 0.7201 | Val Loss: 0.7481\n",
      "Epoch 31 | Train Loss: 0.7244 | Val Loss: 0.7799\n",
      "Epoch 32 | Train Loss: 0.7332 | Val Loss: 0.8772\n",
      "Epoch 33 | Train Loss: 0.7284 | Val Loss: 0.8059\n",
      "Epoch 34 | Train Loss: 0.7769 | Val Loss: 0.6966\n",
      "Epoch 35 | Train Loss: 0.7552 | Val Loss: 0.7487\n",
      "Epoch 36 | Train Loss: 0.7235 | Val Loss: 0.8060\n",
      "Epoch 37 | Train Loss: 0.7156 | Val Loss: 0.7684\n",
      "Epoch 38 | Train Loss: 0.7325 | Val Loss: 0.7144\n",
      "Epoch 39 | Train Loss: 0.7140 | Val Loss: 0.8206\n",
      "Epoch 40 | Train Loss: 0.7476 | Val Loss: 0.7271\n",
      "Epoch 41 | Train Loss: 0.7068 | Val Loss: 0.7382\n",
      "Epoch 42 | Train Loss: 0.7214 | Val Loss: 0.7150\n",
      "Epoch 43 | Train Loss: 0.7260 | Val Loss: 0.7626\n",
      "Epoch 44 | Train Loss: 0.6969 | Val Loss: 0.7933\n",
      "Epoch 45 | Train Loss: 0.7007 | Val Loss: 0.6984\n",
      "Epoch 46 | Train Loss: 0.6988 | Val Loss: 0.7075\n",
      "Epoch 47 | Train Loss: 0.6991 | Val Loss: 0.7233\n",
      "Epoch 48 | Train Loss: 0.7062 | Val Loss: 0.7030\n",
      "Epoch 49 | Train Loss: 0.7165 | Val Loss: 0.7489\n",
      "Epoch 50 | Train Loss: 0.7209 | Val Loss: 0.8299\n",
      "Fold 2 ‚ñ∂ AUC: 0.665, Balanced Acc: 0.544\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9351 | Val Loss: 0.8591\n",
      "Epoch 02 | Train Loss: 0.8795 | Val Loss: 0.8503\n",
      "Epoch 03 | Train Loss: 0.8666 | Val Loss: 0.8488\n",
      "Epoch 04 | Train Loss: 0.8631 | Val Loss: 0.8246\n",
      "Epoch 05 | Train Loss: 0.8485 | Val Loss: 0.8085\n",
      "Epoch 06 | Train Loss: 0.8415 | Val Loss: 0.8311\n",
      "Epoch 07 | Train Loss: 0.7927 | Val Loss: 0.7739\n",
      "Epoch 08 | Train Loss: 0.7590 | Val Loss: 0.7480\n",
      "Epoch 09 | Train Loss: 0.7765 | Val Loss: 0.7492\n",
      "Epoch 10 | Train Loss: 0.7670 | Val Loss: 0.7528\n",
      "Epoch 11 | Train Loss: 0.7625 | Val Loss: 0.7660\n",
      "Epoch 12 | Train Loss: 0.7382 | Val Loss: 0.7344\n",
      "Epoch 13 | Train Loss: 0.7526 | Val Loss: 0.7435\n",
      "Epoch 14 | Train Loss: 0.7526 | Val Loss: 0.7366\n",
      "Epoch 15 | Train Loss: 0.7421 | Val Loss: 0.7397\n",
      "Epoch 16 | Train Loss: 0.7203 | Val Loss: 0.7456\n",
      "Epoch 17 | Train Loss: 0.7774 | Val Loss: 0.7317\n",
      "Epoch 18 | Train Loss: 0.7375 | Val Loss: 0.7698\n",
      "Epoch 19 | Train Loss: 0.7268 | Val Loss: 0.7308\n",
      "Epoch 20 | Train Loss: 0.7320 | Val Loss: 0.7290\n",
      "Epoch 21 | Train Loss: 0.7402 | Val Loss: 0.7241\n",
      "Epoch 22 | Train Loss: 0.7423 | Val Loss: 0.7210\n",
      "Epoch 23 | Train Loss: 0.7310 | Val Loss: 0.7187\n",
      "Epoch 24 | Train Loss: 0.7233 | Val Loss: 0.7745\n",
      "Epoch 25 | Train Loss: 0.7345 | Val Loss: 0.7470\n",
      "Epoch 26 | Train Loss: 0.7529 | Val Loss: 0.7277\n",
      "Epoch 27 | Train Loss: 0.7343 | Val Loss: 0.7329\n",
      "Epoch 28 | Train Loss: 0.7358 | Val Loss: 0.7281\n",
      "Epoch 29 | Train Loss: 0.7251 | Val Loss: 0.7254\n",
      "Epoch 30 | Train Loss: 0.7372 | Val Loss: 0.7792\n",
      "Epoch 31 | Train Loss: 0.7399 | Val Loss: 0.7236\n",
      "Epoch 32 | Train Loss: 0.7353 | Val Loss: 0.7197\n",
      "Epoch 33 | Train Loss: 0.7234 | Val Loss: 0.7191\n",
      "Epoch 34 | Train Loss: 0.7284 | Val Loss: 0.7198\n",
      "Epoch 35 | Train Loss: 0.7581 | Val Loss: 0.7170\n",
      "Epoch 36 | Train Loss: 0.7311 | Val Loss: 0.7183\n",
      "Epoch 37 | Train Loss: 0.7110 | Val Loss: 0.7167\n",
      "Epoch 38 | Train Loss: 0.7044 | Val Loss: 0.7121\n",
      "Epoch 39 | Train Loss: 0.7241 | Val Loss: 0.7106\n",
      "Epoch 40 | Train Loss: 0.7233 | Val Loss: 0.7118\n",
      "Epoch 41 | Train Loss: 0.7206 | Val Loss: 0.7490\n",
      "Epoch 42 | Train Loss: 0.7354 | Val Loss: 0.7212\n",
      "Epoch 43 | Train Loss: 0.7320 | Val Loss: 0.7140\n",
      "Epoch 44 | Train Loss: 0.7127 | Val Loss: 0.7637\n",
      "Epoch 45 | Train Loss: 0.7228 | Val Loss: 0.7224\n",
      "Epoch 46 | Train Loss: 0.7085 | Val Loss: 0.7142\n",
      "Epoch 47 | Train Loss: 0.6985 | Val Loss: 0.7044\n",
      "Epoch 48 | Train Loss: 0.7170 | Val Loss: 0.7116\n",
      "Epoch 49 | Train Loss: 0.7592 | Val Loss: 0.7228\n",
      "Epoch 50 | Train Loss: 0.7043 | Val Loss: 0.7168\n",
      "Fold 3 ‚ñ∂ AUC: 0.766, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.8936 | Val Loss: 0.8469\n",
      "Epoch 02 | Train Loss: 0.8874 | Val Loss: 0.9195\n",
      "Epoch 03 | Train Loss: 0.8841 | Val Loss: 0.8435\n",
      "Epoch 04 | Train Loss: 0.8638 | Val Loss: 0.8505\n",
      "Epoch 05 | Train Loss: 0.8619 | Val Loss: 0.8245\n",
      "Epoch 06 | Train Loss: 0.8329 | Val Loss: 0.7766\n",
      "Epoch 07 | Train Loss: 0.7818 | Val Loss: 0.7551\n",
      "Epoch 08 | Train Loss: 0.7937 | Val Loss: 0.7365\n",
      "Epoch 09 | Train Loss: 0.7970 | Val Loss: 0.7225\n",
      "Epoch 10 | Train Loss: 0.7714 | Val Loss: 0.6866\n",
      "Epoch 11 | Train Loss: 0.7849 | Val Loss: 0.6847\n",
      "Epoch 12 | Train Loss: 0.7514 | Val Loss: 0.6822\n",
      "Epoch 13 | Train Loss: 0.7494 | Val Loss: 0.6746\n",
      "Epoch 14 | Train Loss: 0.7652 | Val Loss: 0.6734\n",
      "Epoch 15 | Train Loss: 0.7269 | Val Loss: 0.6608\n",
      "Epoch 16 | Train Loss: 0.7417 | Val Loss: 0.6919\n",
      "Epoch 17 | Train Loss: 0.7522 | Val Loss: 0.6833\n",
      "Epoch 18 | Train Loss: 0.7344 | Val Loss: 0.6507\n",
      "Epoch 19 | Train Loss: 0.7308 | Val Loss: 0.6619\n",
      "Epoch 20 | Train Loss: 0.7233 | Val Loss: 0.6564\n",
      "Epoch 21 | Train Loss: 0.7446 | Val Loss: 0.6625\n",
      "Epoch 22 | Train Loss: 0.7427 | Val Loss: 0.6750\n",
      "Epoch 23 | Train Loss: 0.7253 | Val Loss: 0.6559\n",
      "Epoch 24 | Train Loss: 0.7621 | Val Loss: 0.7053\n",
      "Epoch 25 | Train Loss: 0.7321 | Val Loss: 0.6752\n",
      "Epoch 26 | Train Loss: 0.7261 | Val Loss: 0.6667\n",
      "Epoch 27 | Train Loss: 0.7320 | Val Loss: 0.6760\n",
      "Epoch 28 | Train Loss: 0.7499 | Val Loss: 0.6955\n",
      "Epoch 29 | Train Loss: 0.7281 | Val Loss: 0.6828\n",
      "Epoch 30 | Train Loss: 0.7451 | Val Loss: 0.6599\n",
      "Epoch 31 | Train Loss: 0.7249 | Val Loss: 0.6715\n",
      "Epoch 32 | Train Loss: 0.7250 | Val Loss: 0.6615\n",
      "Epoch 33 | Train Loss: 0.7301 | Val Loss: 0.6702\n",
      "Epoch 34 | Train Loss: 0.7124 | Val Loss: 0.6947\n",
      "Epoch 35 | Train Loss: 0.7265 | Val Loss: 0.6669\n",
      "Epoch 36 | Train Loss: 0.7413 | Val Loss: 0.6715\n",
      "Epoch 37 | Train Loss: 0.7441 | Val Loss: 0.6597\n",
      "Epoch 38 | Train Loss: 0.7121 | Val Loss: 0.6921\n",
      "Epoch 39 | Train Loss: 0.7228 | Val Loss: 0.6687\n",
      "Epoch 40 | Train Loss: 0.7185 | Val Loss: 0.6747\n",
      "Epoch 41 | Train Loss: 0.7272 | Val Loss: 0.6738\n",
      "Epoch 42 | Train Loss: 0.7085 | Val Loss: 0.6837\n",
      "Epoch 43 | Train Loss: 0.7106 | Val Loss: 0.6705\n",
      "Epoch 44 | Train Loss: 0.7146 | Val Loss: 0.6718\n",
      "Epoch 45 | Train Loss: 0.7108 | Val Loss: 0.6794\n",
      "Epoch 46 | Train Loss: 0.7146 | Val Loss: 0.6785\n",
      "Epoch 47 | Train Loss: 0.7148 | Val Loss: 0.6818\n",
      "Epoch 48 | Train Loss: 0.6853 | Val Loss: 0.7289\n",
      "Epoch 49 | Train Loss: 0.7434 | Val Loss: 0.6876\n",
      "Epoch 50 | Train Loss: 0.7081 | Val Loss: 0.6823\n",
      "Fold 4 ‚ñ∂ AUC: 0.793, Balanced Acc: 0.524\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9454 | Val Loss: 0.8919\n",
      "Epoch 02 | Train Loss: 0.8776 | Val Loss: 0.8973\n",
      "Epoch 03 | Train Loss: 0.8621 | Val Loss: 0.8897\n",
      "Epoch 04 | Train Loss: 0.8613 | Val Loss: 0.8710\n",
      "Epoch 05 | Train Loss: 0.8581 | Val Loss: 0.8700\n",
      "Epoch 06 | Train Loss: 0.8141 | Val Loss: 0.8958\n",
      "Epoch 07 | Train Loss: 0.8275 | Val Loss: 0.8478\n",
      "Epoch 08 | Train Loss: 0.7872 | Val Loss: 0.8715\n",
      "Epoch 09 | Train Loss: 0.8053 | Val Loss: 0.9190\n",
      "Epoch 10 | Train Loss: 0.7810 | Val Loss: 0.9443\n",
      "Epoch 11 | Train Loss: 0.7887 | Val Loss: 0.8429\n",
      "Epoch 12 | Train Loss: 0.7724 | Val Loss: 0.8428\n",
      "Epoch 13 | Train Loss: 0.7546 | Val Loss: 0.8391\n",
      "Epoch 14 | Train Loss: 0.7434 | Val Loss: 0.8378\n",
      "Epoch 15 | Train Loss: 0.7334 | Val Loss: 0.8248\n",
      "Epoch 16 | Train Loss: 0.7370 | Val Loss: 0.8309\n",
      "Epoch 17 | Train Loss: 0.7513 | Val Loss: 0.8101\n",
      "Epoch 18 | Train Loss: 0.7211 | Val Loss: 0.8072\n",
      "Epoch 19 | Train Loss: 0.7169 | Val Loss: 0.8242\n",
      "Epoch 20 | Train Loss: 0.7200 | Val Loss: 0.7994\n",
      "Epoch 21 | Train Loss: 0.7190 | Val Loss: 0.8212\n",
      "Epoch 22 | Train Loss: 0.7308 | Val Loss: 0.7990\n",
      "Epoch 23 | Train Loss: 0.7173 | Val Loss: 0.7944\n",
      "Epoch 24 | Train Loss: 0.7076 | Val Loss: 0.8105\n",
      "Epoch 25 | Train Loss: 0.7088 | Val Loss: 0.8018\n",
      "Epoch 26 | Train Loss: 0.7092 | Val Loss: 0.7937\n",
      "Epoch 27 | Train Loss: 0.7119 | Val Loss: 0.8396\n",
      "Epoch 28 | Train Loss: 0.6903 | Val Loss: 0.7845\n",
      "Epoch 29 | Train Loss: 0.7146 | Val Loss: 0.7943\n",
      "Epoch 30 | Train Loss: 0.7185 | Val Loss: 0.7832\n",
      "Epoch 31 | Train Loss: 0.7252 | Val Loss: 0.7938\n",
      "Epoch 32 | Train Loss: 0.7332 | Val Loss: 0.7868\n",
      "Epoch 33 | Train Loss: 0.7348 | Val Loss: 0.8383\n",
      "Epoch 34 | Train Loss: 0.6945 | Val Loss: 0.8063\n",
      "Epoch 35 | Train Loss: 0.7343 | Val Loss: 0.8020\n",
      "Epoch 36 | Train Loss: 0.7160 | Val Loss: 0.8192\n",
      "Epoch 37 | Train Loss: 0.7055 | Val Loss: 0.8250\n",
      "Epoch 38 | Train Loss: 0.7210 | Val Loss: 0.8026\n",
      "Epoch 39 | Train Loss: 0.7099 | Val Loss: 0.8123\n",
      "Epoch 40 | Train Loss: 0.6930 | Val Loss: 0.7992\n",
      "Epoch 41 | Train Loss: 0.7149 | Val Loss: 0.7964\n",
      "Epoch 42 | Train Loss: 0.7067 | Val Loss: 0.7932\n",
      "Epoch 43 | Train Loss: 0.6882 | Val Loss: 0.8001\n",
      "Epoch 44 | Train Loss: 0.7358 | Val Loss: 0.8090\n",
      "Epoch 45 | Train Loss: 0.7123 | Val Loss: 0.8155\n",
      "Epoch 46 | Train Loss: 0.6979 | Val Loss: 0.7935\n",
      "Epoch 47 | Train Loss: 0.7175 | Val Loss: 0.8012\n",
      "Epoch 48 | Train Loss: 0.7008 | Val Loss: 0.7959\n",
      "Epoch 49 | Train Loss: 0.7033 | Val Loss: 0.8239\n",
      "Epoch 50 | Train Loss: 0.7276 | Val Loss: 0.8053\n",
      "Fold 5 ‚ñ∂ AUC: 0.735, Balanced Acc: 0.442\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9189 | Val Loss: 0.9248\n",
      "Epoch 02 | Train Loss: 0.8796 | Val Loss: 0.9052\n",
      "Epoch 03 | Train Loss: 0.8679 | Val Loss: 0.8854\n",
      "Epoch 04 | Train Loss: 0.8470 | Val Loss: 0.8752\n",
      "Epoch 05 | Train Loss: 0.8311 | Val Loss: 0.8931\n",
      "Epoch 06 | Train Loss: 0.8708 | Val Loss: 0.8856\n",
      "Epoch 07 | Train Loss: 0.8632 | Val Loss: 0.8625\n",
      "Epoch 08 | Train Loss: 0.8116 | Val Loss: 0.8609\n",
      "Epoch 09 | Train Loss: 0.7929 | Val Loss: 0.8243\n",
      "Epoch 10 | Train Loss: 0.7555 | Val Loss: 0.8242\n",
      "Epoch 11 | Train Loss: 0.7565 | Val Loss: 0.8861\n",
      "Epoch 12 | Train Loss: 0.7696 | Val Loss: 0.8064\n",
      "Epoch 13 | Train Loss: 0.7542 | Val Loss: 0.8110\n",
      "Epoch 14 | Train Loss: 0.7403 | Val Loss: 0.8157\n",
      "Epoch 15 | Train Loss: 0.7500 | Val Loss: 0.8106\n",
      "Epoch 16 | Train Loss: 0.7434 | Val Loss: 0.8069\n",
      "Epoch 17 | Train Loss: 0.7566 | Val Loss: 0.8078\n",
      "Epoch 18 | Train Loss: 0.7399 | Val Loss: 0.8148\n",
      "Epoch 19 | Train Loss: 0.7249 | Val Loss: 0.8100\n",
      "Epoch 20 | Train Loss: 0.7160 | Val Loss: 0.8235\n",
      "Epoch 21 | Train Loss: 0.7341 | Val Loss: 0.8567\n",
      "Epoch 22 | Train Loss: 0.7600 | Val Loss: 0.8241\n",
      "Epoch 23 | Train Loss: 0.7438 | Val Loss: 0.8240\n",
      "Epoch 24 | Train Loss: 0.7052 | Val Loss: 0.8130\n",
      "Epoch 25 | Train Loss: 0.7249 | Val Loss: 0.8177\n",
      "Epoch 26 | Train Loss: 0.7168 | Val Loss: 0.8134\n",
      "Epoch 27 | Train Loss: 0.7080 | Val Loss: 0.8237\n",
      "Epoch 28 | Train Loss: 0.7332 | Val Loss: 0.8249\n",
      "Epoch 29 | Train Loss: 0.7345 | Val Loss: 0.8212\n",
      "Epoch 30 | Train Loss: 0.6985 | Val Loss: 0.8161\n",
      "Epoch 31 | Train Loss: 0.7133 | Val Loss: 0.8512\n",
      "Epoch 32 | Train Loss: 0.7498 | Val Loss: 0.8201\n",
      "Epoch 33 | Train Loss: 0.7067 | Val Loss: 0.8066\n",
      "Epoch 34 | Train Loss: 0.7058 | Val Loss: 0.8139\n",
      "Epoch 35 | Train Loss: 0.7102 | Val Loss: 0.8263\n",
      "Epoch 36 | Train Loss: 0.7085 | Val Loss: 0.8407\n",
      "Epoch 37 | Train Loss: 0.7052 | Val Loss: 0.8054\n",
      "Epoch 38 | Train Loss: 0.7134 | Val Loss: 0.8409\n",
      "Epoch 39 | Train Loss: 0.6904 | Val Loss: 0.8286\n",
      "Epoch 40 | Train Loss: 0.7146 | Val Loss: 0.8117\n",
      "Epoch 41 | Train Loss: 0.6950 | Val Loss: 0.8120\n",
      "Epoch 42 | Train Loss: 0.7266 | Val Loss: 0.8017\n",
      "Epoch 43 | Train Loss: 0.7002 | Val Loss: 0.8160\n",
      "Epoch 44 | Train Loss: 0.7230 | Val Loss: 0.8354\n",
      "Epoch 45 | Train Loss: 0.7099 | Val Loss: 0.8093\n",
      "Epoch 46 | Train Loss: 0.7327 | Val Loss: 0.8241\n",
      "Epoch 47 | Train Loss: 0.7278 | Val Loss: 0.8276\n",
      "Epoch 48 | Train Loss: 0.7101 | Val Loss: 0.8193\n",
      "Epoch 49 | Train Loss: 0.6960 | Val Loss: 0.8104\n",
      "Epoch 50 | Train Loss: 0.6816 | Val Loss: 0.8501\n",
      "Fold 6 ‚ñ∂ AUC: 0.724, Balanced Acc: 0.440\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9209 | Val Loss: 0.8630\n",
      "Epoch 02 | Train Loss: 0.8645 | Val Loss: 0.8497\n",
      "Epoch 03 | Train Loss: 0.8547 | Val Loss: 0.8337\n",
      "Epoch 04 | Train Loss: 0.8532 | Val Loss: 0.8157\n",
      "Epoch 05 | Train Loss: 0.8614 | Val Loss: 0.8025\n",
      "Epoch 06 | Train Loss: 0.8295 | Val Loss: 0.8063\n",
      "Epoch 07 | Train Loss: 0.8120 | Val Loss: 0.7595\n",
      "Epoch 08 | Train Loss: 0.8119 | Val Loss: 0.7577\n",
      "Epoch 09 | Train Loss: 0.7969 | Val Loss: 0.7311\n",
      "Epoch 10 | Train Loss: 0.8108 | Val Loss: 0.7720\n",
      "Epoch 11 | Train Loss: 0.8051 | Val Loss: 0.7109\n",
      "Epoch 12 | Train Loss: 0.7907 | Val Loss: 0.6964\n",
      "Epoch 13 | Train Loss: 0.7844 | Val Loss: 0.7088\n",
      "Epoch 14 | Train Loss: 0.7712 | Val Loss: 0.7077\n",
      "Epoch 15 | Train Loss: 0.7691 | Val Loss: 0.6993\n",
      "Epoch 16 | Train Loss: 0.7514 | Val Loss: 0.7105\n",
      "Epoch 17 | Train Loss: 0.7655 | Val Loss: 0.6999\n",
      "Epoch 18 | Train Loss: 0.7550 | Val Loss: 0.7099\n",
      "Epoch 19 | Train Loss: 0.7290 | Val Loss: 0.7029\n",
      "Epoch 20 | Train Loss: 0.7447 | Val Loss: 0.7113\n",
      "Epoch 21 | Train Loss: 0.7340 | Val Loss: 0.7344\n",
      "Epoch 22 | Train Loss: 0.7413 | Val Loss: 0.7224\n",
      "Epoch 23 | Train Loss: 0.7239 | Val Loss: 0.7783\n",
      "Epoch 24 | Train Loss: 0.7265 | Val Loss: 0.7489\n",
      "Epoch 25 | Train Loss: 0.7458 | Val Loss: 0.7294\n",
      "Epoch 26 | Train Loss: 0.7691 | Val Loss: 0.7336\n",
      "Epoch 27 | Train Loss: 0.7742 | Val Loss: 0.7680\n",
      "Epoch 28 | Train Loss: 0.7216 | Val Loss: 0.7020\n",
      "Epoch 29 | Train Loss: 0.7206 | Val Loss: 0.7243\n",
      "Epoch 30 | Train Loss: 0.7504 | Val Loss: 0.7388\n",
      "Epoch 31 | Train Loss: 0.7373 | Val Loss: 0.7125\n",
      "Epoch 32 | Train Loss: 0.7270 | Val Loss: 0.7307\n",
      "Epoch 33 | Train Loss: 0.7501 | Val Loss: 0.7284\n",
      "Epoch 34 | Train Loss: 0.7212 | Val Loss: 0.7201\n",
      "Epoch 35 | Train Loss: 0.7180 | Val Loss: 0.7216\n",
      "Epoch 36 | Train Loss: 0.7148 | Val Loss: 0.7376\n",
      "Epoch 37 | Train Loss: 0.7154 | Val Loss: 0.7435\n",
      "Epoch 38 | Train Loss: 0.7186 | Val Loss: 0.7298\n",
      "Epoch 39 | Train Loss: 0.7214 | Val Loss: 0.7283\n",
      "Epoch 40 | Train Loss: 0.7155 | Val Loss: 0.7301\n",
      "Epoch 41 | Train Loss: 0.7352 | Val Loss: 0.7322\n",
      "Epoch 42 | Train Loss: 0.7139 | Val Loss: 0.7318\n",
      "Epoch 43 | Train Loss: 0.7090 | Val Loss: 0.7398\n",
      "Epoch 44 | Train Loss: 0.7489 | Val Loss: 0.7318\n",
      "Epoch 45 | Train Loss: 0.7113 | Val Loss: 0.7255\n",
      "Epoch 46 | Train Loss: 0.7032 | Val Loss: 0.7475\n",
      "Epoch 47 | Train Loss: 0.7259 | Val Loss: 0.7325\n",
      "Epoch 48 | Train Loss: 0.7214 | Val Loss: 0.7292\n",
      "Epoch 49 | Train Loss: 0.7300 | Val Loss: 0.7423\n",
      "Epoch 50 | Train Loss: 0.7107 | Val Loss: 0.7651\n",
      "Fold 7 ‚ñ∂ AUC: 0.756, Balanced Acc: 0.437\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9236 | Val Loss: 0.8703\n",
      "Epoch 02 | Train Loss: 0.8753 | Val Loss: 0.8664\n",
      "Epoch 03 | Train Loss: 0.8752 | Val Loss: 0.8802\n",
      "Epoch 04 | Train Loss: 0.8871 | Val Loss: 0.8535\n",
      "Epoch 05 | Train Loss: 0.8504 | Val Loss: 0.8613\n",
      "Epoch 06 | Train Loss: 0.8589 | Val Loss: 0.8309\n",
      "Epoch 07 | Train Loss: 0.8254 | Val Loss: 0.8015\n",
      "Epoch 08 | Train Loss: 0.8007 | Val Loss: 0.7850\n",
      "Epoch 09 | Train Loss: 0.7559 | Val Loss: 0.9027\n",
      "Epoch 10 | Train Loss: 0.8145 | Val Loss: 0.8373\n",
      "Epoch 11 | Train Loss: 0.7499 | Val Loss: 0.7882\n",
      "Epoch 12 | Train Loss: 0.7514 | Val Loss: 0.8037\n",
      "Epoch 13 | Train Loss: 0.7370 | Val Loss: 0.7967\n",
      "Epoch 14 | Train Loss: 0.7285 | Val Loss: 0.7975\n",
      "Epoch 15 | Train Loss: 0.7251 | Val Loss: 0.7891\n",
      "Epoch 16 | Train Loss: 0.7604 | Val Loss: 0.7931\n",
      "Epoch 17 | Train Loss: 0.7335 | Val Loss: 0.7885\n",
      "Epoch 18 | Train Loss: 0.7230 | Val Loss: 0.8115\n",
      "Epoch 19 | Train Loss: 0.7184 | Val Loss: 0.8159\n",
      "Epoch 20 | Train Loss: 0.7393 | Val Loss: 0.7860\n",
      "Epoch 21 | Train Loss: 0.7126 | Val Loss: 0.8123\n",
      "Epoch 22 | Train Loss: 0.7198 | Val Loss: 0.7868\n",
      "Epoch 23 | Train Loss: 0.7339 | Val Loss: 0.8155\n",
      "Epoch 24 | Train Loss: 0.7190 | Val Loss: 0.8404\n",
      "Epoch 25 | Train Loss: 0.7138 | Val Loss: 0.8311\n",
      "Epoch 26 | Train Loss: 0.7020 | Val Loss: 0.7846\n",
      "Epoch 27 | Train Loss: 0.7215 | Val Loss: 0.8444\n",
      "Epoch 28 | Train Loss: 0.7504 | Val Loss: 0.8170\n",
      "Epoch 29 | Train Loss: 0.7199 | Val Loss: 0.7956\n",
      "Epoch 30 | Train Loss: 0.7142 | Val Loss: 0.8062\n",
      "Epoch 31 | Train Loss: 0.7349 | Val Loss: 0.8191\n",
      "Epoch 32 | Train Loss: 0.7357 | Val Loss: 0.8026\n",
      "Epoch 33 | Train Loss: 0.7192 | Val Loss: 0.8003\n",
      "Epoch 34 | Train Loss: 0.7192 | Val Loss: 0.8116\n",
      "Epoch 35 | Train Loss: 0.7120 | Val Loss: 0.7915\n",
      "Epoch 36 | Train Loss: 0.7012 | Val Loss: 0.8164\n",
      "Epoch 37 | Train Loss: 0.7022 | Val Loss: 0.7978\n",
      "Epoch 38 | Train Loss: 0.6913 | Val Loss: 0.8067\n",
      "Epoch 39 | Train Loss: 0.7139 | Val Loss: 0.7983\n",
      "Epoch 40 | Train Loss: 0.6835 | Val Loss: 0.8175\n",
      "Epoch 41 | Train Loss: 0.7084 | Val Loss: 0.8292\n",
      "Epoch 42 | Train Loss: 0.7064 | Val Loss: 0.8001\n",
      "Epoch 43 | Train Loss: 0.7002 | Val Loss: 0.8108\n",
      "Epoch 44 | Train Loss: 0.6891 | Val Loss: 0.8108\n",
      "Epoch 45 | Train Loss: 0.6855 | Val Loss: 0.8096\n",
      "Epoch 46 | Train Loss: 0.6799 | Val Loss: 0.8160\n",
      "Epoch 47 | Train Loss: 0.6804 | Val Loss: 0.8134\n",
      "Epoch 48 | Train Loss: 0.7327 | Val Loss: 0.7999\n",
      "Epoch 49 | Train Loss: 0.7078 | Val Loss: 0.8185\n",
      "Epoch 50 | Train Loss: 0.6932 | Val Loss: 0.8247\n",
      "Fold 8 ‚ñ∂ AUC: 0.730, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9157 | Val Loss: 0.8831\n",
      "Epoch 02 | Train Loss: 0.8894 | Val Loss: 0.8762\n",
      "Epoch 03 | Train Loss: 0.8560 | Val Loss: 0.8671\n",
      "Epoch 04 | Train Loss: 0.8511 | Val Loss: 0.8547\n",
      "Epoch 05 | Train Loss: 0.8958 | Val Loss: 0.8530\n",
      "Epoch 06 | Train Loss: 0.8517 | Val Loss: 0.8508\n",
      "Epoch 07 | Train Loss: 0.8226 | Val Loss: 0.8333\n",
      "Epoch 08 | Train Loss: 0.7927 | Val Loss: 0.8448\n",
      "Epoch 09 | Train Loss: 0.8003 | Val Loss: 0.8727\n",
      "Epoch 10 | Train Loss: 0.8196 | Val Loss: 0.8425\n",
      "Epoch 11 | Train Loss: 0.8061 | Val Loss: 0.8069\n",
      "Epoch 12 | Train Loss: 0.7676 | Val Loss: 0.8037\n",
      "Epoch 13 | Train Loss: 0.7679 | Val Loss: 0.7965\n",
      "Epoch 14 | Train Loss: 0.7409 | Val Loss: 0.7926\n",
      "Epoch 15 | Train Loss: 0.7337 | Val Loss: 0.7983\n",
      "Epoch 16 | Train Loss: 0.7383 | Val Loss: 0.7909\n",
      "Epoch 17 | Train Loss: 0.7396 | Val Loss: 0.7859\n",
      "Epoch 18 | Train Loss: 0.7805 | Val Loss: 0.7999\n",
      "Epoch 19 | Train Loss: 0.7932 | Val Loss: 0.7827\n",
      "Epoch 20 | Train Loss: 0.7569 | Val Loss: 0.8187\n",
      "Epoch 21 | Train Loss: 0.7336 | Val Loss: 0.7754\n",
      "Epoch 22 | Train Loss: 0.7459 | Val Loss: 0.7760\n",
      "Epoch 23 | Train Loss: 0.7189 | Val Loss: 0.7808\n",
      "Epoch 24 | Train Loss: 0.7143 | Val Loss: 0.7765\n",
      "Epoch 25 | Train Loss: 0.7297 | Val Loss: 0.7863\n",
      "Epoch 26 | Train Loss: 0.7124 | Val Loss: 0.7696\n",
      "Epoch 27 | Train Loss: 0.7333 | Val Loss: 0.8588\n",
      "Epoch 28 | Train Loss: 0.7649 | Val Loss: 0.7732\n",
      "Epoch 29 | Train Loss: 0.7261 | Val Loss: 0.7619\n",
      "Epoch 30 | Train Loss: 0.7170 | Val Loss: 0.7814\n",
      "Epoch 31 | Train Loss: 0.7287 | Val Loss: 0.7884\n",
      "Epoch 32 | Train Loss: 0.7412 | Val Loss: 0.8023\n",
      "Epoch 33 | Train Loss: 0.7384 | Val Loss: 0.7626\n",
      "Epoch 34 | Train Loss: 0.7306 | Val Loss: 0.7468\n",
      "Epoch 35 | Train Loss: 0.7139 | Val Loss: 0.7466\n",
      "Epoch 36 | Train Loss: 0.7189 | Val Loss: 0.7555\n",
      "Epoch 37 | Train Loss: 0.7319 | Val Loss: 0.7670\n",
      "Epoch 38 | Train Loss: 0.7179 | Val Loss: 0.7603\n",
      "Epoch 39 | Train Loss: 0.7201 | Val Loss: 0.7680\n",
      "Epoch 40 | Train Loss: 0.7126 | Val Loss: 0.7511\n",
      "Epoch 41 | Train Loss: 0.7171 | Val Loss: 0.7461\n",
      "Epoch 42 | Train Loss: 0.7095 | Val Loss: 0.7883\n",
      "Epoch 43 | Train Loss: 0.7271 | Val Loss: 0.7932\n",
      "Epoch 44 | Train Loss: 0.7052 | Val Loss: 0.7595\n",
      "Epoch 45 | Train Loss: 0.6949 | Val Loss: 0.7874\n",
      "Epoch 46 | Train Loss: 0.7096 | Val Loss: 0.8065\n",
      "Epoch 47 | Train Loss: 0.7181 | Val Loss: 0.7845\n",
      "Epoch 48 | Train Loss: 0.7170 | Val Loss: 0.7535\n",
      "Epoch 49 | Train Loss: 0.7120 | Val Loss: 0.7510\n",
      "Epoch 50 | Train Loss: 0.7085 | Val Loss: 0.7440\n",
      "Fold 9 ‚ñ∂ AUC: 0.760, Balanced Acc: 0.481\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9356 | Val Loss: 0.8794\n",
      "Epoch 02 | Train Loss: 0.8877 | Val Loss: 0.8687\n",
      "Epoch 03 | Train Loss: 0.8666 | Val Loss: 0.8586\n",
      "Epoch 04 | Train Loss: 0.8437 | Val Loss: 0.9235\n",
      "Epoch 05 | Train Loss: 0.8465 | Val Loss: 0.8283\n",
      "Epoch 06 | Train Loss: 0.7989 | Val Loss: 0.8954\n",
      "Epoch 07 | Train Loss: 0.8040 | Val Loss: 0.7779\n",
      "Epoch 08 | Train Loss: 0.7702 | Val Loss: 0.7893\n",
      "Epoch 09 | Train Loss: 0.7850 | Val Loss: 0.7936\n",
      "Epoch 10 | Train Loss: 0.7886 | Val Loss: 0.8483\n",
      "Epoch 11 | Train Loss: 0.7980 | Val Loss: 0.8247\n",
      "Epoch 12 | Train Loss: 0.7919 | Val Loss: 0.8358\n",
      "Epoch 13 | Train Loss: 0.7632 | Val Loss: 0.8277\n",
      "Epoch 14 | Train Loss: 0.7550 | Val Loss: 0.7686\n",
      "Epoch 15 | Train Loss: 0.7327 | Val Loss: 0.7662\n",
      "Epoch 16 | Train Loss: 0.7146 | Val Loss: 0.8257\n",
      "Epoch 17 | Train Loss: 0.7179 | Val Loss: 0.7745\n",
      "Epoch 18 | Train Loss: 0.7137 | Val Loss: 0.7693\n",
      "Epoch 19 | Train Loss: 0.7199 | Val Loss: 0.7640\n",
      "Epoch 20 | Train Loss: 0.7241 | Val Loss: 0.8031\n",
      "Epoch 21 | Train Loss: 0.7169 | Val Loss: 0.8133\n",
      "Epoch 22 | Train Loss: 0.7498 | Val Loss: 0.8317\n",
      "Epoch 23 | Train Loss: 0.7160 | Val Loss: 0.7664\n",
      "Epoch 24 | Train Loss: 0.7023 | Val Loss: 0.8062\n",
      "Epoch 25 | Train Loss: 0.7250 | Val Loss: 0.7972\n",
      "Epoch 26 | Train Loss: 0.7028 | Val Loss: 0.7830\n",
      "Epoch 27 | Train Loss: 0.7099 | Val Loss: 0.7927\n",
      "Epoch 28 | Train Loss: 0.7229 | Val Loss: 0.7694\n",
      "Epoch 29 | Train Loss: 0.7183 | Val Loss: 0.7550\n",
      "Epoch 30 | Train Loss: 0.6918 | Val Loss: 0.7876\n",
      "Epoch 31 | Train Loss: 0.7066 | Val Loss: 0.8253\n",
      "Epoch 32 | Train Loss: 0.7228 | Val Loss: 0.7773\n",
      "Epoch 33 | Train Loss: 0.7063 | Val Loss: 0.7732\n",
      "Epoch 34 | Train Loss: 0.7024 | Val Loss: 0.8131\n",
      "Epoch 35 | Train Loss: 0.7049 | Val Loss: 0.7611\n",
      "Epoch 36 | Train Loss: 0.7201 | Val Loss: 0.7815\n",
      "Epoch 37 | Train Loss: 0.7308 | Val Loss: 0.7824\n",
      "Epoch 38 | Train Loss: 0.7057 | Val Loss: 0.7840\n",
      "Epoch 39 | Train Loss: 0.7006 | Val Loss: 0.7794\n",
      "Epoch 40 | Train Loss: 0.7107 | Val Loss: 0.7840\n",
      "Epoch 41 | Train Loss: 0.7055 | Val Loss: 0.7867\n",
      "Epoch 42 | Train Loss: 0.7127 | Val Loss: 0.8145\n",
      "Epoch 43 | Train Loss: 0.7203 | Val Loss: 0.7914\n",
      "Epoch 44 | Train Loss: 0.7383 | Val Loss: 0.8266\n",
      "Epoch 45 | Train Loss: 0.7292 | Val Loss: 0.8021\n",
      "Epoch 46 | Train Loss: 0.7076 | Val Loss: 0.7927\n",
      "Epoch 47 | Train Loss: 0.7201 | Val Loss: 0.7744\n",
      "Epoch 48 | Train Loss: 0.7078 | Val Loss: 0.7697\n",
      "Epoch 49 | Train Loss: 0.6926 | Val Loss: 0.7742\n",
      "Epoch 50 | Train Loss: 0.7105 | Val Loss: 0.8750\n",
      "Fold 10 ‚ñ∂ AUC: 0.734, Balanced Acc: 0.425\n",
      "üîç Summary for hd=128, dp=0.0, lr=0.001 ‚Üí AUC: 0.7445¬±0.0345 | BalAcc: 0.4643¬±0.0427\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.0, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9172 | Val Loss: 0.8606\n",
      "Epoch 02 | Train Loss: 0.8690 | Val Loss: 0.8484\n",
      "Epoch 03 | Train Loss: 0.8596 | Val Loss: 0.8421\n",
      "Epoch 04 | Train Loss: 0.8613 | Val Loss: 0.8441\n",
      "Epoch 05 | Train Loss: 0.8407 | Val Loss: 0.8300\n",
      "Epoch 06 | Train Loss: 0.8431 | Val Loss: 0.8349\n",
      "Epoch 07 | Train Loss: 0.8150 | Val Loss: 0.8246\n",
      "Epoch 08 | Train Loss: 0.8185 | Val Loss: 0.7916\n",
      "Epoch 09 | Train Loss: 0.7879 | Val Loss: 0.7746\n",
      "Epoch 10 | Train Loss: 0.8040 | Val Loss: 0.7623\n",
      "Epoch 11 | Train Loss: 0.7786 | Val Loss: 0.7637\n",
      "Epoch 12 | Train Loss: 0.7896 | Val Loss: 0.7482\n",
      "Epoch 13 | Train Loss: 0.7795 | Val Loss: 0.7339\n",
      "Epoch 14 | Train Loss: 0.7630 | Val Loss: 0.7384\n",
      "Epoch 15 | Train Loss: 0.7654 | Val Loss: 0.7248\n",
      "Epoch 16 | Train Loss: 0.7689 | Val Loss: 0.7218\n",
      "Epoch 17 | Train Loss: 0.7583 | Val Loss: 0.7163\n",
      "Epoch 18 | Train Loss: 0.7560 | Val Loss: 0.7174\n",
      "Epoch 19 | Train Loss: 0.7549 | Val Loss: 0.7339\n",
      "Epoch 20 | Train Loss: 0.8081 | Val Loss: 0.7127\n",
      "Epoch 21 | Train Loss: 0.7699 | Val Loss: 0.7195\n",
      "Epoch 22 | Train Loss: 0.7631 | Val Loss: 0.7027\n",
      "Epoch 23 | Train Loss: 0.7433 | Val Loss: 0.7182\n",
      "Epoch 24 | Train Loss: 0.7548 | Val Loss: 0.7028\n",
      "Epoch 25 | Train Loss: 0.7350 | Val Loss: 0.6974\n",
      "Epoch 26 | Train Loss: 0.7476 | Val Loss: 0.6910\n",
      "Epoch 27 | Train Loss: 0.7309 | Val Loss: 0.7024\n",
      "Epoch 28 | Train Loss: 0.7328 | Val Loss: 0.7032\n",
      "Epoch 29 | Train Loss: 0.7234 | Val Loss: 0.7130\n",
      "Epoch 30 | Train Loss: 0.7208 | Val Loss: 0.6950\n",
      "Epoch 31 | Train Loss: 0.7146 | Val Loss: 0.7162\n",
      "Epoch 32 | Train Loss: 0.7526 | Val Loss: 0.6871\n",
      "Epoch 33 | Train Loss: 0.7250 | Val Loss: 0.6899\n",
      "Epoch 34 | Train Loss: 0.7136 | Val Loss: 0.6860\n",
      "Epoch 35 | Train Loss: 0.7267 | Val Loss: 0.6875\n",
      "Epoch 36 | Train Loss: 0.7267 | Val Loss: 0.6845\n",
      "Epoch 37 | Train Loss: 0.7258 | Val Loss: 0.6974\n",
      "Epoch 38 | Train Loss: 0.7082 | Val Loss: 0.6807\n",
      "Epoch 39 | Train Loss: 0.7278 | Val Loss: 0.6841\n",
      "Epoch 40 | Train Loss: 0.7181 | Val Loss: 0.6833\n",
      "Epoch 41 | Train Loss: 0.6990 | Val Loss: 0.6848\n",
      "Epoch 42 | Train Loss: 0.7120 | Val Loss: 0.6980\n",
      "Epoch 43 | Train Loss: 0.7099 | Val Loss: 0.6858\n",
      "Epoch 44 | Train Loss: 0.7366 | Val Loss: 0.6825\n",
      "Epoch 45 | Train Loss: 0.7220 | Val Loss: 0.6862\n",
      "Epoch 46 | Train Loss: 0.7449 | Val Loss: 0.6915\n",
      "Epoch 47 | Train Loss: 0.7132 | Val Loss: 0.7196\n",
      "Epoch 48 | Train Loss: 0.7011 | Val Loss: 0.6916\n",
      "Epoch 49 | Train Loss: 0.7305 | Val Loss: 0.7111\n",
      "Epoch 50 | Train Loss: 0.7375 | Val Loss: 0.6990\n",
      "Fold 1 ‚ñ∂ AUC: 0.781, Balanced Acc: 0.488\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.8894 | Val Loss: 0.8722\n",
      "Epoch 02 | Train Loss: 0.8729 | Val Loss: 0.8703\n",
      "Epoch 03 | Train Loss: 0.8721 | Val Loss: 0.8487\n",
      "Epoch 04 | Train Loss: 0.8619 | Val Loss: 0.8443\n",
      "Epoch 05 | Train Loss: 0.8374 | Val Loss: 0.8518\n",
      "Epoch 06 | Train Loss: 0.8317 | Val Loss: 0.8188\n",
      "Epoch 07 | Train Loss: 0.8400 | Val Loss: 0.8058\n",
      "Epoch 08 | Train Loss: 0.8092 | Val Loss: 0.8043\n",
      "Epoch 09 | Train Loss: 0.8636 | Val Loss: 0.8273\n",
      "Epoch 10 | Train Loss: 0.8025 | Val Loss: 0.8073\n",
      "Epoch 11 | Train Loss: 0.7820 | Val Loss: 0.7766\n",
      "Epoch 12 | Train Loss: 0.7775 | Val Loss: 0.7743\n",
      "Epoch 13 | Train Loss: 0.7638 | Val Loss: 0.7998\n",
      "Epoch 14 | Train Loss: 0.7776 | Val Loss: 0.7596\n",
      "Epoch 15 | Train Loss: 0.7614 | Val Loss: 0.7531\n",
      "Epoch 16 | Train Loss: 0.7571 | Val Loss: 0.7615\n",
      "Epoch 17 | Train Loss: 0.7707 | Val Loss: 0.7512\n",
      "Epoch 18 | Train Loss: 0.7779 | Val Loss: 0.7701\n",
      "Epoch 19 | Train Loss: 0.7460 | Val Loss: 0.7990\n",
      "Epoch 20 | Train Loss: 0.7506 | Val Loss: 0.7674\n",
      "Epoch 21 | Train Loss: 0.7553 | Val Loss: 0.7806\n",
      "Epoch 22 | Train Loss: 0.7338 | Val Loss: 0.7698\n",
      "Epoch 23 | Train Loss: 0.7280 | Val Loss: 0.7765\n",
      "Epoch 24 | Train Loss: 0.7501 | Val Loss: 0.7949\n",
      "Epoch 25 | Train Loss: 0.7554 | Val Loss: 0.7743\n",
      "Epoch 26 | Train Loss: 0.7303 | Val Loss: 0.7435\n",
      "Epoch 27 | Train Loss: 0.7078 | Val Loss: 0.8377\n",
      "Epoch 28 | Train Loss: 0.7293 | Val Loss: 0.7421\n",
      "Epoch 29 | Train Loss: 0.7350 | Val Loss: 0.7271\n",
      "Epoch 30 | Train Loss: 0.7392 | Val Loss: 0.7474\n",
      "Epoch 31 | Train Loss: 0.7273 | Val Loss: 0.7589\n",
      "Epoch 32 | Train Loss: 0.7277 | Val Loss: 0.8434\n",
      "Epoch 33 | Train Loss: 0.7274 | Val Loss: 0.7806\n",
      "Epoch 34 | Train Loss: 0.7332 | Val Loss: 0.7342\n",
      "Epoch 35 | Train Loss: 0.7337 | Val Loss: 0.7756\n",
      "Epoch 36 | Train Loss: 0.7166 | Val Loss: 0.7227\n",
      "Epoch 37 | Train Loss: 0.7549 | Val Loss: 0.7587\n",
      "Epoch 38 | Train Loss: 0.7270 | Val Loss: 0.7643\n",
      "Epoch 39 | Train Loss: 0.7296 | Val Loss: 0.7629\n",
      "Epoch 40 | Train Loss: 0.7161 | Val Loss: 0.8114\n",
      "Epoch 41 | Train Loss: 0.7353 | Val Loss: 0.7601\n",
      "Epoch 42 | Train Loss: 0.7567 | Val Loss: 0.7247\n",
      "Epoch 43 | Train Loss: 0.7346 | Val Loss: 0.7291\n",
      "Epoch 44 | Train Loss: 0.7289 | Val Loss: 0.8285\n",
      "Epoch 45 | Train Loss: 0.7257 | Val Loss: 0.7734\n",
      "Epoch 46 | Train Loss: 0.7263 | Val Loss: 0.7158\n",
      "Epoch 47 | Train Loss: 0.7114 | Val Loss: 0.7633\n",
      "Epoch 48 | Train Loss: 0.7367 | Val Loss: 0.7527\n",
      "Epoch 49 | Train Loss: 0.7151 | Val Loss: 0.7571\n",
      "Epoch 50 | Train Loss: 0.7071 | Val Loss: 0.7675\n",
      "Fold 2 ‚ñ∂ AUC: 0.668, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9135 | Val Loss: 0.8619\n",
      "Epoch 02 | Train Loss: 0.8778 | Val Loss: 0.8497\n",
      "Epoch 03 | Train Loss: 0.8607 | Val Loss: 0.8455\n",
      "Epoch 04 | Train Loss: 0.8592 | Val Loss: 0.8304\n",
      "Epoch 05 | Train Loss: 0.8403 | Val Loss: 0.8175\n",
      "Epoch 06 | Train Loss: 0.8445 | Val Loss: 0.7991\n",
      "Epoch 07 | Train Loss: 0.8344 | Val Loss: 0.7959\n",
      "Epoch 08 | Train Loss: 0.8215 | Val Loss: 0.7804\n",
      "Epoch 09 | Train Loss: 0.8643 | Val Loss: 0.7749\n",
      "Epoch 10 | Train Loss: 0.8402 | Val Loss: 0.8409\n",
      "Epoch 11 | Train Loss: 0.8172 | Val Loss: 0.7970\n",
      "Epoch 12 | Train Loss: 0.7810 | Val Loss: 0.7782\n",
      "Epoch 13 | Train Loss: 0.7616 | Val Loss: 0.7718\n",
      "Epoch 14 | Train Loss: 0.7652 | Val Loss: 0.7351\n",
      "Epoch 15 | Train Loss: 0.7465 | Val Loss: 0.7353\n",
      "Epoch 16 | Train Loss: 0.7407 | Val Loss: 0.7370\n",
      "Epoch 17 | Train Loss: 0.7366 | Val Loss: 0.8302\n",
      "Epoch 18 | Train Loss: 0.7469 | Val Loss: 0.7375\n",
      "Epoch 19 | Train Loss: 0.7430 | Val Loss: 0.7274\n",
      "Epoch 20 | Train Loss: 0.7438 | Val Loss: 0.7325\n",
      "Epoch 21 | Train Loss: 0.7562 | Val Loss: 0.7386\n",
      "Epoch 22 | Train Loss: 0.7482 | Val Loss: 0.7279\n",
      "Epoch 23 | Train Loss: 0.7375 | Val Loss: 0.7356\n",
      "Epoch 24 | Train Loss: 0.7553 | Val Loss: 0.7436\n",
      "Epoch 25 | Train Loss: 0.7363 | Val Loss: 0.7394\n",
      "Epoch 26 | Train Loss: 0.7451 | Val Loss: 0.7287\n",
      "Epoch 27 | Train Loss: 0.7254 | Val Loss: 0.7578\n",
      "Epoch 28 | Train Loss: 0.7403 | Val Loss: 0.7589\n",
      "Epoch 29 | Train Loss: 0.7347 | Val Loss: 0.7288\n",
      "Epoch 30 | Train Loss: 0.7387 | Val Loss: 0.7267\n",
      "Epoch 31 | Train Loss: 0.7183 | Val Loss: 0.7199\n",
      "Epoch 32 | Train Loss: 0.7411 | Val Loss: 0.7198\n",
      "Epoch 33 | Train Loss: 0.7349 | Val Loss: 0.7193\n",
      "Epoch 34 | Train Loss: 0.7058 | Val Loss: 0.7180\n",
      "Epoch 35 | Train Loss: 0.7174 | Val Loss: 0.7185\n",
      "Epoch 36 | Train Loss: 0.7324 | Val Loss: 0.7240\n",
      "Epoch 37 | Train Loss: 0.7197 | Val Loss: 0.7727\n",
      "Epoch 38 | Train Loss: 0.7364 | Val Loss: 0.7237\n",
      "Epoch 39 | Train Loss: 0.7248 | Val Loss: 0.7341\n",
      "Epoch 40 | Train Loss: 0.7238 | Val Loss: 0.7362\n",
      "Epoch 41 | Train Loss: 0.7146 | Val Loss: 0.7166\n",
      "Epoch 42 | Train Loss: 0.7115 | Val Loss: 0.7157\n",
      "Epoch 43 | Train Loss: 0.7399 | Val Loss: 0.7176\n",
      "Epoch 44 | Train Loss: 0.7216 | Val Loss: 0.7397\n",
      "Epoch 45 | Train Loss: 0.7187 | Val Loss: 0.7171\n",
      "Epoch 46 | Train Loss: 0.7080 | Val Loss: 0.7191\n",
      "Epoch 47 | Train Loss: 0.7406 | Val Loss: 0.7662\n",
      "Epoch 48 | Train Loss: 0.7200 | Val Loss: 0.7188\n",
      "Epoch 49 | Train Loss: 0.7203 | Val Loss: 0.7355\n",
      "Epoch 50 | Train Loss: 0.7169 | Val Loss: 0.7144\n",
      "Fold 3 ‚ñ∂ AUC: 0.775, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9745 | Val Loss: 0.8654\n",
      "Epoch 02 | Train Loss: 0.8929 | Val Loss: 0.8524\n",
      "Epoch 03 | Train Loss: 0.8667 | Val Loss: 0.8428\n",
      "Epoch 04 | Train Loss: 0.8526 | Val Loss: 0.8280\n",
      "Epoch 05 | Train Loss: 0.8508 | Val Loss: 0.8172\n",
      "Epoch 06 | Train Loss: 0.8336 | Val Loss: 0.8186\n",
      "Epoch 07 | Train Loss: 0.8423 | Val Loss: 0.7883\n",
      "Epoch 08 | Train Loss: 0.8364 | Val Loss: 0.8026\n",
      "Epoch 09 | Train Loss: 0.8146 | Val Loss: 0.7750\n",
      "Epoch 10 | Train Loss: 0.7795 | Val Loss: 0.7564\n",
      "Epoch 11 | Train Loss: 0.7905 | Val Loss: 0.7449\n",
      "Epoch 12 | Train Loss: 0.7802 | Val Loss: 0.7330\n",
      "Epoch 13 | Train Loss: 0.7781 | Val Loss: 0.7138\n",
      "Epoch 14 | Train Loss: 0.7471 | Val Loss: 0.7181\n",
      "Epoch 15 | Train Loss: 0.7737 | Val Loss: 0.7073\n",
      "Epoch 16 | Train Loss: 0.8017 | Val Loss: 0.7605\n",
      "Epoch 17 | Train Loss: 0.7868 | Val Loss: 0.7643\n",
      "Epoch 18 | Train Loss: 0.7933 | Val Loss: 0.7079\n",
      "Epoch 19 | Train Loss: 0.7639 | Val Loss: 0.6946\n",
      "Epoch 20 | Train Loss: 0.7328 | Val Loss: 0.6859\n",
      "Epoch 21 | Train Loss: 0.7350 | Val Loss: 0.6813\n",
      "Epoch 22 | Train Loss: 0.7706 | Val Loss: 0.7284\n",
      "Epoch 23 | Train Loss: 0.7580 | Val Loss: 0.7106\n",
      "Epoch 24 | Train Loss: 0.7538 | Val Loss: 0.6778\n",
      "Epoch 25 | Train Loss: 0.7333 | Val Loss: 0.6718\n",
      "Epoch 26 | Train Loss: 0.7232 | Val Loss: 0.6785\n",
      "Epoch 27 | Train Loss: 0.7329 | Val Loss: 0.6763\n",
      "Epoch 28 | Train Loss: 0.7209 | Val Loss: 0.6800\n",
      "Epoch 29 | Train Loss: 0.7378 | Val Loss: 0.6703\n",
      "Epoch 30 | Train Loss: 0.7278 | Val Loss: 0.6715\n",
      "Epoch 31 | Train Loss: 0.7174 | Val Loss: 0.6762\n",
      "Epoch 32 | Train Loss: 0.7384 | Val Loss: 0.6648\n",
      "Epoch 33 | Train Loss: 0.7246 | Val Loss: 0.6779\n",
      "Epoch 34 | Train Loss: 0.7207 | Val Loss: 0.6728\n",
      "Epoch 35 | Train Loss: 0.7129 | Val Loss: 0.6639\n",
      "Epoch 36 | Train Loss: 0.7214 | Val Loss: 0.6784\n",
      "Epoch 37 | Train Loss: 0.7268 | Val Loss: 0.6784\n",
      "Epoch 38 | Train Loss: 0.7280 | Val Loss: 0.7054\n",
      "Epoch 39 | Train Loss: 0.7514 | Val Loss: 0.6829\n",
      "Epoch 40 | Train Loss: 0.7110 | Val Loss: 0.6937\n",
      "Epoch 41 | Train Loss: 0.7031 | Val Loss: 0.6713\n",
      "Epoch 42 | Train Loss: 0.7121 | Val Loss: 0.6695\n",
      "Epoch 43 | Train Loss: 0.7083 | Val Loss: 0.6717\n",
      "Epoch 44 | Train Loss: 0.7028 | Val Loss: 0.6830\n",
      "Epoch 45 | Train Loss: 0.7192 | Val Loss: 0.6763\n",
      "Epoch 46 | Train Loss: 0.7071 | Val Loss: 0.6753\n",
      "Epoch 47 | Train Loss: 0.7121 | Val Loss: 0.7002\n",
      "Epoch 48 | Train Loss: 0.7151 | Val Loss: 0.6748\n",
      "Epoch 49 | Train Loss: 0.7013 | Val Loss: 0.6966\n",
      "Epoch 50 | Train Loss: 0.7187 | Val Loss: 0.6927\n",
      "Fold 4 ‚ñ∂ AUC: 0.765, Balanced Acc: 0.524\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9168 | Val Loss: 0.9219\n",
      "Epoch 02 | Train Loss: 0.8766 | Val Loss: 0.9005\n",
      "Epoch 03 | Train Loss: 0.8690 | Val Loss: 0.8979\n",
      "Epoch 04 | Train Loss: 0.8516 | Val Loss: 0.8745\n",
      "Epoch 05 | Train Loss: 0.8328 | Val Loss: 0.8632\n",
      "Epoch 06 | Train Loss: 0.8342 | Val Loss: 0.8689\n",
      "Epoch 07 | Train Loss: 0.8191 | Val Loss: 0.8593\n",
      "Epoch 08 | Train Loss: 0.8083 | Val Loss: 0.8511\n",
      "Epoch 09 | Train Loss: 0.8099 | Val Loss: 0.8268\n",
      "Epoch 10 | Train Loss: 0.7919 | Val Loss: 0.8267\n",
      "Epoch 11 | Train Loss: 0.7651 | Val Loss: 0.8649\n",
      "Epoch 12 | Train Loss: 0.7650 | Val Loss: 0.8085\n",
      "Epoch 13 | Train Loss: 0.7447 | Val Loss: 0.7940\n",
      "Epoch 14 | Train Loss: 0.7548 | Val Loss: 0.8458\n",
      "Epoch 15 | Train Loss: 0.7524 | Val Loss: 0.7875\n",
      "Epoch 16 | Train Loss: 0.7512 | Val Loss: 0.7907\n",
      "Epoch 17 | Train Loss: 0.7337 | Val Loss: 0.7968\n",
      "Epoch 18 | Train Loss: 0.7425 | Val Loss: 0.8100\n",
      "Epoch 19 | Train Loss: 0.7679 | Val Loss: 0.7904\n",
      "Epoch 20 | Train Loss: 0.7515 | Val Loss: 0.8108\n",
      "Epoch 21 | Train Loss: 0.7340 | Val Loss: 0.7852\n",
      "Epoch 22 | Train Loss: 0.7331 | Val Loss: 0.7824\n",
      "Epoch 23 | Train Loss: 0.7062 | Val Loss: 0.7839\n",
      "Epoch 24 | Train Loss: 0.7347 | Val Loss: 0.7948\n",
      "Epoch 25 | Train Loss: 0.7202 | Val Loss: 0.7932\n",
      "Epoch 26 | Train Loss: 0.7412 | Val Loss: 0.7797\n",
      "Epoch 27 | Train Loss: 0.7392 | Val Loss: 0.7883\n",
      "Epoch 28 | Train Loss: 0.7378 | Val Loss: 0.7756\n",
      "Epoch 29 | Train Loss: 0.7243 | Val Loss: 0.8025\n",
      "Epoch 30 | Train Loss: 0.7231 | Val Loss: 0.7902\n",
      "Epoch 31 | Train Loss: 0.7096 | Val Loss: 0.7798\n",
      "Epoch 32 | Train Loss: 0.7209 | Val Loss: 0.8205\n",
      "Epoch 33 | Train Loss: 0.7384 | Val Loss: 0.7877\n",
      "Epoch 34 | Train Loss: 0.7149 | Val Loss: 0.7857\n",
      "Epoch 35 | Train Loss: 0.7095 | Val Loss: 0.7845\n",
      "Epoch 36 | Train Loss: 0.7236 | Val Loss: 0.7829\n",
      "Epoch 37 | Train Loss: 0.7086 | Val Loss: 0.7836\n",
      "Epoch 38 | Train Loss: 0.7063 | Val Loss: 0.8362\n",
      "Epoch 39 | Train Loss: 0.7616 | Val Loss: 0.8218\n",
      "Epoch 40 | Train Loss: 0.7284 | Val Loss: 0.7909\n",
      "Epoch 41 | Train Loss: 0.7218 | Val Loss: 0.7840\n",
      "Epoch 42 | Train Loss: 0.7041 | Val Loss: 0.7908\n",
      "Epoch 43 | Train Loss: 0.7075 | Val Loss: 0.7816\n",
      "Epoch 44 | Train Loss: 0.7084 | Val Loss: 0.7956\n",
      "Epoch 45 | Train Loss: 0.7320 | Val Loss: 0.8341\n",
      "Epoch 46 | Train Loss: 0.7381 | Val Loss: 0.7868\n",
      "Epoch 47 | Train Loss: 0.7201 | Val Loss: 0.8210\n",
      "Epoch 48 | Train Loss: 0.7004 | Val Loss: 0.7888\n",
      "Epoch 49 | Train Loss: 0.7063 | Val Loss: 0.7901\n",
      "Epoch 50 | Train Loss: 0.7277 | Val Loss: 0.7779\n",
      "Fold 5 ‚ñ∂ AUC: 0.749, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9498 | Val Loss: 0.9492\n",
      "Epoch 02 | Train Loss: 0.8888 | Val Loss: 0.8919\n",
      "Epoch 03 | Train Loss: 0.8582 | Val Loss: 0.8890\n",
      "Epoch 04 | Train Loss: 0.8530 | Val Loss: 0.8825\n",
      "Epoch 05 | Train Loss: 0.8487 | Val Loss: 0.8921\n",
      "Epoch 06 | Train Loss: 0.8479 | Val Loss: 0.8744\n",
      "Epoch 07 | Train Loss: 0.8524 | Val Loss: 0.9040\n",
      "Epoch 08 | Train Loss: 0.8442 | Val Loss: 0.8662\n",
      "Epoch 09 | Train Loss: 0.8417 | Val Loss: 0.8824\n",
      "Epoch 10 | Train Loss: 0.8240 | Val Loss: 0.8640\n",
      "Epoch 11 | Train Loss: 0.7972 | Val Loss: 0.8470\n",
      "Epoch 12 | Train Loss: 0.7867 | Val Loss: 0.8655\n",
      "Epoch 13 | Train Loss: 0.8101 | Val Loss: 0.8531\n",
      "Epoch 14 | Train Loss: 0.7794 | Val Loss: 0.8274\n",
      "Epoch 15 | Train Loss: 0.7614 | Val Loss: 0.8319\n",
      "Epoch 16 | Train Loss: 0.7578 | Val Loss: 0.8174\n",
      "Epoch 17 | Train Loss: 0.7507 | Val Loss: 0.8298\n",
      "Epoch 18 | Train Loss: 0.7519 | Val Loss: 0.8360\n",
      "Epoch 19 | Train Loss: 0.7502 | Val Loss: 0.8144\n",
      "Epoch 20 | Train Loss: 0.7424 | Val Loss: 0.8160\n",
      "Epoch 21 | Train Loss: 0.7266 | Val Loss: 0.8092\n",
      "Epoch 22 | Train Loss: 0.7190 | Val Loss: 0.8267\n",
      "Epoch 23 | Train Loss: 0.7219 | Val Loss: 0.8139\n",
      "Epoch 24 | Train Loss: 0.7294 | Val Loss: 0.8124\n",
      "Epoch 25 | Train Loss: 0.7156 | Val Loss: 0.8180\n",
      "Epoch 26 | Train Loss: 0.7160 | Val Loss: 0.8196\n",
      "Epoch 27 | Train Loss: 0.7241 | Val Loss: 0.8192\n",
      "Epoch 28 | Train Loss: 0.7349 | Val Loss: 0.8096\n",
      "Epoch 29 | Train Loss: 0.7202 | Val Loss: 0.8203\n",
      "Epoch 30 | Train Loss: 0.7337 | Val Loss: 0.8223\n",
      "Epoch 31 | Train Loss: 0.7309 | Val Loss: 0.8156\n",
      "Epoch 32 | Train Loss: 0.7283 | Val Loss: 0.8146\n",
      "Epoch 33 | Train Loss: 0.7058 | Val Loss: 0.8119\n",
      "Epoch 34 | Train Loss: 0.7292 | Val Loss: 0.8157\n",
      "Epoch 35 | Train Loss: 0.7073 | Val Loss: 0.8102\n",
      "Epoch 36 | Train Loss: 0.7042 | Val Loss: 0.8104\n",
      "Epoch 37 | Train Loss: 0.7133 | Val Loss: 0.8144\n",
      "Epoch 38 | Train Loss: 0.7136 | Val Loss: 0.8059\n",
      "Epoch 39 | Train Loss: 0.7254 | Val Loss: 0.8508\n",
      "Epoch 40 | Train Loss: 0.7241 | Val Loss: 0.8401\n",
      "Epoch 41 | Train Loss: 0.7327 | Val Loss: 0.8052\n",
      "Epoch 42 | Train Loss: 0.7104 | Val Loss: 0.8199\n",
      "Epoch 43 | Train Loss: 0.6912 | Val Loss: 0.8115\n",
      "Epoch 44 | Train Loss: 0.6954 | Val Loss: 0.8199\n",
      "Epoch 45 | Train Loss: 0.7046 | Val Loss: 0.8038\n",
      "Epoch 46 | Train Loss: 0.7037 | Val Loss: 0.8276\n",
      "Epoch 47 | Train Loss: 0.7007 | Val Loss: 0.8187\n",
      "Epoch 48 | Train Loss: 0.6926 | Val Loss: 0.8049\n",
      "Epoch 49 | Train Loss: 0.7136 | Val Loss: 0.8190\n",
      "Epoch 50 | Train Loss: 0.7333 | Val Loss: 0.8128\n",
      "Fold 6 ‚ñ∂ AUC: 0.729, Balanced Acc: 0.491\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9162 | Val Loss: 0.8471\n",
      "Epoch 02 | Train Loss: 0.8607 | Val Loss: 0.8370\n",
      "Epoch 03 | Train Loss: 0.8528 | Val Loss: 0.8390\n",
      "Epoch 04 | Train Loss: 0.8655 | Val Loss: 0.8124\n",
      "Epoch 05 | Train Loss: 0.8261 | Val Loss: 0.8163\n",
      "Epoch 06 | Train Loss: 0.8043 | Val Loss: 0.7793\n",
      "Epoch 07 | Train Loss: 0.8071 | Val Loss: 0.7571\n",
      "Epoch 08 | Train Loss: 0.8250 | Val Loss: 0.7434\n",
      "Epoch 09 | Train Loss: 0.7914 | Val Loss: 0.7581\n",
      "Epoch 10 | Train Loss: 0.7799 | Val Loss: 0.7677\n",
      "Epoch 11 | Train Loss: 0.7945 | Val Loss: 0.7595\n",
      "Epoch 12 | Train Loss: 0.7763 | Val Loss: 0.7274\n",
      "Epoch 13 | Train Loss: 0.7600 | Val Loss: 0.7151\n",
      "Epoch 14 | Train Loss: 0.7528 | Val Loss: 0.7073\n",
      "Epoch 15 | Train Loss: 0.7582 | Val Loss: 0.7145\n",
      "Epoch 16 | Train Loss: 0.7327 | Val Loss: 0.7262\n",
      "Epoch 17 | Train Loss: 0.7364 | Val Loss: 0.7300\n",
      "Epoch 18 | Train Loss: 0.7447 | Val Loss: 0.7366\n",
      "Epoch 19 | Train Loss: 0.7324 | Val Loss: 0.7230\n",
      "Epoch 20 | Train Loss: 0.7334 | Val Loss: 0.7282\n",
      "Epoch 21 | Train Loss: 0.7383 | Val Loss: 0.7219\n",
      "Epoch 22 | Train Loss: 0.7259 | Val Loss: 0.7361\n",
      "Epoch 23 | Train Loss: 0.7380 | Val Loss: 0.7344\n",
      "Epoch 24 | Train Loss: 0.7563 | Val Loss: 0.7321\n",
      "Epoch 25 | Train Loss: 0.7378 | Val Loss: 0.7170\n",
      "Epoch 26 | Train Loss: 0.7178 | Val Loss: 0.7386\n",
      "Epoch 27 | Train Loss: 0.7371 | Val Loss: 0.7198\n",
      "Epoch 28 | Train Loss: 0.7528 | Val Loss: 0.7375\n",
      "Epoch 29 | Train Loss: 0.7258 | Val Loss: 0.7231\n",
      "Epoch 30 | Train Loss: 0.7320 | Val Loss: 0.7302\n",
      "Epoch 31 | Train Loss: 0.7215 | Val Loss: 0.7237\n",
      "Epoch 32 | Train Loss: 0.7081 | Val Loss: 0.7264\n",
      "Epoch 33 | Train Loss: 0.7236 | Val Loss: 0.7273\n",
      "Epoch 34 | Train Loss: 0.7212 | Val Loss: 0.8096\n",
      "Epoch 35 | Train Loss: 0.7322 | Val Loss: 0.7266\n",
      "Epoch 36 | Train Loss: 0.7242 | Val Loss: 0.7246\n",
      "Epoch 37 | Train Loss: 0.7109 | Val Loss: 0.7469\n",
      "Epoch 38 | Train Loss: 0.7278 | Val Loss: 0.7334\n",
      "Epoch 39 | Train Loss: 0.7136 | Val Loss: 0.7392\n",
      "Epoch 40 | Train Loss: 0.7285 | Val Loss: 0.7382\n",
      "Epoch 41 | Train Loss: 0.7018 | Val Loss: 0.7297\n",
      "Epoch 42 | Train Loss: 0.7181 | Val Loss: 0.7371\n",
      "Epoch 43 | Train Loss: 0.7014 | Val Loss: 0.7450\n",
      "Epoch 44 | Train Loss: 0.7291 | Val Loss: 0.7573\n",
      "Epoch 45 | Train Loss: 0.6914 | Val Loss: 0.7666\n",
      "Epoch 46 | Train Loss: 0.7058 | Val Loss: 0.7693\n",
      "Epoch 47 | Train Loss: 0.7054 | Val Loss: 0.7314\n",
      "Epoch 48 | Train Loss: 0.6949 | Val Loss: 0.7311\n",
      "Epoch 49 | Train Loss: 0.7109 | Val Loss: 0.7511\n",
      "Epoch 50 | Train Loss: 0.6886 | Val Loss: 0.7514\n",
      "Fold 7 ‚ñ∂ AUC: 0.733, Balanced Acc: 0.491\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9488 | Val Loss: 0.8698\n",
      "Epoch 02 | Train Loss: 0.8674 | Val Loss: 0.8633\n",
      "Epoch 03 | Train Loss: 0.8635 | Val Loss: 0.8530\n",
      "Epoch 04 | Train Loss: 0.8468 | Val Loss: 0.8647\n",
      "Epoch 05 | Train Loss: 0.8350 | Val Loss: 0.8461\n",
      "Epoch 06 | Train Loss: 0.8273 | Val Loss: 0.8212\n",
      "Epoch 07 | Train Loss: 0.8253 | Val Loss: 0.8370\n",
      "Epoch 08 | Train Loss: 0.8188 | Val Loss: 0.8106\n",
      "Epoch 09 | Train Loss: 0.7959 | Val Loss: 0.7970\n",
      "Epoch 10 | Train Loss: 0.7648 | Val Loss: 0.7936\n",
      "Epoch 11 | Train Loss: 0.7645 | Val Loss: 0.8124\n",
      "Epoch 12 | Train Loss: 0.7582 | Val Loss: 0.7969\n",
      "Epoch 13 | Train Loss: 0.7650 | Val Loss: 0.8302\n",
      "Epoch 14 | Train Loss: 0.7582 | Val Loss: 0.7970\n",
      "Epoch 15 | Train Loss: 0.7372 | Val Loss: 0.7936\n",
      "Epoch 16 | Train Loss: 0.7177 | Val Loss: 0.8220\n",
      "Epoch 17 | Train Loss: 0.7114 | Val Loss: 0.8321\n",
      "Epoch 18 | Train Loss: 0.7225 | Val Loss: 0.8126\n",
      "Epoch 19 | Train Loss: 0.7051 | Val Loss: 0.8127\n",
      "Epoch 20 | Train Loss: 0.7064 | Val Loss: 0.8439\n",
      "Epoch 21 | Train Loss: 0.7112 | Val Loss: 0.8235\n",
      "Epoch 22 | Train Loss: 0.7148 | Val Loss: 0.8140\n",
      "Epoch 23 | Train Loss: 0.7204 | Val Loss: 0.8400\n",
      "Epoch 24 | Train Loss: 0.7046 | Val Loss: 0.8782\n",
      "Epoch 25 | Train Loss: 0.7424 | Val Loss: 0.8784\n",
      "Epoch 26 | Train Loss: 0.7606 | Val Loss: 0.8512\n",
      "Epoch 27 | Train Loss: 0.7259 | Val Loss: 0.7999\n",
      "Epoch 28 | Train Loss: 0.6811 | Val Loss: 0.8673\n",
      "Epoch 29 | Train Loss: 0.7239 | Val Loss: 0.8196\n",
      "Epoch 30 | Train Loss: 0.7218 | Val Loss: 0.8415\n",
      "Epoch 31 | Train Loss: 0.7038 | Val Loss: 0.8214\n",
      "Epoch 32 | Train Loss: 0.7004 | Val Loss: 0.8165\n",
      "Epoch 33 | Train Loss: 0.7042 | Val Loss: 0.8072\n",
      "Epoch 34 | Train Loss: 0.7152 | Val Loss: 0.8133\n",
      "Epoch 35 | Train Loss: 0.7151 | Val Loss: 0.8051\n",
      "Epoch 36 | Train Loss: 0.6758 | Val Loss: 0.8385\n",
      "Epoch 37 | Train Loss: 0.7114 | Val Loss: 0.8398\n",
      "Epoch 38 | Train Loss: 0.6801 | Val Loss: 0.8189\n",
      "Epoch 39 | Train Loss: 0.6882 | Val Loss: 0.8418\n",
      "Epoch 40 | Train Loss: 0.7368 | Val Loss: 0.8192\n",
      "Epoch 41 | Train Loss: 0.7203 | Val Loss: 0.8118\n",
      "Epoch 42 | Train Loss: 0.7328 | Val Loss: 0.8412\n",
      "Epoch 43 | Train Loss: 0.7039 | Val Loss: 0.8234\n",
      "Epoch 44 | Train Loss: 0.6956 | Val Loss: 0.8069\n",
      "Epoch 45 | Train Loss: 0.7086 | Val Loss: 0.8455\n",
      "Epoch 46 | Train Loss: 0.7147 | Val Loss: 0.8012\n",
      "Epoch 47 | Train Loss: 0.7099 | Val Loss: 0.8019\n",
      "Epoch 48 | Train Loss: 0.6911 | Val Loss: 0.8222\n",
      "Epoch 49 | Train Loss: 0.7115 | Val Loss: 0.8476\n",
      "Epoch 50 | Train Loss: 0.6965 | Val Loss: 0.8193\n",
      "Fold 8 ‚ñ∂ AUC: 0.720, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9182 | Val Loss: 0.8747\n",
      "Epoch 02 | Train Loss: 0.8710 | Val Loss: 0.8981\n",
      "Epoch 03 | Train Loss: 0.8734 | Val Loss: 0.8627\n",
      "Epoch 04 | Train Loss: 0.8400 | Val Loss: 0.8561\n",
      "Epoch 05 | Train Loss: 0.8379 | Val Loss: 0.8445\n",
      "Epoch 06 | Train Loss: 0.8116 | Val Loss: 0.8351\n",
      "Epoch 07 | Train Loss: 0.7919 | Val Loss: 0.8302\n",
      "Epoch 08 | Train Loss: 0.7698 | Val Loss: 0.8313\n",
      "Epoch 09 | Train Loss: 0.7879 | Val Loss: 0.8558\n",
      "Epoch 10 | Train Loss: 0.7808 | Val Loss: 0.9267\n",
      "Epoch 11 | Train Loss: 0.7897 | Val Loss: 0.8073\n",
      "Epoch 12 | Train Loss: 0.7955 | Val Loss: 0.8093\n",
      "Epoch 13 | Train Loss: 0.7967 | Val Loss: 0.8036\n",
      "Epoch 14 | Train Loss: 0.7598 | Val Loss: 0.8022\n",
      "Epoch 15 | Train Loss: 0.7616 | Val Loss: 0.7905\n",
      "Epoch 16 | Train Loss: 0.7326 | Val Loss: 0.7881\n",
      "Epoch 17 | Train Loss: 0.7409 | Val Loss: 0.8240\n",
      "Epoch 18 | Train Loss: 0.7627 | Val Loss: 0.8613\n",
      "Epoch 19 | Train Loss: 0.7745 | Val Loss: 0.8068\n",
      "Epoch 20 | Train Loss: 0.7593 | Val Loss: 0.7843\n",
      "Epoch 21 | Train Loss: 0.7312 | Val Loss: 0.7891\n",
      "Epoch 22 | Train Loss: 0.7462 | Val Loss: 0.8978\n",
      "Epoch 23 | Train Loss: 0.7499 | Val Loss: 0.7651\n",
      "Epoch 24 | Train Loss: 0.7284 | Val Loss: 0.7852\n",
      "Epoch 25 | Train Loss: 0.7387 | Val Loss: 0.8438\n",
      "Epoch 26 | Train Loss: 0.7445 | Val Loss: 0.7660\n",
      "Epoch 27 | Train Loss: 0.7302 | Val Loss: 0.7744\n",
      "Epoch 28 | Train Loss: 0.7288 | Val Loss: 0.7775\n",
      "Epoch 29 | Train Loss: 0.7480 | Val Loss: 0.7820\n",
      "Epoch 30 | Train Loss: 0.7260 | Val Loss: 0.7875\n",
      "Epoch 31 | Train Loss: 0.7174 | Val Loss: 0.7752\n",
      "Epoch 32 | Train Loss: 0.7249 | Val Loss: 0.8481\n",
      "Epoch 33 | Train Loss: 0.7566 | Val Loss: 0.7547\n",
      "Epoch 34 | Train Loss: 0.7234 | Val Loss: 0.7682\n",
      "Epoch 35 | Train Loss: 0.7724 | Val Loss: 0.7505\n",
      "Epoch 36 | Train Loss: 0.7531 | Val Loss: 0.7899\n",
      "Epoch 37 | Train Loss: 0.7209 | Val Loss: 0.7721\n",
      "Epoch 38 | Train Loss: 0.7204 | Val Loss: 0.7486\n",
      "Epoch 39 | Train Loss: 0.7095 | Val Loss: 0.7818\n",
      "Epoch 40 | Train Loss: 0.7316 | Val Loss: 0.7560\n",
      "Epoch 41 | Train Loss: 0.7233 | Val Loss: 0.7476\n",
      "Epoch 42 | Train Loss: 0.7341 | Val Loss: 0.7770\n",
      "Epoch 43 | Train Loss: 0.7076 | Val Loss: 0.7535\n",
      "Epoch 44 | Train Loss: 0.7476 | Val Loss: 0.7930\n",
      "Epoch 45 | Train Loss: 0.7229 | Val Loss: 0.7455\n",
      "Epoch 46 | Train Loss: 0.7258 | Val Loss: 0.7739\n",
      "Epoch 47 | Train Loss: 0.6967 | Val Loss: 0.7482\n",
      "Epoch 48 | Train Loss: 0.7118 | Val Loss: 0.7442\n",
      "Epoch 49 | Train Loss: 0.7134 | Val Loss: 0.7772\n",
      "Epoch 50 | Train Loss: 0.7022 | Val Loss: 0.7783\n",
      "Fold 9 ‚ñ∂ AUC: 0.763, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9413 | Val Loss: 0.8690\n",
      "Epoch 02 | Train Loss: 0.8821 | Val Loss: 0.8554\n",
      "Epoch 03 | Train Loss: 0.8636 | Val Loss: 0.8446\n",
      "Epoch 04 | Train Loss: 0.8471 | Val Loss: 0.8800\n",
      "Epoch 05 | Train Loss: 0.8494 | Val Loss: 0.8573\n",
      "Epoch 06 | Train Loss: 0.8273 | Val Loss: 0.8336\n",
      "Epoch 07 | Train Loss: 0.8136 | Val Loss: 0.8041\n",
      "Epoch 08 | Train Loss: 0.7957 | Val Loss: 0.7798\n",
      "Epoch 09 | Train Loss: 0.7786 | Val Loss: 0.7638\n",
      "Epoch 10 | Train Loss: 0.7651 | Val Loss: 0.7595\n",
      "Epoch 11 | Train Loss: 0.7500 | Val Loss: 0.8365\n",
      "Epoch 12 | Train Loss: 0.7583 | Val Loss: 0.7485\n",
      "Epoch 13 | Train Loss: 0.7392 | Val Loss: 0.7445\n",
      "Epoch 14 | Train Loss: 0.7527 | Val Loss: 0.7552\n",
      "Epoch 15 | Train Loss: 0.7460 | Val Loss: 0.7712\n",
      "Epoch 16 | Train Loss: 0.7310 | Val Loss: 0.8003\n",
      "Epoch 17 | Train Loss: 0.7312 | Val Loss: 0.7541\n",
      "Epoch 18 | Train Loss: 0.7250 | Val Loss: 0.7594\n",
      "Epoch 19 | Train Loss: 0.7227 | Val Loss: 0.7742\n",
      "Epoch 20 | Train Loss: 0.7316 | Val Loss: 0.7871\n",
      "Epoch 21 | Train Loss: 0.7184 | Val Loss: 0.8007\n",
      "Epoch 22 | Train Loss: 0.7111 | Val Loss: 0.8161\n",
      "Epoch 23 | Train Loss: 0.7239 | Val Loss: 0.7573\n",
      "Epoch 24 | Train Loss: 0.7301 | Val Loss: 0.7857\n",
      "Epoch 25 | Train Loss: 0.7091 | Val Loss: 0.7679\n",
      "Epoch 26 | Train Loss: 0.7200 | Val Loss: 0.7676\n",
      "Epoch 27 | Train Loss: 0.7001 | Val Loss: 0.8383\n",
      "Epoch 28 | Train Loss: 0.7093 | Val Loss: 0.7661\n",
      "Epoch 29 | Train Loss: 0.7005 | Val Loss: 0.7683\n",
      "Epoch 30 | Train Loss: 0.7052 | Val Loss: 0.7698\n",
      "Epoch 31 | Train Loss: 0.7227 | Val Loss: 0.7982\n",
      "Epoch 32 | Train Loss: 0.7207 | Val Loss: 0.7725\n",
      "Epoch 33 | Train Loss: 0.7012 | Val Loss: 0.7896\n",
      "Epoch 34 | Train Loss: 0.7274 | Val Loss: 0.8065\n",
      "Epoch 35 | Train Loss: 0.6994 | Val Loss: 0.7858\n",
      "Epoch 36 | Train Loss: 0.6961 | Val Loss: 0.8242\n",
      "Epoch 37 | Train Loss: 0.7234 | Val Loss: 0.8073\n",
      "Epoch 38 | Train Loss: 0.7004 | Val Loss: 0.7703\n",
      "Epoch 39 | Train Loss: 0.6936 | Val Loss: 0.7885\n",
      "Epoch 40 | Train Loss: 0.7028 | Val Loss: 0.7678\n",
      "Epoch 41 | Train Loss: 0.6839 | Val Loss: 0.7891\n",
      "Epoch 42 | Train Loss: 0.7202 | Val Loss: 0.8485\n",
      "Epoch 43 | Train Loss: 0.6970 | Val Loss: 0.7759\n",
      "Epoch 44 | Train Loss: 0.6812 | Val Loss: 0.7799\n",
      "Epoch 45 | Train Loss: 0.6948 | Val Loss: 0.7709\n",
      "Epoch 46 | Train Loss: 0.7072 | Val Loss: 0.7692\n",
      "Epoch 47 | Train Loss: 0.7103 | Val Loss: 0.7972\n",
      "Epoch 48 | Train Loss: 0.6943 | Val Loss: 0.8033\n",
      "Epoch 49 | Train Loss: 0.7320 | Val Loss: 0.8059\n",
      "Epoch 50 | Train Loss: 0.7208 | Val Loss: 0.7900\n",
      "Fold 10 ‚ñ∂ AUC: 0.724, Balanced Acc: 0.451\n",
      "üîç Summary for hd=128, dp=0.0, lr=0.0005 ‚Üí AUC: 0.7407¬±0.0318 | BalAcc: 0.4818¬±0.0411\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.0, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 1.0629 | Val Loss: 0.9167\n",
      "Epoch 02 | Train Loss: 0.8834 | Val Loss: 0.8591\n",
      "Epoch 03 | Train Loss: 0.8870 | Val Loss: 0.8549\n",
      "Epoch 04 | Train Loss: 0.8615 | Val Loss: 0.8513\n",
      "Epoch 05 | Train Loss: 0.8637 | Val Loss: 0.8494\n",
      "Epoch 06 | Train Loss: 0.8706 | Val Loss: 0.8490\n",
      "Epoch 07 | Train Loss: 0.8617 | Val Loss: 0.8485\n",
      "Epoch 08 | Train Loss: 0.8502 | Val Loss: 0.8466\n",
      "Epoch 09 | Train Loss: 0.8572 | Val Loss: 0.8424\n",
      "Epoch 10 | Train Loss: 0.8582 | Val Loss: 0.8414\n",
      "Epoch 11 | Train Loss: 0.8545 | Val Loss: 0.8390\n",
      "Epoch 12 | Train Loss: 0.8506 | Val Loss: 0.8364\n",
      "Epoch 13 | Train Loss: 0.8464 | Val Loss: 0.8335\n",
      "Epoch 14 | Train Loss: 0.8370 | Val Loss: 0.8314\n",
      "Epoch 15 | Train Loss: 0.8401 | Val Loss: 0.8271\n",
      "Epoch 16 | Train Loss: 0.8478 | Val Loss: 0.8271\n",
      "Epoch 17 | Train Loss: 0.8330 | Val Loss: 0.8221\n",
      "Epoch 18 | Train Loss: 0.8291 | Val Loss: 0.8198\n",
      "Epoch 19 | Train Loss: 0.8280 | Val Loss: 0.8181\n",
      "Epoch 20 | Train Loss: 0.8211 | Val Loss: 0.8154\n",
      "Epoch 21 | Train Loss: 0.8338 | Val Loss: 0.8121\n",
      "Epoch 22 | Train Loss: 0.8141 | Val Loss: 0.8056\n",
      "Epoch 23 | Train Loss: 0.8295 | Val Loss: 0.8064\n",
      "Epoch 24 | Train Loss: 0.8048 | Val Loss: 0.7986\n",
      "Epoch 25 | Train Loss: 0.8149 | Val Loss: 0.7973\n",
      "Epoch 26 | Train Loss: 0.8209 | Val Loss: 0.7933\n",
      "Epoch 27 | Train Loss: 0.7972 | Val Loss: 0.7890\n",
      "Epoch 28 | Train Loss: 0.8064 | Val Loss: 0.7859\n",
      "Epoch 29 | Train Loss: 0.7960 | Val Loss: 0.7813\n",
      "Epoch 30 | Train Loss: 0.7959 | Val Loss: 0.7761\n",
      "Epoch 31 | Train Loss: 0.7896 | Val Loss: 0.7749\n",
      "Epoch 32 | Train Loss: 0.7772 | Val Loss: 0.7671\n",
      "Epoch 33 | Train Loss: 0.7876 | Val Loss: 0.7626\n",
      "Epoch 34 | Train Loss: 0.7763 | Val Loss: 0.7591\n",
      "Epoch 35 | Train Loss: 0.7731 | Val Loss: 0.7557\n",
      "Epoch 36 | Train Loss: 0.7668 | Val Loss: 0.7566\n",
      "Epoch 37 | Train Loss: 0.7679 | Val Loss: 0.7433\n",
      "Epoch 38 | Train Loss: 0.7651 | Val Loss: 0.7379\n",
      "Epoch 39 | Train Loss: 0.7486 | Val Loss: 0.7336\n",
      "Epoch 40 | Train Loss: 0.7672 | Val Loss: 0.7285\n",
      "Epoch 41 | Train Loss: 0.7557 | Val Loss: 0.7323\n",
      "Epoch 42 | Train Loss: 0.7646 | Val Loss: 0.7354\n",
      "Epoch 43 | Train Loss: 0.7458 | Val Loss: 0.7185\n",
      "Epoch 44 | Train Loss: 0.7555 | Val Loss: 0.7199\n",
      "Epoch 45 | Train Loss: 0.7365 | Val Loss: 0.7141\n",
      "Epoch 46 | Train Loss: 0.7652 | Val Loss: 0.7134\n",
      "Epoch 47 | Train Loss: 0.7534 | Val Loss: 0.7123\n",
      "Epoch 48 | Train Loss: 0.7399 | Val Loss: 0.7112\n",
      "Epoch 49 | Train Loss: 0.7673 | Val Loss: 0.7044\n",
      "Epoch 50 | Train Loss: 0.7507 | Val Loss: 0.7150\n",
      "Fold 1 ‚ñ∂ AUC: 0.775, Balanced Acc: 0.496\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9831 | Val Loss: 0.8820\n",
      "Epoch 02 | Train Loss: 0.8720 | Val Loss: 0.8642\n",
      "Epoch 03 | Train Loss: 0.8824 | Val Loss: 0.8620\n",
      "Epoch 04 | Train Loss: 0.8723 | Val Loss: 0.8586\n",
      "Epoch 05 | Train Loss: 0.8592 | Val Loss: 0.8559\n",
      "Epoch 06 | Train Loss: 0.8629 | Val Loss: 0.8538\n",
      "Epoch 07 | Train Loss: 0.8527 | Val Loss: 0.8512\n",
      "Epoch 08 | Train Loss: 0.8685 | Val Loss: 0.8493\n",
      "Epoch 09 | Train Loss: 0.8656 | Val Loss: 0.8473\n",
      "Epoch 10 | Train Loss: 0.8528 | Val Loss: 0.8454\n",
      "Epoch 11 | Train Loss: 0.8436 | Val Loss: 0.8427\n",
      "Epoch 12 | Train Loss: 0.8447 | Val Loss: 0.8405\n",
      "Epoch 13 | Train Loss: 0.8495 | Val Loss: 0.8388\n",
      "Epoch 14 | Train Loss: 0.8531 | Val Loss: 0.8374\n",
      "Epoch 15 | Train Loss: 0.8575 | Val Loss: 0.8347\n",
      "Epoch 16 | Train Loss: 0.8468 | Val Loss: 0.8341\n",
      "Epoch 17 | Train Loss: 0.8285 | Val Loss: 0.8305\n",
      "Epoch 18 | Train Loss: 0.8372 | Val Loss: 0.8386\n",
      "Epoch 19 | Train Loss: 0.8280 | Val Loss: 0.8251\n",
      "Epoch 20 | Train Loss: 0.8321 | Val Loss: 0.8271\n",
      "Epoch 21 | Train Loss: 0.8262 | Val Loss: 0.8192\n",
      "Epoch 22 | Train Loss: 0.8254 | Val Loss: 0.8185\n",
      "Epoch 23 | Train Loss: 0.8255 | Val Loss: 0.8126\n",
      "Epoch 24 | Train Loss: 0.8122 | Val Loss: 0.8100\n",
      "Epoch 25 | Train Loss: 0.8255 | Val Loss: 0.8108\n",
      "Epoch 26 | Train Loss: 0.7999 | Val Loss: 0.8024\n",
      "Epoch 27 | Train Loss: 0.8131 | Val Loss: 0.7998\n",
      "Epoch 28 | Train Loss: 0.7949 | Val Loss: 0.7950\n",
      "Epoch 29 | Train Loss: 0.8289 | Val Loss: 0.7922\n",
      "Epoch 30 | Train Loss: 0.7851 | Val Loss: 0.8188\n",
      "Epoch 31 | Train Loss: 0.8214 | Val Loss: 0.7909\n",
      "Epoch 32 | Train Loss: 0.7819 | Val Loss: 0.7883\n",
      "Epoch 33 | Train Loss: 0.7782 | Val Loss: 0.7809\n",
      "Epoch 34 | Train Loss: 0.7759 | Val Loss: 0.7802\n",
      "Epoch 35 | Train Loss: 0.7884 | Val Loss: 0.7728\n",
      "Epoch 36 | Train Loss: 0.7749 | Val Loss: 0.7705\n",
      "Epoch 37 | Train Loss: 0.7674 | Val Loss: 0.8034\n",
      "Epoch 38 | Train Loss: 0.7804 | Val Loss: 0.7636\n",
      "Epoch 39 | Train Loss: 0.7812 | Val Loss: 0.7917\n",
      "Epoch 40 | Train Loss: 0.7998 | Val Loss: 0.7616\n",
      "Epoch 41 | Train Loss: 0.7646 | Val Loss: 0.7717\n",
      "Epoch 42 | Train Loss: 0.7704 | Val Loss: 0.7533\n",
      "Epoch 43 | Train Loss: 0.7740 | Val Loss: 0.7539\n",
      "Epoch 44 | Train Loss: 0.7593 | Val Loss: 0.7776\n",
      "Epoch 45 | Train Loss: 0.7604 | Val Loss: 0.7621\n",
      "Epoch 46 | Train Loss: 0.7623 | Val Loss: 0.7419\n",
      "Epoch 47 | Train Loss: 0.7582 | Val Loss: 0.7470\n",
      "Epoch 48 | Train Loss: 0.7577 | Val Loss: 0.7390\n",
      "Epoch 49 | Train Loss: 0.7523 | Val Loss: 0.7731\n",
      "Epoch 50 | Train Loss: 0.7407 | Val Loss: 0.7339\n",
      "Fold 2 ‚ñ∂ AUC: 0.657, Balanced Acc: 0.549\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9399 | Val Loss: 0.8674\n",
      "Epoch 02 | Train Loss: 0.8703 | Val Loss: 0.8521\n",
      "Epoch 03 | Train Loss: 0.8643 | Val Loss: 0.8490\n",
      "Epoch 04 | Train Loss: 0.8616 | Val Loss: 0.8450\n",
      "Epoch 05 | Train Loss: 0.8643 | Val Loss: 0.8440\n",
      "Epoch 06 | Train Loss: 0.8499 | Val Loss: 0.8401\n",
      "Epoch 07 | Train Loss: 0.8618 | Val Loss: 0.8365\n",
      "Epoch 08 | Train Loss: 0.8535 | Val Loss: 0.8331\n",
      "Epoch 09 | Train Loss: 0.8565 | Val Loss: 0.8344\n",
      "Epoch 10 | Train Loss: 0.8576 | Val Loss: 0.8270\n",
      "Epoch 11 | Train Loss: 0.8565 | Val Loss: 0.8230\n",
      "Epoch 12 | Train Loss: 0.8388 | Val Loss: 0.8162\n",
      "Epoch 13 | Train Loss: 0.8281 | Val Loss: 0.8165\n",
      "Epoch 14 | Train Loss: 0.8394 | Val Loss: 0.8080\n",
      "Epoch 15 | Train Loss: 0.8382 | Val Loss: 0.8011\n",
      "Epoch 16 | Train Loss: 0.8226 | Val Loss: 0.8009\n",
      "Epoch 17 | Train Loss: 0.8161 | Val Loss: 0.7890\n",
      "Epoch 18 | Train Loss: 0.8198 | Val Loss: 0.7845\n",
      "Epoch 19 | Train Loss: 0.8145 | Val Loss: 0.7931\n",
      "Epoch 20 | Train Loss: 0.8129 | Val Loss: 0.7777\n",
      "Epoch 21 | Train Loss: 0.8107 | Val Loss: 0.7738\n",
      "Epoch 22 | Train Loss: 0.7919 | Val Loss: 0.7845\n",
      "Epoch 23 | Train Loss: 0.7941 | Val Loss: 0.7642\n",
      "Epoch 24 | Train Loss: 0.7855 | Val Loss: 0.7623\n",
      "Epoch 25 | Train Loss: 0.7922 | Val Loss: 0.7673\n",
      "Epoch 26 | Train Loss: 0.7946 | Val Loss: 0.7545\n",
      "Epoch 27 | Train Loss: 0.7805 | Val Loss: 0.7519\n",
      "Epoch 28 | Train Loss: 0.7860 | Val Loss: 0.7486\n",
      "Epoch 29 | Train Loss: 0.7956 | Val Loss: 0.7715\n",
      "Epoch 30 | Train Loss: 0.7716 | Val Loss: 0.7463\n",
      "Epoch 31 | Train Loss: 0.7686 | Val Loss: 0.7404\n",
      "Epoch 32 | Train Loss: 0.7701 | Val Loss: 0.7564\n",
      "Epoch 33 | Train Loss: 0.7804 | Val Loss: 0.7475\n",
      "Epoch 34 | Train Loss: 0.7684 | Val Loss: 0.7342\n",
      "Epoch 35 | Train Loss: 0.7785 | Val Loss: 0.7370\n",
      "Epoch 36 | Train Loss: 0.7604 | Val Loss: 0.7522\n",
      "Epoch 37 | Train Loss: 0.7953 | Val Loss: 0.8004\n",
      "Epoch 38 | Train Loss: 0.7613 | Val Loss: 0.7370\n",
      "Epoch 39 | Train Loss: 0.7579 | Val Loss: 0.7406\n",
      "Epoch 40 | Train Loss: 0.7438 | Val Loss: 0.7304\n",
      "Epoch 41 | Train Loss: 0.7512 | Val Loss: 0.7375\n",
      "Epoch 42 | Train Loss: 0.7486 | Val Loss: 0.7298\n",
      "Epoch 43 | Train Loss: 0.7674 | Val Loss: 0.7232\n",
      "Epoch 44 | Train Loss: 0.7370 | Val Loss: 0.7353\n",
      "Epoch 45 | Train Loss: 0.7329 | Val Loss: 0.7336\n",
      "Epoch 46 | Train Loss: 0.7447 | Val Loss: 0.7187\n",
      "Epoch 47 | Train Loss: 0.7421 | Val Loss: 0.7267\n",
      "Epoch 48 | Train Loss: 0.7831 | Val Loss: 0.7702\n",
      "Epoch 49 | Train Loss: 0.7479 | Val Loss: 0.7442\n",
      "Epoch 50 | Train Loss: 0.7474 | Val Loss: 0.7329\n",
      "Fold 3 ‚ñ∂ AUC: 0.766, Balanced Acc: 0.476\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9109 | Val Loss: 0.8492\n",
      "Epoch 02 | Train Loss: 0.8709 | Val Loss: 0.8414\n",
      "Epoch 03 | Train Loss: 0.8623 | Val Loss: 0.8427\n",
      "Epoch 04 | Train Loss: 0.8663 | Val Loss: 0.8373\n",
      "Epoch 05 | Train Loss: 0.8667 | Val Loss: 0.8378\n",
      "Epoch 06 | Train Loss: 0.8605 | Val Loss: 0.8346\n",
      "Epoch 07 | Train Loss: 0.8565 | Val Loss: 0.8302\n",
      "Epoch 08 | Train Loss: 0.8562 | Val Loss: 0.8283\n",
      "Epoch 09 | Train Loss: 0.8602 | Val Loss: 0.8255\n",
      "Epoch 10 | Train Loss: 0.8410 | Val Loss: 0.8229\n",
      "Epoch 11 | Train Loss: 0.8483 | Val Loss: 0.8219\n",
      "Epoch 12 | Train Loss: 0.8523 | Val Loss: 0.8190\n",
      "Epoch 13 | Train Loss: 0.8427 | Val Loss: 0.8155\n",
      "Epoch 14 | Train Loss: 0.8315 | Val Loss: 0.8151\n",
      "Epoch 15 | Train Loss: 0.8419 | Val Loss: 0.8095\n",
      "Epoch 16 | Train Loss: 0.8319 | Val Loss: 0.8087\n",
      "Epoch 17 | Train Loss: 0.8260 | Val Loss: 0.8017\n",
      "Epoch 18 | Train Loss: 0.8163 | Val Loss: 0.7992\n",
      "Epoch 19 | Train Loss: 0.8112 | Val Loss: 0.7965\n",
      "Epoch 20 | Train Loss: 0.8171 | Val Loss: 0.7875\n",
      "Epoch 21 | Train Loss: 0.8053 | Val Loss: 0.7969\n",
      "Epoch 22 | Train Loss: 0.8115 | Val Loss: 0.7910\n",
      "Epoch 23 | Train Loss: 0.8158 | Val Loss: 0.7769\n",
      "Epoch 24 | Train Loss: 0.8010 | Val Loss: 0.7808\n",
      "Epoch 25 | Train Loss: 0.7886 | Val Loss: 0.7676\n",
      "Epoch 26 | Train Loss: 0.7934 | Val Loss: 0.7719\n",
      "Epoch 27 | Train Loss: 0.8062 | Val Loss: 0.7597\n",
      "Epoch 28 | Train Loss: 0.7802 | Val Loss: 0.7554\n",
      "Epoch 29 | Train Loss: 0.7850 | Val Loss: 0.7530\n",
      "Epoch 30 | Train Loss: 0.8010 | Val Loss: 0.7529\n",
      "Epoch 31 | Train Loss: 0.7810 | Val Loss: 0.7408\n",
      "Epoch 32 | Train Loss: 0.7750 | Val Loss: 0.7354\n",
      "Epoch 33 | Train Loss: 0.7706 | Val Loss: 0.7664\n",
      "Epoch 34 | Train Loss: 0.7571 | Val Loss: 0.7389\n",
      "Epoch 35 | Train Loss: 0.7915 | Val Loss: 0.7334\n",
      "Epoch 36 | Train Loss: 0.7639 | Val Loss: 0.7257\n",
      "Epoch 37 | Train Loss: 0.7857 | Val Loss: 0.7430\n",
      "Epoch 38 | Train Loss: 0.7723 | Val Loss: 0.7197\n",
      "Epoch 39 | Train Loss: 0.7637 | Val Loss: 0.7170\n",
      "Epoch 40 | Train Loss: 0.7644 | Val Loss: 0.7120\n",
      "Epoch 41 | Train Loss: 0.7427 | Val Loss: 0.7185\n",
      "Epoch 42 | Train Loss: 0.7517 | Val Loss: 0.7094\n",
      "Epoch 43 | Train Loss: 0.7469 | Val Loss: 0.7032\n",
      "Epoch 44 | Train Loss: 0.7671 | Val Loss: 0.7001\n",
      "Epoch 45 | Train Loss: 0.7488 | Val Loss: 0.7010\n",
      "Epoch 46 | Train Loss: 0.7492 | Val Loss: 0.6939\n",
      "Epoch 47 | Train Loss: 0.7588 | Val Loss: 0.7024\n",
      "Epoch 48 | Train Loss: 0.7681 | Val Loss: 0.7206\n",
      "Epoch 49 | Train Loss: 0.7609 | Val Loss: 0.7124\n",
      "Epoch 50 | Train Loss: 0.7526 | Val Loss: 0.6905\n",
      "Fold 4 ‚ñ∂ AUC: 0.806, Balanced Acc: 0.513\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 1.1218 | Val Loss: 0.9352\n",
      "Epoch 02 | Train Loss: 0.8921 | Val Loss: 0.9010\n",
      "Epoch 03 | Train Loss: 0.8847 | Val Loss: 0.9038\n",
      "Epoch 04 | Train Loss: 0.8677 | Val Loss: 0.8978\n",
      "Epoch 05 | Train Loss: 0.8647 | Val Loss: 0.8946\n",
      "Epoch 06 | Train Loss: 0.8717 | Val Loss: 0.8926\n",
      "Epoch 07 | Train Loss: 0.8562 | Val Loss: 0.8886\n",
      "Epoch 08 | Train Loss: 0.8644 | Val Loss: 0.8899\n",
      "Epoch 09 | Train Loss: 0.8455 | Val Loss: 0.8846\n",
      "Epoch 10 | Train Loss: 0.8590 | Val Loss: 0.8848\n",
      "Epoch 11 | Train Loss: 0.8570 | Val Loss: 0.8799\n",
      "Epoch 12 | Train Loss: 0.8449 | Val Loss: 0.8809\n",
      "Epoch 13 | Train Loss: 0.8459 | Val Loss: 0.8762\n",
      "Epoch 14 | Train Loss: 0.8422 | Val Loss: 0.8773\n",
      "Epoch 15 | Train Loss: 0.8268 | Val Loss: 0.8715\n",
      "Epoch 16 | Train Loss: 0.8383 | Val Loss: 0.8688\n",
      "Epoch 17 | Train Loss: 0.8579 | Val Loss: 0.8761\n",
      "Epoch 18 | Train Loss: 0.8219 | Val Loss: 0.8650\n",
      "Epoch 19 | Train Loss: 0.8382 | Val Loss: 0.8624\n",
      "Epoch 20 | Train Loss: 0.8213 | Val Loss: 0.8571\n",
      "Epoch 21 | Train Loss: 0.8109 | Val Loss: 0.8530\n",
      "Epoch 22 | Train Loss: 0.8194 | Val Loss: 0.8604\n",
      "Epoch 23 | Train Loss: 0.8112 | Val Loss: 0.8569\n",
      "Epoch 24 | Train Loss: 0.8027 | Val Loss: 0.8566\n",
      "Epoch 25 | Train Loss: 0.8083 | Val Loss: 0.8438\n",
      "Epoch 26 | Train Loss: 0.8112 | Val Loss: 0.8393\n",
      "Epoch 27 | Train Loss: 0.7850 | Val Loss: 0.8356\n",
      "Epoch 28 | Train Loss: 0.7897 | Val Loss: 0.8436\n",
      "Epoch 29 | Train Loss: 0.8015 | Val Loss: 0.8403\n",
      "Epoch 30 | Train Loss: 0.7847 | Val Loss: 0.8316\n",
      "Epoch 31 | Train Loss: 0.8105 | Val Loss: 0.8271\n",
      "Epoch 32 | Train Loss: 0.7783 | Val Loss: 0.8285\n",
      "Epoch 33 | Train Loss: 0.7822 | Val Loss: 0.8224\n",
      "Epoch 34 | Train Loss: 0.7808 | Val Loss: 0.8188\n",
      "Epoch 35 | Train Loss: 0.7672 | Val Loss: 0.8162\n",
      "Epoch 36 | Train Loss: 0.7567 | Val Loss: 0.8148\n",
      "Epoch 37 | Train Loss: 0.7636 | Val Loss: 0.8149\n",
      "Epoch 38 | Train Loss: 0.7696 | Val Loss: 0.8195\n",
      "Epoch 39 | Train Loss: 0.7519 | Val Loss: 0.8158\n",
      "Epoch 40 | Train Loss: 0.7578 | Val Loss: 0.8672\n",
      "Epoch 41 | Train Loss: 0.7882 | Val Loss: 0.8115\n",
      "Epoch 42 | Train Loss: 0.7773 | Val Loss: 0.8170\n",
      "Epoch 43 | Train Loss: 0.7519 | Val Loss: 0.8101\n",
      "Epoch 44 | Train Loss: 0.7450 | Val Loss: 0.8235\n",
      "Epoch 45 | Train Loss: 0.7449 | Val Loss: 0.8127\n",
      "Epoch 46 | Train Loss: 0.7517 | Val Loss: 0.8051\n",
      "Epoch 47 | Train Loss: 0.7392 | Val Loss: 0.8005\n",
      "Epoch 48 | Train Loss: 0.7440 | Val Loss: 0.8060\n",
      "Epoch 49 | Train Loss: 0.7483 | Val Loss: 0.8001\n",
      "Epoch 50 | Train Loss: 0.7378 | Val Loss: 0.8057\n",
      "Fold 5 ‚ñ∂ AUC: 0.721, Balanced Acc: 0.490\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 1.0235 | Val Loss: 0.9070\n",
      "Epoch 02 | Train Loss: 0.8654 | Val Loss: 0.8982\n",
      "Epoch 03 | Train Loss: 0.8533 | Val Loss: 0.9014\n",
      "Epoch 04 | Train Loss: 0.8556 | Val Loss: 0.8983\n",
      "Epoch 05 | Train Loss: 0.8619 | Val Loss: 0.8966\n",
      "Epoch 06 | Train Loss: 0.8571 | Val Loss: 0.8908\n",
      "Epoch 07 | Train Loss: 0.8564 | Val Loss: 0.8910\n",
      "Epoch 08 | Train Loss: 0.8479 | Val Loss: 0.8887\n",
      "Epoch 09 | Train Loss: 0.8406 | Val Loss: 0.8875\n",
      "Epoch 10 | Train Loss: 0.8464 | Val Loss: 0.8880\n",
      "Epoch 11 | Train Loss: 0.8493 | Val Loss: 0.8856\n",
      "Epoch 12 | Train Loss: 0.8374 | Val Loss: 0.8839\n",
      "Epoch 13 | Train Loss: 0.8431 | Val Loss: 0.8818\n",
      "Epoch 14 | Train Loss: 0.8504 | Val Loss: 0.8822\n",
      "Epoch 15 | Train Loss: 0.8437 | Val Loss: 0.8789\n",
      "Epoch 16 | Train Loss: 0.8503 | Val Loss: 0.8764\n",
      "Epoch 17 | Train Loss: 0.8262 | Val Loss: 0.8741\n",
      "Epoch 18 | Train Loss: 0.8262 | Val Loss: 0.8728\n",
      "Epoch 19 | Train Loss: 0.8262 | Val Loss: 0.8752\n",
      "Epoch 20 | Train Loss: 0.8187 | Val Loss: 0.8741\n",
      "Epoch 21 | Train Loss: 0.8245 | Val Loss: 0.8723\n",
      "Epoch 22 | Train Loss: 0.8211 | Val Loss: 0.8668\n",
      "Epoch 23 | Train Loss: 0.8178 | Val Loss: 0.8695\n",
      "Epoch 24 | Train Loss: 0.8228 | Val Loss: 0.8649\n",
      "Epoch 25 | Train Loss: 0.8177 | Val Loss: 0.8582\n",
      "Epoch 26 | Train Loss: 0.8021 | Val Loss: 0.8604\n",
      "Epoch 27 | Train Loss: 0.8162 | Val Loss: 0.8559\n",
      "Epoch 28 | Train Loss: 0.7965 | Val Loss: 0.8591\n",
      "Epoch 29 | Train Loss: 0.8026 | Val Loss: 0.8538\n",
      "Epoch 30 | Train Loss: 0.8005 | Val Loss: 0.8522\n",
      "Epoch 31 | Train Loss: 0.7964 | Val Loss: 0.8586\n",
      "Epoch 32 | Train Loss: 0.7867 | Val Loss: 0.8481\n",
      "Epoch 33 | Train Loss: 0.7752 | Val Loss: 0.8535\n",
      "Epoch 34 | Train Loss: 0.8022 | Val Loss: 0.8652\n",
      "Epoch 35 | Train Loss: 0.7907 | Val Loss: 0.8496\n",
      "Epoch 36 | Train Loss: 0.7864 | Val Loss: 0.8454\n",
      "Epoch 37 | Train Loss: 0.7756 | Val Loss: 0.8406\n",
      "Epoch 38 | Train Loss: 0.7694 | Val Loss: 0.8495\n",
      "Epoch 39 | Train Loss: 0.7874 | Val Loss: 0.8436\n",
      "Epoch 40 | Train Loss: 0.7637 | Val Loss: 0.8449\n",
      "Epoch 41 | Train Loss: 0.7663 | Val Loss: 0.8462\n",
      "Epoch 42 | Train Loss: 0.7756 | Val Loss: 0.8371\n",
      "Epoch 43 | Train Loss: 0.7556 | Val Loss: 0.8387\n",
      "Epoch 44 | Train Loss: 0.7511 | Val Loss: 0.8329\n",
      "Epoch 45 | Train Loss: 0.7547 | Val Loss: 0.8379\n",
      "Epoch 46 | Train Loss: 0.7561 | Val Loss: 0.8420\n",
      "Epoch 47 | Train Loss: 0.7405 | Val Loss: 0.8304\n",
      "Epoch 48 | Train Loss: 0.7545 | Val Loss: 0.8326\n",
      "Epoch 49 | Train Loss: 0.7386 | Val Loss: 0.8346\n",
      "Epoch 50 | Train Loss: 0.7449 | Val Loss: 0.8259\n",
      "Fold 6 ‚ñ∂ AUC: 0.717, Balanced Acc: 0.449\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9559 | Val Loss: 0.8616\n",
      "Epoch 02 | Train Loss: 0.8734 | Val Loss: 0.8510\n",
      "Epoch 03 | Train Loss: 0.8673 | Val Loss: 0.8496\n",
      "Epoch 04 | Train Loss: 0.8655 | Val Loss: 0.8472\n",
      "Epoch 05 | Train Loss: 0.8693 | Val Loss: 0.8462\n",
      "Epoch 06 | Train Loss: 0.8576 | Val Loss: 0.8437\n",
      "Epoch 07 | Train Loss: 0.8645 | Val Loss: 0.8415\n",
      "Epoch 08 | Train Loss: 0.8522 | Val Loss: 0.8389\n",
      "Epoch 09 | Train Loss: 0.8618 | Val Loss: 0.8376\n",
      "Epoch 10 | Train Loss: 0.8571 | Val Loss: 0.8341\n",
      "Epoch 11 | Train Loss: 0.8472 | Val Loss: 0.8320\n",
      "Epoch 12 | Train Loss: 0.8591 | Val Loss: 0.8275\n",
      "Epoch 13 | Train Loss: 0.8370 | Val Loss: 0.8272\n",
      "Epoch 14 | Train Loss: 0.8540 | Val Loss: 0.8203\n",
      "Epoch 15 | Train Loss: 0.8323 | Val Loss: 0.8195\n",
      "Epoch 16 | Train Loss: 0.8276 | Val Loss: 0.8141\n",
      "Epoch 17 | Train Loss: 0.8401 | Val Loss: 0.8108\n",
      "Epoch 18 | Train Loss: 0.8220 | Val Loss: 0.8051\n",
      "Epoch 19 | Train Loss: 0.8375 | Val Loss: 0.8016\n",
      "Epoch 20 | Train Loss: 0.8263 | Val Loss: 0.7979\n",
      "Epoch 21 | Train Loss: 0.8080 | Val Loss: 0.7931\n",
      "Epoch 22 | Train Loss: 0.8044 | Val Loss: 0.7852\n",
      "Epoch 23 | Train Loss: 0.8083 | Val Loss: 0.7808\n",
      "Epoch 24 | Train Loss: 0.7919 | Val Loss: 0.7799\n",
      "Epoch 25 | Train Loss: 0.8058 | Val Loss: 0.7714\n",
      "Epoch 26 | Train Loss: 0.7960 | Val Loss: 0.7770\n",
      "Epoch 27 | Train Loss: 0.7996 | Val Loss: 0.7746\n",
      "Epoch 28 | Train Loss: 0.8030 | Val Loss: 0.7860\n",
      "Epoch 29 | Train Loss: 0.7987 | Val Loss: 0.7629\n",
      "Epoch 30 | Train Loss: 0.8067 | Val Loss: 0.7575\n",
      "Epoch 31 | Train Loss: 0.7872 | Val Loss: 0.7586\n",
      "Epoch 32 | Train Loss: 0.7795 | Val Loss: 0.7784\n",
      "Epoch 33 | Train Loss: 0.7897 | Val Loss: 0.7512\n",
      "Epoch 34 | Train Loss: 0.7677 | Val Loss: 0.7502\n",
      "Epoch 35 | Train Loss: 0.7772 | Val Loss: 0.7483\n",
      "Epoch 36 | Train Loss: 0.7648 | Val Loss: 0.7388\n",
      "Epoch 37 | Train Loss: 0.7630 | Val Loss: 0.7414\n",
      "Epoch 38 | Train Loss: 0.7643 | Val Loss: 0.7509\n",
      "Epoch 39 | Train Loss: 0.7595 | Val Loss: 0.7390\n",
      "Epoch 40 | Train Loss: 0.7780 | Val Loss: 0.7347\n",
      "Epoch 41 | Train Loss: 0.7577 | Val Loss: 0.7324\n",
      "Epoch 42 | Train Loss: 0.7423 | Val Loss: 0.7338\n",
      "Epoch 43 | Train Loss: 0.7413 | Val Loss: 0.7316\n",
      "Epoch 44 | Train Loss: 0.7592 | Val Loss: 0.7402\n",
      "Epoch 45 | Train Loss: 0.7640 | Val Loss: 0.7333\n",
      "Epoch 46 | Train Loss: 0.7568 | Val Loss: 0.7384\n",
      "Epoch 47 | Train Loss: 0.7750 | Val Loss: 0.7288\n",
      "Epoch 48 | Train Loss: 0.7723 | Val Loss: 0.7385\n",
      "Epoch 49 | Train Loss: 0.7385 | Val Loss: 0.7363\n",
      "Epoch 50 | Train Loss: 0.7493 | Val Loss: 0.7325\n",
      "Fold 7 ‚ñ∂ AUC: 0.782, Balanced Acc: 0.517\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9343 | Val Loss: 0.8743\n",
      "Epoch 02 | Train Loss: 0.8679 | Val Loss: 0.8636\n",
      "Epoch 03 | Train Loss: 0.8673 | Val Loss: 0.8605\n",
      "Epoch 04 | Train Loss: 0.8608 | Val Loss: 0.8579\n",
      "Epoch 05 | Train Loss: 0.8665 | Val Loss: 0.8582\n",
      "Epoch 06 | Train Loss: 0.8543 | Val Loss: 0.8543\n",
      "Epoch 07 | Train Loss: 0.8597 | Val Loss: 0.8519\n",
      "Epoch 08 | Train Loss: 0.8599 | Val Loss: 0.8507\n",
      "Epoch 09 | Train Loss: 0.8639 | Val Loss: 0.8481\n",
      "Epoch 10 | Train Loss: 0.8573 | Val Loss: 0.8452\n",
      "Epoch 11 | Train Loss: 0.8419 | Val Loss: 0.8417\n",
      "Epoch 12 | Train Loss: 0.8566 | Val Loss: 0.8384\n",
      "Epoch 13 | Train Loss: 0.8361 | Val Loss: 0.8362\n",
      "Epoch 14 | Train Loss: 0.8492 | Val Loss: 0.8316\n",
      "Epoch 15 | Train Loss: 0.8355 | Val Loss: 0.8302\n",
      "Epoch 16 | Train Loss: 0.8311 | Val Loss: 0.8274\n",
      "Epoch 17 | Train Loss: 0.8317 | Val Loss: 0.8222\n",
      "Epoch 18 | Train Loss: 0.8176 | Val Loss: 0.8185\n",
      "Epoch 19 | Train Loss: 0.8192 | Val Loss: 0.8143\n",
      "Epoch 20 | Train Loss: 0.8096 | Val Loss: 0.8105\n",
      "Epoch 21 | Train Loss: 0.8060 | Val Loss: 0.8045\n",
      "Epoch 22 | Train Loss: 0.8018 | Val Loss: 0.8225\n",
      "Epoch 23 | Train Loss: 0.8031 | Val Loss: 0.7980\n",
      "Epoch 24 | Train Loss: 0.7971 | Val Loss: 0.7963\n",
      "Epoch 25 | Train Loss: 0.7806 | Val Loss: 0.8061\n",
      "Epoch 26 | Train Loss: 0.7950 | Val Loss: 0.7956\n",
      "Epoch 27 | Train Loss: 0.8022 | Val Loss: 0.7982\n",
      "Epoch 28 | Train Loss: 0.7846 | Val Loss: 0.7894\n",
      "Epoch 29 | Train Loss: 0.7721 | Val Loss: 0.7864\n",
      "Epoch 30 | Train Loss: 0.7659 | Val Loss: 0.8016\n",
      "Epoch 31 | Train Loss: 0.7672 | Val Loss: 0.7994\n",
      "Epoch 32 | Train Loss: 0.7559 | Val Loss: 0.7868\n",
      "Epoch 33 | Train Loss: 0.7576 | Val Loss: 0.7913\n",
      "Epoch 34 | Train Loss: 0.7532 | Val Loss: 0.7789\n",
      "Epoch 35 | Train Loss: 0.7541 | Val Loss: 0.7791\n",
      "Epoch 36 | Train Loss: 0.7493 | Val Loss: 0.7827\n",
      "Epoch 37 | Train Loss: 0.7447 | Val Loss: 0.7774\n",
      "Epoch 38 | Train Loss: 0.7520 | Val Loss: 0.7806\n",
      "Epoch 39 | Train Loss: 0.7448 | Val Loss: 0.7825\n",
      "Epoch 40 | Train Loss: 0.7291 | Val Loss: 0.7840\n",
      "Epoch 41 | Train Loss: 0.7663 | Val Loss: 0.8236\n",
      "Epoch 42 | Train Loss: 0.7361 | Val Loss: 0.7818\n",
      "Epoch 43 | Train Loss: 0.7359 | Val Loss: 0.7924\n",
      "Epoch 44 | Train Loss: 0.7416 | Val Loss: 0.7900\n",
      "Epoch 45 | Train Loss: 0.7496 | Val Loss: 0.7944\n",
      "Epoch 46 | Train Loss: 0.7443 | Val Loss: 0.7892\n",
      "Epoch 47 | Train Loss: 0.7407 | Val Loss: 0.7914\n",
      "Epoch 48 | Train Loss: 0.7201 | Val Loss: 0.7858\n",
      "Epoch 49 | Train Loss: 0.7288 | Val Loss: 0.8042\n",
      "Epoch 50 | Train Loss: 0.7294 | Val Loss: 0.7864\n",
      "Fold 8 ‚ñ∂ AUC: 0.701, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9749 | Val Loss: 0.8938\n",
      "Epoch 02 | Train Loss: 0.8837 | Val Loss: 0.8708\n",
      "Epoch 03 | Train Loss: 0.8722 | Val Loss: 0.8692\n",
      "Epoch 04 | Train Loss: 0.8726 | Val Loss: 0.8659\n",
      "Epoch 05 | Train Loss: 0.8568 | Val Loss: 0.8642\n",
      "Epoch 06 | Train Loss: 0.8608 | Val Loss: 0.8613\n",
      "Epoch 07 | Train Loss: 0.8534 | Val Loss: 0.8596\n",
      "Epoch 08 | Train Loss: 0.8401 | Val Loss: 0.8602\n",
      "Epoch 09 | Train Loss: 0.8421 | Val Loss: 0.8572\n",
      "Epoch 10 | Train Loss: 0.8566 | Val Loss: 0.8550\n",
      "Epoch 11 | Train Loss: 0.8459 | Val Loss: 0.8529\n",
      "Epoch 12 | Train Loss: 0.8393 | Val Loss: 0.8516\n",
      "Epoch 13 | Train Loss: 0.8204 | Val Loss: 0.8494\n",
      "Epoch 14 | Train Loss: 0.8154 | Val Loss: 0.8466\n",
      "Epoch 15 | Train Loss: 0.8226 | Val Loss: 0.8454\n",
      "Epoch 16 | Train Loss: 0.8079 | Val Loss: 0.8425\n",
      "Epoch 17 | Train Loss: 0.8172 | Val Loss: 0.8484\n",
      "Epoch 18 | Train Loss: 0.8091 | Val Loss: 0.8469\n",
      "Epoch 19 | Train Loss: 0.8148 | Val Loss: 0.8412\n",
      "Epoch 20 | Train Loss: 0.7869 | Val Loss: 0.8425\n",
      "Epoch 21 | Train Loss: 0.7891 | Val Loss: 0.8364\n",
      "Epoch 22 | Train Loss: 0.7890 | Val Loss: 0.8574\n",
      "Epoch 23 | Train Loss: 0.7762 | Val Loss: 0.8358\n",
      "Epoch 24 | Train Loss: 0.7713 | Val Loss: 0.8362\n",
      "Epoch 25 | Train Loss: 0.8033 | Val Loss: 0.8263\n",
      "Epoch 26 | Train Loss: 0.7888 | Val Loss: 0.8295\n",
      "Epoch 27 | Train Loss: 0.7781 | Val Loss: 0.8277\n",
      "Epoch 28 | Train Loss: 0.7670 | Val Loss: 0.8295\n",
      "Epoch 29 | Train Loss: 0.7616 | Val Loss: 0.8231\n",
      "Epoch 30 | Train Loss: 0.7553 | Val Loss: 0.8245\n",
      "Epoch 31 | Train Loss: 0.7678 | Val Loss: 0.8316\n",
      "Epoch 32 | Train Loss: 0.7730 | Val Loss: 0.8290\n",
      "Epoch 33 | Train Loss: 0.7627 | Val Loss: 0.8193\n",
      "Epoch 34 | Train Loss: 0.7563 | Val Loss: 0.8312\n",
      "Epoch 35 | Train Loss: 0.7541 | Val Loss: 0.8189\n",
      "Epoch 36 | Train Loss: 0.7548 | Val Loss: 0.8216\n",
      "Epoch 37 | Train Loss: 0.7447 | Val Loss: 0.8432\n",
      "Epoch 38 | Train Loss: 0.7410 | Val Loss: 0.8181\n",
      "Epoch 39 | Train Loss: 0.7374 | Val Loss: 0.8675\n",
      "Epoch 40 | Train Loss: 0.7584 | Val Loss: 0.8139\n",
      "Epoch 41 | Train Loss: 0.7476 | Val Loss: 0.8157\n",
      "Epoch 42 | Train Loss: 0.7525 | Val Loss: 0.8075\n",
      "Epoch 43 | Train Loss: 0.7544 | Val Loss: 0.8254\n",
      "Epoch 44 | Train Loss: 0.7478 | Val Loss: 0.8118\n",
      "Epoch 45 | Train Loss: 0.7457 | Val Loss: 0.8590\n",
      "Epoch 46 | Train Loss: 0.7517 | Val Loss: 0.8026\n",
      "Epoch 47 | Train Loss: 0.7306 | Val Loss: 0.8350\n",
      "Epoch 48 | Train Loss: 0.7543 | Val Loss: 0.7989\n",
      "Epoch 49 | Train Loss: 0.7414 | Val Loss: 0.8013\n",
      "Epoch 50 | Train Loss: 0.7303 | Val Loss: 0.7974\n",
      "Fold 9 ‚ñ∂ AUC: 0.705, Balanced Acc: 0.451\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 1.0024 | Val Loss: 0.8974\n",
      "Epoch 02 | Train Loss: 0.8942 | Val Loss: 0.8777\n",
      "Epoch 03 | Train Loss: 0.8732 | Val Loss: 0.8718\n",
      "Epoch 04 | Train Loss: 0.8729 | Val Loss: 0.8693\n",
      "Epoch 05 | Train Loss: 0.8763 | Val Loss: 0.8672\n",
      "Epoch 06 | Train Loss: 0.8625 | Val Loss: 0.8656\n",
      "Epoch 07 | Train Loss: 0.8618 | Val Loss: 0.8692\n",
      "Epoch 08 | Train Loss: 0.8606 | Val Loss: 0.8625\n",
      "Epoch 09 | Train Loss: 0.8553 | Val Loss: 0.8651\n",
      "Epoch 10 | Train Loss: 0.8687 | Val Loss: 0.8594\n",
      "Epoch 11 | Train Loss: 0.8664 | Val Loss: 0.8588\n",
      "Epoch 12 | Train Loss: 0.8539 | Val Loss: 0.8556\n",
      "Epoch 13 | Train Loss: 0.8619 | Val Loss: 0.8575\n",
      "Epoch 14 | Train Loss: 0.8525 | Val Loss: 0.8505\n",
      "Epoch 15 | Train Loss: 0.8644 | Val Loss: 0.8481\n",
      "Epoch 16 | Train Loss: 0.8545 | Val Loss: 0.8479\n",
      "Epoch 17 | Train Loss: 0.8540 | Val Loss: 0.8433\n",
      "Epoch 18 | Train Loss: 0.8545 | Val Loss: 0.8471\n",
      "Epoch 19 | Train Loss: 0.8546 | Val Loss: 0.8407\n",
      "Epoch 20 | Train Loss: 0.8410 | Val Loss: 0.8371\n",
      "Epoch 21 | Train Loss: 0.8361 | Val Loss: 0.8346\n",
      "Epoch 22 | Train Loss: 0.8263 | Val Loss: 0.8341\n",
      "Epoch 23 | Train Loss: 0.8271 | Val Loss: 0.8269\n",
      "Epoch 24 | Train Loss: 0.8176 | Val Loss: 0.8227\n",
      "Epoch 25 | Train Loss: 0.8335 | Val Loss: 0.8193\n",
      "Epoch 26 | Train Loss: 0.8563 | Val Loss: 0.8328\n",
      "Epoch 27 | Train Loss: 0.8088 | Val Loss: 0.8127\n",
      "Epoch 28 | Train Loss: 0.8047 | Val Loss: 0.8128\n",
      "Epoch 29 | Train Loss: 0.7941 | Val Loss: 0.8051\n",
      "Epoch 30 | Train Loss: 0.7948 | Val Loss: 0.7981\n",
      "Epoch 31 | Train Loss: 0.7932 | Val Loss: 0.8042\n",
      "Epoch 32 | Train Loss: 0.7892 | Val Loss: 0.7923\n",
      "Epoch 33 | Train Loss: 0.7956 | Val Loss: 0.7858\n",
      "Epoch 34 | Train Loss: 0.7825 | Val Loss: 0.7838\n",
      "Epoch 35 | Train Loss: 0.7921 | Val Loss: 0.8647\n",
      "Epoch 36 | Train Loss: 0.7894 | Val Loss: 0.7817\n",
      "Epoch 37 | Train Loss: 0.7870 | Val Loss: 0.7781\n",
      "Epoch 38 | Train Loss: 0.7723 | Val Loss: 0.8026\n",
      "Epoch 39 | Train Loss: 0.7725 | Val Loss: 0.7713\n",
      "Epoch 40 | Train Loss: 0.7611 | Val Loss: 0.7683\n",
      "Epoch 41 | Train Loss: 0.7686 | Val Loss: 0.7679\n",
      "Epoch 42 | Train Loss: 0.7518 | Val Loss: 0.7943\n",
      "Epoch 43 | Train Loss: 0.7559 | Val Loss: 0.7742\n",
      "Epoch 44 | Train Loss: 0.7415 | Val Loss: 0.7616\n",
      "Epoch 45 | Train Loss: 0.7507 | Val Loss: 0.7649\n",
      "Epoch 46 | Train Loss: 0.7470 | Val Loss: 0.7573\n",
      "Epoch 47 | Train Loss: 0.7501 | Val Loss: 0.7605\n",
      "Epoch 48 | Train Loss: 0.7344 | Val Loss: 0.8080\n",
      "Epoch 49 | Train Loss: 0.7599 | Val Loss: 0.7725\n",
      "Epoch 50 | Train Loss: 0.7346 | Val Loss: 0.7629\n",
      "Fold 10 ‚ñ∂ AUC: 0.715, Balanced Acc: 0.434\n",
      "üîç Summary for hd=128, dp=0.0, lr=0.0001 ‚Üí AUC: 0.7346¬±0.0434 | BalAcc: 0.4790¬±0.0396\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.2, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9712 | Val Loss: 0.8937\n",
      "Epoch 02 | Train Loss: 0.8921 | Val Loss: 0.8735\n",
      "Epoch 03 | Train Loss: 0.8940 | Val Loss: 0.8779\n",
      "Epoch 04 | Train Loss: 0.9184 | Val Loss: 0.8502\n",
      "Epoch 05 | Train Loss: 0.9019 | Val Loss: 0.8625\n",
      "Epoch 06 | Train Loss: 0.8551 | Val Loss: 0.8369\n",
      "Epoch 07 | Train Loss: 0.8347 | Val Loss: 0.8273\n",
      "Epoch 08 | Train Loss: 0.8163 | Val Loss: 0.7942\n",
      "Epoch 09 | Train Loss: 0.8516 | Val Loss: 0.8056\n",
      "Epoch 10 | Train Loss: 0.8121 | Val Loss: 0.8082\n",
      "Epoch 11 | Train Loss: 0.7932 | Val Loss: 0.7776\n",
      "Epoch 12 | Train Loss: 0.8013 | Val Loss: 0.7465\n",
      "Epoch 13 | Train Loss: 0.7644 | Val Loss: 0.7515\n",
      "Epoch 14 | Train Loss: 0.7743 | Val Loss: 0.7302\n",
      "Epoch 15 | Train Loss: 0.7697 | Val Loss: 0.7284\n",
      "Epoch 16 | Train Loss: 0.7380 | Val Loss: 0.7184\n",
      "Epoch 17 | Train Loss: 0.7701 | Val Loss: 0.7137\n",
      "Epoch 18 | Train Loss: 0.7709 | Val Loss: 0.7427\n",
      "Epoch 19 | Train Loss: 0.7356 | Val Loss: 0.7278\n",
      "Epoch 20 | Train Loss: 0.7605 | Val Loss: 0.7198\n",
      "Epoch 21 | Train Loss: 0.7651 | Val Loss: 0.7181\n",
      "Epoch 22 | Train Loss: 0.7624 | Val Loss: 0.7229\n",
      "Epoch 23 | Train Loss: 0.7727 | Val Loss: 0.6960\n",
      "Epoch 24 | Train Loss: 0.7548 | Val Loss: 0.7062\n",
      "Epoch 25 | Train Loss: 0.7159 | Val Loss: 0.7163\n",
      "Epoch 26 | Train Loss: 0.7559 | Val Loss: 0.7048\n",
      "Epoch 27 | Train Loss: 0.7265 | Val Loss: 0.7059\n",
      "Epoch 28 | Train Loss: 0.7386 | Val Loss: 0.6977\n",
      "Epoch 29 | Train Loss: 0.7555 | Val Loss: 0.6977\n",
      "Epoch 30 | Train Loss: 0.7364 | Val Loss: 0.7050\n",
      "Epoch 31 | Train Loss: 0.7315 | Val Loss: 0.6912\n",
      "Epoch 32 | Train Loss: 0.7360 | Val Loss: 0.6970\n",
      "Epoch 33 | Train Loss: 0.7263 | Val Loss: 0.7018\n",
      "Epoch 34 | Train Loss: 0.7378 | Val Loss: 0.7099\n",
      "Epoch 35 | Train Loss: 0.7256 | Val Loss: 0.7017\n",
      "Epoch 36 | Train Loss: 0.7257 | Val Loss: 0.6959\n",
      "Epoch 37 | Train Loss: 0.7281 | Val Loss: 0.6992\n",
      "Epoch 38 | Train Loss: 0.7190 | Val Loss: 0.6968\n",
      "Epoch 39 | Train Loss: 0.7220 | Val Loss: 0.7028\n",
      "Epoch 40 | Train Loss: 0.7294 | Val Loss: 0.6990\n",
      "Epoch 41 | Train Loss: 0.7234 | Val Loss: 0.6993\n",
      "Epoch 42 | Train Loss: 0.7278 | Val Loss: 0.7009\n",
      "Epoch 43 | Train Loss: 0.7427 | Val Loss: 0.6984\n",
      "Epoch 44 | Train Loss: 0.7358 | Val Loss: 0.7085\n",
      "Epoch 45 | Train Loss: 0.7068 | Val Loss: 0.7104\n",
      "Epoch 46 | Train Loss: 0.7100 | Val Loss: 0.7023\n",
      "Epoch 47 | Train Loss: 0.7657 | Val Loss: 0.7140\n",
      "Epoch 48 | Train Loss: 0.7262 | Val Loss: 0.7249\n",
      "Epoch 49 | Train Loss: 0.7267 | Val Loss: 0.7033\n",
      "Epoch 50 | Train Loss: 0.7397 | Val Loss: 0.7169\n",
      "Fold 1 ‚ñ∂ AUC: 0.757, Balanced Acc: 0.497\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9401 | Val Loss: 0.9043\n",
      "Epoch 02 | Train Loss: 0.8849 | Val Loss: 0.8613\n",
      "Epoch 03 | Train Loss: 0.8625 | Val Loss: 0.8510\n",
      "Epoch 04 | Train Loss: 0.8699 | Val Loss: 0.8447\n",
      "Epoch 05 | Train Loss: 0.8675 | Val Loss: 0.8353\n",
      "Epoch 06 | Train Loss: 0.8322 | Val Loss: 0.8186\n",
      "Epoch 07 | Train Loss: 0.8417 | Val Loss: 0.8400\n",
      "Epoch 08 | Train Loss: 0.8374 | Val Loss: 0.8403\n",
      "Epoch 09 | Train Loss: 0.8206 | Val Loss: 0.7842\n",
      "Epoch 10 | Train Loss: 0.7814 | Val Loss: 0.7656\n",
      "Epoch 11 | Train Loss: 0.7966 | Val Loss: 0.7734\n",
      "Epoch 12 | Train Loss: 0.7912 | Val Loss: 0.7584\n",
      "Epoch 13 | Train Loss: 0.7722 | Val Loss: 0.7444\n",
      "Epoch 14 | Train Loss: 0.7606 | Val Loss: 0.7392\n",
      "Epoch 15 | Train Loss: 0.7405 | Val Loss: 0.7922\n",
      "Epoch 16 | Train Loss: 0.7553 | Val Loss: 0.7347\n",
      "Epoch 17 | Train Loss: 0.7554 | Val Loss: 0.7558\n",
      "Epoch 18 | Train Loss: 0.7783 | Val Loss: 0.7418\n",
      "Epoch 19 | Train Loss: 0.7507 | Val Loss: 0.7430\n",
      "Epoch 20 | Train Loss: 0.7382 | Val Loss: 0.7721\n",
      "Epoch 21 | Train Loss: 0.7473 | Val Loss: 0.7481\n",
      "Epoch 22 | Train Loss: 0.7693 | Val Loss: 0.7558\n",
      "Epoch 23 | Train Loss: 0.7519 | Val Loss: 0.7280\n",
      "Epoch 24 | Train Loss: 0.7715 | Val Loss: 0.8266\n",
      "Epoch 25 | Train Loss: 0.7358 | Val Loss: 0.7723\n",
      "Epoch 26 | Train Loss: 0.7466 | Val Loss: 0.7297\n",
      "Epoch 27 | Train Loss: 0.7469 | Val Loss: 0.7201\n",
      "Epoch 28 | Train Loss: 0.7339 | Val Loss: 0.7307\n",
      "Epoch 29 | Train Loss: 0.7372 | Val Loss: 0.7315\n",
      "Epoch 30 | Train Loss: 0.7450 | Val Loss: 0.7170\n",
      "Epoch 31 | Train Loss: 0.7405 | Val Loss: 0.7276\n",
      "Epoch 32 | Train Loss: 0.7531 | Val Loss: 0.7595\n",
      "Epoch 33 | Train Loss: 0.7164 | Val Loss: 0.7268\n",
      "Epoch 34 | Train Loss: 0.7375 | Val Loss: 0.7230\n",
      "Epoch 35 | Train Loss: 0.7285 | Val Loss: 0.7179\n",
      "Epoch 36 | Train Loss: 0.7176 | Val Loss: 0.7123\n",
      "Epoch 37 | Train Loss: 0.7282 | Val Loss: 0.7591\n",
      "Epoch 38 | Train Loss: 0.7362 | Val Loss: 0.7609\n",
      "Epoch 39 | Train Loss: 0.7277 | Val Loss: 0.7191\n",
      "Epoch 40 | Train Loss: 0.7127 | Val Loss: 0.8592\n",
      "Epoch 41 | Train Loss: 0.7193 | Val Loss: 0.7714\n",
      "Epoch 42 | Train Loss: 0.7291 | Val Loss: 0.6975\n",
      "Epoch 43 | Train Loss: 0.7151 | Val Loss: 0.7458\n",
      "Epoch 44 | Train Loss: 0.7085 | Val Loss: 0.7875\n",
      "Epoch 45 | Train Loss: 0.7431 | Val Loss: 0.7129\n",
      "Epoch 46 | Train Loss: 0.7315 | Val Loss: 0.7771\n",
      "Epoch 47 | Train Loss: 0.7244 | Val Loss: 0.7087\n",
      "Epoch 48 | Train Loss: 0.7314 | Val Loss: 0.7584\n",
      "Epoch 49 | Train Loss: 0.7279 | Val Loss: 0.6986\n",
      "Epoch 50 | Train Loss: 0.7144 | Val Loss: 0.8281\n",
      "Fold 2 ‚ñ∂ AUC: 0.699, Balanced Acc: 0.491\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9190 | Val Loss: 0.8512\n",
      "Epoch 02 | Train Loss: 0.8880 | Val Loss: 0.8453\n",
      "Epoch 03 | Train Loss: 0.8855 | Val Loss: 0.8322\n",
      "Epoch 04 | Train Loss: 0.8466 | Val Loss: 0.8150\n",
      "Epoch 05 | Train Loss: 0.8409 | Val Loss: 0.7919\n",
      "Epoch 06 | Train Loss: 0.8190 | Val Loss: 0.8083\n",
      "Epoch 07 | Train Loss: 0.8122 | Val Loss: 0.7932\n",
      "Epoch 08 | Train Loss: 0.8395 | Val Loss: 0.7910\n",
      "Epoch 09 | Train Loss: 0.8137 | Val Loss: 0.7930\n",
      "Epoch 10 | Train Loss: 0.7729 | Val Loss: 0.7541\n",
      "Epoch 11 | Train Loss: 0.7608 | Val Loss: 0.7371\n",
      "Epoch 12 | Train Loss: 0.7520 | Val Loss: 0.7279\n",
      "Epoch 13 | Train Loss: 0.7435 | Val Loss: 0.7335\n",
      "Epoch 14 | Train Loss: 0.7471 | Val Loss: 0.7236\n",
      "Epoch 15 | Train Loss: 0.7440 | Val Loss: 0.7194\n",
      "Epoch 16 | Train Loss: 0.7473 | Val Loss: 0.7367\n",
      "Epoch 17 | Train Loss: 0.7491 | Val Loss: 0.7271\n",
      "Epoch 18 | Train Loss: 0.7419 | Val Loss: 0.7211\n",
      "Epoch 19 | Train Loss: 0.7457 | Val Loss: 0.7222\n",
      "Epoch 20 | Train Loss: 0.7464 | Val Loss: 0.7241\n",
      "Epoch 21 | Train Loss: 0.7301 | Val Loss: 0.7147\n",
      "Epoch 22 | Train Loss: 0.7555 | Val Loss: 0.7121\n",
      "Epoch 23 | Train Loss: 0.7145 | Val Loss: 0.7125\n",
      "Epoch 24 | Train Loss: 0.7334 | Val Loss: 0.7426\n",
      "Epoch 25 | Train Loss: 0.7324 | Val Loss: 0.7474\n",
      "Epoch 26 | Train Loss: 0.7257 | Val Loss: 0.7076\n",
      "Epoch 27 | Train Loss: 0.7372 | Val Loss: 0.7121\n",
      "Epoch 28 | Train Loss: 0.7450 | Val Loss: 0.7135\n",
      "Epoch 29 | Train Loss: 0.7058 | Val Loss: 0.7158\n",
      "Epoch 30 | Train Loss: 0.7237 | Val Loss: 0.7116\n",
      "Epoch 31 | Train Loss: 0.7174 | Val Loss: 0.7355\n",
      "Epoch 32 | Train Loss: 0.7353 | Val Loss: 0.7970\n",
      "Epoch 33 | Train Loss: 0.7508 | Val Loss: 0.7160\n",
      "Epoch 34 | Train Loss: 0.7290 | Val Loss: 0.7421\n",
      "Epoch 35 | Train Loss: 0.7293 | Val Loss: 0.7339\n",
      "Epoch 36 | Train Loss: 0.7146 | Val Loss: 0.7038\n",
      "Epoch 37 | Train Loss: 0.7158 | Val Loss: 0.7206\n",
      "Epoch 38 | Train Loss: 0.7091 | Val Loss: 0.7128\n",
      "Epoch 39 | Train Loss: 0.7405 | Val Loss: 0.7099\n",
      "Epoch 40 | Train Loss: 0.7154 | Val Loss: 0.7109\n",
      "Epoch 41 | Train Loss: 0.7104 | Val Loss: 0.7019\n",
      "Epoch 42 | Train Loss: 0.7259 | Val Loss: 0.7053\n",
      "Epoch 43 | Train Loss: 0.7195 | Val Loss: 0.7038\n",
      "Epoch 44 | Train Loss: 0.7136 | Val Loss: 0.7228\n",
      "Epoch 45 | Train Loss: 0.7380 | Val Loss: 0.7578\n",
      "Epoch 46 | Train Loss: 0.7206 | Val Loss: 0.7097\n",
      "Epoch 47 | Train Loss: 0.7119 | Val Loss: 0.7111\n",
      "Epoch 48 | Train Loss: 0.7173 | Val Loss: 0.7059\n",
      "Epoch 49 | Train Loss: 0.7173 | Val Loss: 0.7231\n",
      "Epoch 50 | Train Loss: 0.7103 | Val Loss: 0.7072\n",
      "Fold 3 ‚ñ∂ AUC: 0.784, Balanced Acc: 0.467\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9601 | Val Loss: 0.8915\n",
      "Epoch 02 | Train Loss: 0.8861 | Val Loss: 0.8607\n",
      "Epoch 03 | Train Loss: 0.8785 | Val Loss: 0.8628\n",
      "Epoch 04 | Train Loss: 0.8700 | Val Loss: 0.8454\n",
      "Epoch 05 | Train Loss: 0.8685 | Val Loss: 0.8528\n",
      "Epoch 06 | Train Loss: 0.8611 | Val Loss: 0.8347\n",
      "Epoch 07 | Train Loss: 0.8504 | Val Loss: 0.9413\n",
      "Epoch 08 | Train Loss: 0.8692 | Val Loss: 0.8223\n",
      "Epoch 09 | Train Loss: 0.8444 | Val Loss: 0.7984\n",
      "Epoch 10 | Train Loss: 0.8075 | Val Loss: 0.7803\n",
      "Epoch 11 | Train Loss: 0.8178 | Val Loss: 0.7425\n",
      "Epoch 12 | Train Loss: 0.7927 | Val Loss: 0.7341\n",
      "Epoch 13 | Train Loss: 0.7860 | Val Loss: 0.7256\n",
      "Epoch 14 | Train Loss: 0.7761 | Val Loss: 0.8089\n",
      "Epoch 15 | Train Loss: 0.7905 | Val Loss: 0.7168\n",
      "Epoch 16 | Train Loss: 0.7678 | Val Loss: 0.7069\n",
      "Epoch 17 | Train Loss: 0.7618 | Val Loss: 0.7165\n",
      "Epoch 18 | Train Loss: 0.7526 | Val Loss: 0.7010\n",
      "Epoch 19 | Train Loss: 0.7573 | Val Loss: 0.6971\n",
      "Epoch 20 | Train Loss: 0.7624 | Val Loss: 0.7452\n",
      "Epoch 21 | Train Loss: 0.7523 | Val Loss: 0.6895\n",
      "Epoch 22 | Train Loss: 0.7516 | Val Loss: 0.6845\n",
      "Epoch 23 | Train Loss: 0.7438 | Val Loss: 0.6878\n",
      "Epoch 24 | Train Loss: 0.7614 | Val Loss: 0.6767\n",
      "Epoch 25 | Train Loss: 0.7395 | Val Loss: 0.6715\n",
      "Epoch 26 | Train Loss: 0.7514 | Val Loss: 0.7055\n",
      "Epoch 27 | Train Loss: 0.7569 | Val Loss: 0.6835\n",
      "Epoch 28 | Train Loss: 0.7664 | Val Loss: 0.6767\n",
      "Epoch 29 | Train Loss: 0.7353 | Val Loss: 0.6792\n",
      "Epoch 30 | Train Loss: 0.7684 | Val Loss: 0.6725\n",
      "Epoch 31 | Train Loss: 0.7544 | Val Loss: 0.6993\n",
      "Epoch 32 | Train Loss: 0.7433 | Val Loss: 0.6824\n",
      "Epoch 33 | Train Loss: 0.7300 | Val Loss: 0.6686\n",
      "Epoch 34 | Train Loss: 0.7409 | Val Loss: 0.6926\n",
      "Epoch 35 | Train Loss: 0.7161 | Val Loss: 0.6785\n",
      "Epoch 36 | Train Loss: 0.7415 | Val Loss: 0.6643\n",
      "Epoch 37 | Train Loss: 0.7433 | Val Loss: 0.6855\n",
      "Epoch 38 | Train Loss: 0.7413 | Val Loss: 0.6631\n",
      "Epoch 39 | Train Loss: 0.7471 | Val Loss: 0.6751\n",
      "Epoch 40 | Train Loss: 0.7438 | Val Loss: 0.6700\n",
      "Epoch 41 | Train Loss: 0.7205 | Val Loss: 0.6690\n",
      "Epoch 42 | Train Loss: 0.7234 | Val Loss: 0.6850\n",
      "Epoch 43 | Train Loss: 0.7300 | Val Loss: 0.6676\n",
      "Epoch 44 | Train Loss: 0.7338 | Val Loss: 0.6774\n",
      "Epoch 45 | Train Loss: 0.7408 | Val Loss: 0.6744\n",
      "Epoch 46 | Train Loss: 0.7439 | Val Loss: 0.6731\n",
      "Epoch 47 | Train Loss: 0.7323 | Val Loss: 0.6761\n",
      "Epoch 48 | Train Loss: 0.7288 | Val Loss: 0.6748\n",
      "Epoch 49 | Train Loss: 0.7057 | Val Loss: 0.6802\n",
      "Epoch 50 | Train Loss: 0.7258 | Val Loss: 0.6913\n",
      "Fold 4 ‚ñ∂ AUC: 0.777, Balanced Acc: 0.524\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9252 | Val Loss: 0.9022\n",
      "Epoch 02 | Train Loss: 0.8730 | Val Loss: 0.8928\n",
      "Epoch 03 | Train Loss: 0.8547 | Val Loss: 0.8852\n",
      "Epoch 04 | Train Loss: 0.8401 | Val Loss: 0.8679\n",
      "Epoch 05 | Train Loss: 0.8303 | Val Loss: 0.9322\n",
      "Epoch 06 | Train Loss: 0.8468 | Val Loss: 0.8493\n",
      "Epoch 07 | Train Loss: 0.7963 | Val Loss: 0.8431\n",
      "Epoch 08 | Train Loss: 0.7846 | Val Loss: 0.8340\n",
      "Epoch 09 | Train Loss: 0.7858 | Val Loss: 0.9017\n",
      "Epoch 10 | Train Loss: 0.7735 | Val Loss: 0.8397\n",
      "Epoch 11 | Train Loss: 0.7376 | Val Loss: 0.8373\n",
      "Epoch 12 | Train Loss: 0.7555 | Val Loss: 0.8360\n",
      "Epoch 13 | Train Loss: 0.7381 | Val Loss: 0.8162\n",
      "Epoch 14 | Train Loss: 0.7362 | Val Loss: 0.8165\n",
      "Epoch 15 | Train Loss: 0.7515 | Val Loss: 0.8094\n",
      "Epoch 16 | Train Loss: 0.7615 | Val Loss: 0.8177\n",
      "Epoch 17 | Train Loss: 0.7420 | Val Loss: 0.8166\n",
      "Epoch 18 | Train Loss: 0.7519 | Val Loss: 0.8029\n",
      "Epoch 19 | Train Loss: 0.7248 | Val Loss: 0.8108\n",
      "Epoch 20 | Train Loss: 0.7550 | Val Loss: 0.8257\n",
      "Epoch 21 | Train Loss: 0.7286 | Val Loss: 0.8098\n",
      "Epoch 22 | Train Loss: 0.7380 | Val Loss: 0.8136\n",
      "Epoch 23 | Train Loss: 0.7160 | Val Loss: 0.7966\n",
      "Epoch 24 | Train Loss: 0.7199 | Val Loss: 0.8022\n",
      "Epoch 25 | Train Loss: 0.7457 | Val Loss: 0.8116\n",
      "Epoch 26 | Train Loss: 0.7084 | Val Loss: 0.7893\n",
      "Epoch 27 | Train Loss: 0.7089 | Val Loss: 0.8036\n",
      "Epoch 28 | Train Loss: 0.7180 | Val Loss: 0.7968\n",
      "Epoch 29 | Train Loss: 0.7550 | Val Loss: 0.7930\n",
      "Epoch 30 | Train Loss: 0.7185 | Val Loss: 0.7836\n",
      "Epoch 31 | Train Loss: 0.7417 | Val Loss: 0.8034\n",
      "Epoch 32 | Train Loss: 0.7531 | Val Loss: 0.7911\n",
      "Epoch 33 | Train Loss: 0.7290 | Val Loss: 0.8543\n",
      "Epoch 34 | Train Loss: 0.7467 | Val Loss: 0.7958\n",
      "Epoch 35 | Train Loss: 0.7178 | Val Loss: 0.7882\n",
      "Epoch 36 | Train Loss: 0.7073 | Val Loss: 0.8026\n",
      "Epoch 37 | Train Loss: 0.7144 | Val Loss: 0.7965\n",
      "Epoch 38 | Train Loss: 0.7265 | Val Loss: 0.7955\n",
      "Epoch 39 | Train Loss: 0.7289 | Val Loss: 0.7948\n",
      "Epoch 40 | Train Loss: 0.7325 | Val Loss: 0.7873\n",
      "Epoch 41 | Train Loss: 0.7388 | Val Loss: 0.8005\n",
      "Epoch 42 | Train Loss: 0.7192 | Val Loss: 0.8102\n",
      "Epoch 43 | Train Loss: 0.7055 | Val Loss: 0.7943\n",
      "Epoch 44 | Train Loss: 0.7098 | Val Loss: 0.8042\n",
      "Epoch 45 | Train Loss: 0.6914 | Val Loss: 0.8301\n",
      "Epoch 46 | Train Loss: 0.7439 | Val Loss: 0.8040\n",
      "Epoch 47 | Train Loss: 0.7507 | Val Loss: 0.8269\n",
      "Epoch 48 | Train Loss: 0.6956 | Val Loss: 0.8096\n",
      "Epoch 49 | Train Loss: 0.7126 | Val Loss: 0.8089\n",
      "Epoch 50 | Train Loss: 0.6844 | Val Loss: 0.8168\n",
      "Fold 5 ‚ñ∂ AUC: 0.713, Balanced Acc: 0.423\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.8876 | Val Loss: 0.9204\n",
      "Epoch 02 | Train Loss: 0.8840 | Val Loss: 0.9148\n",
      "Epoch 03 | Train Loss: 0.8857 | Val Loss: 0.8788\n",
      "Epoch 04 | Train Loss: 0.8507 | Val Loss: 0.8540\n",
      "Epoch 05 | Train Loss: 0.8528 | Val Loss: 0.8492\n",
      "Epoch 06 | Train Loss: 0.8094 | Val Loss: 0.8440\n",
      "Epoch 07 | Train Loss: 0.7830 | Val Loss: 0.8239\n",
      "Epoch 08 | Train Loss: 0.7735 | Val Loss: 0.8372\n",
      "Epoch 09 | Train Loss: 0.7558 | Val Loss: 0.8064\n",
      "Epoch 10 | Train Loss: 0.7685 | Val Loss: 0.8042\n",
      "Epoch 11 | Train Loss: 0.7411 | Val Loss: 0.8003\n",
      "Epoch 12 | Train Loss: 0.7549 | Val Loss: 0.8156\n",
      "Epoch 13 | Train Loss: 0.7479 | Val Loss: 0.8103\n",
      "Epoch 14 | Train Loss: 0.7515 | Val Loss: 0.8407\n",
      "Epoch 15 | Train Loss: 0.7350 | Val Loss: 0.8105\n",
      "Epoch 16 | Train Loss: 0.7185 | Val Loss: 0.8255\n",
      "Epoch 17 | Train Loss: 0.7265 | Val Loss: 0.8205\n",
      "Epoch 18 | Train Loss: 0.7233 | Val Loss: 0.8501\n",
      "Epoch 19 | Train Loss: 0.7073 | Val Loss: 0.8331\n",
      "Epoch 20 | Train Loss: 0.7805 | Val Loss: 0.9326\n",
      "Epoch 21 | Train Loss: 0.7485 | Val Loss: 0.8216\n",
      "Epoch 22 | Train Loss: 0.7362 | Val Loss: 0.8420\n",
      "Epoch 23 | Train Loss: 0.7189 | Val Loss: 0.8240\n",
      "Epoch 24 | Train Loss: 0.7334 | Val Loss: 0.8234\n",
      "Epoch 25 | Train Loss: 0.7193 | Val Loss: 0.8149\n",
      "Epoch 26 | Train Loss: 0.7154 | Val Loss: 0.8213\n",
      "Epoch 27 | Train Loss: 0.7103 | Val Loss: 0.8194\n",
      "Epoch 28 | Train Loss: 0.7112 | Val Loss: 0.8351\n",
      "Epoch 29 | Train Loss: 0.7417 | Val Loss: 0.8321\n",
      "Epoch 30 | Train Loss: 0.7092 | Val Loss: 0.8652\n",
      "Epoch 31 | Train Loss: 0.7157 | Val Loss: 0.8030\n",
      "Epoch 32 | Train Loss: 0.7075 | Val Loss: 0.8092\n",
      "Epoch 33 | Train Loss: 0.6945 | Val Loss: 0.8287\n",
      "Epoch 34 | Train Loss: 0.7001 | Val Loss: 0.8207\n",
      "Epoch 35 | Train Loss: 0.7066 | Val Loss: 0.8223\n",
      "Epoch 36 | Train Loss: 0.7030 | Val Loss: 0.8037\n",
      "Epoch 37 | Train Loss: 0.7128 | Val Loss: 0.8314\n",
      "Epoch 38 | Train Loss: 0.6981 | Val Loss: 0.8174\n",
      "Epoch 39 | Train Loss: 0.7221 | Val Loss: 0.8084\n",
      "Epoch 40 | Train Loss: 0.7218 | Val Loss: 0.8200\n",
      "Epoch 41 | Train Loss: 0.6899 | Val Loss: 0.8185\n",
      "Epoch 42 | Train Loss: 0.6922 | Val Loss: 0.8172\n",
      "Epoch 43 | Train Loss: 0.6802 | Val Loss: 0.8383\n",
      "Epoch 44 | Train Loss: 0.7080 | Val Loss: 0.8143\n",
      "Epoch 45 | Train Loss: 0.6733 | Val Loss: 0.8086\n",
      "Epoch 46 | Train Loss: 0.7039 | Val Loss: 0.8036\n",
      "Epoch 47 | Train Loss: 0.7035 | Val Loss: 0.8329\n",
      "Epoch 48 | Train Loss: 0.7330 | Val Loss: 0.8310\n",
      "Epoch 49 | Train Loss: 0.7035 | Val Loss: 0.8125\n",
      "Epoch 50 | Train Loss: 0.6854 | Val Loss: 0.8116\n",
      "Fold 6 ‚ñ∂ AUC: 0.757, Balanced Acc: 0.504\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9349 | Val Loss: 0.8562\n",
      "Epoch 02 | Train Loss: 0.9247 | Val Loss: 0.8764\n",
      "Epoch 03 | Train Loss: 0.8799 | Val Loss: 0.8478\n",
      "Epoch 04 | Train Loss: 0.8631 | Val Loss: 0.8446\n",
      "Epoch 05 | Train Loss: 0.8370 | Val Loss: 0.8256\n",
      "Epoch 06 | Train Loss: 0.8201 | Val Loss: 0.7778\n",
      "Epoch 07 | Train Loss: 0.8205 | Val Loss: 0.7367\n",
      "Epoch 08 | Train Loss: 0.8081 | Val Loss: 0.7452\n",
      "Epoch 09 | Train Loss: 0.7800 | Val Loss: 0.7234\n",
      "Epoch 10 | Train Loss: 0.7818 | Val Loss: 0.6900\n",
      "Epoch 11 | Train Loss: 0.7644 | Val Loss: 0.7466\n",
      "Epoch 12 | Train Loss: 0.7940 | Val Loss: 0.7075\n",
      "Epoch 13 | Train Loss: 0.7421 | Val Loss: 0.7339\n",
      "Epoch 14 | Train Loss: 0.7599 | Val Loss: 0.7091\n",
      "Epoch 15 | Train Loss: 0.7534 | Val Loss: 0.7167\n",
      "Epoch 16 | Train Loss: 0.7389 | Val Loss: 0.7390\n",
      "Epoch 17 | Train Loss: 0.7296 | Val Loss: 0.7043\n",
      "Epoch 18 | Train Loss: 0.7508 | Val Loss: 0.7364\n",
      "Epoch 19 | Train Loss: 0.7605 | Val Loss: 0.7390\n",
      "Epoch 20 | Train Loss: 0.7327 | Val Loss: 0.7249\n",
      "Epoch 21 | Train Loss: 0.7424 | Val Loss: 0.7524\n",
      "Epoch 22 | Train Loss: 0.7459 | Val Loss: 0.7155\n",
      "Epoch 23 | Train Loss: 0.7227 | Val Loss: 0.7125\n",
      "Epoch 24 | Train Loss: 0.7370 | Val Loss: 0.7280\n",
      "Epoch 25 | Train Loss: 0.7196 | Val Loss: 0.7148\n",
      "Epoch 26 | Train Loss: 0.7144 | Val Loss: 0.7220\n",
      "Epoch 27 | Train Loss: 0.7312 | Val Loss: 0.7199\n",
      "Epoch 28 | Train Loss: 0.7356 | Val Loss: 0.7140\n",
      "Epoch 29 | Train Loss: 0.7273 | Val Loss: 0.7139\n",
      "Epoch 30 | Train Loss: 0.7180 | Val Loss: 0.7165\n",
      "Epoch 31 | Train Loss: 0.7275 | Val Loss: 0.7426\n",
      "Epoch 32 | Train Loss: 0.7431 | Val Loss: 0.7076\n",
      "Epoch 33 | Train Loss: 0.7208 | Val Loss: 0.7098\n",
      "Epoch 34 | Train Loss: 0.7328 | Val Loss: 0.7483\n",
      "Epoch 35 | Train Loss: 0.7353 | Val Loss: 0.7292\n",
      "Epoch 36 | Train Loss: 0.7398 | Val Loss: 0.7138\n",
      "Epoch 37 | Train Loss: 0.7252 | Val Loss: 0.7109\n",
      "Epoch 38 | Train Loss: 0.7051 | Val Loss: 0.7246\n",
      "Epoch 39 | Train Loss: 0.7247 | Val Loss: 0.7463\n",
      "Epoch 40 | Train Loss: 0.7278 | Val Loss: 0.7098\n",
      "Epoch 41 | Train Loss: 0.7263 | Val Loss: 0.7103\n",
      "Epoch 42 | Train Loss: 0.7327 | Val Loss: 0.7063\n",
      "Epoch 43 | Train Loss: 0.7365 | Val Loss: 0.7611\n",
      "Epoch 44 | Train Loss: 0.7426 | Val Loss: 0.7000\n",
      "Epoch 45 | Train Loss: 0.7242 | Val Loss: 0.7034\n",
      "Epoch 46 | Train Loss: 0.7477 | Val Loss: 0.7090\n",
      "Epoch 47 | Train Loss: 0.7206 | Val Loss: 0.7079\n",
      "Epoch 48 | Train Loss: 0.7236 | Val Loss: 0.7271\n",
      "Epoch 49 | Train Loss: 0.7188 | Val Loss: 0.7069\n",
      "Epoch 50 | Train Loss: 0.7106 | Val Loss: 0.7106\n",
      "Fold 7 ‚ñ∂ AUC: 0.773, Balanced Acc: 0.462\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9097 | Val Loss: 0.8728\n",
      "Epoch 02 | Train Loss: 0.8651 | Val Loss: 0.8559\n",
      "Epoch 03 | Train Loss: 0.8659 | Val Loss: 0.8726\n",
      "Epoch 04 | Train Loss: 0.8829 | Val Loss: 0.8447\n",
      "Epoch 05 | Train Loss: 0.8456 | Val Loss: 0.8511\n",
      "Epoch 06 | Train Loss: 0.8240 | Val Loss: 0.8063\n",
      "Epoch 07 | Train Loss: 0.8441 | Val Loss: 0.8029\n",
      "Epoch 08 | Train Loss: 0.8025 | Val Loss: 0.7889\n",
      "Epoch 09 | Train Loss: 0.7796 | Val Loss: 0.7839\n",
      "Epoch 10 | Train Loss: 0.7946 | Val Loss: 0.7977\n",
      "Epoch 11 | Train Loss: 0.7429 | Val Loss: 0.8060\n",
      "Epoch 12 | Train Loss: 0.7664 | Val Loss: 0.8004\n",
      "Epoch 13 | Train Loss: 0.7714 | Val Loss: 0.8406\n",
      "Epoch 14 | Train Loss: 0.7406 | Val Loss: 0.8057\n",
      "Epoch 15 | Train Loss: 0.7559 | Val Loss: 0.7946\n",
      "Epoch 16 | Train Loss: 0.7332 | Val Loss: 0.7829\n",
      "Epoch 17 | Train Loss: 0.7312 | Val Loss: 0.7938\n",
      "Epoch 18 | Train Loss: 0.7533 | Val Loss: 0.8354\n",
      "Epoch 19 | Train Loss: 0.7851 | Val Loss: 0.7966\n",
      "Epoch 20 | Train Loss: 0.7313 | Val Loss: 0.8041\n",
      "Epoch 21 | Train Loss: 0.7300 | Val Loss: 0.7879\n",
      "Epoch 22 | Train Loss: 0.7307 | Val Loss: 0.7741\n",
      "Epoch 23 | Train Loss: 0.7222 | Val Loss: 0.7867\n",
      "Epoch 24 | Train Loss: 0.7303 | Val Loss: 0.7930\n",
      "Epoch 25 | Train Loss: 0.7362 | Val Loss: 0.7870\n",
      "Epoch 26 | Train Loss: 0.7224 | Val Loss: 0.7872\n",
      "Epoch 27 | Train Loss: 0.7091 | Val Loss: 0.8185\n",
      "Epoch 28 | Train Loss: 0.7216 | Val Loss: 0.7974\n",
      "Epoch 29 | Train Loss: 0.7132 | Val Loss: 0.7993\n",
      "Epoch 30 | Train Loss: 0.7105 | Val Loss: 0.8061\n",
      "Epoch 31 | Train Loss: 0.7456 | Val Loss: 0.8018\n",
      "Epoch 32 | Train Loss: 0.7113 | Val Loss: 0.7956\n",
      "Epoch 33 | Train Loss: 0.7320 | Val Loss: 0.7914\n",
      "Epoch 34 | Train Loss: 0.7114 | Val Loss: 0.8955\n",
      "Epoch 35 | Train Loss: 0.7384 | Val Loss: 0.8270\n",
      "Epoch 36 | Train Loss: 0.7787 | Val Loss: 0.8076\n",
      "Epoch 37 | Train Loss: 0.7434 | Val Loss: 0.7898\n",
      "Epoch 38 | Train Loss: 0.7015 | Val Loss: 0.8071\n",
      "Epoch 39 | Train Loss: 0.7461 | Val Loss: 0.7905\n",
      "Epoch 40 | Train Loss: 0.7141 | Val Loss: 0.7893\n",
      "Epoch 41 | Train Loss: 0.7202 | Val Loss: 0.8019\n",
      "Epoch 42 | Train Loss: 0.7382 | Val Loss: 0.8343\n",
      "Epoch 43 | Train Loss: 0.7343 | Val Loss: 0.7890\n",
      "Epoch 44 | Train Loss: 0.7142 | Val Loss: 0.8166\n",
      "Epoch 45 | Train Loss: 0.7251 | Val Loss: 0.7951\n",
      "Epoch 46 | Train Loss: 0.6998 | Val Loss: 0.8048\n",
      "Epoch 47 | Train Loss: 0.7039 | Val Loss: 0.8402\n",
      "Epoch 48 | Train Loss: 0.7173 | Val Loss: 0.8038\n",
      "Epoch 49 | Train Loss: 0.7147 | Val Loss: 0.8221\n",
      "Epoch 50 | Train Loss: 0.6956 | Val Loss: 0.8073\n",
      "Fold 8 ‚ñ∂ AUC: 0.718, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9280 | Val Loss: 0.8772\n",
      "Epoch 02 | Train Loss: 0.8528 | Val Loss: 0.8813\n",
      "Epoch 03 | Train Loss: 0.8597 | Val Loss: 0.8794\n",
      "Epoch 04 | Train Loss: 0.8302 | Val Loss: 0.8463\n",
      "Epoch 05 | Train Loss: 0.8095 | Val Loss: 0.8544\n",
      "Epoch 06 | Train Loss: 0.8295 | Val Loss: 0.8183\n",
      "Epoch 07 | Train Loss: 0.8131 | Val Loss: 0.9077\n",
      "Epoch 08 | Train Loss: 0.7840 | Val Loss: 0.8006\n",
      "Epoch 09 | Train Loss: 0.7731 | Val Loss: 0.8176\n",
      "Epoch 10 | Train Loss: 0.7675 | Val Loss: 0.8122\n",
      "Epoch 11 | Train Loss: 0.7800 | Val Loss: 0.8088\n",
      "Epoch 12 | Train Loss: 0.7821 | Val Loss: 0.7924\n",
      "Epoch 13 | Train Loss: 0.7818 | Val Loss: 0.7810\n",
      "Epoch 14 | Train Loss: 0.7729 | Val Loss: 0.7904\n",
      "Epoch 15 | Train Loss: 0.7732 | Val Loss: 0.7587\n",
      "Epoch 16 | Train Loss: 0.7239 | Val Loss: 0.7625\n",
      "Epoch 17 | Train Loss: 0.7444 | Val Loss: 0.7564\n",
      "Epoch 18 | Train Loss: 0.7340 | Val Loss: 0.7565\n",
      "Epoch 19 | Train Loss: 0.7308 | Val Loss: 0.7448\n",
      "Epoch 20 | Train Loss: 0.7407 | Val Loss: 0.7561\n",
      "Epoch 21 | Train Loss: 0.7321 | Val Loss: 0.7732\n",
      "Epoch 22 | Train Loss: 0.7363 | Val Loss: 0.7485\n",
      "Epoch 23 | Train Loss: 0.7274 | Val Loss: 0.7459\n",
      "Epoch 24 | Train Loss: 0.7355 | Val Loss: 0.7597\n",
      "Epoch 25 | Train Loss: 0.7376 | Val Loss: 0.7583\n",
      "Epoch 26 | Train Loss: 0.7262 | Val Loss: 0.7394\n",
      "Epoch 27 | Train Loss: 0.7348 | Val Loss: 0.7644\n",
      "Epoch 28 | Train Loss: 0.7080 | Val Loss: 0.7493\n",
      "Epoch 29 | Train Loss: 0.7566 | Val Loss: 0.7433\n",
      "Epoch 30 | Train Loss: 0.7516 | Val Loss: 0.7363\n",
      "Epoch 31 | Train Loss: 0.7172 | Val Loss: 0.7433\n",
      "Epoch 32 | Train Loss: 0.7163 | Val Loss: 0.7431\n",
      "Epoch 33 | Train Loss: 0.7057 | Val Loss: 0.7550\n",
      "Epoch 34 | Train Loss: 0.7236 | Val Loss: 0.7421\n",
      "Epoch 35 | Train Loss: 0.7336 | Val Loss: 0.7349\n",
      "Epoch 36 | Train Loss: 0.7226 | Val Loss: 0.8329\n",
      "Epoch 37 | Train Loss: 0.7437 | Val Loss: 0.7342\n",
      "Epoch 38 | Train Loss: 0.7289 | Val Loss: 0.7411\n",
      "Epoch 39 | Train Loss: 0.7253 | Val Loss: 0.7477\n",
      "Epoch 40 | Train Loss: 0.7204 | Val Loss: 0.7532\n",
      "Epoch 41 | Train Loss: 0.7005 | Val Loss: 0.7493\n",
      "Epoch 42 | Train Loss: 0.7181 | Val Loss: 0.7542\n",
      "Epoch 43 | Train Loss: 0.7092 | Val Loss: 0.7551\n",
      "Epoch 44 | Train Loss: 0.6988 | Val Loss: 0.7622\n",
      "Epoch 45 | Train Loss: 0.7135 | Val Loss: 0.7331\n",
      "Epoch 46 | Train Loss: 0.7239 | Val Loss: 0.7306\n",
      "Epoch 47 | Train Loss: 0.7042 | Val Loss: 0.7360\n",
      "Epoch 48 | Train Loss: 0.7019 | Val Loss: 0.7533\n",
      "Epoch 49 | Train Loss: 0.7412 | Val Loss: 0.8208\n",
      "Epoch 50 | Train Loss: 0.7474 | Val Loss: 0.8108\n",
      "Fold 9 ‚ñ∂ AUC: 0.762, Balanced Acc: 0.525\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9452 | Val Loss: 0.8830\n",
      "Epoch 02 | Train Loss: 0.8712 | Val Loss: 0.8633\n",
      "Epoch 03 | Train Loss: 0.8807 | Val Loss: 0.8628\n",
      "Epoch 04 | Train Loss: 0.8545 | Val Loss: 0.8389\n",
      "Epoch 05 | Train Loss: 0.8449 | Val Loss: 0.8246\n",
      "Epoch 06 | Train Loss: 0.8229 | Val Loss: 0.8173\n",
      "Epoch 07 | Train Loss: 0.8172 | Val Loss: 0.8142\n",
      "Epoch 08 | Train Loss: 0.7764 | Val Loss: 0.8937\n",
      "Epoch 09 | Train Loss: 0.8000 | Val Loss: 0.7559\n",
      "Epoch 10 | Train Loss: 0.8057 | Val Loss: 0.7731\n",
      "Epoch 11 | Train Loss: 0.7848 | Val Loss: 0.7603\n",
      "Epoch 12 | Train Loss: 0.7413 | Val Loss: 0.8597\n",
      "Epoch 13 | Train Loss: 0.7820 | Val Loss: 0.8531\n",
      "Epoch 14 | Train Loss: 0.7810 | Val Loss: 0.7613\n",
      "Epoch 15 | Train Loss: 0.7466 | Val Loss: 0.7614\n",
      "Epoch 16 | Train Loss: 0.7371 | Val Loss: 0.7744\n",
      "Epoch 17 | Train Loss: 0.7406 | Val Loss: 0.7646\n",
      "Epoch 18 | Train Loss: 0.7284 | Val Loss: 0.7767\n",
      "Epoch 19 | Train Loss: 0.7267 | Val Loss: 0.8666\n",
      "Epoch 20 | Train Loss: 0.7480 | Val Loss: 0.8285\n",
      "Epoch 21 | Train Loss: 0.7423 | Val Loss: 0.7600\n",
      "Epoch 22 | Train Loss: 0.7466 | Val Loss: 0.7616\n",
      "Epoch 23 | Train Loss: 0.7273 | Val Loss: 0.7664\n",
      "Epoch 24 | Train Loss: 0.7216 | Val Loss: 0.8053\n",
      "Epoch 25 | Train Loss: 0.7266 | Val Loss: 0.8043\n",
      "Epoch 26 | Train Loss: 0.7292 | Val Loss: 0.7980\n",
      "Epoch 27 | Train Loss: 0.7514 | Val Loss: 0.7749\n",
      "Epoch 28 | Train Loss: 0.7465 | Val Loss: 0.7763\n",
      "Epoch 29 | Train Loss: 0.7182 | Val Loss: 0.7732\n",
      "Epoch 30 | Train Loss: 0.7440 | Val Loss: 0.7763\n",
      "Epoch 31 | Train Loss: 0.7322 | Val Loss: 0.8664\n",
      "Epoch 32 | Train Loss: 0.7449 | Val Loss: 0.7800\n",
      "Epoch 33 | Train Loss: 0.7330 | Val Loss: 0.7826\n",
      "Epoch 34 | Train Loss: 0.7388 | Val Loss: 0.7979\n",
      "Epoch 35 | Train Loss: 0.7466 | Val Loss: 0.7760\n",
      "Epoch 36 | Train Loss: 0.6994 | Val Loss: 0.8431\n",
      "Epoch 37 | Train Loss: 0.7271 | Val Loss: 0.7838\n",
      "Epoch 38 | Train Loss: 0.7290 | Val Loss: 0.7769\n",
      "Epoch 39 | Train Loss: 0.7199 | Val Loss: 0.7772\n",
      "Epoch 40 | Train Loss: 0.7088 | Val Loss: 0.7709\n",
      "Epoch 41 | Train Loss: 0.7372 | Val Loss: 0.7769\n",
      "Epoch 42 | Train Loss: 0.7123 | Val Loss: 0.7938\n",
      "Epoch 43 | Train Loss: 0.7005 | Val Loss: 0.7755\n",
      "Epoch 44 | Train Loss: 0.7052 | Val Loss: 0.8153\n",
      "Epoch 45 | Train Loss: 0.7171 | Val Loss: 0.7736\n",
      "Epoch 46 | Train Loss: 0.7272 | Val Loss: 0.7712\n",
      "Epoch 47 | Train Loss: 0.7235 | Val Loss: 0.8281\n",
      "Epoch 48 | Train Loss: 0.7183 | Val Loss: 0.7659\n",
      "Epoch 49 | Train Loss: 0.7105 | Val Loss: 0.7728\n",
      "Epoch 50 | Train Loss: 0.7086 | Val Loss: 0.8356\n",
      "Fold 10 ‚ñ∂ AUC: 0.739, Balanced Acc: 0.416\n",
      "üîç Summary for hd=128, dp=0.2, lr=0.001 ‚Üí AUC: 0.7479¬±0.0278 | BalAcc: 0.4708¬±0.0433\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.2, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9629 | Val Loss: 0.8718\n",
      "Epoch 02 | Train Loss: 0.8935 | Val Loss: 0.8633\n",
      "Epoch 03 | Train Loss: 0.8805 | Val Loss: 0.8528\n",
      "Epoch 04 | Train Loss: 0.8849 | Val Loss: 0.8496\n",
      "Epoch 05 | Train Loss: 0.8987 | Val Loss: 0.8412\n",
      "Epoch 06 | Train Loss: 0.8631 | Val Loss: 0.8393\n",
      "Epoch 07 | Train Loss: 0.8400 | Val Loss: 0.8636\n",
      "Epoch 08 | Train Loss: 0.8716 | Val Loss: 0.8485\n",
      "Epoch 09 | Train Loss: 0.8412 | Val Loss: 0.8163\n",
      "Epoch 10 | Train Loss: 0.8206 | Val Loss: 0.8084\n",
      "Epoch 11 | Train Loss: 0.8180 | Val Loss: 0.8540\n",
      "Epoch 12 | Train Loss: 0.8007 | Val Loss: 0.7724\n",
      "Epoch 13 | Train Loss: 0.7714 | Val Loss: 0.7471\n",
      "Epoch 14 | Train Loss: 0.7820 | Val Loss: 0.7341\n",
      "Epoch 15 | Train Loss: 0.7932 | Val Loss: 0.7423\n",
      "Epoch 16 | Train Loss: 0.7832 | Val Loss: 0.7290\n",
      "Epoch 17 | Train Loss: 0.8202 | Val Loss: 0.8068\n",
      "Epoch 18 | Train Loss: 0.7857 | Val Loss: 0.7309\n",
      "Epoch 19 | Train Loss: 0.7787 | Val Loss: 0.7103\n",
      "Epoch 20 | Train Loss: 0.7581 | Val Loss: 0.7271\n",
      "Epoch 21 | Train Loss: 0.7476 | Val Loss: 0.7017\n",
      "Epoch 22 | Train Loss: 0.7471 | Val Loss: 0.7166\n",
      "Epoch 23 | Train Loss: 0.7452 | Val Loss: 0.6958\n",
      "Epoch 24 | Train Loss: 0.7311 | Val Loss: 0.6922\n",
      "Epoch 25 | Train Loss: 0.7228 | Val Loss: 0.6938\n",
      "Epoch 26 | Train Loss: 0.7290 | Val Loss: 0.6887\n",
      "Epoch 27 | Train Loss: 0.7461 | Val Loss: 0.6999\n",
      "Epoch 28 | Train Loss: 0.7279 | Val Loss: 0.6905\n",
      "Epoch 29 | Train Loss: 0.7343 | Val Loss: 0.7069\n",
      "Epoch 30 | Train Loss: 0.7199 | Val Loss: 0.6829\n",
      "Epoch 31 | Train Loss: 0.7256 | Val Loss: 0.6845\n",
      "Epoch 32 | Train Loss: 0.7327 | Val Loss: 0.6798\n",
      "Epoch 33 | Train Loss: 0.7505 | Val Loss: 0.6786\n",
      "Epoch 34 | Train Loss: 0.7308 | Val Loss: 0.6837\n",
      "Epoch 35 | Train Loss: 0.7319 | Val Loss: 0.6783\n",
      "Epoch 36 | Train Loss: 0.7631 | Val Loss: 0.6942\n",
      "Epoch 37 | Train Loss: 0.7272 | Val Loss: 0.6801\n",
      "Epoch 38 | Train Loss: 0.7640 | Val Loss: 0.6949\n",
      "Epoch 39 | Train Loss: 0.7636 | Val Loss: 0.6961\n",
      "Epoch 40 | Train Loss: 0.7398 | Val Loss: 0.6935\n",
      "Epoch 41 | Train Loss: 0.7162 | Val Loss: 0.6814\n",
      "Epoch 42 | Train Loss: 0.7435 | Val Loss: 0.6782\n",
      "Epoch 43 | Train Loss: 0.7316 | Val Loss: 0.6910\n",
      "Epoch 44 | Train Loss: 0.7211 | Val Loss: 0.6785\n",
      "Epoch 45 | Train Loss: 0.7365 | Val Loss: 0.7362\n",
      "Epoch 46 | Train Loss: 0.7271 | Val Loss: 0.6887\n",
      "Epoch 47 | Train Loss: 0.7232 | Val Loss: 0.6771\n",
      "Epoch 48 | Train Loss: 0.7107 | Val Loss: 0.6786\n",
      "Epoch 49 | Train Loss: 0.7383 | Val Loss: 0.6902\n",
      "Epoch 50 | Train Loss: 0.7105 | Val Loss: 0.6842\n",
      "Fold 1 ‚ñ∂ AUC: 0.782, Balanced Acc: 0.510\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9343 | Val Loss: 0.8672\n",
      "Epoch 02 | Train Loss: 0.8726 | Val Loss: 0.8643\n",
      "Epoch 03 | Train Loss: 0.8635 | Val Loss: 0.8518\n",
      "Epoch 04 | Train Loss: 0.8698 | Val Loss: 0.8485\n",
      "Epoch 05 | Train Loss: 0.8616 | Val Loss: 0.8633\n",
      "Epoch 06 | Train Loss: 0.8827 | Val Loss: 0.8748\n",
      "Epoch 07 | Train Loss: 0.8446 | Val Loss: 0.8642\n",
      "Epoch 08 | Train Loss: 0.8445 | Val Loss: 0.8376\n",
      "Epoch 09 | Train Loss: 0.8218 | Val Loss: 0.8134\n",
      "Epoch 10 | Train Loss: 0.8164 | Val Loss: 0.8126\n",
      "Epoch 11 | Train Loss: 0.7937 | Val Loss: 0.7942\n",
      "Epoch 12 | Train Loss: 0.7821 | Val Loss: 0.8277\n",
      "Epoch 13 | Train Loss: 0.7892 | Val Loss: 0.8633\n",
      "Epoch 14 | Train Loss: 0.8121 | Val Loss: 0.8207\n",
      "Epoch 15 | Train Loss: 0.7631 | Val Loss: 0.8316\n",
      "Epoch 16 | Train Loss: 0.7643 | Val Loss: 0.7513\n",
      "Epoch 17 | Train Loss: 0.7673 | Val Loss: 0.7493\n",
      "Epoch 18 | Train Loss: 0.7505 | Val Loss: 0.7887\n",
      "Epoch 19 | Train Loss: 0.7929 | Val Loss: 0.7518\n",
      "Epoch 20 | Train Loss: 0.7709 | Val Loss: 0.7577\n",
      "Epoch 21 | Train Loss: 0.7581 | Val Loss: 0.7988\n",
      "Epoch 22 | Train Loss: 0.7513 | Val Loss: 0.7626\n",
      "Epoch 23 | Train Loss: 0.7536 | Val Loss: 0.7540\n",
      "Epoch 24 | Train Loss: 0.7336 | Val Loss: 0.7875\n",
      "Epoch 25 | Train Loss: 0.7723 | Val Loss: 0.7563\n",
      "Epoch 26 | Train Loss: 0.7602 | Val Loss: 0.7350\n",
      "Epoch 27 | Train Loss: 0.7545 | Val Loss: 0.7474\n",
      "Epoch 28 | Train Loss: 0.7369 | Val Loss: 0.7267\n",
      "Epoch 29 | Train Loss: 0.7628 | Val Loss: 0.7826\n",
      "Epoch 30 | Train Loss: 0.7589 | Val Loss: 0.7701\n",
      "Epoch 31 | Train Loss: 0.7491 | Val Loss: 0.7387\n",
      "Epoch 32 | Train Loss: 0.7433 | Val Loss: 0.7391\n",
      "Epoch 33 | Train Loss: 0.7365 | Val Loss: 0.7286\n",
      "Epoch 34 | Train Loss: 0.7239 | Val Loss: 0.7273\n",
      "Epoch 35 | Train Loss: 0.7398 | Val Loss: 0.7153\n",
      "Epoch 36 | Train Loss: 0.7474 | Val Loss: 0.7878\n",
      "Epoch 37 | Train Loss: 0.7407 | Val Loss: 0.7419\n",
      "Epoch 38 | Train Loss: 0.7337 | Val Loss: 0.7262\n",
      "Epoch 39 | Train Loss: 0.7152 | Val Loss: 0.7912\n",
      "Epoch 40 | Train Loss: 0.7283 | Val Loss: 0.7203\n",
      "Epoch 41 | Train Loss: 0.7308 | Val Loss: 0.7169\n",
      "Epoch 42 | Train Loss: 0.7290 | Val Loss: 0.7559\n",
      "Epoch 43 | Train Loss: 0.7248 | Val Loss: 0.7133\n",
      "Epoch 44 | Train Loss: 0.7786 | Val Loss: 0.7178\n",
      "Epoch 45 | Train Loss: 0.7356 | Val Loss: 0.7691\n",
      "Epoch 46 | Train Loss: 0.7195 | Val Loss: 0.6955\n",
      "Epoch 47 | Train Loss: 0.7590 | Val Loss: 0.7096\n",
      "Epoch 48 | Train Loss: 0.7286 | Val Loss: 0.7578\n",
      "Epoch 49 | Train Loss: 0.7314 | Val Loss: 0.7037\n",
      "Epoch 50 | Train Loss: 0.7236 | Val Loss: 0.7266\n",
      "Fold 2 ‚ñ∂ AUC: 0.675, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9227 | Val Loss: 0.8562\n",
      "Epoch 02 | Train Loss: 0.8722 | Val Loss: 0.8507\n",
      "Epoch 03 | Train Loss: 0.8653 | Val Loss: 0.8620\n",
      "Epoch 04 | Train Loss: 0.8653 | Val Loss: 0.8751\n",
      "Epoch 05 | Train Loss: 0.8895 | Val Loss: 0.8342\n",
      "Epoch 06 | Train Loss: 0.8815 | Val Loss: 0.8413\n",
      "Epoch 07 | Train Loss: 0.8473 | Val Loss: 0.8529\n",
      "Epoch 08 | Train Loss: 0.8335 | Val Loss: 0.8034\n",
      "Epoch 09 | Train Loss: 0.8186 | Val Loss: 0.8503\n",
      "Epoch 10 | Train Loss: 0.8081 | Val Loss: 0.8151\n",
      "Epoch 11 | Train Loss: 0.7827 | Val Loss: 0.7603\n",
      "Epoch 12 | Train Loss: 0.7896 | Val Loss: 0.7508\n",
      "Epoch 13 | Train Loss: 0.7782 | Val Loss: 0.7489\n",
      "Epoch 14 | Train Loss: 0.7857 | Val Loss: 0.7767\n",
      "Epoch 15 | Train Loss: 0.7583 | Val Loss: 0.7662\n",
      "Epoch 16 | Train Loss: 0.7598 | Val Loss: 0.7870\n",
      "Epoch 17 | Train Loss: 0.7753 | Val Loss: 0.8332\n",
      "Epoch 18 | Train Loss: 0.7896 | Val Loss: 0.7849\n",
      "Epoch 19 | Train Loss: 0.7800 | Val Loss: 0.7417\n",
      "Epoch 20 | Train Loss: 0.7526 | Val Loss: 0.7356\n",
      "Epoch 21 | Train Loss: 0.7618 | Val Loss: 0.7826\n",
      "Epoch 22 | Train Loss: 0.7578 | Val Loss: 0.7378\n",
      "Epoch 23 | Train Loss: 0.7358 | Val Loss: 0.7352\n",
      "Epoch 24 | Train Loss: 0.7267 | Val Loss: 0.7436\n",
      "Epoch 25 | Train Loss: 0.7585 | Val Loss: 0.7272\n",
      "Epoch 26 | Train Loss: 0.7718 | Val Loss: 0.7526\n",
      "Epoch 27 | Train Loss: 0.7544 | Val Loss: 0.7313\n",
      "Epoch 28 | Train Loss: 0.7501 | Val Loss: 0.7733\n",
      "Epoch 29 | Train Loss: 0.7497 | Val Loss: 0.7248\n",
      "Epoch 30 | Train Loss: 0.7259 | Val Loss: 0.7372\n",
      "Epoch 31 | Train Loss: 0.7175 | Val Loss: 0.7199\n",
      "Epoch 32 | Train Loss: 0.7167 | Val Loss: 0.7191\n",
      "Epoch 33 | Train Loss: 0.7091 | Val Loss: 0.7307\n",
      "Epoch 34 | Train Loss: 0.7262 | Val Loss: 0.7332\n",
      "Epoch 35 | Train Loss: 0.7204 | Val Loss: 0.7331\n",
      "Epoch 36 | Train Loss: 0.7465 | Val Loss: 0.7173\n",
      "Epoch 37 | Train Loss: 0.7297 | Val Loss: 0.7235\n",
      "Epoch 38 | Train Loss: 0.7262 | Val Loss: 0.7158\n",
      "Epoch 39 | Train Loss: 0.7092 | Val Loss: 0.7343\n",
      "Epoch 40 | Train Loss: 0.7049 | Val Loss: 0.7371\n",
      "Epoch 41 | Train Loss: 0.7455 | Val Loss: 0.7479\n",
      "Epoch 42 | Train Loss: 0.7662 | Val Loss: 0.7446\n",
      "Epoch 43 | Train Loss: 0.7498 | Val Loss: 0.7197\n",
      "Epoch 44 | Train Loss: 0.7360 | Val Loss: 0.7157\n",
      "Epoch 45 | Train Loss: 0.7232 | Val Loss: 0.7253\n",
      "Epoch 46 | Train Loss: 0.7172 | Val Loss: 0.7132\n",
      "Epoch 47 | Train Loss: 0.7025 | Val Loss: 0.7178\n",
      "Epoch 48 | Train Loss: 0.7235 | Val Loss: 0.7146\n",
      "Epoch 49 | Train Loss: 0.7164 | Val Loss: 0.7353\n",
      "Epoch 50 | Train Loss: 0.7136 | Val Loss: 0.7139\n",
      "Fold 3 ‚ñ∂ AUC: 0.758, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.8966 | Val Loss: 0.8498\n",
      "Epoch 02 | Train Loss: 0.8618 | Val Loss: 0.8443\n",
      "Epoch 03 | Train Loss: 0.8687 | Val Loss: 0.8536\n",
      "Epoch 04 | Train Loss: 0.8621 | Val Loss: 0.8285\n",
      "Epoch 05 | Train Loss: 0.8563 | Val Loss: 0.8214\n",
      "Epoch 06 | Train Loss: 0.8502 | Val Loss: 0.8002\n",
      "Epoch 07 | Train Loss: 0.8547 | Val Loss: 0.7794\n",
      "Epoch 08 | Train Loss: 0.8112 | Val Loss: 0.7655\n",
      "Epoch 09 | Train Loss: 0.8005 | Val Loss: 0.7438\n",
      "Epoch 10 | Train Loss: 0.7856 | Val Loss: 0.7295\n",
      "Epoch 11 | Train Loss: 0.7806 | Val Loss: 0.7789\n",
      "Epoch 12 | Train Loss: 0.8318 | Val Loss: 0.7504\n",
      "Epoch 13 | Train Loss: 0.7806 | Val Loss: 0.7154\n",
      "Epoch 14 | Train Loss: 0.7654 | Val Loss: 0.6946\n",
      "Epoch 15 | Train Loss: 0.7491 | Val Loss: 0.7169\n",
      "Epoch 16 | Train Loss: 0.7808 | Val Loss: 0.6825\n",
      "Epoch 17 | Train Loss: 0.7900 | Val Loss: 0.6953\n",
      "Epoch 18 | Train Loss: 0.7520 | Val Loss: 0.6788\n",
      "Epoch 19 | Train Loss: 0.7542 | Val Loss: 0.6975\n",
      "Epoch 20 | Train Loss: 0.7493 | Val Loss: 0.6947\n",
      "Epoch 21 | Train Loss: 0.7592 | Val Loss: 0.6733\n",
      "Epoch 22 | Train Loss: 0.7593 | Val Loss: 0.6680\n",
      "Epoch 23 | Train Loss: 0.7660 | Val Loss: 0.6814\n",
      "Epoch 24 | Train Loss: 0.7567 | Val Loss: 0.7314\n",
      "Epoch 25 | Train Loss: 0.7539 | Val Loss: 0.6853\n",
      "Epoch 26 | Train Loss: 0.7460 | Val Loss: 0.6627\n",
      "Epoch 27 | Train Loss: 0.7406 | Val Loss: 0.6692\n",
      "Epoch 28 | Train Loss: 0.7658 | Val Loss: 0.6757\n",
      "Epoch 29 | Train Loss: 0.7429 | Val Loss: 0.6669\n",
      "Epoch 30 | Train Loss: 0.7232 | Val Loss: 0.6668\n",
      "Epoch 31 | Train Loss: 0.7281 | Val Loss: 0.6677\n",
      "Epoch 32 | Train Loss: 0.7265 | Val Loss: 0.6746\n",
      "Epoch 33 | Train Loss: 0.7503 | Val Loss: 0.6591\n",
      "Epoch 34 | Train Loss: 0.7312 | Val Loss: 0.6602\n",
      "Epoch 35 | Train Loss: 0.7154 | Val Loss: 0.6864\n",
      "Epoch 36 | Train Loss: 0.7285 | Val Loss: 0.6635\n",
      "Epoch 37 | Train Loss: 0.7516 | Val Loss: 0.6709\n",
      "Epoch 38 | Train Loss: 0.7366 | Val Loss: 0.6621\n",
      "Epoch 39 | Train Loss: 0.7337 | Val Loss: 0.6881\n",
      "Epoch 40 | Train Loss: 0.7347 | Val Loss: 0.6588\n",
      "Epoch 41 | Train Loss: 0.7465 | Val Loss: 0.6780\n",
      "Epoch 42 | Train Loss: 0.7243 | Val Loss: 0.6724\n",
      "Epoch 43 | Train Loss: 0.7338 | Val Loss: 0.6539\n",
      "Epoch 44 | Train Loss: 0.7193 | Val Loss: 0.6678\n",
      "Epoch 45 | Train Loss: 0.7423 | Val Loss: 0.6747\n",
      "Epoch 46 | Train Loss: 0.7181 | Val Loss: 0.6737\n",
      "Epoch 47 | Train Loss: 0.7236 | Val Loss: 0.6654\n",
      "Epoch 48 | Train Loss: 0.7165 | Val Loss: 0.6741\n",
      "Epoch 49 | Train Loss: 0.7123 | Val Loss: 0.6678\n",
      "Epoch 50 | Train Loss: 0.7210 | Val Loss: 0.6733\n",
      "Fold 4 ‚ñ∂ AUC: 0.769, Balanced Acc: 0.520\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9778 | Val Loss: 0.9230\n",
      "Epoch 02 | Train Loss: 0.8778 | Val Loss: 0.8948\n",
      "Epoch 03 | Train Loss: 0.8635 | Val Loss: 0.8964\n",
      "Epoch 04 | Train Loss: 0.8810 | Val Loss: 0.8844\n",
      "Epoch 05 | Train Loss: 0.8506 | Val Loss: 0.8779\n",
      "Epoch 06 | Train Loss: 0.8463 | Val Loss: 0.8740\n",
      "Epoch 07 | Train Loss: 0.8269 | Val Loss: 0.8653\n",
      "Epoch 08 | Train Loss: 0.8252 | Val Loss: 0.8421\n",
      "Epoch 09 | Train Loss: 0.8183 | Val Loss: 0.8341\n",
      "Epoch 10 | Train Loss: 0.8180 | Val Loss: 0.8236\n",
      "Epoch 11 | Train Loss: 0.7835 | Val Loss: 0.8190\n",
      "Epoch 12 | Train Loss: 0.7617 | Val Loss: 0.8203\n",
      "Epoch 13 | Train Loss: 0.7720 | Val Loss: 0.8211\n",
      "Epoch 14 | Train Loss: 0.7672 | Val Loss: 0.8365\n",
      "Epoch 15 | Train Loss: 0.8080 | Val Loss: 0.8649\n",
      "Epoch 16 | Train Loss: 0.7784 | Val Loss: 0.8370\n",
      "Epoch 17 | Train Loss: 0.7592 | Val Loss: 0.8237\n",
      "Epoch 18 | Train Loss: 0.7561 | Val Loss: 0.8257\n",
      "Epoch 19 | Train Loss: 0.7507 | Val Loss: 0.8260\n",
      "Epoch 20 | Train Loss: 0.7501 | Val Loss: 0.8170\n",
      "Epoch 21 | Train Loss: 0.7767 | Val Loss: 0.8291\n",
      "Epoch 22 | Train Loss: 0.7691 | Val Loss: 0.8316\n",
      "Epoch 23 | Train Loss: 0.7385 | Val Loss: 0.8113\n",
      "Epoch 24 | Train Loss: 0.7382 | Val Loss: 0.8551\n",
      "Epoch 25 | Train Loss: 0.7811 | Val Loss: 0.8099\n",
      "Epoch 26 | Train Loss: 0.7521 | Val Loss: 0.8308\n",
      "Epoch 27 | Train Loss: 0.7267 | Val Loss: 0.8089\n",
      "Epoch 28 | Train Loss: 0.7262 | Val Loss: 0.8062\n",
      "Epoch 29 | Train Loss: 0.7313 | Val Loss: 0.8097\n",
      "Epoch 30 | Train Loss: 0.7040 | Val Loss: 0.8013\n",
      "Epoch 31 | Train Loss: 0.7256 | Val Loss: 0.7957\n",
      "Epoch 32 | Train Loss: 0.7150 | Val Loss: 0.8125\n",
      "Epoch 33 | Train Loss: 0.7323 | Val Loss: 0.7941\n",
      "Epoch 34 | Train Loss: 0.7196 | Val Loss: 0.7847\n",
      "Epoch 35 | Train Loss: 0.7312 | Val Loss: 0.8216\n",
      "Epoch 36 | Train Loss: 0.7068 | Val Loss: 0.8534\n",
      "Epoch 37 | Train Loss: 0.7523 | Val Loss: 0.8076\n",
      "Epoch 38 | Train Loss: 0.7277 | Val Loss: 0.7903\n",
      "Epoch 39 | Train Loss: 0.7039 | Val Loss: 0.7928\n",
      "Epoch 40 | Train Loss: 0.7203 | Val Loss: 0.7946\n",
      "Epoch 41 | Train Loss: 0.7227 | Val Loss: 0.8065\n",
      "Epoch 42 | Train Loss: 0.7146 | Val Loss: 0.7837\n",
      "Epoch 43 | Train Loss: 0.7229 | Val Loss: 0.7828\n",
      "Epoch 44 | Train Loss: 0.7072 | Val Loss: 0.8224\n",
      "Epoch 45 | Train Loss: 0.7300 | Val Loss: 0.7960\n",
      "Epoch 46 | Train Loss: 0.7173 | Val Loss: 0.7932\n",
      "Epoch 47 | Train Loss: 0.7148 | Val Loss: 0.7785\n",
      "Epoch 48 | Train Loss: 0.7215 | Val Loss: 0.7847\n",
      "Epoch 49 | Train Loss: 0.7163 | Val Loss: 0.7806\n",
      "Epoch 50 | Train Loss: 0.7143 | Val Loss: 0.7844\n",
      "Fold 5 ‚ñ∂ AUC: 0.736, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9330 | Val Loss: 0.9189\n",
      "Epoch 02 | Train Loss: 0.8902 | Val Loss: 0.8944\n",
      "Epoch 03 | Train Loss: 0.8726 | Val Loss: 0.8922\n",
      "Epoch 04 | Train Loss: 0.8669 | Val Loss: 0.8874\n",
      "Epoch 05 | Train Loss: 0.8433 | Val Loss: 0.8826\n",
      "Epoch 06 | Train Loss: 0.8487 | Val Loss: 0.8832\n",
      "Epoch 07 | Train Loss: 0.8478 | Val Loss: 0.8650\n",
      "Epoch 08 | Train Loss: 0.8323 | Val Loss: 0.8555\n",
      "Epoch 09 | Train Loss: 0.8036 | Val Loss: 0.8848\n",
      "Epoch 10 | Train Loss: 0.8049 | Val Loss: 0.8434\n",
      "Epoch 11 | Train Loss: 0.8176 | Val Loss: 0.8330\n",
      "Epoch 12 | Train Loss: 0.7566 | Val Loss: 0.8416\n",
      "Epoch 13 | Train Loss: 0.7645 | Val Loss: 0.8700\n",
      "Epoch 14 | Train Loss: 0.7699 | Val Loss: 0.8797\n",
      "Epoch 15 | Train Loss: 0.7811 | Val Loss: 0.8322\n",
      "Epoch 16 | Train Loss: 0.7789 | Val Loss: 0.8263\n",
      "Epoch 17 | Train Loss: 0.7534 | Val Loss: 0.8254\n",
      "Epoch 18 | Train Loss: 0.7518 | Val Loss: 0.8199\n",
      "Epoch 19 | Train Loss: 0.7487 | Val Loss: 0.8393\n",
      "Epoch 20 | Train Loss: 0.7528 | Val Loss: 0.8124\n",
      "Epoch 21 | Train Loss: 0.7426 | Val Loss: 0.8227\n",
      "Epoch 22 | Train Loss: 0.7527 | Val Loss: 0.8509\n",
      "Epoch 23 | Train Loss: 0.7309 | Val Loss: 0.8098\n",
      "Epoch 24 | Train Loss: 0.7284 | Val Loss: 0.8470\n",
      "Epoch 25 | Train Loss: 0.7502 | Val Loss: 0.8150\n",
      "Epoch 26 | Train Loss: 0.7312 | Val Loss: 0.8115\n",
      "Epoch 27 | Train Loss: 0.7255 | Val Loss: 0.8177\n",
      "Epoch 28 | Train Loss: 0.7178 | Val Loss: 0.8169\n",
      "Epoch 29 | Train Loss: 0.7442 | Val Loss: 0.8227\n",
      "Epoch 30 | Train Loss: 0.7384 | Val Loss: 0.8107\n",
      "Epoch 31 | Train Loss: 0.7498 | Val Loss: 0.8557\n",
      "Epoch 32 | Train Loss: 0.7016 | Val Loss: 0.8266\n",
      "Epoch 33 | Train Loss: 0.7363 | Val Loss: 0.8201\n",
      "Epoch 34 | Train Loss: 0.7143 | Val Loss: 0.8171\n",
      "Epoch 35 | Train Loss: 0.7104 | Val Loss: 0.8271\n",
      "Epoch 36 | Train Loss: 0.6983 | Val Loss: 0.8406\n",
      "Epoch 37 | Train Loss: 0.7013 | Val Loss: 0.8484\n",
      "Epoch 38 | Train Loss: 0.7519 | Val Loss: 0.8426\n",
      "Epoch 39 | Train Loss: 0.7159 | Val Loss: 0.8350\n",
      "Epoch 40 | Train Loss: 0.7183 | Val Loss: 0.8249\n",
      "Epoch 41 | Train Loss: 0.7255 | Val Loss: 0.8172\n",
      "Epoch 42 | Train Loss: 0.7192 | Val Loss: 0.8233\n",
      "Epoch 43 | Train Loss: 0.7201 | Val Loss: 0.8162\n",
      "Epoch 44 | Train Loss: 0.7049 | Val Loss: 0.8080\n",
      "Epoch 45 | Train Loss: 0.6965 | Val Loss: 0.8271\n",
      "Epoch 46 | Train Loss: 0.6926 | Val Loss: 0.8316\n",
      "Epoch 47 | Train Loss: 0.7256 | Val Loss: 0.8210\n",
      "Epoch 48 | Train Loss: 0.7207 | Val Loss: 0.8160\n",
      "Epoch 49 | Train Loss: 0.7065 | Val Loss: 0.8576\n",
      "Epoch 50 | Train Loss: 0.6894 | Val Loss: 0.8349\n",
      "Fold 6 ‚ñ∂ AUC: 0.723, Balanced Acc: 0.486\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9162 | Val Loss: 0.8601\n",
      "Epoch 02 | Train Loss: 0.8915 | Val Loss: 0.8706\n",
      "Epoch 03 | Train Loss: 0.8721 | Val Loss: 0.8413\n",
      "Epoch 04 | Train Loss: 0.8584 | Val Loss: 0.8255\n",
      "Epoch 05 | Train Loss: 0.8462 | Val Loss: 0.8647\n",
      "Epoch 06 | Train Loss: 0.8308 | Val Loss: 0.7904\n",
      "Epoch 07 | Train Loss: 0.8280 | Val Loss: 0.7637\n",
      "Epoch 08 | Train Loss: 0.8071 | Val Loss: 0.7454\n",
      "Epoch 09 | Train Loss: 0.7990 | Val Loss: 0.7605\n",
      "Epoch 10 | Train Loss: 0.8181 | Val Loss: 0.8127\n",
      "Epoch 11 | Train Loss: 0.7995 | Val Loss: 0.7380\n",
      "Epoch 12 | Train Loss: 0.8011 | Val Loss: 0.7177\n",
      "Epoch 13 | Train Loss: 0.7767 | Val Loss: 0.7186\n",
      "Epoch 14 | Train Loss: 0.7729 | Val Loss: 0.7058\n",
      "Epoch 15 | Train Loss: 0.7633 | Val Loss: 0.7054\n",
      "Epoch 16 | Train Loss: 0.7646 | Val Loss: 0.7502\n",
      "Epoch 17 | Train Loss: 0.7676 | Val Loss: 0.7117\n",
      "Epoch 18 | Train Loss: 0.7684 | Val Loss: 0.7079\n",
      "Epoch 19 | Train Loss: 0.7808 | Val Loss: 0.7098\n",
      "Epoch 20 | Train Loss: 0.7716 | Val Loss: 0.7193\n",
      "Epoch 21 | Train Loss: 0.7440 | Val Loss: 0.7106\n",
      "Epoch 22 | Train Loss: 0.7495 | Val Loss: 0.7137\n",
      "Epoch 23 | Train Loss: 0.7413 | Val Loss: 0.7255\n",
      "Epoch 24 | Train Loss: 0.7490 | Val Loss: 0.7145\n",
      "Epoch 25 | Train Loss: 0.7432 | Val Loss: 0.7203\n",
      "Epoch 26 | Train Loss: 0.7339 | Val Loss: 0.7425\n",
      "Epoch 27 | Train Loss: 0.7219 | Val Loss: 0.7210\n",
      "Epoch 28 | Train Loss: 0.7360 | Val Loss: 0.7178\n",
      "Epoch 29 | Train Loss: 0.7165 | Val Loss: 0.7361\n",
      "Epoch 30 | Train Loss: 0.7322 | Val Loss: 0.7288\n",
      "Epoch 31 | Train Loss: 0.7583 | Val Loss: 0.7361\n",
      "Epoch 32 | Train Loss: 0.7594 | Val Loss: 0.7189\n",
      "Epoch 33 | Train Loss: 0.7139 | Val Loss: 0.7313\n",
      "Epoch 34 | Train Loss: 0.7212 | Val Loss: 0.7274\n",
      "Epoch 35 | Train Loss: 0.7186 | Val Loss: 0.7356\n",
      "Epoch 36 | Train Loss: 0.7170 | Val Loss: 0.7273\n",
      "Epoch 37 | Train Loss: 0.7321 | Val Loss: 0.7373\n",
      "Epoch 38 | Train Loss: 0.7104 | Val Loss: 0.7319\n",
      "Epoch 39 | Train Loss: 0.7202 | Val Loss: 0.7341\n",
      "Epoch 40 | Train Loss: 0.7238 | Val Loss: 0.7314\n",
      "Epoch 41 | Train Loss: 0.7119 | Val Loss: 0.7351\n",
      "Epoch 42 | Train Loss: 0.7330 | Val Loss: 0.7370\n",
      "Epoch 43 | Train Loss: 0.7003 | Val Loss: 0.7440\n",
      "Epoch 44 | Train Loss: 0.7098 | Val Loss: 0.7705\n",
      "Epoch 45 | Train Loss: 0.7358 | Val Loss: 0.7859\n",
      "Epoch 46 | Train Loss: 0.7202 | Val Loss: 0.7400\n",
      "Epoch 47 | Train Loss: 0.7008 | Val Loss: 0.7434\n",
      "Epoch 48 | Train Loss: 0.7074 | Val Loss: 0.7386\n",
      "Epoch 49 | Train Loss: 0.7120 | Val Loss: 0.7514\n",
      "Epoch 50 | Train Loss: 0.7169 | Val Loss: 0.7534\n",
      "Fold 7 ‚ñ∂ AUC: 0.747, Balanced Acc: 0.456\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9040 | Val Loss: 0.8844\n",
      "Epoch 02 | Train Loss: 0.8808 | Val Loss: 0.8642\n",
      "Epoch 03 | Train Loss: 0.8698 | Val Loss: 0.8547\n",
      "Epoch 04 | Train Loss: 0.8525 | Val Loss: 0.8422\n",
      "Epoch 05 | Train Loss: 0.8352 | Val Loss: 0.8269\n",
      "Epoch 06 | Train Loss: 0.8221 | Val Loss: 0.8098\n",
      "Epoch 07 | Train Loss: 0.8055 | Val Loss: 0.8045\n",
      "Epoch 08 | Train Loss: 0.7886 | Val Loss: 0.8164\n",
      "Epoch 09 | Train Loss: 0.7973 | Val Loss: 0.8209\n",
      "Epoch 10 | Train Loss: 0.7734 | Val Loss: 0.7952\n",
      "Epoch 11 | Train Loss: 0.7844 | Val Loss: 0.8128\n",
      "Epoch 12 | Train Loss: 0.7632 | Val Loss: 0.8470\n",
      "Epoch 13 | Train Loss: 0.7524 | Val Loss: 0.7932\n",
      "Epoch 14 | Train Loss: 0.7432 | Val Loss: 0.8225\n",
      "Epoch 15 | Train Loss: 0.7666 | Val Loss: 0.8090\n",
      "Epoch 16 | Train Loss: 0.7632 | Val Loss: 0.8262\n",
      "Epoch 17 | Train Loss: 0.7305 | Val Loss: 0.8008\n",
      "Epoch 18 | Train Loss: 0.7353 | Val Loss: 0.8021\n",
      "Epoch 19 | Train Loss: 0.7321 | Val Loss: 0.8509\n",
      "Epoch 20 | Train Loss: 0.7871 | Val Loss: 0.7934\n",
      "Epoch 21 | Train Loss: 0.7582 | Val Loss: 0.8299\n",
      "Epoch 22 | Train Loss: 0.7350 | Val Loss: 0.7966\n",
      "Epoch 23 | Train Loss: 0.7279 | Val Loss: 0.8058\n",
      "Epoch 24 | Train Loss: 0.7260 | Val Loss: 0.8046\n",
      "Epoch 25 | Train Loss: 0.7166 | Val Loss: 0.8102\n",
      "Epoch 26 | Train Loss: 0.7197 | Val Loss: 0.8164\n",
      "Epoch 27 | Train Loss: 0.7550 | Val Loss: 0.8000\n",
      "Epoch 28 | Train Loss: 0.7324 | Val Loss: 0.8313\n",
      "Epoch 29 | Train Loss: 0.7215 | Val Loss: 0.8101\n",
      "Epoch 30 | Train Loss: 0.7195 | Val Loss: 0.7947\n",
      "Epoch 31 | Train Loss: 0.6974 | Val Loss: 0.8238\n",
      "Epoch 32 | Train Loss: 0.7054 | Val Loss: 0.8222\n",
      "Epoch 33 | Train Loss: 0.7296 | Val Loss: 0.8010\n",
      "Epoch 34 | Train Loss: 0.7287 | Val Loss: 0.8250\n",
      "Epoch 35 | Train Loss: 0.7077 | Val Loss: 0.7864\n",
      "Epoch 36 | Train Loss: 0.7353 | Val Loss: 0.8104\n",
      "Epoch 37 | Train Loss: 0.7278 | Val Loss: 0.8109\n",
      "Epoch 38 | Train Loss: 0.7114 | Val Loss: 0.8021\n",
      "Epoch 39 | Train Loss: 0.7008 | Val Loss: 0.7920\n",
      "Epoch 40 | Train Loss: 0.6945 | Val Loss: 0.8094\n",
      "Epoch 41 | Train Loss: 0.7128 | Val Loss: 0.8216\n",
      "Epoch 42 | Train Loss: 0.7073 | Val Loss: 0.8065\n",
      "Epoch 43 | Train Loss: 0.7087 | Val Loss: 0.8128\n",
      "Epoch 44 | Train Loss: 0.7084 | Val Loss: 0.8071\n",
      "Epoch 45 | Train Loss: 0.7059 | Val Loss: 0.8119\n",
      "Epoch 46 | Train Loss: 0.7075 | Val Loss: 0.8297\n",
      "Epoch 47 | Train Loss: 0.6903 | Val Loss: 0.8212\n",
      "Epoch 48 | Train Loss: 0.6857 | Val Loss: 0.8295\n",
      "Epoch 49 | Train Loss: 0.7088 | Val Loss: 0.8276\n",
      "Epoch 50 | Train Loss: 0.6958 | Val Loss: 0.8155\n",
      "Fold 8 ‚ñ∂ AUC: 0.694, Balanced Acc: 0.451\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.8847 | Val Loss: 0.9028\n",
      "Epoch 02 | Train Loss: 0.8790 | Val Loss: 0.8755\n",
      "Epoch 03 | Train Loss: 0.8648 | Val Loss: 0.8607\n",
      "Epoch 04 | Train Loss: 0.8472 | Val Loss: 0.8635\n",
      "Epoch 05 | Train Loss: 0.8473 | Val Loss: 0.8500\n",
      "Epoch 06 | Train Loss: 0.8317 | Val Loss: 0.8806\n",
      "Epoch 07 | Train Loss: 0.8406 | Val Loss: 0.8576\n",
      "Epoch 08 | Train Loss: 0.8232 | Val Loss: 0.8501\n",
      "Epoch 09 | Train Loss: 0.8015 | Val Loss: 0.8230\n",
      "Epoch 10 | Train Loss: 0.8143 | Val Loss: 0.8230\n",
      "Epoch 11 | Train Loss: 0.7669 | Val Loss: 0.8107\n",
      "Epoch 12 | Train Loss: 0.7602 | Val Loss: 0.8308\n",
      "Epoch 13 | Train Loss: 0.7780 | Val Loss: 0.8164\n",
      "Epoch 14 | Train Loss: 0.7691 | Val Loss: 0.8419\n",
      "Epoch 15 | Train Loss: 0.7628 | Val Loss: 0.8069\n",
      "Epoch 16 | Train Loss: 0.7545 | Val Loss: 0.7920\n",
      "Epoch 17 | Train Loss: 0.7393 | Val Loss: 0.8675\n",
      "Epoch 18 | Train Loss: 0.7670 | Val Loss: 0.8174\n",
      "Epoch 19 | Train Loss: 0.7347 | Val Loss: 0.7831\n",
      "Epoch 20 | Train Loss: 0.7362 | Val Loss: 0.7786\n",
      "Epoch 21 | Train Loss: 0.7579 | Val Loss: 0.7679\n",
      "Epoch 22 | Train Loss: 0.7431 | Val Loss: 0.7879\n",
      "Epoch 23 | Train Loss: 0.7321 | Val Loss: 0.7877\n",
      "Epoch 24 | Train Loss: 0.7299 | Val Loss: 0.7664\n",
      "Epoch 25 | Train Loss: 0.7337 | Val Loss: 0.7670\n",
      "Epoch 26 | Train Loss: 0.7199 | Val Loss: 0.7632\n",
      "Epoch 27 | Train Loss: 0.7507 | Val Loss: 0.7788\n",
      "Epoch 28 | Train Loss: 0.7544 | Val Loss: 0.7888\n",
      "Epoch 29 | Train Loss: 0.7436 | Val Loss: 0.7497\n",
      "Epoch 30 | Train Loss: 0.7264 | Val Loss: 0.7603\n",
      "Epoch 31 | Train Loss: 0.7164 | Val Loss: 0.7675\n",
      "Epoch 32 | Train Loss: 0.7420 | Val Loss: 0.7607\n",
      "Epoch 33 | Train Loss: 0.7258 | Val Loss: 0.7606\n",
      "Epoch 34 | Train Loss: 0.7139 | Val Loss: 0.7611\n",
      "Epoch 35 | Train Loss: 0.7168 | Val Loss: 0.7795\n",
      "Epoch 36 | Train Loss: 0.7257 | Val Loss: 0.7490\n",
      "Epoch 37 | Train Loss: 0.7161 | Val Loss: 0.7608\n",
      "Epoch 38 | Train Loss: 0.7064 | Val Loss: 0.7715\n",
      "Epoch 39 | Train Loss: 0.7276 | Val Loss: 0.7560\n",
      "Epoch 40 | Train Loss: 0.7219 | Val Loss: 0.7776\n",
      "Epoch 41 | Train Loss: 0.7206 | Val Loss: 0.8093\n",
      "Epoch 42 | Train Loss: 0.7363 | Val Loss: 0.7604\n",
      "Epoch 43 | Train Loss: 0.7164 | Val Loss: 0.7477\n",
      "Epoch 44 | Train Loss: 0.7330 | Val Loss: 0.7501\n",
      "Epoch 45 | Train Loss: 0.7339 | Val Loss: 0.7433\n",
      "Epoch 46 | Train Loss: 0.7051 | Val Loss: 0.7459\n",
      "Epoch 47 | Train Loss: 0.7097 | Val Loss: 0.7349\n",
      "Epoch 48 | Train Loss: 0.7067 | Val Loss: 0.7741\n",
      "Epoch 49 | Train Loss: 0.7174 | Val Loss: 0.7530\n",
      "Epoch 50 | Train Loss: 0.7129 | Val Loss: 0.7190\n",
      "Fold 9 ‚ñ∂ AUC: 0.762, Balanced Acc: 0.508\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9157 | Val Loss: 0.8686\n",
      "Epoch 02 | Train Loss: 0.8634 | Val Loss: 0.8757\n",
      "Epoch 03 | Train Loss: 0.8738 | Val Loss: 0.8534\n",
      "Epoch 04 | Train Loss: 0.8637 | Val Loss: 0.8478\n",
      "Epoch 05 | Train Loss: 0.8402 | Val Loss: 0.8408\n",
      "Epoch 06 | Train Loss: 0.8306 | Val Loss: 0.8211\n",
      "Epoch 07 | Train Loss: 0.8247 | Val Loss: 0.8004\n",
      "Epoch 08 | Train Loss: 0.8182 | Val Loss: 0.7967\n",
      "Epoch 09 | Train Loss: 0.8092 | Val Loss: 0.7884\n",
      "Epoch 10 | Train Loss: 0.7707 | Val Loss: 0.7960\n",
      "Epoch 11 | Train Loss: 0.7782 | Val Loss: 0.7652\n",
      "Epoch 12 | Train Loss: 0.7629 | Val Loss: 0.7585\n",
      "Epoch 13 | Train Loss: 0.7731 | Val Loss: 0.7584\n",
      "Epoch 14 | Train Loss: 0.7450 | Val Loss: 0.7646\n",
      "Epoch 15 | Train Loss: 0.7525 | Val Loss: 0.7558\n",
      "Epoch 16 | Train Loss: 0.7941 | Val Loss: 0.7834\n",
      "Epoch 17 | Train Loss: 0.7662 | Val Loss: 0.7669\n",
      "Epoch 18 | Train Loss: 0.7491 | Val Loss: 0.7709\n",
      "Epoch 19 | Train Loss: 0.7485 | Val Loss: 0.7655\n",
      "Epoch 20 | Train Loss: 0.7312 | Val Loss: 0.7885\n",
      "Epoch 21 | Train Loss: 0.7394 | Val Loss: 0.8148\n",
      "Epoch 22 | Train Loss: 0.7549 | Val Loss: 0.7680\n",
      "Epoch 23 | Train Loss: 0.7307 | Val Loss: 0.7683\n",
      "Epoch 24 | Train Loss: 0.7260 | Val Loss: 0.7670\n",
      "Epoch 25 | Train Loss: 0.7416 | Val Loss: 0.7728\n",
      "Epoch 26 | Train Loss: 0.7407 | Val Loss: 0.7770\n",
      "Epoch 27 | Train Loss: 0.7458 | Val Loss: 0.7905\n",
      "Epoch 28 | Train Loss: 0.7605 | Val Loss: 0.8013\n",
      "Epoch 29 | Train Loss: 0.7149 | Val Loss: 0.7707\n",
      "Epoch 30 | Train Loss: 0.7198 | Val Loss: 0.7634\n",
      "Epoch 31 | Train Loss: 0.7285 | Val Loss: 0.7626\n",
      "Epoch 32 | Train Loss: 0.7438 | Val Loss: 0.8530\n",
      "Epoch 33 | Train Loss: 0.7297 | Val Loss: 0.7699\n",
      "Epoch 34 | Train Loss: 0.7331 | Val Loss: 0.7681\n",
      "Epoch 35 | Train Loss: 0.7097 | Val Loss: 0.7652\n",
      "Epoch 36 | Train Loss: 0.6985 | Val Loss: 0.7654\n",
      "Epoch 37 | Train Loss: 0.7243 | Val Loss: 0.8047\n",
      "Epoch 38 | Train Loss: 0.7243 | Val Loss: 0.8282\n",
      "Epoch 39 | Train Loss: 0.7226 | Val Loss: 0.7969\n",
      "Epoch 40 | Train Loss: 0.7099 | Val Loss: 0.7869\n",
      "Epoch 41 | Train Loss: 0.7131 | Val Loss: 0.7821\n",
      "Epoch 42 | Train Loss: 0.7020 | Val Loss: 0.7727\n",
      "Epoch 43 | Train Loss: 0.7170 | Val Loss: 0.7902\n",
      "Epoch 44 | Train Loss: 0.7288 | Val Loss: 0.7675\n",
      "Epoch 45 | Train Loss: 0.7351 | Val Loss: 0.7734\n",
      "Epoch 46 | Train Loss: 0.7195 | Val Loss: 0.7826\n",
      "Epoch 47 | Train Loss: 0.7079 | Val Loss: 0.7682\n",
      "Epoch 48 | Train Loss: 0.7144 | Val Loss: 0.7752\n",
      "Epoch 49 | Train Loss: 0.7269 | Val Loss: 0.8017\n",
      "Epoch 50 | Train Loss: 0.7173 | Val Loss: 0.7885\n",
      "Fold 10 ‚ñ∂ AUC: 0.710, Balanced Acc: 0.451\n",
      "üîç Summary for hd=128, dp=0.2, lr=0.0005 ‚Üí AUC: 0.7357¬±0.0329 | BalAcc: 0.4882¬±0.0345\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.2, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 1.1708 | Val Loss: 0.9448\n",
      "Epoch 02 | Train Loss: 0.9172 | Val Loss: 0.8577\n",
      "Epoch 03 | Train Loss: 0.8837 | Val Loss: 0.8559\n",
      "Epoch 04 | Train Loss: 0.8752 | Val Loss: 0.8533\n",
      "Epoch 05 | Train Loss: 0.8683 | Val Loss: 0.8535\n",
      "Epoch 06 | Train Loss: 0.8692 | Val Loss: 0.8520\n",
      "Epoch 07 | Train Loss: 0.8637 | Val Loss: 0.8510\n",
      "Epoch 08 | Train Loss: 0.8637 | Val Loss: 0.8464\n",
      "Epoch 09 | Train Loss: 0.8620 | Val Loss: 0.8450\n",
      "Epoch 10 | Train Loss: 0.8574 | Val Loss: 0.8484\n",
      "Epoch 11 | Train Loss: 0.8576 | Val Loss: 0.8432\n",
      "Epoch 12 | Train Loss: 0.8380 | Val Loss: 0.8440\n",
      "Epoch 13 | Train Loss: 0.8513 | Val Loss: 0.8373\n",
      "Epoch 14 | Train Loss: 0.8401 | Val Loss: 0.8369\n",
      "Epoch 15 | Train Loss: 0.8453 | Val Loss: 0.8338\n",
      "Epoch 16 | Train Loss: 0.8562 | Val Loss: 0.8301\n",
      "Epoch 17 | Train Loss: 0.8453 | Val Loss: 0.8275\n",
      "Epoch 18 | Train Loss: 0.8375 | Val Loss: 0.8256\n",
      "Epoch 19 | Train Loss: 0.8436 | Val Loss: 0.8204\n",
      "Epoch 20 | Train Loss: 0.8240 | Val Loss: 0.8186\n",
      "Epoch 21 | Train Loss: 0.8271 | Val Loss: 0.8177\n",
      "Epoch 22 | Train Loss: 0.8299 | Val Loss: 0.8207\n",
      "Epoch 23 | Train Loss: 0.8328 | Val Loss: 0.8181\n",
      "Epoch 24 | Train Loss: 0.8135 | Val Loss: 0.8092\n",
      "Epoch 25 | Train Loss: 0.8194 | Val Loss: 0.7964\n",
      "Epoch 26 | Train Loss: 0.8085 | Val Loss: 0.7919\n",
      "Epoch 27 | Train Loss: 0.8003 | Val Loss: 0.7871\n",
      "Epoch 28 | Train Loss: 0.7937 | Val Loss: 0.7794\n",
      "Epoch 29 | Train Loss: 0.7840 | Val Loss: 0.7786\n",
      "Epoch 30 | Train Loss: 0.7932 | Val Loss: 0.7826\n",
      "Epoch 31 | Train Loss: 0.8015 | Val Loss: 0.7656\n",
      "Epoch 32 | Train Loss: 0.7933 | Val Loss: 0.7601\n",
      "Epoch 33 | Train Loss: 0.7705 | Val Loss: 0.7752\n",
      "Epoch 34 | Train Loss: 0.7974 | Val Loss: 0.7691\n",
      "Epoch 35 | Train Loss: 0.7753 | Val Loss: 0.7550\n",
      "Epoch 36 | Train Loss: 0.7673 | Val Loss: 0.7462\n",
      "Epoch 37 | Train Loss: 0.7710 | Val Loss: 0.7428\n",
      "Epoch 38 | Train Loss: 0.7788 | Val Loss: 0.7354\n",
      "Epoch 39 | Train Loss: 0.7578 | Val Loss: 0.7339\n",
      "Epoch 40 | Train Loss: 0.7539 | Val Loss: 0.7269\n",
      "Epoch 41 | Train Loss: 0.7631 | Val Loss: 0.7281\n",
      "Epoch 42 | Train Loss: 0.7661 | Val Loss: 0.7242\n",
      "Epoch 43 | Train Loss: 0.7680 | Val Loss: 0.7202\n",
      "Epoch 44 | Train Loss: 0.7529 | Val Loss: 0.7176\n",
      "Epoch 45 | Train Loss: 0.7761 | Val Loss: 0.7140\n",
      "Epoch 46 | Train Loss: 0.7711 | Val Loss: 0.7164\n",
      "Epoch 47 | Train Loss: 0.7675 | Val Loss: 0.7102\n",
      "Epoch 48 | Train Loss: 0.7382 | Val Loss: 0.7076\n",
      "Epoch 49 | Train Loss: 0.7423 | Val Loss: 0.7073\n",
      "Epoch 50 | Train Loss: 0.7615 | Val Loss: 0.7049\n",
      "Fold 1 ‚ñ∂ AUC: 0.759, Balanced Acc: 0.505\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 1.0160 | Val Loss: 0.8876\n",
      "Epoch 02 | Train Loss: 0.8754 | Val Loss: 0.8643\n",
      "Epoch 03 | Train Loss: 0.8788 | Val Loss: 0.8660\n",
      "Epoch 04 | Train Loss: 0.8700 | Val Loss: 0.8609\n",
      "Epoch 05 | Train Loss: 0.8700 | Val Loss: 0.8588\n",
      "Epoch 06 | Train Loss: 0.8620 | Val Loss: 0.8565\n",
      "Epoch 07 | Train Loss: 0.8873 | Val Loss: 0.8541\n",
      "Epoch 08 | Train Loss: 0.8650 | Val Loss: 0.8533\n",
      "Epoch 09 | Train Loss: 0.8690 | Val Loss: 0.8503\n",
      "Epoch 10 | Train Loss: 0.8713 | Val Loss: 0.8491\n",
      "Epoch 11 | Train Loss: 0.8577 | Val Loss: 0.8477\n",
      "Epoch 12 | Train Loss: 0.8497 | Val Loss: 0.8445\n",
      "Epoch 13 | Train Loss: 0.8648 | Val Loss: 0.8431\n",
      "Epoch 14 | Train Loss: 0.8567 | Val Loss: 0.8412\n",
      "Epoch 15 | Train Loss: 0.8565 | Val Loss: 0.8384\n",
      "Epoch 16 | Train Loss: 0.8469 | Val Loss: 0.8365\n",
      "Epoch 17 | Train Loss: 0.8481 | Val Loss: 0.8337\n",
      "Epoch 18 | Train Loss: 0.8456 | Val Loss: 0.8304\n",
      "Epoch 19 | Train Loss: 0.8648 | Val Loss: 0.8291\n",
      "Epoch 20 | Train Loss: 0.8366 | Val Loss: 0.8281\n",
      "Epoch 21 | Train Loss: 0.8349 | Val Loss: 0.8236\n",
      "Epoch 22 | Train Loss: 0.8291 | Val Loss: 0.8208\n",
      "Epoch 23 | Train Loss: 0.8267 | Val Loss: 0.8278\n",
      "Epoch 24 | Train Loss: 0.8202 | Val Loss: 0.8166\n",
      "Epoch 25 | Train Loss: 0.8137 | Val Loss: 0.8114\n",
      "Epoch 26 | Train Loss: 0.8246 | Val Loss: 0.8075\n",
      "Epoch 27 | Train Loss: 0.8149 | Val Loss: 0.8050\n",
      "Epoch 28 | Train Loss: 0.8043 | Val Loss: 0.8092\n",
      "Epoch 29 | Train Loss: 0.8116 | Val Loss: 0.8004\n",
      "Epoch 30 | Train Loss: 0.8128 | Val Loss: 0.8025\n",
      "Epoch 31 | Train Loss: 0.8019 | Val Loss: 0.8047\n",
      "Epoch 32 | Train Loss: 0.7978 | Val Loss: 0.7893\n",
      "Epoch 33 | Train Loss: 0.7910 | Val Loss: 0.7884\n",
      "Epoch 34 | Train Loss: 0.7921 | Val Loss: 0.7815\n",
      "Epoch 35 | Train Loss: 0.7678 | Val Loss: 0.7924\n",
      "Epoch 36 | Train Loss: 0.7902 | Val Loss: 0.7933\n",
      "Epoch 37 | Train Loss: 0.7712 | Val Loss: 0.7779\n",
      "Epoch 38 | Train Loss: 0.7780 | Val Loss: 0.7748\n",
      "Epoch 39 | Train Loss: 0.7704 | Val Loss: 0.7817\n",
      "Epoch 40 | Train Loss: 0.7641 | Val Loss: 0.7607\n",
      "Epoch 41 | Train Loss: 0.7697 | Val Loss: 0.7651\n",
      "Epoch 42 | Train Loss: 0.7709 | Val Loss: 0.7733\n",
      "Epoch 43 | Train Loss: 0.7626 | Val Loss: 0.7989\n",
      "Epoch 44 | Train Loss: 0.7738 | Val Loss: 0.7544\n",
      "Epoch 45 | Train Loss: 0.7527 | Val Loss: 0.7905\n",
      "Epoch 46 | Train Loss: 0.7639 | Val Loss: 0.7475\n",
      "Epoch 47 | Train Loss: 0.7625 | Val Loss: 0.7465\n",
      "Epoch 48 | Train Loss: 0.7548 | Val Loss: 0.7562\n",
      "Epoch 49 | Train Loss: 0.7627 | Val Loss: 0.7434\n",
      "Epoch 50 | Train Loss: 0.7614 | Val Loss: 0.7489\n",
      "Fold 2 ‚ñ∂ AUC: 0.649, Balanced Acc: 0.531\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9513 | Val Loss: 0.8747\n",
      "Epoch 02 | Train Loss: 0.8943 | Val Loss: 0.8672\n",
      "Epoch 03 | Train Loss: 0.8712 | Val Loss: 0.8608\n",
      "Epoch 04 | Train Loss: 0.8616 | Val Loss: 0.8563\n",
      "Epoch 05 | Train Loss: 0.8841 | Val Loss: 0.8543\n",
      "Epoch 06 | Train Loss: 0.8781 | Val Loss: 0.8516\n",
      "Epoch 07 | Train Loss: 0.8710 | Val Loss: 0.8484\n",
      "Epoch 08 | Train Loss: 0.8545 | Val Loss: 0.8453\n",
      "Epoch 09 | Train Loss: 0.8621 | Val Loss: 0.8409\n",
      "Epoch 10 | Train Loss: 0.8660 | Val Loss: 0.8381\n",
      "Epoch 11 | Train Loss: 0.8556 | Val Loss: 0.8374\n",
      "Epoch 12 | Train Loss: 0.8486 | Val Loss: 0.8322\n",
      "Epoch 13 | Train Loss: 0.8444 | Val Loss: 0.8307\n",
      "Epoch 14 | Train Loss: 0.8356 | Val Loss: 0.8258\n",
      "Epoch 15 | Train Loss: 0.8474 | Val Loss: 0.8231\n",
      "Epoch 16 | Train Loss: 0.8259 | Val Loss: 0.8188\n",
      "Epoch 17 | Train Loss: 0.8440 | Val Loss: 0.8258\n",
      "Epoch 18 | Train Loss: 0.8292 | Val Loss: 0.8114\n",
      "Epoch 19 | Train Loss: 0.8220 | Val Loss: 0.8090\n",
      "Epoch 20 | Train Loss: 0.8254 | Val Loss: 0.8112\n",
      "Epoch 21 | Train Loss: 0.8215 | Val Loss: 0.8004\n",
      "Epoch 22 | Train Loss: 0.8354 | Val Loss: 0.8032\n",
      "Epoch 23 | Train Loss: 0.8080 | Val Loss: 0.7983\n",
      "Epoch 24 | Train Loss: 0.8289 | Val Loss: 0.8247\n",
      "Epoch 25 | Train Loss: 0.8318 | Val Loss: 0.7964\n",
      "Epoch 26 | Train Loss: 0.8110 | Val Loss: 0.7865\n",
      "Epoch 27 | Train Loss: 0.8088 | Val Loss: 0.7827\n",
      "Epoch 28 | Train Loss: 0.7947 | Val Loss: 0.7798\n",
      "Epoch 29 | Train Loss: 0.8022 | Val Loss: 0.7742\n",
      "Epoch 30 | Train Loss: 0.7893 | Val Loss: 0.7697\n",
      "Epoch 31 | Train Loss: 0.7831 | Val Loss: 0.7870\n",
      "Epoch 32 | Train Loss: 0.7977 | Val Loss: 0.7611\n",
      "Epoch 33 | Train Loss: 0.7833 | Val Loss: 0.7655\n",
      "Epoch 34 | Train Loss: 0.7863 | Val Loss: 0.7575\n",
      "Epoch 35 | Train Loss: 0.7835 | Val Loss: 0.7559\n",
      "Epoch 36 | Train Loss: 0.7818 | Val Loss: 0.7522\n",
      "Epoch 37 | Train Loss: 0.7690 | Val Loss: 0.7564\n",
      "Epoch 38 | Train Loss: 0.7698 | Val Loss: 0.7530\n",
      "Epoch 39 | Train Loss: 0.7670 | Val Loss: 0.7630\n",
      "Epoch 40 | Train Loss: 0.7716 | Val Loss: 0.7459\n",
      "Epoch 41 | Train Loss: 0.7716 | Val Loss: 0.7660\n",
      "Epoch 42 | Train Loss: 0.7990 | Val Loss: 0.7515\n",
      "Epoch 43 | Train Loss: 0.7590 | Val Loss: 0.7405\n",
      "Epoch 44 | Train Loss: 0.7755 | Val Loss: 0.7595\n",
      "Epoch 45 | Train Loss: 0.7620 | Val Loss: 0.8024\n",
      "Epoch 46 | Train Loss: 0.7974 | Val Loss: 0.7384\n",
      "Epoch 47 | Train Loss: 0.7790 | Val Loss: 0.7385\n",
      "Epoch 48 | Train Loss: 0.7628 | Val Loss: 0.7536\n",
      "Epoch 49 | Train Loss: 0.7471 | Val Loss: 0.7356\n",
      "Epoch 50 | Train Loss: 0.7442 | Val Loss: 0.7518\n",
      "Fold 3 ‚ñ∂ AUC: 0.773, Balanced Acc: 0.511\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9005 | Val Loss: 0.8632\n",
      "Epoch 02 | Train Loss: 0.8765 | Val Loss: 0.8589\n",
      "Epoch 03 | Train Loss: 0.8726 | Val Loss: 0.8545\n",
      "Epoch 04 | Train Loss: 0.8717 | Val Loss: 0.8519\n",
      "Epoch 05 | Train Loss: 0.8621 | Val Loss: 0.8484\n",
      "Epoch 06 | Train Loss: 0.8714 | Val Loss: 0.8454\n",
      "Epoch 07 | Train Loss: 0.8692 | Val Loss: 0.8440\n",
      "Epoch 08 | Train Loss: 0.8615 | Val Loss: 0.8392\n",
      "Epoch 09 | Train Loss: 0.8638 | Val Loss: 0.8344\n",
      "Epoch 10 | Train Loss: 0.8605 | Val Loss: 0.8346\n",
      "Epoch 11 | Train Loss: 0.8630 | Val Loss: 0.8314\n",
      "Epoch 12 | Train Loss: 0.8514 | Val Loss: 0.8262\n",
      "Epoch 13 | Train Loss: 0.8574 | Val Loss: 0.8248\n",
      "Epoch 14 | Train Loss: 0.8386 | Val Loss: 0.8203\n",
      "Epoch 15 | Train Loss: 0.8418 | Val Loss: 0.8162\n",
      "Epoch 16 | Train Loss: 0.8308 | Val Loss: 0.8132\n",
      "Epoch 17 | Train Loss: 0.8407 | Val Loss: 0.8116\n",
      "Epoch 18 | Train Loss: 0.8460 | Val Loss: 0.8065\n",
      "Epoch 19 | Train Loss: 0.8334 | Val Loss: 0.8040\n",
      "Epoch 20 | Train Loss: 0.8429 | Val Loss: 0.7987\n",
      "Epoch 21 | Train Loss: 0.8254 | Val Loss: 0.7941\n",
      "Epoch 22 | Train Loss: 0.8343 | Val Loss: 0.7906\n",
      "Epoch 23 | Train Loss: 0.8172 | Val Loss: 0.7928\n",
      "Epoch 24 | Train Loss: 0.8351 | Val Loss: 0.7833\n",
      "Epoch 25 | Train Loss: 0.8224 | Val Loss: 0.7863\n",
      "Epoch 26 | Train Loss: 0.8119 | Val Loss: 0.7779\n",
      "Epoch 27 | Train Loss: 0.8194 | Val Loss: 0.7803\n",
      "Epoch 28 | Train Loss: 0.7994 | Val Loss: 0.7776\n",
      "Epoch 29 | Train Loss: 0.7825 | Val Loss: 0.7675\n",
      "Epoch 30 | Train Loss: 0.7977 | Val Loss: 0.7625\n",
      "Epoch 31 | Train Loss: 0.7976 | Val Loss: 0.7663\n",
      "Epoch 32 | Train Loss: 0.7842 | Val Loss: 0.7535\n",
      "Epoch 33 | Train Loss: 0.7922 | Val Loss: 0.7635\n",
      "Epoch 34 | Train Loss: 0.7967 | Val Loss: 0.7461\n",
      "Epoch 35 | Train Loss: 0.7764 | Val Loss: 0.7412\n",
      "Epoch 36 | Train Loss: 0.7841 | Val Loss: 0.7401\n",
      "Epoch 37 | Train Loss: 0.7663 | Val Loss: 0.7407\n",
      "Epoch 38 | Train Loss: 0.7755 | Val Loss: 0.7309\n",
      "Epoch 39 | Train Loss: 0.7755 | Val Loss: 0.7348\n",
      "Epoch 40 | Train Loss: 0.7827 | Val Loss: 0.7383\n",
      "Epoch 41 | Train Loss: 0.8020 | Val Loss: 0.7342\n",
      "Epoch 42 | Train Loss: 0.7674 | Val Loss: 0.7196\n",
      "Epoch 43 | Train Loss: 0.7664 | Val Loss: 0.7192\n",
      "Epoch 44 | Train Loss: 0.7824 | Val Loss: 0.7296\n",
      "Epoch 45 | Train Loss: 0.7649 | Val Loss: 0.7095\n",
      "Epoch 46 | Train Loss: 0.7640 | Val Loss: 0.7203\n",
      "Epoch 47 | Train Loss: 0.7474 | Val Loss: 0.7049\n",
      "Epoch 48 | Train Loss: 0.7467 | Val Loss: 0.7023\n",
      "Epoch 49 | Train Loss: 0.7679 | Val Loss: 0.7530\n",
      "Epoch 50 | Train Loss: 0.7687 | Val Loss: 0.7003\n",
      "Fold 4 ‚ñ∂ AUC: 0.784, Balanced Acc: 0.505\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9042 | Val Loss: 0.8980\n",
      "Epoch 02 | Train Loss: 0.8801 | Val Loss: 0.9010\n",
      "Epoch 03 | Train Loss: 0.8605 | Val Loss: 0.8912\n",
      "Epoch 04 | Train Loss: 0.8675 | Val Loss: 0.8887\n",
      "Epoch 05 | Train Loss: 0.8612 | Val Loss: 0.8885\n",
      "Epoch 06 | Train Loss: 0.8594 | Val Loss: 0.8846\n",
      "Epoch 07 | Train Loss: 0.8534 | Val Loss: 0.8823\n",
      "Epoch 08 | Train Loss: 0.8704 | Val Loss: 0.8819\n",
      "Epoch 09 | Train Loss: 0.8707 | Val Loss: 0.8750\n",
      "Epoch 10 | Train Loss: 0.8560 | Val Loss: 0.8731\n",
      "Epoch 11 | Train Loss: 0.8481 | Val Loss: 0.8698\n",
      "Epoch 12 | Train Loss: 0.8491 | Val Loss: 0.8731\n",
      "Epoch 13 | Train Loss: 0.8403 | Val Loss: 0.8674\n",
      "Epoch 14 | Train Loss: 0.8446 | Val Loss: 0.8678\n",
      "Epoch 15 | Train Loss: 0.8375 | Val Loss: 0.8654\n",
      "Epoch 16 | Train Loss: 0.8295 | Val Loss: 0.8666\n",
      "Epoch 17 | Train Loss: 0.8298 | Val Loss: 0.8554\n",
      "Epoch 18 | Train Loss: 0.8297 | Val Loss: 0.8583\n",
      "Epoch 19 | Train Loss: 0.8152 | Val Loss: 0.8640\n",
      "Epoch 20 | Train Loss: 0.8196 | Val Loss: 0.8449\n",
      "Epoch 21 | Train Loss: 0.8114 | Val Loss: 0.8389\n",
      "Epoch 22 | Train Loss: 0.8376 | Val Loss: 0.8731\n",
      "Epoch 23 | Train Loss: 0.8063 | Val Loss: 0.8484\n",
      "Epoch 24 | Train Loss: 0.8086 | Val Loss: 0.8328\n",
      "Epoch 25 | Train Loss: 0.7918 | Val Loss: 0.8326\n",
      "Epoch 26 | Train Loss: 0.7980 | Val Loss: 0.8337\n",
      "Epoch 27 | Train Loss: 0.8213 | Val Loss: 0.8269\n",
      "Epoch 28 | Train Loss: 0.7962 | Val Loss: 0.8197\n",
      "Epoch 29 | Train Loss: 0.7956 | Val Loss: 0.8148\n",
      "Epoch 30 | Train Loss: 0.7866 | Val Loss: 0.8181\n",
      "Epoch 31 | Train Loss: 0.7762 | Val Loss: 0.8159\n",
      "Epoch 32 | Train Loss: 0.7730 | Val Loss: 0.8102\n",
      "Epoch 33 | Train Loss: 0.7720 | Val Loss: 0.8084\n",
      "Epoch 34 | Train Loss: 0.7726 | Val Loss: 0.8332\n",
      "Epoch 35 | Train Loss: 0.7877 | Val Loss: 0.8099\n",
      "Epoch 36 | Train Loss: 0.7779 | Val Loss: 0.8079\n",
      "Epoch 37 | Train Loss: 0.7633 | Val Loss: 0.8042\n",
      "Epoch 38 | Train Loss: 0.7687 | Val Loss: 0.8059\n",
      "Epoch 39 | Train Loss: 0.7787 | Val Loss: 0.8033\n",
      "Epoch 40 | Train Loss: 0.7686 | Val Loss: 0.8055\n",
      "Epoch 41 | Train Loss: 0.7536 | Val Loss: 0.8023\n",
      "Epoch 42 | Train Loss: 0.7535 | Val Loss: 0.7989\n",
      "Epoch 43 | Train Loss: 0.7721 | Val Loss: 0.8176\n",
      "Epoch 44 | Train Loss: 0.7456 | Val Loss: 0.7992\n",
      "Epoch 45 | Train Loss: 0.7669 | Val Loss: 0.8028\n",
      "Epoch 46 | Train Loss: 0.7613 | Val Loss: 0.7929\n",
      "Epoch 47 | Train Loss: 0.7543 | Val Loss: 0.8025\n",
      "Epoch 48 | Train Loss: 0.7575 | Val Loss: 0.7935\n",
      "Epoch 49 | Train Loss: 0.7598 | Val Loss: 0.7981\n",
      "Epoch 50 | Train Loss: 0.7361 | Val Loss: 0.7922\n",
      "Fold 5 ‚ñ∂ AUC: 0.736, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9914 | Val Loss: 0.9058\n",
      "Epoch 02 | Train Loss: 0.8624 | Val Loss: 0.9020\n",
      "Epoch 03 | Train Loss: 0.8569 | Val Loss: 0.9008\n",
      "Epoch 04 | Train Loss: 0.8652 | Val Loss: 0.9002\n",
      "Epoch 05 | Train Loss: 0.8523 | Val Loss: 0.8916\n",
      "Epoch 06 | Train Loss: 0.8585 | Val Loss: 0.8904\n",
      "Epoch 07 | Train Loss: 0.8424 | Val Loss: 0.8877\n",
      "Epoch 08 | Train Loss: 0.8626 | Val Loss: 0.8875\n",
      "Epoch 09 | Train Loss: 0.8492 | Val Loss: 0.8851\n",
      "Epoch 10 | Train Loss: 0.8325 | Val Loss: 0.8853\n",
      "Epoch 11 | Train Loss: 0.8425 | Val Loss: 0.8824\n",
      "Epoch 12 | Train Loss: 0.8470 | Val Loss: 0.8805\n",
      "Epoch 13 | Train Loss: 0.8376 | Val Loss: 0.8802\n",
      "Epoch 14 | Train Loss: 0.8479 | Val Loss: 0.8770\n",
      "Epoch 15 | Train Loss: 0.8282 | Val Loss: 0.8721\n",
      "Epoch 16 | Train Loss: 0.8160 | Val Loss: 0.8738\n",
      "Epoch 17 | Train Loss: 0.8212 | Val Loss: 0.8702\n",
      "Epoch 18 | Train Loss: 0.8120 | Val Loss: 0.8704\n",
      "Epoch 19 | Train Loss: 0.8108 | Val Loss: 0.8652\n",
      "Epoch 20 | Train Loss: 0.8112 | Val Loss: 0.8639\n",
      "Epoch 21 | Train Loss: 0.8002 | Val Loss: 0.8662\n",
      "Epoch 22 | Train Loss: 0.7993 | Val Loss: 0.8633\n",
      "Epoch 23 | Train Loss: 0.7939 | Val Loss: 0.8660\n",
      "Epoch 24 | Train Loss: 0.7887 | Val Loss: 0.8682\n",
      "Epoch 25 | Train Loss: 0.7924 | Val Loss: 0.8662\n",
      "Epoch 26 | Train Loss: 0.7912 | Val Loss: 0.8550\n",
      "Epoch 27 | Train Loss: 0.7848 | Val Loss: 0.8474\n",
      "Epoch 28 | Train Loss: 0.7845 | Val Loss: 0.8481\n",
      "Epoch 29 | Train Loss: 0.7723 | Val Loss: 0.8497\n",
      "Epoch 30 | Train Loss: 0.7772 | Val Loss: 0.8471\n",
      "Epoch 31 | Train Loss: 0.7622 | Val Loss: 0.8554\n",
      "Epoch 32 | Train Loss: 0.7777 | Val Loss: 0.8415\n",
      "Epoch 33 | Train Loss: 0.7492 | Val Loss: 0.8444\n",
      "Epoch 34 | Train Loss: 0.7496 | Val Loss: 0.8468\n",
      "Epoch 35 | Train Loss: 0.7809 | Val Loss: 0.8423\n",
      "Epoch 36 | Train Loss: 0.7617 | Val Loss: 0.8595\n",
      "Epoch 37 | Train Loss: 0.7549 | Val Loss: 0.8404\n",
      "Epoch 38 | Train Loss: 0.7522 | Val Loss: 0.8394\n",
      "Epoch 39 | Train Loss: 0.7455 | Val Loss: 0.8383\n",
      "Epoch 40 | Train Loss: 0.7533 | Val Loss: 0.8532\n",
      "Epoch 41 | Train Loss: 0.7471 | Val Loss: 0.8383\n",
      "Epoch 42 | Train Loss: 0.7371 | Val Loss: 0.8379\n",
      "Epoch 43 | Train Loss: 0.7527 | Val Loss: 0.8525\n",
      "Epoch 44 | Train Loss: 0.7619 | Val Loss: 0.8355\n",
      "Epoch 45 | Train Loss: 0.7597 | Val Loss: 0.8445\n",
      "Epoch 46 | Train Loss: 0.7433 | Val Loss: 0.8421\n",
      "Epoch 47 | Train Loss: 0.7357 | Val Loss: 0.8355\n",
      "Epoch 48 | Train Loss: 0.7378 | Val Loss: 0.8401\n",
      "Epoch 49 | Train Loss: 0.7336 | Val Loss: 0.8308\n",
      "Epoch 50 | Train Loss: 0.7310 | Val Loss: 0.8482\n",
      "Fold 6 ‚ñ∂ AUC: 0.713, Balanced Acc: 0.449\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 1.0623 | Val Loss: 0.8639\n",
      "Epoch 02 | Train Loss: 0.8777 | Val Loss: 0.8535\n",
      "Epoch 03 | Train Loss: 0.8730 | Val Loss: 0.8540\n",
      "Epoch 04 | Train Loss: 0.8788 | Val Loss: 0.8483\n",
      "Epoch 05 | Train Loss: 0.8577 | Val Loss: 0.8464\n",
      "Epoch 06 | Train Loss: 0.8708 | Val Loss: 0.8462\n",
      "Epoch 07 | Train Loss: 0.8727 | Val Loss: 0.8445\n",
      "Epoch 08 | Train Loss: 0.8623 | Val Loss: 0.8416\n",
      "Epoch 09 | Train Loss: 0.8555 | Val Loss: 0.8399\n",
      "Epoch 10 | Train Loss: 0.8664 | Val Loss: 0.8387\n",
      "Epoch 11 | Train Loss: 0.8602 | Val Loss: 0.8375\n",
      "Epoch 12 | Train Loss: 0.8572 | Val Loss: 0.8365\n",
      "Epoch 13 | Train Loss: 0.8655 | Val Loss: 0.8344\n",
      "Epoch 14 | Train Loss: 0.8438 | Val Loss: 0.8313\n",
      "Epoch 15 | Train Loss: 0.8571 | Val Loss: 0.8301\n",
      "Epoch 16 | Train Loss: 0.8500 | Val Loss: 0.8275\n",
      "Epoch 17 | Train Loss: 0.8527 | Val Loss: 0.8249\n",
      "Epoch 18 | Train Loss: 0.8374 | Val Loss: 0.8231\n",
      "Epoch 19 | Train Loss: 0.8466 | Val Loss: 0.8201\n",
      "Epoch 20 | Train Loss: 0.8301 | Val Loss: 0.8169\n",
      "Epoch 21 | Train Loss: 0.8380 | Val Loss: 0.8160\n",
      "Epoch 22 | Train Loss: 0.8386 | Val Loss: 0.8142\n",
      "Epoch 23 | Train Loss: 0.8365 | Val Loss: 0.8115\n",
      "Epoch 24 | Train Loss: 0.8176 | Val Loss: 0.8171\n",
      "Epoch 25 | Train Loss: 0.8101 | Val Loss: 0.8046\n",
      "Epoch 26 | Train Loss: 0.8247 | Val Loss: 0.8182\n",
      "Epoch 27 | Train Loss: 0.8279 | Val Loss: 0.7977\n",
      "Epoch 28 | Train Loss: 0.7999 | Val Loss: 0.7954\n",
      "Epoch 29 | Train Loss: 0.8294 | Val Loss: 0.8057\n",
      "Epoch 30 | Train Loss: 0.8003 | Val Loss: 0.7898\n",
      "Epoch 31 | Train Loss: 0.8089 | Val Loss: 0.8099\n",
      "Epoch 32 | Train Loss: 0.8061 | Val Loss: 0.7824\n",
      "Epoch 33 | Train Loss: 0.7883 | Val Loss: 0.7789\n",
      "Epoch 34 | Train Loss: 0.7917 | Val Loss: 0.7936\n",
      "Epoch 35 | Train Loss: 0.7970 | Val Loss: 0.7793\n",
      "Epoch 36 | Train Loss: 0.8097 | Val Loss: 0.7952\n",
      "Epoch 37 | Train Loss: 0.8026 | Val Loss: 0.7803\n",
      "Epoch 38 | Train Loss: 0.7922 | Val Loss: 0.7757\n",
      "Epoch 39 | Train Loss: 0.7948 | Val Loss: 0.7801\n",
      "Epoch 40 | Train Loss: 0.7930 | Val Loss: 0.7713\n",
      "Epoch 41 | Train Loss: 0.7707 | Val Loss: 0.7636\n",
      "Epoch 42 | Train Loss: 0.7814 | Val Loss: 0.7622\n",
      "Epoch 43 | Train Loss: 0.7697 | Val Loss: 0.7690\n",
      "Epoch 44 | Train Loss: 0.7476 | Val Loss: 0.7568\n",
      "Epoch 45 | Train Loss: 0.7513 | Val Loss: 0.7617\n",
      "Epoch 46 | Train Loss: 0.7726 | Val Loss: 0.7519\n",
      "Epoch 47 | Train Loss: 0.7619 | Val Loss: 0.7504\n",
      "Epoch 48 | Train Loss: 0.7407 | Val Loss: 0.7487\n",
      "Epoch 49 | Train Loss: 0.7473 | Val Loss: 0.7431\n",
      "Epoch 50 | Train Loss: 0.7679 | Val Loss: 0.7712\n",
      "Fold 7 ‚ñ∂ AUC: 0.777, Balanced Acc: 0.444\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9181 | Val Loss: 0.8665\n",
      "Epoch 02 | Train Loss: 0.8703 | Val Loss: 0.8655\n",
      "Epoch 03 | Train Loss: 0.8713 | Val Loss: 0.8603\n",
      "Epoch 04 | Train Loss: 0.8733 | Val Loss: 0.8583\n",
      "Epoch 05 | Train Loss: 0.8716 | Val Loss: 0.8558\n",
      "Epoch 06 | Train Loss: 0.8759 | Val Loss: 0.8534\n",
      "Epoch 07 | Train Loss: 0.8558 | Val Loss: 0.8506\n",
      "Epoch 08 | Train Loss: 0.8447 | Val Loss: 0.8503\n",
      "Epoch 09 | Train Loss: 0.8458 | Val Loss: 0.8454\n",
      "Epoch 10 | Train Loss: 0.8463 | Val Loss: 0.8418\n",
      "Epoch 11 | Train Loss: 0.8318 | Val Loss: 0.8393\n",
      "Epoch 12 | Train Loss: 0.8439 | Val Loss: 0.8361\n",
      "Epoch 13 | Train Loss: 0.8355 | Val Loss: 0.8310\n",
      "Epoch 14 | Train Loss: 0.8339 | Val Loss: 0.8274\n",
      "Epoch 15 | Train Loss: 0.8269 | Val Loss: 0.8221\n",
      "Epoch 16 | Train Loss: 0.8159 | Val Loss: 0.8180\n",
      "Epoch 17 | Train Loss: 0.8110 | Val Loss: 0.8327\n",
      "Epoch 18 | Train Loss: 0.8306 | Val Loss: 0.8143\n",
      "Epoch 19 | Train Loss: 0.8078 | Val Loss: 0.8106\n",
      "Epoch 20 | Train Loss: 0.8207 | Val Loss: 0.8064\n",
      "Epoch 21 | Train Loss: 0.7962 | Val Loss: 0.8056\n",
      "Epoch 22 | Train Loss: 0.7993 | Val Loss: 0.8010\n",
      "Epoch 23 | Train Loss: 0.7860 | Val Loss: 0.8135\n",
      "Epoch 24 | Train Loss: 0.7934 | Val Loss: 0.8345\n",
      "Epoch 25 | Train Loss: 0.7789 | Val Loss: 0.8359\n",
      "Epoch 26 | Train Loss: 0.8028 | Val Loss: 0.7953\n",
      "Epoch 27 | Train Loss: 0.7979 | Val Loss: 0.7942\n",
      "Epoch 28 | Train Loss: 0.7834 | Val Loss: 0.7945\n",
      "Epoch 29 | Train Loss: 0.7804 | Val Loss: 0.8035\n",
      "Epoch 30 | Train Loss: 0.7775 | Val Loss: 0.8119\n",
      "Epoch 31 | Train Loss: 0.7925 | Val Loss: 0.7960\n",
      "Epoch 32 | Train Loss: 0.7661 | Val Loss: 0.7933\n",
      "Epoch 33 | Train Loss: 0.7535 | Val Loss: 0.7983\n",
      "Epoch 34 | Train Loss: 0.7622 | Val Loss: 0.7919\n",
      "Epoch 35 | Train Loss: 0.7499 | Val Loss: 0.8298\n",
      "Epoch 36 | Train Loss: 0.7952 | Val Loss: 0.7923\n",
      "Epoch 37 | Train Loss: 0.7808 | Val Loss: 0.8061\n",
      "Epoch 38 | Train Loss: 0.7817 | Val Loss: 0.7945\n",
      "Epoch 39 | Train Loss: 0.7718 | Val Loss: 0.7937\n",
      "Epoch 40 | Train Loss: 0.7434 | Val Loss: 0.8019\n",
      "Epoch 41 | Train Loss: 0.7464 | Val Loss: 0.8019\n",
      "Epoch 42 | Train Loss: 0.7411 | Val Loss: 0.8069\n",
      "Epoch 43 | Train Loss: 0.7555 | Val Loss: 0.7948\n",
      "Epoch 44 | Train Loss: 0.7449 | Val Loss: 0.7965\n",
      "Epoch 45 | Train Loss: 0.7560 | Val Loss: 0.7970\n",
      "Epoch 46 | Train Loss: 0.7460 | Val Loss: 0.7964\n",
      "Epoch 47 | Train Loss: 0.7296 | Val Loss: 0.8084\n",
      "Epoch 48 | Train Loss: 0.7258 | Val Loss: 0.8141\n",
      "Epoch 49 | Train Loss: 0.7352 | Val Loss: 0.8053\n",
      "Epoch 50 | Train Loss: 0.7429 | Val Loss: 0.8074\n",
      "Fold 8 ‚ñ∂ AUC: 0.688, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 1.2471 | Val Loss: 1.0207\n",
      "Epoch 02 | Train Loss: 0.9296 | Val Loss: 0.8901\n",
      "Epoch 03 | Train Loss: 0.8842 | Val Loss: 0.8720\n",
      "Epoch 04 | Train Loss: 0.8810 | Val Loss: 0.8707\n",
      "Epoch 05 | Train Loss: 0.8663 | Val Loss: 0.8695\n",
      "Epoch 06 | Train Loss: 0.8547 | Val Loss: 0.8696\n",
      "Epoch 07 | Train Loss: 0.8606 | Val Loss: 0.8690\n",
      "Epoch 08 | Train Loss: 0.8601 | Val Loss: 0.8652\n",
      "Epoch 09 | Train Loss: 0.8697 | Val Loss: 0.8655\n",
      "Epoch 10 | Train Loss: 0.8576 | Val Loss: 0.8641\n",
      "Epoch 11 | Train Loss: 0.8708 | Val Loss: 0.8617\n",
      "Epoch 12 | Train Loss: 0.8538 | Val Loss: 0.8597\n",
      "Epoch 13 | Train Loss: 0.8539 | Val Loss: 0.8601\n",
      "Epoch 14 | Train Loss: 0.8521 | Val Loss: 0.8562\n",
      "Epoch 15 | Train Loss: 0.8457 | Val Loss: 0.8558\n",
      "Epoch 16 | Train Loss: 0.8401 | Val Loss: 0.8518\n",
      "Epoch 17 | Train Loss: 0.8356 | Val Loss: 0.8517\n",
      "Epoch 18 | Train Loss: 0.8469 | Val Loss: 0.8509\n",
      "Epoch 19 | Train Loss: 0.8476 | Val Loss: 0.8493\n",
      "Epoch 20 | Train Loss: 0.8308 | Val Loss: 0.8516\n",
      "Epoch 21 | Train Loss: 0.8423 | Val Loss: 0.8443\n",
      "Epoch 22 | Train Loss: 0.8283 | Val Loss: 0.8445\n",
      "Epoch 23 | Train Loss: 0.8356 | Val Loss: 0.8410\n",
      "Epoch 24 | Train Loss: 0.8221 | Val Loss: 0.8398\n",
      "Epoch 25 | Train Loss: 0.8237 | Val Loss: 0.8362\n",
      "Epoch 26 | Train Loss: 0.8572 | Val Loss: 0.8566\n",
      "Epoch 27 | Train Loss: 0.8436 | Val Loss: 0.8334\n",
      "Epoch 28 | Train Loss: 0.8071 | Val Loss: 0.8329\n",
      "Epoch 29 | Train Loss: 0.8044 | Val Loss: 0.8309\n",
      "Epoch 30 | Train Loss: 0.8086 | Val Loss: 0.8276\n",
      "Epoch 31 | Train Loss: 0.8108 | Val Loss: 0.8310\n",
      "Epoch 32 | Train Loss: 0.7963 | Val Loss: 0.8308\n",
      "Epoch 33 | Train Loss: 0.7934 | Val Loss: 0.8230\n",
      "Epoch 34 | Train Loss: 0.7806 | Val Loss: 0.8351\n",
      "Epoch 35 | Train Loss: 0.7888 | Val Loss: 0.8400\n",
      "Epoch 36 | Train Loss: 0.7866 | Val Loss: 0.8222\n",
      "Epoch 37 | Train Loss: 0.7680 | Val Loss: 0.8242\n",
      "Epoch 38 | Train Loss: 0.7714 | Val Loss: 0.8157\n",
      "Epoch 39 | Train Loss: 0.7786 | Val Loss: 0.8146\n",
      "Epoch 40 | Train Loss: 0.7646 | Val Loss: 0.8263\n",
      "Epoch 41 | Train Loss: 0.7794 | Val Loss: 0.8202\n",
      "Epoch 42 | Train Loss: 0.7741 | Val Loss: 0.8155\n",
      "Epoch 43 | Train Loss: 0.7656 | Val Loss: 0.8103\n",
      "Epoch 44 | Train Loss: 0.7583 | Val Loss: 0.8313\n",
      "Epoch 45 | Train Loss: 0.7422 | Val Loss: 0.8114\n",
      "Epoch 46 | Train Loss: 0.7564 | Val Loss: 0.8124\n",
      "Epoch 47 | Train Loss: 0.7443 | Val Loss: 0.8182\n",
      "Epoch 48 | Train Loss: 0.7680 | Val Loss: 0.8123\n",
      "Epoch 49 | Train Loss: 0.7548 | Val Loss: 0.8082\n",
      "Epoch 50 | Train Loss: 0.7532 | Val Loss: 0.8094\n",
      "Fold 9 ‚ñ∂ AUC: 0.713, Balanced Acc: 0.486\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 1.1967 | Val Loss: 0.9597\n",
      "Epoch 02 | Train Loss: 0.9151 | Val Loss: 0.8777\n",
      "Epoch 03 | Train Loss: 0.8700 | Val Loss: 0.8736\n",
      "Epoch 04 | Train Loss: 0.8641 | Val Loss: 0.8746\n",
      "Epoch 05 | Train Loss: 0.8832 | Val Loss: 0.8681\n",
      "Epoch 06 | Train Loss: 0.8644 | Val Loss: 0.8657\n",
      "Epoch 07 | Train Loss: 0.8728 | Val Loss: 0.8636\n",
      "Epoch 08 | Train Loss: 0.8654 | Val Loss: 0.8607\n",
      "Epoch 09 | Train Loss: 0.8539 | Val Loss: 0.8605\n",
      "Epoch 10 | Train Loss: 0.8526 | Val Loss: 0.8552\n",
      "Epoch 11 | Train Loss: 0.8513 | Val Loss: 0.8532\n",
      "Epoch 12 | Train Loss: 0.8518 | Val Loss: 0.8499\n",
      "Epoch 13 | Train Loss: 0.8634 | Val Loss: 0.8488\n",
      "Epoch 14 | Train Loss: 0.8591 | Val Loss: 0.8472\n",
      "Epoch 15 | Train Loss: 0.8571 | Val Loss: 0.8438\n",
      "Epoch 16 | Train Loss: 0.8469 | Val Loss: 0.8458\n",
      "Epoch 17 | Train Loss: 0.8509 | Val Loss: 0.8387\n",
      "Epoch 18 | Train Loss: 0.8514 | Val Loss: 0.8372\n",
      "Epoch 19 | Train Loss: 0.8324 | Val Loss: 0.8331\n",
      "Epoch 20 | Train Loss: 0.8480 | Val Loss: 0.8300\n",
      "Epoch 21 | Train Loss: 0.8314 | Val Loss: 0.8324\n",
      "Epoch 22 | Train Loss: 0.8334 | Val Loss: 0.8239\n",
      "Epoch 23 | Train Loss: 0.8425 | Val Loss: 0.8249\n",
      "Epoch 24 | Train Loss: 0.8381 | Val Loss: 0.8223\n",
      "Epoch 25 | Train Loss: 0.8255 | Val Loss: 0.8419\n",
      "Epoch 26 | Train Loss: 0.8187 | Val Loss: 0.8183\n",
      "Epoch 27 | Train Loss: 0.8233 | Val Loss: 0.8122\n",
      "Epoch 28 | Train Loss: 0.8174 | Val Loss: 0.8361\n",
      "Epoch 29 | Train Loss: 0.8152 | Val Loss: 0.8165\n",
      "Epoch 30 | Train Loss: 0.8386 | Val Loss: 0.8054\n",
      "Epoch 31 | Train Loss: 0.8130 | Val Loss: 0.8022\n",
      "Epoch 32 | Train Loss: 0.8002 | Val Loss: 0.7995\n",
      "Epoch 33 | Train Loss: 0.7908 | Val Loss: 0.7943\n",
      "Epoch 34 | Train Loss: 0.7949 | Val Loss: 0.7946\n",
      "Epoch 35 | Train Loss: 0.7922 | Val Loss: 0.7946\n",
      "Epoch 36 | Train Loss: 0.7846 | Val Loss: 0.8218\n",
      "Epoch 37 | Train Loss: 0.7962 | Val Loss: 0.7859\n",
      "Epoch 38 | Train Loss: 0.7966 | Val Loss: 0.7973\n",
      "Epoch 39 | Train Loss: 0.7893 | Val Loss: 0.8261\n",
      "Epoch 40 | Train Loss: 0.8317 | Val Loss: 0.7832\n",
      "Epoch 41 | Train Loss: 0.7778 | Val Loss: 0.7996\n",
      "Epoch 42 | Train Loss: 0.7866 | Val Loss: 0.7804\n",
      "Epoch 43 | Train Loss: 0.7961 | Val Loss: 0.7735\n",
      "Epoch 44 | Train Loss: 0.7925 | Val Loss: 0.7791\n",
      "Epoch 45 | Train Loss: 0.7863 | Val Loss: 0.7708\n",
      "Epoch 46 | Train Loss: 0.7695 | Val Loss: 0.8217\n",
      "Epoch 47 | Train Loss: 0.7874 | Val Loss: 0.7671\n",
      "Epoch 48 | Train Loss: 0.7721 | Val Loss: 0.7782\n",
      "Epoch 49 | Train Loss: 0.7771 | Val Loss: 0.7687\n",
      "Epoch 50 | Train Loss: 0.7699 | Val Loss: 0.7777\n",
      "Fold 10 ‚ñ∂ AUC: 0.718, Balanced Acc: 0.425\n",
      "üîç Summary for hd=128, dp=0.2, lr=0.0001 ‚Üí AUC: 0.7310¬±0.0412 | BalAcc: 0.4715¬±0.0407\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.4, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9140 | Val Loss: 0.8685\n",
      "Epoch 02 | Train Loss: 0.8801 | Val Loss: 0.8578\n",
      "Epoch 03 | Train Loss: 0.8903 | Val Loss: 0.8417\n",
      "Epoch 04 | Train Loss: 0.8834 | Val Loss: 0.8495\n",
      "Epoch 05 | Train Loss: 0.8482 | Val Loss: 0.8150\n",
      "Epoch 06 | Train Loss: 0.8366 | Val Loss: 0.7899\n",
      "Epoch 07 | Train Loss: 0.8164 | Val Loss: 0.7706\n",
      "Epoch 08 | Train Loss: 0.8034 | Val Loss: 0.7884\n",
      "Epoch 09 | Train Loss: 0.8038 | Val Loss: 0.7650\n",
      "Epoch 10 | Train Loss: 0.8277 | Val Loss: 0.7452\n",
      "Epoch 11 | Train Loss: 0.7754 | Val Loss: 0.7998\n",
      "Epoch 12 | Train Loss: 0.7588 | Val Loss: 0.7161\n",
      "Epoch 13 | Train Loss: 0.7525 | Val Loss: 0.7187\n",
      "Epoch 14 | Train Loss: 0.7902 | Val Loss: 0.7120\n",
      "Epoch 15 | Train Loss: 0.7759 | Val Loss: 0.7357\n",
      "Epoch 16 | Train Loss: 0.7648 | Val Loss: 0.7030\n",
      "Epoch 17 | Train Loss: 0.7526 | Val Loss: 0.6986\n",
      "Epoch 18 | Train Loss: 0.7453 | Val Loss: 0.6935\n",
      "Epoch 19 | Train Loss: 0.7350 | Val Loss: 0.7024\n",
      "Epoch 20 | Train Loss: 0.7426 | Val Loss: 0.6894\n",
      "Epoch 21 | Train Loss: 0.7385 | Val Loss: 0.7024\n",
      "Epoch 22 | Train Loss: 0.7385 | Val Loss: 0.7413\n",
      "Epoch 23 | Train Loss: 0.7813 | Val Loss: 0.7047\n",
      "Epoch 24 | Train Loss: 0.7462 | Val Loss: 0.6913\n",
      "Epoch 25 | Train Loss: 0.7186 | Val Loss: 0.6800\n",
      "Epoch 26 | Train Loss: 0.7411 | Val Loss: 0.6944\n",
      "Epoch 27 | Train Loss: 0.7285 | Val Loss: 0.7009\n",
      "Epoch 28 | Train Loss: 0.7446 | Val Loss: 0.6846\n",
      "Epoch 29 | Train Loss: 0.7407 | Val Loss: 0.7080\n",
      "Epoch 30 | Train Loss: 0.7464 | Val Loss: 0.6848\n",
      "Epoch 31 | Train Loss: 0.7323 | Val Loss: 0.6923\n",
      "Epoch 32 | Train Loss: 0.7223 | Val Loss: 0.6811\n",
      "Epoch 33 | Train Loss: 0.7500 | Val Loss: 0.6957\n",
      "Epoch 34 | Train Loss: 0.7349 | Val Loss: 0.7020\n",
      "Epoch 35 | Train Loss: 0.7501 | Val Loss: 0.6783\n",
      "Epoch 36 | Train Loss: 0.7425 | Val Loss: 0.6901\n",
      "Epoch 37 | Train Loss: 0.7450 | Val Loss: 0.6894\n",
      "Epoch 38 | Train Loss: 0.7314 | Val Loss: 0.6953\n",
      "Epoch 39 | Train Loss: 0.7315 | Val Loss: 0.7003\n",
      "Epoch 40 | Train Loss: 0.7489 | Val Loss: 0.6812\n",
      "Epoch 41 | Train Loss: 0.7615 | Val Loss: 0.6939\n",
      "Epoch 42 | Train Loss: 0.7530 | Val Loss: 0.6765\n",
      "Epoch 43 | Train Loss: 0.7219 | Val Loss: 0.6930\n",
      "Epoch 44 | Train Loss: 0.7473 | Val Loss: 0.7390\n",
      "Epoch 45 | Train Loss: 0.7200 | Val Loss: 0.6795\n",
      "Epoch 46 | Train Loss: 0.7362 | Val Loss: 0.6812\n",
      "Epoch 47 | Train Loss: 0.7348 | Val Loss: 0.6830\n",
      "Epoch 48 | Train Loss: 0.7433 | Val Loss: 0.6790\n",
      "Epoch 49 | Train Loss: 0.7299 | Val Loss: 0.6828\n",
      "Epoch 50 | Train Loss: 0.7144 | Val Loss: 0.6796\n",
      "Fold 1 ‚ñ∂ AUC: 0.785, Balanced Acc: 0.493\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9153 | Val Loss: 0.8562\n",
      "Epoch 02 | Train Loss: 0.8985 | Val Loss: 0.8542\n",
      "Epoch 03 | Train Loss: 0.8621 | Val Loss: 0.8738\n",
      "Epoch 04 | Train Loss: 0.8640 | Val Loss: 0.8412\n",
      "Epoch 05 | Train Loss: 0.8518 | Val Loss: 0.8550\n",
      "Epoch 06 | Train Loss: 0.8416 | Val Loss: 0.8069\n",
      "Epoch 07 | Train Loss: 0.8170 | Val Loss: 0.7885\n",
      "Epoch 08 | Train Loss: 0.7947 | Val Loss: 0.8621\n",
      "Epoch 09 | Train Loss: 0.8208 | Val Loss: 0.7810\n",
      "Epoch 10 | Train Loss: 0.8151 | Val Loss: 0.8263\n",
      "Epoch 11 | Train Loss: 0.7642 | Val Loss: 0.7563\n",
      "Epoch 12 | Train Loss: 0.7837 | Val Loss: 0.7440\n",
      "Epoch 13 | Train Loss: 0.7694 | Val Loss: 0.7483\n",
      "Epoch 14 | Train Loss: 0.7613 | Val Loss: 0.7575\n",
      "Epoch 15 | Train Loss: 0.7578 | Val Loss: 0.7824\n",
      "Epoch 16 | Train Loss: 0.7745 | Val Loss: 0.7387\n",
      "Epoch 17 | Train Loss: 0.7925 | Val Loss: 0.7632\n",
      "Epoch 18 | Train Loss: 0.7915 | Val Loss: 0.7644\n",
      "Epoch 19 | Train Loss: 0.7792 | Val Loss: 0.7845\n",
      "Epoch 20 | Train Loss: 0.7676 | Val Loss: 0.7293\n",
      "Epoch 21 | Train Loss: 0.7454 | Val Loss: 0.7255\n",
      "Epoch 22 | Train Loss: 0.7607 | Val Loss: 0.7353\n",
      "Epoch 23 | Train Loss: 0.7541 | Val Loss: 0.7202\n",
      "Epoch 24 | Train Loss: 0.7329 | Val Loss: 0.7999\n",
      "Epoch 25 | Train Loss: 0.7594 | Val Loss: 0.7456\n",
      "Epoch 26 | Train Loss: 0.7357 | Val Loss: 0.7621\n",
      "Epoch 27 | Train Loss: 0.7365 | Val Loss: 0.7158\n",
      "Epoch 28 | Train Loss: 0.7256 | Val Loss: 0.7803\n",
      "Epoch 29 | Train Loss: 0.7239 | Val Loss: 0.7100\n",
      "Epoch 30 | Train Loss: 0.7358 | Val Loss: 0.7207\n",
      "Epoch 31 | Train Loss: 0.7322 | Val Loss: 0.7190\n",
      "Epoch 32 | Train Loss: 0.7404 | Val Loss: 0.7231\n",
      "Epoch 33 | Train Loss: 0.7113 | Val Loss: 0.7210\n",
      "Epoch 34 | Train Loss: 0.7268 | Val Loss: 0.7181\n",
      "Epoch 35 | Train Loss: 0.7601 | Val Loss: 0.6950\n",
      "Epoch 36 | Train Loss: 0.7650 | Val Loss: 0.7806\n",
      "Epoch 37 | Train Loss: 0.7377 | Val Loss: 0.7073\n",
      "Epoch 38 | Train Loss: 0.7214 | Val Loss: 0.7033\n",
      "Epoch 39 | Train Loss: 0.7373 | Val Loss: 0.6998\n",
      "Epoch 40 | Train Loss: 0.7445 | Val Loss: 0.7945\n",
      "Epoch 41 | Train Loss: 0.7342 | Val Loss: 0.7280\n",
      "Epoch 42 | Train Loss: 0.7260 | Val Loss: 0.7536\n",
      "Epoch 43 | Train Loss: 0.7333 | Val Loss: 0.7047\n",
      "Epoch 44 | Train Loss: 0.7365 | Val Loss: 0.7025\n",
      "Epoch 45 | Train Loss: 0.7458 | Val Loss: 0.7150\n",
      "Epoch 46 | Train Loss: 0.7207 | Val Loss: 0.7943\n",
      "Epoch 47 | Train Loss: 0.7362 | Val Loss: 0.7598\n",
      "Epoch 48 | Train Loss: 0.7184 | Val Loss: 0.8000\n",
      "Epoch 49 | Train Loss: 0.7318 | Val Loss: 0.7121\n",
      "Epoch 50 | Train Loss: 0.7180 | Val Loss: 0.7410\n",
      "Fold 2 ‚ñ∂ AUC: 0.694, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9238 | Val Loss: 0.8718\n",
      "Epoch 02 | Train Loss: 0.8733 | Val Loss: 0.8559\n",
      "Epoch 03 | Train Loss: 0.8805 | Val Loss: 0.8422\n",
      "Epoch 04 | Train Loss: 0.8607 | Val Loss: 0.8301\n",
      "Epoch 05 | Train Loss: 0.8289 | Val Loss: 0.8751\n",
      "Epoch 06 | Train Loss: 0.8426 | Val Loss: 0.8338\n",
      "Epoch 07 | Train Loss: 0.8063 | Val Loss: 0.7720\n",
      "Epoch 08 | Train Loss: 0.8008 | Val Loss: 0.8693\n",
      "Epoch 09 | Train Loss: 0.7746 | Val Loss: 0.7594\n",
      "Epoch 10 | Train Loss: 0.7996 | Val Loss: 0.7590\n",
      "Epoch 11 | Train Loss: 0.7789 | Val Loss: 0.7631\n",
      "Epoch 12 | Train Loss: 0.7815 | Val Loss: 0.7546\n",
      "Epoch 13 | Train Loss: 0.7477 | Val Loss: 0.7390\n",
      "Epoch 14 | Train Loss: 0.7887 | Val Loss: 0.7490\n",
      "Epoch 15 | Train Loss: 0.7550 | Val Loss: 0.7473\n",
      "Epoch 16 | Train Loss: 0.7649 | Val Loss: 0.7394\n",
      "Epoch 17 | Train Loss: 0.7423 | Val Loss: 0.7378\n",
      "Epoch 18 | Train Loss: 0.7608 | Val Loss: 0.7293\n",
      "Epoch 19 | Train Loss: 0.7426 | Val Loss: 0.7454\n",
      "Epoch 20 | Train Loss: 0.7723 | Val Loss: 0.7744\n",
      "Epoch 21 | Train Loss: 0.7797 | Val Loss: 0.7243\n",
      "Epoch 22 | Train Loss: 0.7782 | Val Loss: 0.7379\n",
      "Epoch 23 | Train Loss: 0.7277 | Val Loss: 0.7267\n",
      "Epoch 24 | Train Loss: 0.7309 | Val Loss: 0.7153\n",
      "Epoch 25 | Train Loss: 0.7409 | Val Loss: 0.7222\n",
      "Epoch 26 | Train Loss: 0.7253 | Val Loss: 0.7728\n",
      "Epoch 27 | Train Loss: 0.7191 | Val Loss: 0.7130\n",
      "Epoch 28 | Train Loss: 0.7448 | Val Loss: 0.7091\n",
      "Epoch 29 | Train Loss: 0.7159 | Val Loss: 0.7113\n",
      "Epoch 30 | Train Loss: 0.7554 | Val Loss: 0.7083\n",
      "Epoch 31 | Train Loss: 0.7384 | Val Loss: 0.7162\n",
      "Epoch 32 | Train Loss: 0.7289 | Val Loss: 0.7038\n",
      "Epoch 33 | Train Loss: 0.7344 | Val Loss: 0.7241\n",
      "Epoch 34 | Train Loss: 0.7256 | Val Loss: 0.7653\n",
      "Epoch 35 | Train Loss: 0.7436 | Val Loss: 0.7163\n",
      "Epoch 36 | Train Loss: 0.7158 | Val Loss: 0.7352\n",
      "Epoch 37 | Train Loss: 0.7417 | Val Loss: 0.7100\n",
      "Epoch 38 | Train Loss: 0.7131 | Val Loss: 0.7522\n",
      "Epoch 39 | Train Loss: 0.7171 | Val Loss: 0.7088\n",
      "Epoch 40 | Train Loss: 0.7368 | Val Loss: 0.7138\n",
      "Epoch 41 | Train Loss: 0.7326 | Val Loss: 0.7209\n",
      "Epoch 42 | Train Loss: 0.7278 | Val Loss: 0.7219\n",
      "Epoch 43 | Train Loss: 0.7206 | Val Loss: 0.7170\n",
      "Epoch 44 | Train Loss: 0.7505 | Val Loss: 0.7074\n",
      "Epoch 45 | Train Loss: 0.7341 | Val Loss: 0.7209\n",
      "Epoch 46 | Train Loss: 0.7164 | Val Loss: 0.7263\n",
      "Epoch 47 | Train Loss: 0.7336 | Val Loss: 0.7134\n",
      "Epoch 48 | Train Loss: 0.7503 | Val Loss: 0.7179\n",
      "Epoch 49 | Train Loss: 0.6967 | Val Loss: 0.7057\n",
      "Epoch 50 | Train Loss: 0.7246 | Val Loss: 0.7176\n",
      "Fold 3 ‚ñ∂ AUC: 0.783, Balanced Acc: 0.494\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9834 | Val Loss: 0.8746\n",
      "Epoch 02 | Train Loss: 0.8707 | Val Loss: 0.8551\n",
      "Epoch 03 | Train Loss: 0.8729 | Val Loss: 0.8605\n",
      "Epoch 04 | Train Loss: 0.8697 | Val Loss: 0.8884\n",
      "Epoch 05 | Train Loss: 0.8821 | Val Loss: 0.8490\n",
      "Epoch 06 | Train Loss: 0.8621 | Val Loss: 0.8214\n",
      "Epoch 07 | Train Loss: 0.8372 | Val Loss: 0.8076\n",
      "Epoch 08 | Train Loss: 0.8369 | Val Loss: 0.7484\n",
      "Epoch 09 | Train Loss: 0.8080 | Val Loss: 0.7909\n",
      "Epoch 10 | Train Loss: 0.8071 | Val Loss: 0.7237\n",
      "Epoch 11 | Train Loss: 0.7945 | Val Loss: 0.7972\n",
      "Epoch 12 | Train Loss: 0.8082 | Val Loss: 0.7208\n",
      "Epoch 13 | Train Loss: 0.7670 | Val Loss: 0.7527\n",
      "Epoch 14 | Train Loss: 0.7875 | Val Loss: 0.6981\n",
      "Epoch 15 | Train Loss: 0.7730 | Val Loss: 0.6906\n",
      "Epoch 16 | Train Loss: 0.7649 | Val Loss: 0.6894\n",
      "Epoch 17 | Train Loss: 0.7627 | Val Loss: 0.6860\n",
      "Epoch 18 | Train Loss: 0.7575 | Val Loss: 0.6882\n",
      "Epoch 19 | Train Loss: 0.7635 | Val Loss: 0.6933\n",
      "Epoch 20 | Train Loss: 0.7492 | Val Loss: 0.7452\n",
      "Epoch 21 | Train Loss: 0.7539 | Val Loss: 0.6704\n",
      "Epoch 22 | Train Loss: 0.7531 | Val Loss: 0.6633\n",
      "Epoch 23 | Train Loss: 0.7503 | Val Loss: 0.6719\n",
      "Epoch 24 | Train Loss: 0.7398 | Val Loss: 0.6618\n",
      "Epoch 25 | Train Loss: 0.7802 | Val Loss: 0.6932\n",
      "Epoch 26 | Train Loss: 0.7691 | Val Loss: 0.6647\n",
      "Epoch 27 | Train Loss: 0.7270 | Val Loss: 0.6641\n",
      "Epoch 28 | Train Loss: 0.7438 | Val Loss: 0.7025\n",
      "Epoch 29 | Train Loss: 0.7630 | Val Loss: 0.6722\n",
      "Epoch 30 | Train Loss: 0.7661 | Val Loss: 0.6666\n",
      "Epoch 31 | Train Loss: 0.7619 | Val Loss: 0.6687\n",
      "Epoch 32 | Train Loss: 0.7412 | Val Loss: 0.6797\n",
      "Epoch 33 | Train Loss: 0.7399 | Val Loss: 0.6514\n",
      "Epoch 34 | Train Loss: 0.7602 | Val Loss: 0.6595\n",
      "Epoch 35 | Train Loss: 0.7423 | Val Loss: 0.6639\n",
      "Epoch 36 | Train Loss: 0.7559 | Val Loss: 0.6707\n",
      "Epoch 37 | Train Loss: 0.7700 | Val Loss: 0.6746\n",
      "Epoch 38 | Train Loss: 0.7508 | Val Loss: 0.6732\n",
      "Epoch 39 | Train Loss: 0.7250 | Val Loss: 0.6711\n",
      "Epoch 40 | Train Loss: 0.7193 | Val Loss: 0.6673\n",
      "Epoch 41 | Train Loss: 0.7354 | Val Loss: 0.6789\n",
      "Epoch 42 | Train Loss: 0.7470 | Val Loss: 0.6608\n",
      "Epoch 43 | Train Loss: 0.7363 | Val Loss: 0.6734\n",
      "Epoch 44 | Train Loss: 0.7403 | Val Loss: 0.6847\n",
      "Epoch 45 | Train Loss: 0.7355 | Val Loss: 0.6806\n",
      "Epoch 46 | Train Loss: 0.7171 | Val Loss: 0.6815\n",
      "Epoch 47 | Train Loss: 0.7474 | Val Loss: 0.6944\n",
      "Epoch 48 | Train Loss: 0.7527 | Val Loss: 0.6773\n",
      "Epoch 49 | Train Loss: 0.7155 | Val Loss: 0.6786\n",
      "Epoch 50 | Train Loss: 0.7298 | Val Loss: 0.6787\n",
      "Fold 4 ‚ñ∂ AUC: 0.772, Balanced Acc: 0.520\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9256 | Val Loss: 0.8986\n",
      "Epoch 02 | Train Loss: 0.8604 | Val Loss: 0.8839\n",
      "Epoch 03 | Train Loss: 0.8446 | Val Loss: 0.8748\n",
      "Epoch 04 | Train Loss: 0.8414 | Val Loss: 0.8673\n",
      "Epoch 05 | Train Loss: 0.8558 | Val Loss: 0.8383\n",
      "Epoch 06 | Train Loss: 0.8645 | Val Loss: 0.8748\n",
      "Epoch 07 | Train Loss: 0.7802 | Val Loss: 0.8415\n",
      "Epoch 08 | Train Loss: 0.7761 | Val Loss: 0.9114\n",
      "Epoch 09 | Train Loss: 0.8106 | Val Loss: 0.8533\n",
      "Epoch 10 | Train Loss: 0.7877 | Val Loss: 0.8632\n",
      "Epoch 11 | Train Loss: 0.7986 | Val Loss: 0.8457\n",
      "Epoch 12 | Train Loss: 0.7653 | Val Loss: 0.8513\n",
      "Epoch 13 | Train Loss: 0.7526 | Val Loss: 0.8451\n",
      "Epoch 14 | Train Loss: 0.7718 | Val Loss: 0.8313\n",
      "Epoch 15 | Train Loss: 0.7306 | Val Loss: 0.8257\n",
      "Epoch 16 | Train Loss: 0.7595 | Val Loss: 0.8270\n",
      "Epoch 17 | Train Loss: 0.7468 | Val Loss: 0.8089\n",
      "Epoch 18 | Train Loss: 0.7404 | Val Loss: 0.8062\n",
      "Epoch 19 | Train Loss: 0.7644 | Val Loss: 0.8132\n",
      "Epoch 20 | Train Loss: 0.7445 | Val Loss: 0.8005\n",
      "Epoch 21 | Train Loss: 0.7233 | Val Loss: 0.8144\n",
      "Epoch 22 | Train Loss: 0.7240 | Val Loss: 0.7989\n",
      "Epoch 23 | Train Loss: 0.7302 | Val Loss: 0.7917\n",
      "Epoch 24 | Train Loss: 0.7459 | Val Loss: 0.8069\n",
      "Epoch 25 | Train Loss: 0.7204 | Val Loss: 0.7914\n",
      "Epoch 26 | Train Loss: 0.7119 | Val Loss: 0.8138\n",
      "Epoch 27 | Train Loss: 0.7373 | Val Loss: 0.8114\n",
      "Epoch 28 | Train Loss: 0.7438 | Val Loss: 0.8400\n",
      "Epoch 29 | Train Loss: 0.7213 | Val Loss: 0.7945\n",
      "Epoch 30 | Train Loss: 0.7324 | Val Loss: 0.7919\n",
      "Epoch 31 | Train Loss: 0.6979 | Val Loss: 0.8256\n",
      "Epoch 32 | Train Loss: 0.7142 | Val Loss: 0.7941\n",
      "Epoch 33 | Train Loss: 0.7220 | Val Loss: 0.7864\n",
      "Epoch 34 | Train Loss: 0.7293 | Val Loss: 0.7890\n",
      "Epoch 35 | Train Loss: 0.7320 | Val Loss: 0.8170\n",
      "Epoch 36 | Train Loss: 0.7335 | Val Loss: 0.7901\n",
      "Epoch 37 | Train Loss: 0.7306 | Val Loss: 0.8516\n",
      "Epoch 38 | Train Loss: 0.7247 | Val Loss: 0.8104\n",
      "Epoch 39 | Train Loss: 0.6969 | Val Loss: 0.7924\n",
      "Epoch 40 | Train Loss: 0.7201 | Val Loss: 0.7958\n",
      "Epoch 41 | Train Loss: 0.7571 | Val Loss: 0.8207\n",
      "Epoch 42 | Train Loss: 0.7474 | Val Loss: 0.7924\n",
      "Epoch 43 | Train Loss: 0.7045 | Val Loss: 0.8066\n",
      "Epoch 44 | Train Loss: 0.7210 | Val Loss: 0.7985\n",
      "Epoch 45 | Train Loss: 0.7235 | Val Loss: 0.8632\n",
      "Epoch 46 | Train Loss: 0.7466 | Val Loss: 0.7983\n",
      "Epoch 47 | Train Loss: 0.7570 | Val Loss: 0.8391\n",
      "Epoch 48 | Train Loss: 0.7405 | Val Loss: 0.8323\n",
      "Epoch 49 | Train Loss: 0.7266 | Val Loss: 0.7982\n",
      "Epoch 50 | Train Loss: 0.7067 | Val Loss: 0.8125\n",
      "Fold 5 ‚ñ∂ AUC: 0.735, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9131 | Val Loss: 0.8930\n",
      "Epoch 02 | Train Loss: 0.8598 | Val Loss: 0.8881\n",
      "Epoch 03 | Train Loss: 0.8832 | Val Loss: 0.8978\n",
      "Epoch 04 | Train Loss: 0.8780 | Val Loss: 0.9106\n",
      "Epoch 05 | Train Loss: 0.8728 | Val Loss: 0.8839\n",
      "Epoch 06 | Train Loss: 0.8413 | Val Loss: 0.8564\n",
      "Epoch 07 | Train Loss: 0.8218 | Val Loss: 0.8783\n",
      "Epoch 08 | Train Loss: 0.7682 | Val Loss: 0.8241\n",
      "Epoch 09 | Train Loss: 0.7724 | Val Loss: 0.8139\n",
      "Epoch 10 | Train Loss: 0.7714 | Val Loss: 0.8092\n",
      "Epoch 11 | Train Loss: 0.7620 | Val Loss: 0.8149\n",
      "Epoch 12 | Train Loss: 0.7585 | Val Loss: 0.8297\n",
      "Epoch 13 | Train Loss: 0.7711 | Val Loss: 0.8475\n",
      "Epoch 14 | Train Loss: 0.7842 | Val Loss: 0.8769\n",
      "Epoch 15 | Train Loss: 0.7653 | Val Loss: 0.8059\n",
      "Epoch 16 | Train Loss: 0.7200 | Val Loss: 0.8162\n",
      "Epoch 17 | Train Loss: 0.7393 | Val Loss: 0.8242\n",
      "Epoch 18 | Train Loss: 0.7505 | Val Loss: 0.8172\n",
      "Epoch 19 | Train Loss: 0.7390 | Val Loss: 0.8174\n",
      "Epoch 20 | Train Loss: 0.7443 | Val Loss: 0.8506\n",
      "Epoch 21 | Train Loss: 0.7506 | Val Loss: 0.8674\n",
      "Epoch 22 | Train Loss: 0.7522 | Val Loss: 0.8153\n",
      "Epoch 23 | Train Loss: 0.7171 | Val Loss: 0.8636\n",
      "Epoch 24 | Train Loss: 0.7363 | Val Loss: 0.8380\n",
      "Epoch 25 | Train Loss: 0.7266 | Val Loss: 0.8193\n",
      "Epoch 26 | Train Loss: 0.7104 | Val Loss: 0.8473\n",
      "Epoch 27 | Train Loss: 0.7126 | Val Loss: 0.8360\n",
      "Epoch 28 | Train Loss: 0.7264 | Val Loss: 0.8293\n",
      "Epoch 29 | Train Loss: 0.7226 | Val Loss: 0.8233\n",
      "Epoch 30 | Train Loss: 0.7403 | Val Loss: 0.8407\n",
      "Epoch 31 | Train Loss: 0.7007 | Val Loss: 0.8266\n",
      "Epoch 32 | Train Loss: 0.7143 | Val Loss: 0.8317\n",
      "Epoch 33 | Train Loss: 0.7089 | Val Loss: 0.8452\n",
      "Epoch 34 | Train Loss: 0.7138 | Val Loss: 0.8276\n",
      "Epoch 35 | Train Loss: 0.7194 | Val Loss: 0.8475\n",
      "Epoch 36 | Train Loss: 0.7248 | Val Loss: 0.8335\n",
      "Epoch 37 | Train Loss: 0.7046 | Val Loss: 0.8611\n",
      "Epoch 38 | Train Loss: 0.7325 | Val Loss: 0.8372\n",
      "Epoch 39 | Train Loss: 0.7088 | Val Loss: 0.8347\n",
      "Epoch 40 | Train Loss: 0.7238 | Val Loss: 0.8264\n",
      "Epoch 41 | Train Loss: 0.7396 | Val Loss: 0.8441\n",
      "Epoch 42 | Train Loss: 0.7262 | Val Loss: 0.8565\n",
      "Epoch 43 | Train Loss: 0.7348 | Val Loss: 0.8396\n",
      "Epoch 44 | Train Loss: 0.7135 | Val Loss: 0.8441\n",
      "Epoch 45 | Train Loss: 0.7129 | Val Loss: 0.8292\n",
      "Epoch 46 | Train Loss: 0.7224 | Val Loss: 0.8190\n",
      "Epoch 47 | Train Loss: 0.7242 | Val Loss: 0.8457\n",
      "Epoch 48 | Train Loss: 0.7156 | Val Loss: 0.8302\n",
      "Epoch 49 | Train Loss: 0.6960 | Val Loss: 0.8405\n",
      "Epoch 50 | Train Loss: 0.7285 | Val Loss: 0.8356\n",
      "Fold 6 ‚ñ∂ AUC: 0.737, Balanced Acc: 0.440\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.8920 | Val Loss: 0.8687\n",
      "Epoch 02 | Train Loss: 0.8748 | Val Loss: 0.8455\n",
      "Epoch 03 | Train Loss: 0.8635 | Val Loss: 0.8347\n",
      "Epoch 04 | Train Loss: 0.8492 | Val Loss: 0.8129\n",
      "Epoch 05 | Train Loss: 0.8305 | Val Loss: 0.8183\n",
      "Epoch 06 | Train Loss: 0.8132 | Val Loss: 0.7626\n",
      "Epoch 07 | Train Loss: 0.7960 | Val Loss: 0.7470\n",
      "Epoch 08 | Train Loss: 0.7936 | Val Loss: 0.7852\n",
      "Epoch 09 | Train Loss: 0.8289 | Val Loss: 0.7246\n",
      "Epoch 10 | Train Loss: 0.7707 | Val Loss: 0.7054\n",
      "Epoch 11 | Train Loss: 0.7652 | Val Loss: 0.7073\n",
      "Epoch 12 | Train Loss: 0.7481 | Val Loss: 0.7155\n",
      "Epoch 13 | Train Loss: 0.7387 | Val Loss: 0.7165\n",
      "Epoch 14 | Train Loss: 0.7589 | Val Loss: 0.7200\n",
      "Epoch 15 | Train Loss: 0.7797 | Val Loss: 0.7661\n",
      "Epoch 16 | Train Loss: 0.7421 | Val Loss: 0.7200\n",
      "Epoch 17 | Train Loss: 0.7693 | Val Loss: 0.7225\n",
      "Epoch 18 | Train Loss: 0.7288 | Val Loss: 0.7073\n",
      "Epoch 19 | Train Loss: 0.7270 | Val Loss: 0.7835\n",
      "Epoch 20 | Train Loss: 0.7727 | Val Loss: 0.7388\n",
      "Epoch 21 | Train Loss: 0.7647 | Val Loss: 0.7370\n",
      "Epoch 22 | Train Loss: 0.7463 | Val Loss: 0.7231\n",
      "Epoch 23 | Train Loss: 0.7499 | Val Loss: 0.7145\n",
      "Epoch 24 | Train Loss: 0.7259 | Val Loss: 0.7114\n",
      "Epoch 25 | Train Loss: 0.7483 | Val Loss: 0.7147\n",
      "Epoch 26 | Train Loss: 0.7440 | Val Loss: 0.7200\n",
      "Epoch 27 | Train Loss: 0.7511 | Val Loss: 0.7269\n",
      "Epoch 28 | Train Loss: 0.7317 | Val Loss: 0.7306\n",
      "Epoch 29 | Train Loss: 0.7394 | Val Loss: 0.7291\n",
      "Epoch 30 | Train Loss: 0.7489 | Val Loss: 0.7267\n",
      "Epoch 31 | Train Loss: 0.7470 | Val Loss: 0.7209\n",
      "Epoch 32 | Train Loss: 0.7199 | Val Loss: 0.7442\n",
      "Epoch 33 | Train Loss: 0.7258 | Val Loss: 0.7265\n",
      "Epoch 34 | Train Loss: 0.7450 | Val Loss: 0.7245\n",
      "Epoch 35 | Train Loss: 0.7546 | Val Loss: 0.7299\n",
      "Epoch 36 | Train Loss: 0.7241 | Val Loss: 0.7539\n",
      "Epoch 37 | Train Loss: 0.7387 | Val Loss: 0.7323\n",
      "Epoch 38 | Train Loss: 0.7203 | Val Loss: 0.7484\n",
      "Epoch 39 | Train Loss: 0.7367 | Val Loss: 0.7300\n",
      "Epoch 40 | Train Loss: 0.7100 | Val Loss: 0.7271\n",
      "Epoch 41 | Train Loss: 0.7147 | Val Loss: 0.7314\n",
      "Epoch 42 | Train Loss: 0.7057 | Val Loss: 0.8285\n",
      "Epoch 43 | Train Loss: 0.7588 | Val Loss: 0.7294\n",
      "Epoch 44 | Train Loss: 0.7139 | Val Loss: 0.7296\n",
      "Epoch 45 | Train Loss: 0.7416 | Val Loss: 0.7255\n",
      "Epoch 46 | Train Loss: 0.7250 | Val Loss: 0.7341\n",
      "Epoch 47 | Train Loss: 0.7236 | Val Loss: 0.7291\n",
      "Epoch 48 | Train Loss: 0.7167 | Val Loss: 0.7329\n",
      "Epoch 49 | Train Loss: 0.7253 | Val Loss: 0.7367\n",
      "Epoch 50 | Train Loss: 0.7201 | Val Loss: 0.7439\n",
      "Fold 7 ‚ñ∂ AUC: 0.753, Balanced Acc: 0.443\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9176 | Val Loss: 0.8754\n",
      "Epoch 02 | Train Loss: 0.8771 | Val Loss: 0.8680\n",
      "Epoch 03 | Train Loss: 0.8739 | Val Loss: 0.8695\n",
      "Epoch 04 | Train Loss: 0.8628 | Val Loss: 0.8430\n",
      "Epoch 05 | Train Loss: 0.8491 | Val Loss: 0.8304\n",
      "Epoch 06 | Train Loss: 0.8447 | Val Loss: 0.8155\n",
      "Epoch 07 | Train Loss: 0.8389 | Val Loss: 0.8265\n",
      "Epoch 08 | Train Loss: 0.8203 | Val Loss: 0.8107\n",
      "Epoch 09 | Train Loss: 0.7974 | Val Loss: 0.7968\n",
      "Epoch 10 | Train Loss: 0.7683 | Val Loss: 0.7941\n",
      "Epoch 11 | Train Loss: 0.7724 | Val Loss: 0.7995\n",
      "Epoch 12 | Train Loss: 0.7487 | Val Loss: 0.8288\n",
      "Epoch 13 | Train Loss: 0.7552 | Val Loss: 0.8528\n",
      "Epoch 14 | Train Loss: 0.7697 | Val Loss: 0.8022\n",
      "Epoch 15 | Train Loss: 0.7727 | Val Loss: 0.7876\n",
      "Epoch 16 | Train Loss: 0.7899 | Val Loss: 0.7901\n",
      "Epoch 17 | Train Loss: 0.7547 | Val Loss: 0.8043\n",
      "Epoch 18 | Train Loss: 0.7514 | Val Loss: 0.7898\n",
      "Epoch 19 | Train Loss: 0.7425 | Val Loss: 0.7819\n",
      "Epoch 20 | Train Loss: 0.7263 | Val Loss: 0.7831\n",
      "Epoch 21 | Train Loss: 0.7258 | Val Loss: 0.7845\n",
      "Epoch 22 | Train Loss: 0.7308 | Val Loss: 0.7776\n",
      "Epoch 23 | Train Loss: 0.7419 | Val Loss: 0.7933\n",
      "Epoch 24 | Train Loss: 0.7294 | Val Loss: 0.7850\n",
      "Epoch 25 | Train Loss: 0.7461 | Val Loss: 0.7988\n",
      "Epoch 26 | Train Loss: 0.7523 | Val Loss: 0.7811\n",
      "Epoch 27 | Train Loss: 0.7327 | Val Loss: 0.7890\n",
      "Epoch 28 | Train Loss: 0.7176 | Val Loss: 0.7948\n",
      "Epoch 29 | Train Loss: 0.7280 | Val Loss: 0.7893\n",
      "Epoch 30 | Train Loss: 0.7337 | Val Loss: 0.7948\n",
      "Epoch 31 | Train Loss: 0.7234 | Val Loss: 0.7779\n",
      "Epoch 32 | Train Loss: 0.7207 | Val Loss: 0.7902\n",
      "Epoch 33 | Train Loss: 0.7056 | Val Loss: 0.7910\n",
      "Epoch 34 | Train Loss: 0.7250 | Val Loss: 0.8081\n",
      "Epoch 35 | Train Loss: 0.7690 | Val Loss: 0.7793\n",
      "Epoch 36 | Train Loss: 0.7403 | Val Loss: 0.7815\n",
      "Epoch 37 | Train Loss: 0.7225 | Val Loss: 0.8457\n",
      "Epoch 38 | Train Loss: 0.7329 | Val Loss: 0.7927\n",
      "Epoch 39 | Train Loss: 0.7111 | Val Loss: 0.7856\n",
      "Epoch 40 | Train Loss: 0.7340 | Val Loss: 0.7943\n",
      "Epoch 41 | Train Loss: 0.7376 | Val Loss: 0.7947\n",
      "Epoch 42 | Train Loss: 0.7285 | Val Loss: 0.7799\n",
      "Epoch 43 | Train Loss: 0.7106 | Val Loss: 0.7865\n",
      "Epoch 44 | Train Loss: 0.7001 | Val Loss: 0.7826\n",
      "Epoch 45 | Train Loss: 0.6994 | Val Loss: 0.7865\n",
      "Epoch 46 | Train Loss: 0.6854 | Val Loss: 0.7914\n",
      "Epoch 47 | Train Loss: 0.7010 | Val Loss: 0.8128\n",
      "Epoch 48 | Train Loss: 0.7262 | Val Loss: 0.8193\n",
      "Epoch 49 | Train Loss: 0.7425 | Val Loss: 0.8253\n",
      "Epoch 50 | Train Loss: 0.7305 | Val Loss: 0.7948\n",
      "Fold 8 ‚ñ∂ AUC: 0.716, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9648 | Val Loss: 0.8821\n",
      "Epoch 02 | Train Loss: 0.8749 | Val Loss: 0.8876\n",
      "Epoch 03 | Train Loss: 0.8685 | Val Loss: 0.8641\n",
      "Epoch 04 | Train Loss: 0.8533 | Val Loss: 0.8509\n",
      "Epoch 05 | Train Loss: 0.8403 | Val Loss: 0.8538\n",
      "Epoch 06 | Train Loss: 0.8551 | Val Loss: 0.8359\n",
      "Epoch 07 | Train Loss: 0.8400 | Val Loss: 0.8211\n",
      "Epoch 08 | Train Loss: 0.8034 | Val Loss: 0.8117\n",
      "Epoch 09 | Train Loss: 0.7810 | Val Loss: 0.8241\n",
      "Epoch 10 | Train Loss: 0.7767 | Val Loss: 0.8973\n",
      "Epoch 11 | Train Loss: 0.7855 | Val Loss: 0.7942\n",
      "Epoch 12 | Train Loss: 0.7723 | Val Loss: 0.8041\n",
      "Epoch 13 | Train Loss: 0.7607 | Val Loss: 0.8069\n",
      "Epoch 14 | Train Loss: 0.7633 | Val Loss: 0.7741\n",
      "Epoch 15 | Train Loss: 0.7838 | Val Loss: 0.7581\n",
      "Epoch 16 | Train Loss: 0.7492 | Val Loss: 0.7608\n",
      "Epoch 17 | Train Loss: 0.7363 | Val Loss: 0.7607\n",
      "Epoch 18 | Train Loss: 0.7611 | Val Loss: 0.7589\n",
      "Epoch 19 | Train Loss: 0.7374 | Val Loss: 0.7548\n",
      "Epoch 20 | Train Loss: 0.7565 | Val Loss: 0.7717\n",
      "Epoch 21 | Train Loss: 0.7716 | Val Loss: 0.7505\n",
      "Epoch 22 | Train Loss: 0.7440 | Val Loss: 0.7548\n",
      "Epoch 23 | Train Loss: 0.7353 | Val Loss: 0.7375\n",
      "Epoch 24 | Train Loss: 0.7391 | Val Loss: 0.8147\n",
      "Epoch 25 | Train Loss: 0.7544 | Val Loss: 0.7699\n",
      "Epoch 26 | Train Loss: 0.7260 | Val Loss: 0.7417\n",
      "Epoch 27 | Train Loss: 0.7480 | Val Loss: 0.7333\n",
      "Epoch 28 | Train Loss: 0.7493 | Val Loss: 0.7376\n",
      "Epoch 29 | Train Loss: 0.7558 | Val Loss: 0.7370\n",
      "Epoch 30 | Train Loss: 0.7310 | Val Loss: 0.7410\n",
      "Epoch 31 | Train Loss: 0.7203 | Val Loss: 0.7346\n",
      "Epoch 32 | Train Loss: 0.7203 | Val Loss: 0.7663\n",
      "Epoch 33 | Train Loss: 0.7335 | Val Loss: 0.7367\n",
      "Epoch 34 | Train Loss: 0.7627 | Val Loss: 0.7277\n",
      "Epoch 35 | Train Loss: 0.7090 | Val Loss: 0.7250\n",
      "Epoch 36 | Train Loss: 0.7500 | Val Loss: 0.7332\n",
      "Epoch 37 | Train Loss: 0.7508 | Val Loss: 0.8046\n",
      "Epoch 38 | Train Loss: 0.7290 | Val Loss: 0.7338\n",
      "Epoch 39 | Train Loss: 0.7376 | Val Loss: 0.7467\n",
      "Epoch 40 | Train Loss: 0.7046 | Val Loss: 0.7342\n",
      "Epoch 41 | Train Loss: 0.7371 | Val Loss: 0.7255\n",
      "Epoch 42 | Train Loss: 0.7165 | Val Loss: 0.7365\n",
      "Epoch 43 | Train Loss: 0.7246 | Val Loss: 0.7439\n",
      "Epoch 44 | Train Loss: 0.7064 | Val Loss: 0.7557\n",
      "Epoch 45 | Train Loss: 0.7269 | Val Loss: 0.7344\n",
      "Epoch 46 | Train Loss: 0.7249 | Val Loss: 0.7277\n",
      "Epoch 47 | Train Loss: 0.7355 | Val Loss: 0.7246\n",
      "Epoch 48 | Train Loss: 0.7183 | Val Loss: 0.7524\n",
      "Epoch 49 | Train Loss: 0.7334 | Val Loss: 0.7760\n",
      "Epoch 50 | Train Loss: 0.7231 | Val Loss: 0.7280\n",
      "Fold 9 ‚ñ∂ AUC: 0.765, Balanced Acc: 0.499\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9127 | Val Loss: 0.8768\n",
      "Epoch 02 | Train Loss: 0.8704 | Val Loss: 0.8767\n",
      "Epoch 03 | Train Loss: 0.8707 | Val Loss: 0.8667\n",
      "Epoch 04 | Train Loss: 0.8451 | Val Loss: 0.8328\n",
      "Epoch 05 | Train Loss: 0.8482 | Val Loss: 0.8166\n",
      "Epoch 06 | Train Loss: 0.8171 | Val Loss: 0.7833\n",
      "Epoch 07 | Train Loss: 0.8483 | Val Loss: 0.8270\n",
      "Epoch 08 | Train Loss: 0.8090 | Val Loss: 0.7849\n",
      "Epoch 09 | Train Loss: 0.7553 | Val Loss: 0.7790\n",
      "Epoch 10 | Train Loss: 0.7711 | Val Loss: 0.7971\n",
      "Epoch 11 | Train Loss: 0.7508 | Val Loss: 0.7612\n",
      "Epoch 12 | Train Loss: 0.7924 | Val Loss: 0.7748\n",
      "Epoch 13 | Train Loss: 0.7692 | Val Loss: 0.7688\n",
      "Epoch 14 | Train Loss: 0.7587 | Val Loss: 0.7663\n",
      "Epoch 15 | Train Loss: 0.7479 | Val Loss: 0.8445\n",
      "Epoch 16 | Train Loss: 0.7404 | Val Loss: 0.8124\n",
      "Epoch 17 | Train Loss: 0.7511 | Val Loss: 0.7691\n",
      "Epoch 18 | Train Loss: 0.7501 | Val Loss: 0.7884\n",
      "Epoch 19 | Train Loss: 0.7785 | Val Loss: 0.8441\n",
      "Epoch 20 | Train Loss: 0.7841 | Val Loss: 0.7751\n",
      "Epoch 21 | Train Loss: 0.7298 | Val Loss: 0.7948\n",
      "Epoch 22 | Train Loss: 0.7396 | Val Loss: 0.7783\n",
      "Epoch 23 | Train Loss: 0.7282 | Val Loss: 0.7868\n",
      "Epoch 24 | Train Loss: 0.7243 | Val Loss: 0.7843\n",
      "Epoch 25 | Train Loss: 0.7278 | Val Loss: 0.7782\n",
      "Epoch 26 | Train Loss: 0.7215 | Val Loss: 0.7731\n",
      "Epoch 27 | Train Loss: 0.7257 | Val Loss: 0.7872\n",
      "Epoch 28 | Train Loss: 0.7220 | Val Loss: 0.7997\n",
      "Epoch 29 | Train Loss: 0.7151 | Val Loss: 0.8206\n",
      "Epoch 30 | Train Loss: 0.7284 | Val Loss: 0.7773\n",
      "Epoch 31 | Train Loss: 0.7278 | Val Loss: 0.7802\n",
      "Epoch 32 | Train Loss: 0.7286 | Val Loss: 0.7836\n",
      "Epoch 33 | Train Loss: 0.7266 | Val Loss: 0.7827\n",
      "Epoch 34 | Train Loss: 0.7126 | Val Loss: 0.7974\n",
      "Epoch 35 | Train Loss: 0.7309 | Val Loss: 0.7808\n",
      "Epoch 36 | Train Loss: 0.7341 | Val Loss: 0.7865\n",
      "Epoch 37 | Train Loss: 0.7306 | Val Loss: 0.7812\n",
      "Epoch 38 | Train Loss: 0.7241 | Val Loss: 0.7793\n",
      "Epoch 39 | Train Loss: 0.7052 | Val Loss: 0.8272\n",
      "Epoch 40 | Train Loss: 0.7421 | Val Loss: 0.7755\n",
      "Epoch 41 | Train Loss: 0.7182 | Val Loss: 0.7916\n",
      "Epoch 42 | Train Loss: 0.7488 | Val Loss: 0.8174\n",
      "Epoch 43 | Train Loss: 0.7366 | Val Loss: 0.7945\n",
      "Epoch 44 | Train Loss: 0.7261 | Val Loss: 0.8091\n",
      "Epoch 45 | Train Loss: 0.7192 | Val Loss: 0.7727\n",
      "Epoch 46 | Train Loss: 0.7354 | Val Loss: 0.7724\n",
      "Epoch 47 | Train Loss: 0.7241 | Val Loss: 0.7786\n",
      "Epoch 48 | Train Loss: 0.7430 | Val Loss: 0.7657\n",
      "Epoch 49 | Train Loss: 0.7546 | Val Loss: 0.8057\n",
      "Epoch 50 | Train Loss: 0.7465 | Val Loss: 0.7747\n",
      "Fold 10 ‚ñ∂ AUC: 0.702, Balanced Acc: 0.469\n",
      "üîç Summary for hd=128, dp=0.4, lr=0.001 ‚Üí AUC: 0.7441¬±0.0311 | BalAcc: 0.4776¬±0.0437\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.4, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9478 | Val Loss: 0.8800\n",
      "Epoch 02 | Train Loss: 0.8931 | Val Loss: 0.8614\n",
      "Epoch 03 | Train Loss: 0.8887 | Val Loss: 0.8595\n",
      "Epoch 04 | Train Loss: 0.8647 | Val Loss: 0.8538\n",
      "Epoch 05 | Train Loss: 0.8653 | Val Loss: 0.8629\n",
      "Epoch 06 | Train Loss: 0.8578 | Val Loss: 0.8436\n",
      "Epoch 07 | Train Loss: 0.8546 | Val Loss: 0.8353\n",
      "Epoch 08 | Train Loss: 0.8578 | Val Loss: 0.8293\n",
      "Epoch 09 | Train Loss: 0.8408 | Val Loss: 0.8419\n",
      "Epoch 10 | Train Loss: 0.8654 | Val Loss: 0.8530\n",
      "Epoch 11 | Train Loss: 0.8839 | Val Loss: 0.8910\n",
      "Epoch 12 | Train Loss: 0.8603 | Val Loss: 0.8436\n",
      "Epoch 13 | Train Loss: 0.8329 | Val Loss: 0.8175\n",
      "Epoch 14 | Train Loss: 0.8206 | Val Loss: 0.8046\n",
      "Epoch 15 | Train Loss: 0.7988 | Val Loss: 0.8285\n",
      "Epoch 16 | Train Loss: 0.8354 | Val Loss: 0.7864\n",
      "Epoch 17 | Train Loss: 0.8258 | Val Loss: 0.8159\n",
      "Epoch 18 | Train Loss: 0.8136 | Val Loss: 0.7768\n",
      "Epoch 19 | Train Loss: 0.8061 | Val Loss: 0.7705\n",
      "Epoch 20 | Train Loss: 0.7918 | Val Loss: 0.7488\n",
      "Epoch 21 | Train Loss: 0.7829 | Val Loss: 0.7376\n",
      "Epoch 22 | Train Loss: 0.7575 | Val Loss: 0.7308\n",
      "Epoch 23 | Train Loss: 0.7466 | Val Loss: 0.7289\n",
      "Epoch 24 | Train Loss: 0.7579 | Val Loss: 0.7222\n",
      "Epoch 25 | Train Loss: 0.7492 | Val Loss: 0.7736\n",
      "Epoch 26 | Train Loss: 0.7782 | Val Loss: 0.7155\n",
      "Epoch 27 | Train Loss: 0.7466 | Val Loss: 0.7157\n",
      "Epoch 28 | Train Loss: 0.7546 | Val Loss: 0.7274\n",
      "Epoch 29 | Train Loss: 0.7646 | Val Loss: 0.7742\n",
      "Epoch 30 | Train Loss: 0.7660 | Val Loss: 0.7055\n",
      "Epoch 31 | Train Loss: 0.7668 | Val Loss: 0.7088\n",
      "Epoch 32 | Train Loss: 0.7579 | Val Loss: 0.7037\n",
      "Epoch 33 | Train Loss: 0.7416 | Val Loss: 0.7306\n",
      "Epoch 34 | Train Loss: 0.7402 | Val Loss: 0.6975\n",
      "Epoch 35 | Train Loss: 0.7593 | Val Loss: 0.6967\n",
      "Epoch 36 | Train Loss: 0.7660 | Val Loss: 0.6941\n",
      "Epoch 37 | Train Loss: 0.7631 | Val Loss: 0.7039\n",
      "Epoch 38 | Train Loss: 0.7333 | Val Loss: 0.6893\n",
      "Epoch 39 | Train Loss: 0.7437 | Val Loss: 0.6958\n",
      "Epoch 40 | Train Loss: 0.7550 | Val Loss: 0.7175\n",
      "Epoch 41 | Train Loss: 0.7319 | Val Loss: 0.6979\n",
      "Epoch 42 | Train Loss: 0.7323 | Val Loss: 0.6850\n",
      "Epoch 43 | Train Loss: 0.7453 | Val Loss: 0.6983\n",
      "Epoch 44 | Train Loss: 0.7419 | Val Loss: 0.6883\n",
      "Epoch 45 | Train Loss: 0.7327 | Val Loss: 0.6955\n",
      "Epoch 46 | Train Loss: 0.7225 | Val Loss: 0.6825\n",
      "Epoch 47 | Train Loss: 0.7539 | Val Loss: 0.6945\n",
      "Epoch 48 | Train Loss: 0.7370 | Val Loss: 0.6911\n",
      "Epoch 49 | Train Loss: 0.7286 | Val Loss: 0.6889\n",
      "Epoch 50 | Train Loss: 0.7158 | Val Loss: 0.6926\n",
      "Fold 1 ‚ñ∂ AUC: 0.783, Balanced Acc: 0.505\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9990 | Val Loss: 0.9007\n",
      "Epoch 02 | Train Loss: 0.8782 | Val Loss: 0.8662\n",
      "Epoch 03 | Train Loss: 0.8642 | Val Loss: 0.8536\n",
      "Epoch 04 | Train Loss: 0.8613 | Val Loss: 0.8504\n",
      "Epoch 05 | Train Loss: 0.8547 | Val Loss: 0.8512\n",
      "Epoch 06 | Train Loss: 0.8579 | Val Loss: 0.8610\n",
      "Epoch 07 | Train Loss: 0.8682 | Val Loss: 0.8418\n",
      "Epoch 08 | Train Loss: 0.8348 | Val Loss: 0.8274\n",
      "Epoch 09 | Train Loss: 0.8359 | Val Loss: 0.8208\n",
      "Epoch 10 | Train Loss: 0.8367 | Val Loss: 0.8114\n",
      "Epoch 11 | Train Loss: 0.8469 | Val Loss: 0.8298\n",
      "Epoch 12 | Train Loss: 0.8452 | Val Loss: 0.8049\n",
      "Epoch 13 | Train Loss: 0.8255 | Val Loss: 0.8833\n",
      "Epoch 14 | Train Loss: 0.8182 | Val Loss: 0.7909\n",
      "Epoch 15 | Train Loss: 0.7779 | Val Loss: 0.8005\n",
      "Epoch 16 | Train Loss: 0.7797 | Val Loss: 0.7712\n",
      "Epoch 17 | Train Loss: 0.8051 | Val Loss: 0.7634\n",
      "Epoch 18 | Train Loss: 0.7814 | Val Loss: 0.7748\n",
      "Epoch 19 | Train Loss: 0.7612 | Val Loss: 0.8133\n",
      "Epoch 20 | Train Loss: 0.7834 | Val Loss: 0.7547\n",
      "Epoch 21 | Train Loss: 0.7719 | Val Loss: 0.7697\n",
      "Epoch 22 | Train Loss: 0.7602 | Val Loss: 0.8529\n",
      "Epoch 23 | Train Loss: 0.7996 | Val Loss: 0.7533\n",
      "Epoch 24 | Train Loss: 0.7558 | Val Loss: 0.7306\n",
      "Epoch 25 | Train Loss: 0.7510 | Val Loss: 0.7497\n",
      "Epoch 26 | Train Loss: 0.7386 | Val Loss: 0.8114\n",
      "Epoch 27 | Train Loss: 0.7407 | Val Loss: 0.8548\n",
      "Epoch 28 | Train Loss: 0.7636 | Val Loss: 0.7211\n",
      "Epoch 29 | Train Loss: 0.7453 | Val Loss: 0.7228\n",
      "Epoch 30 | Train Loss: 0.7469 | Val Loss: 0.7311\n",
      "Epoch 31 | Train Loss: 0.7679 | Val Loss: 0.8559\n",
      "Epoch 32 | Train Loss: 0.7477 | Val Loss: 0.7109\n",
      "Epoch 33 | Train Loss: 0.7715 | Val Loss: 0.7065\n",
      "Epoch 34 | Train Loss: 0.7422 | Val Loss: 0.7366\n",
      "Epoch 35 | Train Loss: 0.7448 | Val Loss: 0.7316\n",
      "Epoch 36 | Train Loss: 0.7462 | Val Loss: 0.7126\n",
      "Epoch 37 | Train Loss: 0.7517 | Val Loss: 0.7155\n",
      "Epoch 38 | Train Loss: 0.7497 | Val Loss: 0.8303\n",
      "Epoch 39 | Train Loss: 0.7278 | Val Loss: 0.7047\n",
      "Epoch 40 | Train Loss: 0.7237 | Val Loss: 0.6992\n",
      "Epoch 41 | Train Loss: 0.7433 | Val Loss: 0.7680\n",
      "Epoch 42 | Train Loss: 0.7490 | Val Loss: 0.7137\n",
      "Epoch 43 | Train Loss: 0.7402 | Val Loss: 0.7615\n",
      "Epoch 44 | Train Loss: 0.7518 | Val Loss: 0.7021\n",
      "Epoch 45 | Train Loss: 0.7164 | Val Loss: 0.7286\n",
      "Epoch 46 | Train Loss: 0.7292 | Val Loss: 0.7643\n",
      "Epoch 47 | Train Loss: 0.7253 | Val Loss: 0.7250\n",
      "Epoch 48 | Train Loss: 0.7376 | Val Loss: 0.7122\n",
      "Epoch 49 | Train Loss: 0.7467 | Val Loss: 0.7184\n",
      "Epoch 50 | Train Loss: 0.7221 | Val Loss: 0.7390\n",
      "Fold 2 ‚ñ∂ AUC: 0.682, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9126 | Val Loss: 0.8649\n",
      "Epoch 02 | Train Loss: 0.8682 | Val Loss: 0.9046\n",
      "Epoch 03 | Train Loss: 0.8830 | Val Loss: 0.8605\n",
      "Epoch 04 | Train Loss: 0.8560 | Val Loss: 0.8424\n",
      "Epoch 05 | Train Loss: 0.8792 | Val Loss: 0.8531\n",
      "Epoch 06 | Train Loss: 0.8741 | Val Loss: 0.8335\n",
      "Epoch 07 | Train Loss: 0.8467 | Val Loss: 0.8264\n",
      "Epoch 08 | Train Loss: 0.8398 | Val Loss: 0.8098\n",
      "Epoch 09 | Train Loss: 0.8298 | Val Loss: 0.8745\n",
      "Epoch 10 | Train Loss: 0.8446 | Val Loss: 0.8362\n",
      "Epoch 11 | Train Loss: 0.8102 | Val Loss: 0.8634\n",
      "Epoch 12 | Train Loss: 0.8311 | Val Loss: 0.7908\n",
      "Epoch 13 | Train Loss: 0.7967 | Val Loss: 0.7712\n",
      "Epoch 14 | Train Loss: 0.7932 | Val Loss: 0.7789\n",
      "Epoch 15 | Train Loss: 0.7728 | Val Loss: 0.7627\n",
      "Epoch 16 | Train Loss: 0.7649 | Val Loss: 0.7487\n",
      "Epoch 17 | Train Loss: 0.7549 | Val Loss: 0.7987\n",
      "Epoch 18 | Train Loss: 0.7953 | Val Loss: 0.7811\n",
      "Epoch 19 | Train Loss: 0.7798 | Val Loss: 0.7656\n",
      "Epoch 20 | Train Loss: 0.7525 | Val Loss: 0.7383\n",
      "Epoch 21 | Train Loss: 0.7479 | Val Loss: 0.7278\n",
      "Epoch 22 | Train Loss: 0.7587 | Val Loss: 0.7266\n",
      "Epoch 23 | Train Loss: 0.7558 | Val Loss: 0.7258\n",
      "Epoch 24 | Train Loss: 0.7508 | Val Loss: 0.7317\n",
      "Epoch 25 | Train Loss: 0.7558 | Val Loss: 0.7695\n",
      "Epoch 26 | Train Loss: 0.7694 | Val Loss: 0.7382\n",
      "Epoch 27 | Train Loss: 0.7782 | Val Loss: 0.7272\n",
      "Epoch 28 | Train Loss: 0.7378 | Val Loss: 0.7665\n",
      "Epoch 29 | Train Loss: 0.7533 | Val Loss: 0.7404\n",
      "Epoch 30 | Train Loss: 0.7346 | Val Loss: 0.7400\n",
      "Epoch 31 | Train Loss: 0.7790 | Val Loss: 0.7223\n",
      "Epoch 32 | Train Loss: 0.7465 | Val Loss: 0.7267\n",
      "Epoch 33 | Train Loss: 0.7349 | Val Loss: 0.7695\n",
      "Epoch 34 | Train Loss: 0.7231 | Val Loss: 0.7237\n",
      "Epoch 35 | Train Loss: 0.7415 | Val Loss: 0.7359\n",
      "Epoch 36 | Train Loss: 0.7488 | Val Loss: 0.7292\n",
      "Epoch 37 | Train Loss: 0.7320 | Val Loss: 0.7241\n",
      "Epoch 38 | Train Loss: 0.7229 | Val Loss: 0.7366\n",
      "Epoch 39 | Train Loss: 0.7249 | Val Loss: 0.7592\n",
      "Epoch 40 | Train Loss: 0.7278 | Val Loss: 0.7171\n",
      "Epoch 41 | Train Loss: 0.7383 | Val Loss: 0.7212\n",
      "Epoch 42 | Train Loss: 0.7428 | Val Loss: 0.7235\n",
      "Epoch 43 | Train Loss: 0.7377 | Val Loss: 0.7497\n",
      "Epoch 44 | Train Loss: 0.7308 | Val Loss: 0.7282\n",
      "Epoch 45 | Train Loss: 0.7219 | Val Loss: 0.7117\n",
      "Epoch 46 | Train Loss: 0.7469 | Val Loss: 0.7086\n",
      "Epoch 47 | Train Loss: 0.7201 | Val Loss: 0.7587\n",
      "Epoch 48 | Train Loss: 0.7293 | Val Loss: 0.7201\n",
      "Epoch 49 | Train Loss: 0.7109 | Val Loss: 0.7160\n",
      "Epoch 50 | Train Loss: 0.7122 | Val Loss: 0.7302\n",
      "Fold 3 ‚ñ∂ AUC: 0.764, Balanced Acc: 0.476\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9088 | Val Loss: 0.8515\n",
      "Epoch 02 | Train Loss: 0.8848 | Val Loss: 0.8572\n",
      "Epoch 03 | Train Loss: 0.8742 | Val Loss: 0.8445\n",
      "Epoch 04 | Train Loss: 0.8693 | Val Loss: 0.8422\n",
      "Epoch 05 | Train Loss: 0.8620 | Val Loss: 0.8388\n",
      "Epoch 06 | Train Loss: 0.8763 | Val Loss: 0.8324\n",
      "Epoch 07 | Train Loss: 0.8786 | Val Loss: 0.8200\n",
      "Epoch 08 | Train Loss: 0.8298 | Val Loss: 0.8195\n",
      "Epoch 09 | Train Loss: 0.8232 | Val Loss: 0.8014\n",
      "Epoch 10 | Train Loss: 0.8210 | Val Loss: 0.8199\n",
      "Epoch 11 | Train Loss: 0.8165 | Val Loss: 0.7600\n",
      "Epoch 12 | Train Loss: 0.7898 | Val Loss: 0.7435\n",
      "Epoch 13 | Train Loss: 0.7772 | Val Loss: 0.7435\n",
      "Epoch 14 | Train Loss: 0.7744 | Val Loss: 0.7229\n",
      "Epoch 15 | Train Loss: 0.7713 | Val Loss: 0.7118\n",
      "Epoch 16 | Train Loss: 0.7515 | Val Loss: 0.7038\n",
      "Epoch 17 | Train Loss: 0.7850 | Val Loss: 0.7010\n",
      "Epoch 18 | Train Loss: 0.7636 | Val Loss: 0.7145\n",
      "Epoch 19 | Train Loss: 0.7705 | Val Loss: 0.7303\n",
      "Epoch 20 | Train Loss: 0.7513 | Val Loss: 0.7021\n",
      "Epoch 21 | Train Loss: 0.7647 | Val Loss: 0.6871\n",
      "Epoch 22 | Train Loss: 0.7591 | Val Loss: 0.6908\n",
      "Epoch 23 | Train Loss: 0.7526 | Val Loss: 0.6851\n",
      "Epoch 24 | Train Loss: 0.7403 | Val Loss: 0.6797\n",
      "Epoch 25 | Train Loss: 0.7461 | Val Loss: 0.6718\n",
      "Epoch 26 | Train Loss: 0.7485 | Val Loss: 0.6805\n",
      "Epoch 27 | Train Loss: 0.7484 | Val Loss: 0.6855\n",
      "Epoch 28 | Train Loss: 0.7734 | Val Loss: 0.6807\n",
      "Epoch 29 | Train Loss: 0.7494 | Val Loss: 0.6748\n",
      "Epoch 30 | Train Loss: 0.7240 | Val Loss: 0.6655\n",
      "Epoch 31 | Train Loss: 0.7467 | Val Loss: 0.6726\n",
      "Epoch 32 | Train Loss: 0.7294 | Val Loss: 0.6649\n",
      "Epoch 33 | Train Loss: 0.7173 | Val Loss: 0.6693\n",
      "Epoch 34 | Train Loss: 0.7415 | Val Loss: 0.6704\n",
      "Epoch 35 | Train Loss: 0.7261 | Val Loss: 0.6705\n",
      "Epoch 36 | Train Loss: 0.7438 | Val Loss: 0.6934\n",
      "Epoch 37 | Train Loss: 0.7446 | Val Loss: 0.6884\n",
      "Epoch 38 | Train Loss: 0.7297 | Val Loss: 0.6657\n",
      "Epoch 39 | Train Loss: 0.7351 | Val Loss: 0.6726\n",
      "Epoch 40 | Train Loss: 0.7402 | Val Loss: 0.6788\n",
      "Epoch 41 | Train Loss: 0.7596 | Val Loss: 0.6710\n",
      "Epoch 42 | Train Loss: 0.7244 | Val Loss: 0.6925\n",
      "Epoch 43 | Train Loss: 0.7732 | Val Loss: 0.6827\n",
      "Epoch 44 | Train Loss: 0.7191 | Val Loss: 0.6841\n",
      "Epoch 45 | Train Loss: 0.7358 | Val Loss: 0.6625\n",
      "Epoch 46 | Train Loss: 0.7323 | Val Loss: 0.6702\n",
      "Epoch 47 | Train Loss: 0.7452 | Val Loss: 0.6765\n",
      "Epoch 48 | Train Loss: 0.7106 | Val Loss: 0.6696\n",
      "Epoch 49 | Train Loss: 0.7295 | Val Loss: 0.6653\n",
      "Epoch 50 | Train Loss: 0.7268 | Val Loss: 0.6655\n",
      "Fold 4 ‚ñ∂ AUC: 0.774, Balanced Acc: 0.532\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9075 | Val Loss: 0.9045\n",
      "Epoch 02 | Train Loss: 0.8811 | Val Loss: 0.8872\n",
      "Epoch 03 | Train Loss: 0.8506 | Val Loss: 0.8962\n",
      "Epoch 04 | Train Loss: 0.8536 | Val Loss: 0.8749\n",
      "Epoch 05 | Train Loss: 0.8326 | Val Loss: 0.8676\n",
      "Epoch 06 | Train Loss: 0.8578 | Val Loss: 0.8672\n",
      "Epoch 07 | Train Loss: 0.8078 | Val Loss: 0.9136\n",
      "Epoch 08 | Train Loss: 0.8852 | Val Loss: 0.8782\n",
      "Epoch 09 | Train Loss: 0.8255 | Val Loss: 0.8602\n",
      "Epoch 10 | Train Loss: 0.8234 | Val Loss: 0.8539\n",
      "Epoch 11 | Train Loss: 0.8125 | Val Loss: 0.8401\n",
      "Epoch 12 | Train Loss: 0.8097 | Val Loss: 0.8395\n",
      "Epoch 13 | Train Loss: 0.7724 | Val Loss: 0.8304\n",
      "Epoch 14 | Train Loss: 0.7838 | Val Loss: 0.8462\n",
      "Epoch 15 | Train Loss: 0.7915 | Val Loss: 0.8269\n",
      "Epoch 16 | Train Loss: 0.7749 | Val Loss: 0.8184\n",
      "Epoch 17 | Train Loss: 0.7521 | Val Loss: 0.8203\n",
      "Epoch 18 | Train Loss: 0.7404 | Val Loss: 0.8182\n",
      "Epoch 19 | Train Loss: 0.7377 | Val Loss: 0.8218\n",
      "Epoch 20 | Train Loss: 0.7482 | Val Loss: 0.8133\n",
      "Epoch 21 | Train Loss: 0.7650 | Val Loss: 0.8129\n",
      "Epoch 22 | Train Loss: 0.7320 | Val Loss: 0.8567\n",
      "Epoch 23 | Train Loss: 0.7525 | Val Loss: 0.8267\n",
      "Epoch 24 | Train Loss: 0.7863 | Val Loss: 0.8111\n",
      "Epoch 25 | Train Loss: 0.7465 | Val Loss: 0.8255\n",
      "Epoch 26 | Train Loss: 0.7347 | Val Loss: 0.8099\n",
      "Epoch 27 | Train Loss: 0.7317 | Val Loss: 0.8074\n",
      "Epoch 28 | Train Loss: 0.7374 | Val Loss: 0.8210\n",
      "Epoch 29 | Train Loss: 0.7302 | Val Loss: 0.7925\n",
      "Epoch 30 | Train Loss: 0.7397 | Val Loss: 0.8113\n",
      "Epoch 31 | Train Loss: 0.7431 | Val Loss: 0.7916\n",
      "Epoch 32 | Train Loss: 0.7313 | Val Loss: 0.8263\n",
      "Epoch 33 | Train Loss: 0.7230 | Val Loss: 0.8182\n",
      "Epoch 34 | Train Loss: 0.7308 | Val Loss: 0.7937\n",
      "Epoch 35 | Train Loss: 0.7264 | Val Loss: 0.7841\n",
      "Epoch 36 | Train Loss: 0.7134 | Val Loss: 0.7855\n",
      "Epoch 37 | Train Loss: 0.7230 | Val Loss: 0.7928\n",
      "Epoch 38 | Train Loss: 0.7131 | Val Loss: 0.8010\n",
      "Epoch 39 | Train Loss: 0.7336 | Val Loss: 0.7867\n",
      "Epoch 40 | Train Loss: 0.7301 | Val Loss: 0.7799\n",
      "Epoch 41 | Train Loss: 0.7460 | Val Loss: 0.7877\n",
      "Epoch 42 | Train Loss: 0.7127 | Val Loss: 0.7980\n",
      "Epoch 43 | Train Loss: 0.7201 | Val Loss: 0.7921\n",
      "Epoch 44 | Train Loss: 0.7296 | Val Loss: 0.7916\n",
      "Epoch 45 | Train Loss: 0.7223 | Val Loss: 0.7830\n",
      "Epoch 46 | Train Loss: 0.7308 | Val Loss: 0.7911\n",
      "Epoch 47 | Train Loss: 0.7172 | Val Loss: 0.7914\n",
      "Epoch 48 | Train Loss: 0.7261 | Val Loss: 0.7842\n",
      "Epoch 49 | Train Loss: 0.7129 | Val Loss: 0.8048\n",
      "Epoch 50 | Train Loss: 0.7230 | Val Loss: 0.8231\n",
      "Fold 5 ‚ñ∂ AUC: 0.724, Balanced Acc: 0.425\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9138 | Val Loss: 0.9068\n",
      "Epoch 02 | Train Loss: 0.8657 | Val Loss: 0.8887\n",
      "Epoch 03 | Train Loss: 0.8843 | Val Loss: 0.8872\n",
      "Epoch 04 | Train Loss: 0.8759 | Val Loss: 0.8954\n",
      "Epoch 05 | Train Loss: 0.8592 | Val Loss: 0.8952\n",
      "Epoch 06 | Train Loss: 0.8418 | Val Loss: 0.8811\n",
      "Epoch 07 | Train Loss: 0.8378 | Val Loss: 0.9338\n",
      "Epoch 08 | Train Loss: 0.8617 | Val Loss: 0.8656\n",
      "Epoch 09 | Train Loss: 0.8139 | Val Loss: 0.9083\n",
      "Epoch 10 | Train Loss: 0.8489 | Val Loss: 0.8653\n",
      "Epoch 11 | Train Loss: 0.8043 | Val Loss: 0.8432\n",
      "Epoch 12 | Train Loss: 0.7794 | Val Loss: 0.8444\n",
      "Epoch 13 | Train Loss: 0.7631 | Val Loss: 0.8452\n",
      "Epoch 14 | Train Loss: 0.7780 | Val Loss: 0.8454\n",
      "Epoch 15 | Train Loss: 0.7851 | Val Loss: 0.8279\n",
      "Epoch 16 | Train Loss: 0.7666 | Val Loss: 0.8880\n",
      "Epoch 17 | Train Loss: 0.8146 | Val Loss: 0.8536\n",
      "Epoch 18 | Train Loss: 0.7666 | Val Loss: 0.8225\n",
      "Epoch 19 | Train Loss: 0.7455 | Val Loss: 0.8453\n",
      "Epoch 20 | Train Loss: 0.7379 | Val Loss: 0.8344\n",
      "Epoch 21 | Train Loss: 0.7415 | Val Loss: 0.8348\n",
      "Epoch 22 | Train Loss: 0.7498 | Val Loss: 0.8248\n",
      "Epoch 23 | Train Loss: 0.7547 | Val Loss: 0.8184\n",
      "Epoch 24 | Train Loss: 0.7296 | Val Loss: 0.8305\n",
      "Epoch 25 | Train Loss: 0.7208 | Val Loss: 0.8247\n",
      "Epoch 26 | Train Loss: 0.7302 | Val Loss: 0.8364\n",
      "Epoch 27 | Train Loss: 0.7334 | Val Loss: 0.8230\n",
      "Epoch 28 | Train Loss: 0.7282 | Val Loss: 0.8454\n",
      "Epoch 29 | Train Loss: 0.7503 | Val Loss: 0.8263\n",
      "Epoch 30 | Train Loss: 0.7181 | Val Loss: 0.8346\n",
      "Epoch 31 | Train Loss: 0.7263 | Val Loss: 0.8435\n",
      "Epoch 32 | Train Loss: 0.7441 | Val Loss: 0.8389\n",
      "Epoch 33 | Train Loss: 0.7264 | Val Loss: 0.8311\n",
      "Epoch 34 | Train Loss: 0.7120 | Val Loss: 0.8367\n",
      "Epoch 35 | Train Loss: 0.7322 | Val Loss: 0.8488\n",
      "Epoch 36 | Train Loss: 0.7455 | Val Loss: 0.8306\n",
      "Epoch 37 | Train Loss: 0.7296 | Val Loss: 0.8277\n",
      "Epoch 38 | Train Loss: 0.7197 | Val Loss: 0.8342\n",
      "Epoch 39 | Train Loss: 0.7216 | Val Loss: 0.8896\n",
      "Epoch 40 | Train Loss: 0.7204 | Val Loss: 0.8338\n",
      "Epoch 41 | Train Loss: 0.7380 | Val Loss: 0.8336\n",
      "Epoch 42 | Train Loss: 0.7044 | Val Loss: 0.8343\n",
      "Epoch 43 | Train Loss: 0.7004 | Val Loss: 0.8391\n",
      "Epoch 44 | Train Loss: 0.7279 | Val Loss: 0.8423\n",
      "Epoch 45 | Train Loss: 0.7332 | Val Loss: 0.8416\n",
      "Epoch 46 | Train Loss: 0.7084 | Val Loss: 0.8392\n",
      "Epoch 47 | Train Loss: 0.7205 | Val Loss: 0.8299\n",
      "Epoch 48 | Train Loss: 0.7166 | Val Loss: 0.8469\n",
      "Epoch 49 | Train Loss: 0.7151 | Val Loss: 0.8400\n",
      "Epoch 50 | Train Loss: 0.7005 | Val Loss: 0.8708\n",
      "Fold 6 ‚ñ∂ AUC: 0.700, Balanced Acc: 0.409\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9430 | Val Loss: 0.8620\n",
      "Epoch 02 | Train Loss: 0.8743 | Val Loss: 0.8708\n",
      "Epoch 03 | Train Loss: 0.8943 | Val Loss: 0.8399\n",
      "Epoch 04 | Train Loss: 0.8677 | Val Loss: 0.8348\n",
      "Epoch 05 | Train Loss: 0.8514 | Val Loss: 0.8254\n",
      "Epoch 06 | Train Loss: 0.8441 | Val Loss: 0.8262\n",
      "Epoch 07 | Train Loss: 0.8443 | Val Loss: 0.8019\n",
      "Epoch 08 | Train Loss: 0.8472 | Val Loss: 0.7822\n",
      "Epoch 09 | Train Loss: 0.8419 | Val Loss: 0.8066\n",
      "Epoch 10 | Train Loss: 0.8224 | Val Loss: 0.7585\n",
      "Epoch 11 | Train Loss: 0.8188 | Val Loss: 0.7720\n",
      "Epoch 12 | Train Loss: 0.7889 | Val Loss: 0.7368\n",
      "Epoch 13 | Train Loss: 0.7917 | Val Loss: 0.7193\n",
      "Epoch 14 | Train Loss: 0.7807 | Val Loss: 0.7809\n",
      "Epoch 15 | Train Loss: 0.7938 | Val Loss: 0.7281\n",
      "Epoch 16 | Train Loss: 0.7782 | Val Loss: 0.7560\n",
      "Epoch 17 | Train Loss: 0.7976 | Val Loss: 0.7288\n",
      "Epoch 18 | Train Loss: 0.7725 | Val Loss: 0.7039\n",
      "Epoch 19 | Train Loss: 0.7517 | Val Loss: 0.7102\n",
      "Epoch 20 | Train Loss: 0.7614 | Val Loss: 0.7179\n",
      "Epoch 21 | Train Loss: 0.7359 | Val Loss: 0.7042\n",
      "Epoch 22 | Train Loss: 0.7692 | Val Loss: 0.7392\n",
      "Epoch 23 | Train Loss: 0.7718 | Val Loss: 0.7228\n",
      "Epoch 24 | Train Loss: 0.7419 | Val Loss: 0.7210\n",
      "Epoch 25 | Train Loss: 0.7534 | Val Loss: 0.7230\n",
      "Epoch 26 | Train Loss: 0.7677 | Val Loss: 0.7294\n",
      "Epoch 27 | Train Loss: 0.7521 | Val Loss: 0.7197\n",
      "Epoch 28 | Train Loss: 0.7402 | Val Loss: 0.7179\n",
      "Epoch 29 | Train Loss: 0.7270 | Val Loss: 0.7119\n",
      "Epoch 30 | Train Loss: 0.7492 | Val Loss: 0.7162\n",
      "Epoch 31 | Train Loss: 0.7280 | Val Loss: 0.7305\n",
      "Epoch 32 | Train Loss: 0.7264 | Val Loss: 0.7165\n",
      "Epoch 33 | Train Loss: 0.7289 | Val Loss: 0.7191\n",
      "Epoch 34 | Train Loss: 0.7181 | Val Loss: 0.7449\n",
      "Epoch 35 | Train Loss: 0.7392 | Val Loss: 0.7503\n",
      "Epoch 36 | Train Loss: 0.7471 | Val Loss: 0.7413\n",
      "Epoch 37 | Train Loss: 0.7418 | Val Loss: 0.7306\n",
      "Epoch 38 | Train Loss: 0.7511 | Val Loss: 0.7473\n",
      "Epoch 39 | Train Loss: 0.7390 | Val Loss: 0.7188\n",
      "Epoch 40 | Train Loss: 0.7445 | Val Loss: 0.7212\n",
      "Epoch 41 | Train Loss: 0.7189 | Val Loss: 0.7422\n",
      "Epoch 42 | Train Loss: 0.7600 | Val Loss: 0.7346\n",
      "Epoch 43 | Train Loss: 0.7420 | Val Loss: 0.7462\n",
      "Epoch 44 | Train Loss: 0.7178 | Val Loss: 0.7263\n",
      "Epoch 45 | Train Loss: 0.7175 | Val Loss: 0.7462\n",
      "Epoch 46 | Train Loss: 0.7137 | Val Loss: 0.7297\n",
      "Epoch 47 | Train Loss: 0.7171 | Val Loss: 0.7337\n",
      "Epoch 48 | Train Loss: 0.7202 | Val Loss: 0.7485\n",
      "Epoch 49 | Train Loss: 0.7133 | Val Loss: 0.7360\n",
      "Epoch 50 | Train Loss: 0.7094 | Val Loss: 0.8136\n",
      "Fold 7 ‚ñ∂ AUC: 0.752, Balanced Acc: 0.437\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.8868 | Val Loss: 0.9015\n",
      "Epoch 02 | Train Loss: 0.8978 | Val Loss: 0.8729\n",
      "Epoch 03 | Train Loss: 0.8787 | Val Loss: 0.8647\n",
      "Epoch 04 | Train Loss: 0.8598 | Val Loss: 0.8624\n",
      "Epoch 05 | Train Loss: 0.8689 | Val Loss: 0.8552\n",
      "Epoch 06 | Train Loss: 0.8684 | Val Loss: 0.8489\n",
      "Epoch 07 | Train Loss: 0.8474 | Val Loss: 0.8400\n",
      "Epoch 08 | Train Loss: 0.8327 | Val Loss: 0.8243\n",
      "Epoch 09 | Train Loss: 0.8514 | Val Loss: 0.8044\n",
      "Epoch 10 | Train Loss: 0.8064 | Val Loss: 0.8001\n",
      "Epoch 11 | Train Loss: 0.7897 | Val Loss: 0.7966\n",
      "Epoch 12 | Train Loss: 0.7692 | Val Loss: 0.7921\n",
      "Epoch 13 | Train Loss: 0.7725 | Val Loss: 0.8150\n",
      "Epoch 14 | Train Loss: 0.7528 | Val Loss: 0.7864\n",
      "Epoch 15 | Train Loss: 0.7525 | Val Loss: 0.7924\n",
      "Epoch 16 | Train Loss: 0.7677 | Val Loss: 0.8967\n",
      "Epoch 17 | Train Loss: 0.7571 | Val Loss: 0.7969\n",
      "Epoch 18 | Train Loss: 0.7428 | Val Loss: 0.8115\n",
      "Epoch 19 | Train Loss: 0.7571 | Val Loss: 0.7997\n",
      "Epoch 20 | Train Loss: 0.7522 | Val Loss: 0.7969\n",
      "Epoch 21 | Train Loss: 0.7319 | Val Loss: 0.8150\n",
      "Epoch 22 | Train Loss: 0.7522 | Val Loss: 0.8008\n",
      "Epoch 23 | Train Loss: 0.7415 | Val Loss: 0.7974\n",
      "Epoch 24 | Train Loss: 0.7310 | Val Loss: 0.8005\n",
      "Epoch 25 | Train Loss: 0.7133 | Val Loss: 0.8123\n",
      "Epoch 26 | Train Loss: 0.7234 | Val Loss: 0.7993\n",
      "Epoch 27 | Train Loss: 0.7342 | Val Loss: 0.8094\n",
      "Epoch 28 | Train Loss: 0.7349 | Val Loss: 0.7987\n",
      "Epoch 29 | Train Loss: 0.7570 | Val Loss: 0.8011\n",
      "Epoch 30 | Train Loss: 0.7292 | Val Loss: 0.7898\n",
      "Epoch 31 | Train Loss: 0.7348 | Val Loss: 0.7981\n",
      "Epoch 32 | Train Loss: 0.7458 | Val Loss: 0.7971\n",
      "Epoch 33 | Train Loss: 0.7341 | Val Loss: 0.7914\n",
      "Epoch 34 | Train Loss: 0.7144 | Val Loss: 0.7959\n",
      "Epoch 35 | Train Loss: 0.7076 | Val Loss: 0.8049\n",
      "Epoch 36 | Train Loss: 0.7342 | Val Loss: 0.8009\n",
      "Epoch 37 | Train Loss: 0.7114 | Val Loss: 0.8037\n",
      "Epoch 38 | Train Loss: 0.7217 | Val Loss: 0.8076\n",
      "Epoch 39 | Train Loss: 0.7297 | Val Loss: 0.7893\n",
      "Epoch 40 | Train Loss: 0.7247 | Val Loss: 0.8075\n",
      "Epoch 41 | Train Loss: 0.7239 | Val Loss: 0.8136\n",
      "Epoch 42 | Train Loss: 0.7303 | Val Loss: 0.7980\n",
      "Epoch 43 | Train Loss: 0.7287 | Val Loss: 0.8053\n",
      "Epoch 44 | Train Loss: 0.7258 | Val Loss: 0.7863\n",
      "Epoch 45 | Train Loss: 0.7082 | Val Loss: 0.8079\n",
      "Epoch 46 | Train Loss: 0.7239 | Val Loss: 0.7895\n",
      "Epoch 47 | Train Loss: 0.7099 | Val Loss: 0.8050\n",
      "Epoch 48 | Train Loss: 0.7260 | Val Loss: 0.8160\n",
      "Epoch 49 | Train Loss: 0.7081 | Val Loss: 0.7869\n",
      "Epoch 50 | Train Loss: 0.7037 | Val Loss: 0.8120\n",
      "Fold 8 ‚ñ∂ AUC: 0.688, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9134 | Val Loss: 0.8729\n",
      "Epoch 02 | Train Loss: 0.8668 | Val Loss: 0.8753\n",
      "Epoch 03 | Train Loss: 0.8594 | Val Loss: 0.8629\n",
      "Epoch 04 | Train Loss: 0.8479 | Val Loss: 0.8553\n",
      "Epoch 05 | Train Loss: 0.8490 | Val Loss: 0.8496\n",
      "Epoch 06 | Train Loss: 0.8333 | Val Loss: 0.8482\n",
      "Epoch 07 | Train Loss: 0.8262 | Val Loss: 0.8864\n",
      "Epoch 08 | Train Loss: 0.8350 | Val Loss: 0.8269\n",
      "Epoch 09 | Train Loss: 0.7918 | Val Loss: 0.8196\n",
      "Epoch 10 | Train Loss: 0.7736 | Val Loss: 0.9270\n",
      "Epoch 11 | Train Loss: 0.8157 | Val Loss: 0.8226\n",
      "Epoch 12 | Train Loss: 0.7780 | Val Loss: 0.8077\n",
      "Epoch 13 | Train Loss: 0.7868 | Val Loss: 0.7952\n",
      "Epoch 14 | Train Loss: 0.7670 | Val Loss: 0.8332\n",
      "Epoch 15 | Train Loss: 0.7547 | Val Loss: 0.8429\n",
      "Epoch 16 | Train Loss: 0.7575 | Val Loss: 0.7845\n",
      "Epoch 17 | Train Loss: 0.7403 | Val Loss: 0.7928\n",
      "Epoch 18 | Train Loss: 0.7481 | Val Loss: 0.7818\n",
      "Epoch 19 | Train Loss: 0.7500 | Val Loss: 0.7932\n",
      "Epoch 20 | Train Loss: 0.7488 | Val Loss: 0.7772\n",
      "Epoch 21 | Train Loss: 0.7626 | Val Loss: 0.7802\n",
      "Epoch 22 | Train Loss: 0.7301 | Val Loss: 0.8541\n",
      "Epoch 23 | Train Loss: 0.7687 | Val Loss: 0.7702\n",
      "Epoch 24 | Train Loss: 0.7515 | Val Loss: 0.7584\n",
      "Epoch 25 | Train Loss: 0.7433 | Val Loss: 0.7667\n",
      "Epoch 26 | Train Loss: 0.7323 | Val Loss: 0.7836\n",
      "Epoch 27 | Train Loss: 0.7579 | Val Loss: 0.7951\n",
      "Epoch 28 | Train Loss: 0.7379 | Val Loss: 0.7655\n",
      "Epoch 29 | Train Loss: 0.7241 | Val Loss: 0.7526\n",
      "Epoch 30 | Train Loss: 0.7308 | Val Loss: 0.7686\n",
      "Epoch 31 | Train Loss: 0.7298 | Val Loss: 0.7910\n",
      "Epoch 32 | Train Loss: 0.7340 | Val Loss: 0.7513\n",
      "Epoch 33 | Train Loss: 0.7562 | Val Loss: 0.7484\n",
      "Epoch 34 | Train Loss: 0.7361 | Val Loss: 0.7601\n",
      "Epoch 35 | Train Loss: 0.7299 | Val Loss: 0.8174\n",
      "Epoch 36 | Train Loss: 0.7497 | Val Loss: 0.7438\n",
      "Epoch 37 | Train Loss: 0.7100 | Val Loss: 0.7754\n",
      "Epoch 38 | Train Loss: 0.7187 | Val Loss: 0.7436\n",
      "Epoch 39 | Train Loss: 0.7157 | Val Loss: 0.7779\n",
      "Epoch 40 | Train Loss: 0.7118 | Val Loss: 0.7562\n",
      "Epoch 41 | Train Loss: 0.7352 | Val Loss: 0.7670\n",
      "Epoch 42 | Train Loss: 0.7394 | Val Loss: 0.7410\n",
      "Epoch 43 | Train Loss: 0.7276 | Val Loss: 0.7428\n",
      "Epoch 44 | Train Loss: 0.7161 | Val Loss: 0.7785\n",
      "Epoch 45 | Train Loss: 0.7290 | Val Loss: 0.7796\n",
      "Epoch 46 | Train Loss: 0.7128 | Val Loss: 0.7446\n",
      "Epoch 47 | Train Loss: 0.7201 | Val Loss: 0.7418\n",
      "Epoch 48 | Train Loss: 0.7220 | Val Loss: 0.7668\n",
      "Epoch 49 | Train Loss: 0.7138 | Val Loss: 0.7480\n",
      "Epoch 50 | Train Loss: 0.7231 | Val Loss: 0.7332\n",
      "Fold 9 ‚ñ∂ AUC: 0.755, Balanced Acc: 0.495\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9030 | Val Loss: 0.8617\n",
      "Epoch 02 | Train Loss: 0.8686 | Val Loss: 0.8548\n",
      "Epoch 03 | Train Loss: 0.8653 | Val Loss: 0.8512\n",
      "Epoch 04 | Train Loss: 0.8575 | Val Loss: 0.8388\n",
      "Epoch 05 | Train Loss: 0.8366 | Val Loss: 0.8275\n",
      "Epoch 06 | Train Loss: 0.8325 | Val Loss: 0.8374\n",
      "Epoch 07 | Train Loss: 0.8281 | Val Loss: 0.8052\n",
      "Epoch 08 | Train Loss: 0.8067 | Val Loss: 0.7904\n",
      "Epoch 09 | Train Loss: 0.7930 | Val Loss: 0.7907\n",
      "Epoch 10 | Train Loss: 0.7921 | Val Loss: 0.7660\n",
      "Epoch 11 | Train Loss: 0.7914 | Val Loss: 0.7955\n",
      "Epoch 12 | Train Loss: 0.7825 | Val Loss: 0.7651\n",
      "Epoch 13 | Train Loss: 0.7606 | Val Loss: 0.7706\n",
      "Epoch 14 | Train Loss: 0.7676 | Val Loss: 0.7660\n",
      "Epoch 15 | Train Loss: 0.7721 | Val Loss: 0.8109\n",
      "Epoch 16 | Train Loss: 0.7557 | Val Loss: 0.7943\n",
      "Epoch 17 | Train Loss: 0.7422 | Val Loss: 0.7750\n",
      "Epoch 18 | Train Loss: 0.7561 | Val Loss: 0.7599\n",
      "Epoch 19 | Train Loss: 0.7549 | Val Loss: 0.7596\n",
      "Epoch 20 | Train Loss: 0.7376 | Val Loss: 0.7596\n",
      "Epoch 21 | Train Loss: 0.7527 | Val Loss: 0.7977\n",
      "Epoch 22 | Train Loss: 0.7605 | Val Loss: 0.7681\n",
      "Epoch 23 | Train Loss: 0.7596 | Val Loss: 0.7991\n",
      "Epoch 24 | Train Loss: 0.7311 | Val Loss: 0.7832\n",
      "Epoch 25 | Train Loss: 0.7330 | Val Loss: 0.7693\n",
      "Epoch 26 | Train Loss: 0.7515 | Val Loss: 0.7681\n",
      "Epoch 27 | Train Loss: 0.7599 | Val Loss: 0.7664\n",
      "Epoch 28 | Train Loss: 0.7288 | Val Loss: 0.7819\n",
      "Epoch 29 | Train Loss: 0.7209 | Val Loss: 0.7990\n",
      "Epoch 30 | Train Loss: 0.7239 | Val Loss: 0.7671\n",
      "Epoch 31 | Train Loss: 0.7395 | Val Loss: 0.7712\n",
      "Epoch 32 | Train Loss: 0.7308 | Val Loss: 0.7666\n",
      "Epoch 33 | Train Loss: 0.7163 | Val Loss: 0.8237\n",
      "Epoch 34 | Train Loss: 0.7199 | Val Loss: 0.7961\n",
      "Epoch 35 | Train Loss: 0.7515 | Val Loss: 0.7707\n",
      "Epoch 36 | Train Loss: 0.7277 | Val Loss: 0.7750\n",
      "Epoch 37 | Train Loss: 0.7244 | Val Loss: 0.7934\n",
      "Epoch 38 | Train Loss: 0.7242 | Val Loss: 0.7785\n",
      "Epoch 39 | Train Loss: 0.7118 | Val Loss: 0.7785\n",
      "Epoch 40 | Train Loss: 0.7416 | Val Loss: 0.7792\n",
      "Epoch 41 | Train Loss: 0.7358 | Val Loss: 0.7718\n",
      "Epoch 42 | Train Loss: 0.7292 | Val Loss: 0.7812\n",
      "Epoch 43 | Train Loss: 0.7177 | Val Loss: 0.8074\n",
      "Epoch 44 | Train Loss: 0.7307 | Val Loss: 0.7765\n",
      "Epoch 45 | Train Loss: 0.7245 | Val Loss: 0.7800\n",
      "Epoch 46 | Train Loss: 0.7120 | Val Loss: 0.7819\n",
      "Epoch 47 | Train Loss: 0.7118 | Val Loss: 0.7902\n",
      "Epoch 48 | Train Loss: 0.7277 | Val Loss: 0.7979\n",
      "Epoch 49 | Train Loss: 0.7331 | Val Loss: 0.7956\n",
      "Epoch 50 | Train Loss: 0.7213 | Val Loss: 0.7943\n",
      "Fold 10 ‚ñ∂ AUC: 0.711, Balanced Acc: 0.416\n",
      "üîç Summary for hd=128, dp=0.4, lr=0.0005 ‚Üí AUC: 0.7332¬±0.0348 | BalAcc: 0.4729¬±0.0488\n",
      "\n",
      "üîß Config: hidden_dim=128, dropout=0.4, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 1.0079 | Val Loss: 0.8878\n",
      "Epoch 02 | Train Loss: 0.8842 | Val Loss: 0.8653\n",
      "Epoch 03 | Train Loss: 0.8771 | Val Loss: 0.8655\n",
      "Epoch 04 | Train Loss: 0.8761 | Val Loss: 0.8629\n",
      "Epoch 05 | Train Loss: 0.8727 | Val Loss: 0.8599\n",
      "Epoch 06 | Train Loss: 0.8687 | Val Loss: 0.8571\n",
      "Epoch 07 | Train Loss: 0.8547 | Val Loss: 0.8547\n",
      "Epoch 08 | Train Loss: 0.8714 | Val Loss: 0.8550\n",
      "Epoch 09 | Train Loss: 0.8602 | Val Loss: 0.8509\n",
      "Epoch 10 | Train Loss: 0.8555 | Val Loss: 0.8529\n",
      "Epoch 11 | Train Loss: 0.8552 | Val Loss: 0.8468\n",
      "Epoch 12 | Train Loss: 0.8621 | Val Loss: 0.8470\n",
      "Epoch 13 | Train Loss: 0.8633 | Val Loss: 0.8413\n",
      "Epoch 14 | Train Loss: 0.8538 | Val Loss: 0.8382\n",
      "Epoch 15 | Train Loss: 0.8490 | Val Loss: 0.8352\n",
      "Epoch 16 | Train Loss: 0.8370 | Val Loss: 0.8316\n",
      "Epoch 17 | Train Loss: 0.8343 | Val Loss: 0.8290\n",
      "Epoch 18 | Train Loss: 0.8299 | Val Loss: 0.8270\n",
      "Epoch 19 | Train Loss: 0.8334 | Val Loss: 0.8223\n",
      "Epoch 20 | Train Loss: 0.8519 | Val Loss: 0.8179\n",
      "Epoch 21 | Train Loss: 0.8152 | Val Loss: 0.8290\n",
      "Epoch 22 | Train Loss: 0.8160 | Val Loss: 0.8109\n",
      "Epoch 23 | Train Loss: 0.8389 | Val Loss: 0.8061\n",
      "Epoch 24 | Train Loss: 0.8246 | Val Loss: 0.7998\n",
      "Epoch 25 | Train Loss: 0.8356 | Val Loss: 0.7984\n",
      "Epoch 26 | Train Loss: 0.8136 | Val Loss: 0.8065\n",
      "Epoch 27 | Train Loss: 0.8178 | Val Loss: 0.7891\n",
      "Epoch 28 | Train Loss: 0.7946 | Val Loss: 0.7890\n",
      "Epoch 29 | Train Loss: 0.7997 | Val Loss: 0.7919\n",
      "Epoch 30 | Train Loss: 0.8052 | Val Loss: 0.7710\n",
      "Epoch 31 | Train Loss: 0.8032 | Val Loss: 0.7689\n",
      "Epoch 32 | Train Loss: 0.7922 | Val Loss: 0.7688\n",
      "Epoch 33 | Train Loss: 0.7734 | Val Loss: 0.7602\n",
      "Epoch 34 | Train Loss: 0.7656 | Val Loss: 0.7718\n",
      "Epoch 35 | Train Loss: 0.7739 | Val Loss: 0.7452\n",
      "Epoch 36 | Train Loss: 0.7693 | Val Loss: 0.7421\n",
      "Epoch 37 | Train Loss: 0.7851 | Val Loss: 0.7440\n",
      "Epoch 38 | Train Loss: 0.7742 | Val Loss: 0.7355\n",
      "Epoch 39 | Train Loss: 0.7484 | Val Loss: 0.7446\n",
      "Epoch 40 | Train Loss: 0.7668 | Val Loss: 0.7270\n",
      "Epoch 41 | Train Loss: 0.7774 | Val Loss: 0.7675\n",
      "Epoch 42 | Train Loss: 0.7634 | Val Loss: 0.7265\n",
      "Epoch 43 | Train Loss: 0.7581 | Val Loss: 0.7322\n",
      "Epoch 44 | Train Loss: 0.7759 | Val Loss: 0.7191\n",
      "Epoch 45 | Train Loss: 0.7648 | Val Loss: 0.7155\n",
      "Epoch 46 | Train Loss: 0.7371 | Val Loss: 0.7354\n",
      "Epoch 47 | Train Loss: 0.7609 | Val Loss: 0.7207\n",
      "Epoch 48 | Train Loss: 0.7854 | Val Loss: 0.7332\n",
      "Epoch 49 | Train Loss: 0.7667 | Val Loss: 0.7142\n",
      "Epoch 50 | Train Loss: 0.7579 | Val Loss: 0.7338\n",
      "Fold 1 ‚ñ∂ AUC: 0.767, Balanced Acc: 0.513\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 1.0228 | Val Loss: 0.8846\n",
      "Epoch 02 | Train Loss: 0.8947 | Val Loss: 0.8737\n",
      "Epoch 03 | Train Loss: 0.8693 | Val Loss: 0.8695\n",
      "Epoch 04 | Train Loss: 0.8724 | Val Loss: 0.8694\n",
      "Epoch 05 | Train Loss: 0.8676 | Val Loss: 0.8689\n",
      "Epoch 06 | Train Loss: 0.8729 | Val Loss: 0.8641\n",
      "Epoch 07 | Train Loss: 0.8637 | Val Loss: 0.8622\n",
      "Epoch 08 | Train Loss: 0.8628 | Val Loss: 0.8607\n",
      "Epoch 09 | Train Loss: 0.8639 | Val Loss: 0.8605\n",
      "Epoch 10 | Train Loss: 0.8598 | Val Loss: 0.8578\n",
      "Epoch 11 | Train Loss: 0.8558 | Val Loss: 0.8566\n",
      "Epoch 12 | Train Loss: 0.8650 | Val Loss: 0.8550\n",
      "Epoch 13 | Train Loss: 0.8491 | Val Loss: 0.8531\n",
      "Epoch 14 | Train Loss: 0.8628 | Val Loss: 0.8523\n",
      "Epoch 15 | Train Loss: 0.8424 | Val Loss: 0.8499\n",
      "Epoch 16 | Train Loss: 0.8516 | Val Loss: 0.8477\n",
      "Epoch 17 | Train Loss: 0.8496 | Val Loss: 0.8455\n",
      "Epoch 18 | Train Loss: 0.8613 | Val Loss: 0.8442\n",
      "Epoch 19 | Train Loss: 0.8490 | Val Loss: 0.8409\n",
      "Epoch 20 | Train Loss: 0.8347 | Val Loss: 0.8400\n",
      "Epoch 21 | Train Loss: 0.8353 | Val Loss: 0.8378\n",
      "Epoch 22 | Train Loss: 0.8546 | Val Loss: 0.8353\n",
      "Epoch 23 | Train Loss: 0.8518 | Val Loss: 0.8384\n",
      "Epoch 24 | Train Loss: 0.8340 | Val Loss: 0.8305\n",
      "Epoch 25 | Train Loss: 0.8319 | Val Loss: 0.8303\n",
      "Epoch 26 | Train Loss: 0.8258 | Val Loss: 0.8270\n",
      "Epoch 27 | Train Loss: 0.8419 | Val Loss: 0.8228\n",
      "Epoch 28 | Train Loss: 0.8236 | Val Loss: 0.8245\n",
      "Epoch 29 | Train Loss: 0.8251 | Val Loss: 0.8189\n",
      "Epoch 30 | Train Loss: 0.8201 | Val Loss: 0.8234\n",
      "Epoch 31 | Train Loss: 0.8197 | Val Loss: 0.8131\n",
      "Epoch 32 | Train Loss: 0.8211 | Val Loss: 0.8128\n",
      "Epoch 33 | Train Loss: 0.8082 | Val Loss: 0.8088\n",
      "Epoch 34 | Train Loss: 0.8149 | Val Loss: 0.8042\n",
      "Epoch 35 | Train Loss: 0.8309 | Val Loss: 0.8224\n",
      "Epoch 36 | Train Loss: 0.8085 | Val Loss: 0.7979\n",
      "Epoch 37 | Train Loss: 0.8048 | Val Loss: 0.8025\n",
      "Epoch 38 | Train Loss: 0.8029 | Val Loss: 0.7963\n",
      "Epoch 39 | Train Loss: 0.8122 | Val Loss: 0.7903\n",
      "Epoch 40 | Train Loss: 0.7919 | Val Loss: 0.8083\n",
      "Epoch 41 | Train Loss: 0.8016 | Val Loss: 0.7865\n",
      "Epoch 42 | Train Loss: 0.7842 | Val Loss: 0.7968\n",
      "Epoch 43 | Train Loss: 0.8157 | Val Loss: 0.8015\n",
      "Epoch 44 | Train Loss: 0.7788 | Val Loss: 0.7888\n",
      "Epoch 45 | Train Loss: 0.7808 | Val Loss: 0.7757\n",
      "Epoch 46 | Train Loss: 0.7974 | Val Loss: 0.7768\n",
      "Epoch 47 | Train Loss: 0.8081 | Val Loss: 0.8249\n",
      "Epoch 48 | Train Loss: 0.8011 | Val Loss: 0.7722\n",
      "Epoch 49 | Train Loss: 0.7944 | Val Loss: 0.7776\n",
      "Epoch 50 | Train Loss: 0.7639 | Val Loss: 0.7781\n",
      "Fold 2 ‚ñ∂ AUC: 0.634, Balanced Acc: 0.513\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9863 | Val Loss: 0.8778\n",
      "Epoch 02 | Train Loss: 0.8726 | Val Loss: 0.8559\n",
      "Epoch 03 | Train Loss: 0.8719 | Val Loss: 0.8542\n",
      "Epoch 04 | Train Loss: 0.8694 | Val Loss: 0.8504\n",
      "Epoch 05 | Train Loss: 0.8702 | Val Loss: 0.8481\n",
      "Epoch 06 | Train Loss: 0.8681 | Val Loss: 0.8473\n",
      "Epoch 07 | Train Loss: 0.8717 | Val Loss: 0.8442\n",
      "Epoch 08 | Train Loss: 0.8675 | Val Loss: 0.8415\n",
      "Epoch 09 | Train Loss: 0.8672 | Val Loss: 0.8434\n",
      "Epoch 10 | Train Loss: 0.8644 | Val Loss: 0.8376\n",
      "Epoch 11 | Train Loss: 0.8563 | Val Loss: 0.8345\n",
      "Epoch 12 | Train Loss: 0.8553 | Val Loss: 0.8328\n",
      "Epoch 13 | Train Loss: 0.8465 | Val Loss: 0.8295\n",
      "Epoch 14 | Train Loss: 0.8458 | Val Loss: 0.8266\n",
      "Epoch 15 | Train Loss: 0.8632 | Val Loss: 0.8243\n",
      "Epoch 16 | Train Loss: 0.8591 | Val Loss: 0.8214\n",
      "Epoch 17 | Train Loss: 0.8449 | Val Loss: 0.8201\n",
      "Epoch 18 | Train Loss: 0.8397 | Val Loss: 0.8153\n",
      "Epoch 19 | Train Loss: 0.8418 | Val Loss: 0.8142\n",
      "Epoch 20 | Train Loss: 0.8348 | Val Loss: 0.8077\n",
      "Epoch 21 | Train Loss: 0.8321 | Val Loss: 0.8205\n",
      "Epoch 22 | Train Loss: 0.8275 | Val Loss: 0.8028\n",
      "Epoch 23 | Train Loss: 0.8474 | Val Loss: 0.7980\n",
      "Epoch 24 | Train Loss: 0.8260 | Val Loss: 0.7964\n",
      "Epoch 25 | Train Loss: 0.8294 | Val Loss: 0.7898\n",
      "Epoch 26 | Train Loss: 0.8143 | Val Loss: 0.7908\n",
      "Epoch 27 | Train Loss: 0.8151 | Val Loss: 0.7831\n",
      "Epoch 28 | Train Loss: 0.8187 | Val Loss: 0.7825\n",
      "Epoch 29 | Train Loss: 0.8072 | Val Loss: 0.7738\n",
      "Epoch 30 | Train Loss: 0.8071 | Val Loss: 0.7845\n",
      "Epoch 31 | Train Loss: 0.8094 | Val Loss: 0.7726\n",
      "Epoch 32 | Train Loss: 0.8114 | Val Loss: 0.7777\n",
      "Epoch 33 | Train Loss: 0.8056 | Val Loss: 0.7801\n",
      "Epoch 34 | Train Loss: 0.7887 | Val Loss: 0.7620\n",
      "Epoch 35 | Train Loss: 0.8054 | Val Loss: 0.7613\n",
      "Epoch 36 | Train Loss: 0.7801 | Val Loss: 0.7608\n",
      "Epoch 37 | Train Loss: 0.7818 | Val Loss: 0.7572\n",
      "Epoch 38 | Train Loss: 0.7832 | Val Loss: 0.7726\n",
      "Epoch 39 | Train Loss: 0.7858 | Val Loss: 0.7545\n",
      "Epoch 40 | Train Loss: 0.7731 | Val Loss: 0.7469\n",
      "Epoch 41 | Train Loss: 0.7975 | Val Loss: 0.7462\n",
      "Epoch 42 | Train Loss: 0.7746 | Val Loss: 0.7751\n",
      "Epoch 43 | Train Loss: 0.7781 | Val Loss: 0.7487\n",
      "Epoch 44 | Train Loss: 0.7565 | Val Loss: 0.7439\n",
      "Epoch 45 | Train Loss: 0.7804 | Val Loss: 0.7490\n",
      "Epoch 46 | Train Loss: 0.7679 | Val Loss: 0.7383\n",
      "Epoch 47 | Train Loss: 0.7743 | Val Loss: 0.7463\n",
      "Epoch 48 | Train Loss: 0.7544 | Val Loss: 0.7375\n",
      "Epoch 49 | Train Loss: 0.7599 | Val Loss: 0.7437\n",
      "Epoch 50 | Train Loss: 0.7858 | Val Loss: 0.7661\n",
      "Fold 3 ‚ñ∂ AUC: 0.759, Balanced Acc: 0.499\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 1.0581 | Val Loss: 0.9088\n",
      "Epoch 02 | Train Loss: 0.9045 | Val Loss: 0.8593\n",
      "Epoch 03 | Train Loss: 0.8897 | Val Loss: 0.8530\n",
      "Epoch 04 | Train Loss: 0.8783 | Val Loss: 0.8523\n",
      "Epoch 05 | Train Loss: 0.8787 | Val Loss: 0.8497\n",
      "Epoch 06 | Train Loss: 0.8785 | Val Loss: 0.8481\n",
      "Epoch 07 | Train Loss: 0.8615 | Val Loss: 0.8444\n",
      "Epoch 08 | Train Loss: 0.8612 | Val Loss: 0.8423\n",
      "Epoch 09 | Train Loss: 0.8586 | Val Loss: 0.8418\n",
      "Epoch 10 | Train Loss: 0.8653 | Val Loss: 0.8378\n",
      "Epoch 11 | Train Loss: 0.8668 | Val Loss: 0.8333\n",
      "Epoch 12 | Train Loss: 0.8490 | Val Loss: 0.8303\n",
      "Epoch 13 | Train Loss: 0.8593 | Val Loss: 0.8279\n",
      "Epoch 14 | Train Loss: 0.8586 | Val Loss: 0.8252\n",
      "Epoch 15 | Train Loss: 0.8454 | Val Loss: 0.8215\n",
      "Epoch 16 | Train Loss: 0.8554 | Val Loss: 0.8188\n",
      "Epoch 17 | Train Loss: 0.8574 | Val Loss: 0.8145\n",
      "Epoch 18 | Train Loss: 0.8486 | Val Loss: 0.8135\n",
      "Epoch 19 | Train Loss: 0.8362 | Val Loss: 0.8064\n",
      "Epoch 20 | Train Loss: 0.8438 | Val Loss: 0.8026\n",
      "Epoch 21 | Train Loss: 0.8294 | Val Loss: 0.8087\n",
      "Epoch 22 | Train Loss: 0.8199 | Val Loss: 0.7959\n",
      "Epoch 23 | Train Loss: 0.8141 | Val Loss: 0.7903\n",
      "Epoch 24 | Train Loss: 0.8370 | Val Loss: 0.7899\n",
      "Epoch 25 | Train Loss: 0.8219 | Val Loss: 0.7840\n",
      "Epoch 26 | Train Loss: 0.8184 | Val Loss: 0.7795\n",
      "Epoch 27 | Train Loss: 0.8081 | Val Loss: 0.7812\n",
      "Epoch 28 | Train Loss: 0.8078 | Val Loss: 0.7698\n",
      "Epoch 29 | Train Loss: 0.7995 | Val Loss: 0.7654\n",
      "Epoch 30 | Train Loss: 0.7937 | Val Loss: 0.7594\n",
      "Epoch 31 | Train Loss: 0.7946 | Val Loss: 0.7549\n",
      "Epoch 32 | Train Loss: 0.8022 | Val Loss: 0.7528\n",
      "Epoch 33 | Train Loss: 0.7924 | Val Loss: 0.7518\n",
      "Epoch 34 | Train Loss: 0.7764 | Val Loss: 0.7482\n",
      "Epoch 35 | Train Loss: 0.7791 | Val Loss: 0.7695\n",
      "Epoch 36 | Train Loss: 0.7866 | Val Loss: 0.7485\n",
      "Epoch 37 | Train Loss: 0.7832 | Val Loss: 0.7454\n",
      "Epoch 38 | Train Loss: 0.7803 | Val Loss: 0.7315\n",
      "Epoch 39 | Train Loss: 0.7782 | Val Loss: 0.7335\n",
      "Epoch 40 | Train Loss: 0.7964 | Val Loss: 0.7267\n",
      "Epoch 41 | Train Loss: 0.7734 | Val Loss: 0.7243\n",
      "Epoch 42 | Train Loss: 0.7892 | Val Loss: 0.7340\n",
      "Epoch 43 | Train Loss: 0.7604 | Val Loss: 0.7248\n",
      "Epoch 44 | Train Loss: 0.7805 | Val Loss: 0.7162\n",
      "Epoch 45 | Train Loss: 0.7646 | Val Loss: 0.7108\n",
      "Epoch 46 | Train Loss: 0.7559 | Val Loss: 0.7074\n",
      "Epoch 47 | Train Loss: 0.7601 | Val Loss: 0.7034\n",
      "Epoch 48 | Train Loss: 0.7538 | Val Loss: 0.7022\n",
      "Epoch 49 | Train Loss: 0.7626 | Val Loss: 0.7002\n",
      "Epoch 50 | Train Loss: 0.7576 | Val Loss: 0.6983\n",
      "Fold 4 ‚ñ∂ AUC: 0.788, Balanced Acc: 0.531\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9396 | Val Loss: 0.8929\n",
      "Epoch 02 | Train Loss: 0.8762 | Val Loss: 0.8954\n",
      "Epoch 03 | Train Loss: 0.8613 | Val Loss: 0.8919\n",
      "Epoch 04 | Train Loss: 0.8746 | Val Loss: 0.8896\n",
      "Epoch 05 | Train Loss: 0.8559 | Val Loss: 0.8872\n",
      "Epoch 06 | Train Loss: 0.8699 | Val Loss: 0.8867\n",
      "Epoch 07 | Train Loss: 0.8591 | Val Loss: 0.8867\n",
      "Epoch 08 | Train Loss: 0.8717 | Val Loss: 0.8820\n",
      "Epoch 09 | Train Loss: 0.8710 | Val Loss: 0.8783\n",
      "Epoch 10 | Train Loss: 0.8546 | Val Loss: 0.8863\n",
      "Epoch 11 | Train Loss: 0.8573 | Val Loss: 0.8767\n",
      "Epoch 12 | Train Loss: 0.8611 | Val Loss: 0.8822\n",
      "Epoch 13 | Train Loss: 0.8445 | Val Loss: 0.8713\n",
      "Epoch 14 | Train Loss: 0.8512 | Val Loss: 0.8767\n",
      "Epoch 15 | Train Loss: 0.8414 | Val Loss: 0.8732\n",
      "Epoch 16 | Train Loss: 0.8345 | Val Loss: 0.8714\n",
      "Epoch 17 | Train Loss: 0.8310 | Val Loss: 0.8659\n",
      "Epoch 18 | Train Loss: 0.8296 | Val Loss: 0.8690\n",
      "Epoch 19 | Train Loss: 0.8342 | Val Loss: 0.8674\n",
      "Epoch 20 | Train Loss: 0.8323 | Val Loss: 0.8636\n",
      "Epoch 21 | Train Loss: 0.8345 | Val Loss: 0.8634\n",
      "Epoch 22 | Train Loss: 0.8347 | Val Loss: 0.8574\n",
      "Epoch 23 | Train Loss: 0.8376 | Val Loss: 0.8604\n",
      "Epoch 24 | Train Loss: 0.8205 | Val Loss: 0.8534\n",
      "Epoch 25 | Train Loss: 0.8245 | Val Loss: 0.8579\n",
      "Epoch 26 | Train Loss: 0.8136 | Val Loss: 0.8511\n",
      "Epoch 27 | Train Loss: 0.8252 | Val Loss: 0.8487\n",
      "Epoch 28 | Train Loss: 0.8115 | Val Loss: 0.8480\n",
      "Epoch 29 | Train Loss: 0.8073 | Val Loss: 0.8424\n",
      "Epoch 30 | Train Loss: 0.7957 | Val Loss: 0.8427\n",
      "Epoch 31 | Train Loss: 0.7985 | Val Loss: 0.8419\n",
      "Epoch 32 | Train Loss: 0.7867 | Val Loss: 0.8406\n",
      "Epoch 33 | Train Loss: 0.7973 | Val Loss: 0.8362\n",
      "Epoch 34 | Train Loss: 0.7908 | Val Loss: 0.8435\n",
      "Epoch 35 | Train Loss: 0.7853 | Val Loss: 0.8324\n",
      "Epoch 36 | Train Loss: 0.7898 | Val Loss: 0.8302\n",
      "Epoch 37 | Train Loss: 0.7991 | Val Loss: 0.8398\n",
      "Epoch 38 | Train Loss: 0.7876 | Val Loss: 0.8320\n",
      "Epoch 39 | Train Loss: 0.7891 | Val Loss: 0.8229\n",
      "Epoch 40 | Train Loss: 0.7719 | Val Loss: 0.8243\n",
      "Epoch 41 | Train Loss: 0.8177 | Val Loss: 0.8318\n",
      "Epoch 42 | Train Loss: 0.7696 | Val Loss: 0.8159\n",
      "Epoch 43 | Train Loss: 0.7727 | Val Loss: 0.8191\n",
      "Epoch 44 | Train Loss: 0.7776 | Val Loss: 0.8227\n",
      "Epoch 45 | Train Loss: 0.7606 | Val Loss: 0.8234\n",
      "Epoch 46 | Train Loss: 0.7777 | Val Loss: 0.8395\n",
      "Epoch 47 | Train Loss: 0.8030 | Val Loss: 0.8162\n",
      "Epoch 48 | Train Loss: 0.7743 | Val Loss: 0.8179\n",
      "Epoch 49 | Train Loss: 0.7733 | Val Loss: 0.8212\n",
      "Epoch 50 | Train Loss: 0.7656 | Val Loss: 0.8109\n",
      "Fold 5 ‚ñ∂ AUC: 0.705, Balanced Acc: 0.410\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 1.0477 | Val Loss: 0.9178\n",
      "Epoch 02 | Train Loss: 0.8862 | Val Loss: 0.9019\n",
      "Epoch 03 | Train Loss: 0.8858 | Val Loss: 0.9082\n",
      "Epoch 04 | Train Loss: 0.8646 | Val Loss: 0.8969\n",
      "Epoch 05 | Train Loss: 0.8759 | Val Loss: 0.8973\n",
      "Epoch 06 | Train Loss: 0.8585 | Val Loss: 0.8928\n",
      "Epoch 07 | Train Loss: 0.8723 | Val Loss: 0.8943\n",
      "Epoch 08 | Train Loss: 0.8633 | Val Loss: 0.8910\n",
      "Epoch 09 | Train Loss: 0.8677 | Val Loss: 0.8918\n",
      "Epoch 10 | Train Loss: 0.8484 | Val Loss: 0.8888\n",
      "Epoch 11 | Train Loss: 0.8641 | Val Loss: 0.8937\n",
      "Epoch 12 | Train Loss: 0.8611 | Val Loss: 0.8837\n",
      "Epoch 13 | Train Loss: 0.8501 | Val Loss: 0.8828\n",
      "Epoch 14 | Train Loss: 0.8542 | Val Loss: 0.8821\n",
      "Epoch 15 | Train Loss: 0.8459 | Val Loss: 0.8795\n",
      "Epoch 16 | Train Loss: 0.8489 | Val Loss: 0.8787\n",
      "Epoch 17 | Train Loss: 0.8502 | Val Loss: 0.8799\n",
      "Epoch 18 | Train Loss: 0.8274 | Val Loss: 0.8758\n",
      "Epoch 19 | Train Loss: 0.8212 | Val Loss: 0.8735\n",
      "Epoch 20 | Train Loss: 0.8352 | Val Loss: 0.8708\n",
      "Epoch 21 | Train Loss: 0.8299 | Val Loss: 0.8669\n",
      "Epoch 22 | Train Loss: 0.8274 | Val Loss: 0.8659\n",
      "Epoch 23 | Train Loss: 0.8372 | Val Loss: 0.8644\n",
      "Epoch 24 | Train Loss: 0.8159 | Val Loss: 0.8603\n",
      "Epoch 25 | Train Loss: 0.8061 | Val Loss: 0.8604\n",
      "Epoch 26 | Train Loss: 0.8107 | Val Loss: 0.8571\n",
      "Epoch 27 | Train Loss: 0.8131 | Val Loss: 0.8559\n",
      "Epoch 28 | Train Loss: 0.8038 | Val Loss: 0.8660\n",
      "Epoch 29 | Train Loss: 0.7923 | Val Loss: 0.8658\n",
      "Epoch 30 | Train Loss: 0.8047 | Val Loss: 0.8519\n",
      "Epoch 31 | Train Loss: 0.7805 | Val Loss: 0.8550\n",
      "Epoch 32 | Train Loss: 0.7971 | Val Loss: 0.8517\n",
      "Epoch 33 | Train Loss: 0.8145 | Val Loss: 0.8430\n",
      "Epoch 34 | Train Loss: 0.7899 | Val Loss: 0.8419\n",
      "Epoch 35 | Train Loss: 0.7849 | Val Loss: 0.8404\n",
      "Epoch 36 | Train Loss: 0.7756 | Val Loss: 0.8442\n",
      "Epoch 37 | Train Loss: 0.7722 | Val Loss: 0.8454\n",
      "Epoch 38 | Train Loss: 0.7650 | Val Loss: 0.8472\n",
      "Epoch 39 | Train Loss: 0.7534 | Val Loss: 0.8384\n",
      "Epoch 40 | Train Loss: 0.7550 | Val Loss: 0.8491\n",
      "Epoch 41 | Train Loss: 0.7632 | Val Loss: 0.8389\n",
      "Epoch 42 | Train Loss: 0.7487 | Val Loss: 0.8414\n",
      "Epoch 43 | Train Loss: 0.7429 | Val Loss: 0.8356\n",
      "Epoch 44 | Train Loss: 0.7612 | Val Loss: 0.8342\n",
      "Epoch 45 | Train Loss: 0.7396 | Val Loss: 0.8337\n",
      "Epoch 46 | Train Loss: 0.7613 | Val Loss: 0.8334\n",
      "Epoch 47 | Train Loss: 0.7540 | Val Loss: 0.8322\n",
      "Epoch 48 | Train Loss: 0.7476 | Val Loss: 0.8361\n",
      "Epoch 49 | Train Loss: 0.7628 | Val Loss: 0.8378\n",
      "Epoch 50 | Train Loss: 0.7585 | Val Loss: 0.8369\n",
      "Fold 6 ‚ñ∂ AUC: 0.713, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9501 | Val Loss: 0.8690\n",
      "Epoch 02 | Train Loss: 0.8744 | Val Loss: 0.8582\n",
      "Epoch 03 | Train Loss: 0.8795 | Val Loss: 0.8546\n",
      "Epoch 04 | Train Loss: 0.8678 | Val Loss: 0.8526\n",
      "Epoch 05 | Train Loss: 0.8769 | Val Loss: 0.8497\n",
      "Epoch 06 | Train Loss: 0.8742 | Val Loss: 0.8481\n",
      "Epoch 07 | Train Loss: 0.8751 | Val Loss: 0.8483\n",
      "Epoch 08 | Train Loss: 0.8697 | Val Loss: 0.8447\n",
      "Epoch 09 | Train Loss: 0.8689 | Val Loss: 0.8439\n",
      "Epoch 10 | Train Loss: 0.8590 | Val Loss: 0.8407\n",
      "Epoch 11 | Train Loss: 0.8561 | Val Loss: 0.8378\n",
      "Epoch 12 | Train Loss: 0.8556 | Val Loss: 0.8347\n",
      "Epoch 13 | Train Loss: 0.8487 | Val Loss: 0.8316\n",
      "Epoch 14 | Train Loss: 0.8527 | Val Loss: 0.8286\n",
      "Epoch 15 | Train Loss: 0.8586 | Val Loss: 0.8256\n",
      "Epoch 16 | Train Loss: 0.8531 | Val Loss: 0.8238\n",
      "Epoch 17 | Train Loss: 0.8469 | Val Loss: 0.8195\n",
      "Epoch 18 | Train Loss: 0.8447 | Val Loss: 0.8143\n",
      "Epoch 19 | Train Loss: 0.8443 | Val Loss: 0.8141\n",
      "Epoch 20 | Train Loss: 0.8638 | Val Loss: 0.8135\n",
      "Epoch 21 | Train Loss: 0.8519 | Val Loss: 0.8073\n",
      "Epoch 22 | Train Loss: 0.8485 | Val Loss: 0.8049\n",
      "Epoch 23 | Train Loss: 0.8269 | Val Loss: 0.8037\n",
      "Epoch 24 | Train Loss: 0.8429 | Val Loss: 0.8115\n",
      "Epoch 25 | Train Loss: 0.8419 | Val Loss: 0.7991\n",
      "Epoch 26 | Train Loss: 0.8278 | Val Loss: 0.8019\n",
      "Epoch 27 | Train Loss: 0.8221 | Val Loss: 0.7865\n",
      "Epoch 28 | Train Loss: 0.8157 | Val Loss: 0.7817\n",
      "Epoch 29 | Train Loss: 0.8248 | Val Loss: 0.7789\n",
      "Epoch 30 | Train Loss: 0.8160 | Val Loss: 0.7740\n",
      "Epoch 31 | Train Loss: 0.8157 | Val Loss: 0.7694\n",
      "Epoch 32 | Train Loss: 0.8151 | Val Loss: 0.7672\n",
      "Epoch 33 | Train Loss: 0.8128 | Val Loss: 0.7657\n",
      "Epoch 34 | Train Loss: 0.7860 | Val Loss: 0.7726\n",
      "Epoch 35 | Train Loss: 0.8262 | Val Loss: 0.8074\n",
      "Epoch 36 | Train Loss: 0.8023 | Val Loss: 0.7585\n",
      "Epoch 37 | Train Loss: 0.8002 | Val Loss: 0.7708\n",
      "Epoch 38 | Train Loss: 0.7990 | Val Loss: 0.7487\n",
      "Epoch 39 | Train Loss: 0.8057 | Val Loss: 0.7599\n",
      "Epoch 40 | Train Loss: 0.8024 | Val Loss: 0.7458\n",
      "Epoch 41 | Train Loss: 0.7725 | Val Loss: 0.7408\n",
      "Epoch 42 | Train Loss: 0.7762 | Val Loss: 0.7414\n",
      "Epoch 43 | Train Loss: 0.7703 | Val Loss: 0.7360\n",
      "Epoch 44 | Train Loss: 0.7842 | Val Loss: 0.7332\n",
      "Epoch 45 | Train Loss: 0.7734 | Val Loss: 0.7315\n",
      "Epoch 46 | Train Loss: 0.7660 | Val Loss: 0.7336\n",
      "Epoch 47 | Train Loss: 0.7755 | Val Loss: 0.7320\n",
      "Epoch 48 | Train Loss: 0.7697 | Val Loss: 0.7250\n",
      "Epoch 49 | Train Loss: 0.7684 | Val Loss: 0.7370\n",
      "Epoch 50 | Train Loss: 0.7567 | Val Loss: 0.7320\n",
      "Fold 7 ‚ñ∂ AUC: 0.790, Balanced Acc: 0.536\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.8856 | Val Loss: 0.8793\n",
      "Epoch 02 | Train Loss: 0.8932 | Val Loss: 0.8736\n",
      "Epoch 03 | Train Loss: 0.8692 | Val Loss: 0.8701\n",
      "Epoch 04 | Train Loss: 0.8612 | Val Loss: 0.8698\n",
      "Epoch 05 | Train Loss: 0.8700 | Val Loss: 0.8665\n",
      "Epoch 06 | Train Loss: 0.8679 | Val Loss: 0.8651\n",
      "Epoch 07 | Train Loss: 0.8824 | Val Loss: 0.8632\n",
      "Epoch 08 | Train Loss: 0.8607 | Val Loss: 0.8641\n",
      "Epoch 09 | Train Loss: 0.8582 | Val Loss: 0.8613\n",
      "Epoch 10 | Train Loss: 0.8500 | Val Loss: 0.8599\n",
      "Epoch 11 | Train Loss: 0.8526 | Val Loss: 0.8582\n",
      "Epoch 12 | Train Loss: 0.8664 | Val Loss: 0.8564\n",
      "Epoch 13 | Train Loss: 0.8495 | Val Loss: 0.8544\n",
      "Epoch 14 | Train Loss: 0.8492 | Val Loss: 0.8508\n",
      "Epoch 15 | Train Loss: 0.8534 | Val Loss: 0.8550\n",
      "Epoch 16 | Train Loss: 0.8564 | Val Loss: 0.8493\n",
      "Epoch 17 | Train Loss: 0.8433 | Val Loss: 0.8455\n",
      "Epoch 18 | Train Loss: 0.8395 | Val Loss: 0.8460\n",
      "Epoch 19 | Train Loss: 0.8258 | Val Loss: 0.8521\n",
      "Epoch 20 | Train Loss: 0.8469 | Val Loss: 0.8454\n",
      "Epoch 21 | Train Loss: 0.8203 | Val Loss: 0.8384\n",
      "Epoch 22 | Train Loss: 0.8398 | Val Loss: 0.8471\n",
      "Epoch 23 | Train Loss: 0.8417 | Val Loss: 0.8371\n",
      "Epoch 24 | Train Loss: 0.8216 | Val Loss: 0.8309\n",
      "Epoch 25 | Train Loss: 0.8205 | Val Loss: 0.8271\n",
      "Epoch 26 | Train Loss: 0.8159 | Val Loss: 0.8253\n",
      "Epoch 27 | Train Loss: 0.8102 | Val Loss: 0.8244\n",
      "Epoch 28 | Train Loss: 0.8280 | Val Loss: 0.8362\n",
      "Epoch 29 | Train Loss: 0.8138 | Val Loss: 0.8217\n",
      "Epoch 30 | Train Loss: 0.7925 | Val Loss: 0.8148\n",
      "Epoch 31 | Train Loss: 0.7996 | Val Loss: 0.8104\n",
      "Epoch 32 | Train Loss: 0.7953 | Val Loss: 0.8088\n",
      "Epoch 33 | Train Loss: 0.7956 | Val Loss: 0.8077\n",
      "Epoch 34 | Train Loss: 0.7827 | Val Loss: 0.8036\n",
      "Epoch 35 | Train Loss: 0.7915 | Val Loss: 0.8030\n",
      "Epoch 36 | Train Loss: 0.7761 | Val Loss: 0.8185\n",
      "Epoch 37 | Train Loss: 0.7791 | Val Loss: 0.8038\n",
      "Epoch 38 | Train Loss: 0.7766 | Val Loss: 0.8074\n",
      "Epoch 39 | Train Loss: 0.7707 | Val Loss: 0.8010\n",
      "Epoch 40 | Train Loss: 0.7616 | Val Loss: 0.8024\n",
      "Epoch 41 | Train Loss: 0.7600 | Val Loss: 0.8015\n",
      "Epoch 42 | Train Loss: 0.7630 | Val Loss: 0.8124\n",
      "Epoch 43 | Train Loss: 0.7709 | Val Loss: 0.8111\n",
      "Epoch 44 | Train Loss: 0.7635 | Val Loss: 0.8106\n",
      "Epoch 45 | Train Loss: 0.7744 | Val Loss: 0.8034\n",
      "Epoch 46 | Train Loss: 0.7446 | Val Loss: 0.8089\n",
      "Epoch 47 | Train Loss: 0.7608 | Val Loss: 0.8104\n",
      "Epoch 48 | Train Loss: 0.7627 | Val Loss: 0.8302\n",
      "Epoch 49 | Train Loss: 0.7336 | Val Loss: 0.8671\n",
      "Epoch 50 | Train Loss: 0.7783 | Val Loss: 0.8045\n",
      "Fold 8 ‚ñ∂ AUC: 0.685, Balanced Acc: 0.455\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 1.0532 | Val Loss: 0.8913\n",
      "Epoch 02 | Train Loss: 0.8930 | Val Loss: 0.8839\n",
      "Epoch 03 | Train Loss: 0.8735 | Val Loss: 0.8723\n",
      "Epoch 04 | Train Loss: 0.8551 | Val Loss: 0.8717\n",
      "Epoch 05 | Train Loss: 0.8600 | Val Loss: 0.8692\n",
      "Epoch 06 | Train Loss: 0.8709 | Val Loss: 0.8685\n",
      "Epoch 07 | Train Loss: 0.8565 | Val Loss: 0.8656\n",
      "Epoch 08 | Train Loss: 0.8485 | Val Loss: 0.8644\n",
      "Epoch 09 | Train Loss: 0.8457 | Val Loss: 0.8650\n",
      "Epoch 10 | Train Loss: 0.8534 | Val Loss: 0.8600\n",
      "Epoch 11 | Train Loss: 0.8572 | Val Loss: 0.8616\n",
      "Epoch 12 | Train Loss: 0.8373 | Val Loss: 0.8563\n",
      "Epoch 13 | Train Loss: 0.8402 | Val Loss: 0.8536\n",
      "Epoch 14 | Train Loss: 0.8398 | Val Loss: 0.8513\n",
      "Epoch 15 | Train Loss: 0.8264 | Val Loss: 0.8502\n",
      "Epoch 16 | Train Loss: 0.8326 | Val Loss: 0.8484\n",
      "Epoch 17 | Train Loss: 0.8413 | Val Loss: 0.8455\n",
      "Epoch 18 | Train Loss: 0.8155 | Val Loss: 0.8436\n",
      "Epoch 19 | Train Loss: 0.8060 | Val Loss: 0.8494\n",
      "Epoch 20 | Train Loss: 0.8041 | Val Loss: 0.8481\n",
      "Epoch 21 | Train Loss: 0.8062 | Val Loss: 0.8491\n",
      "Epoch 22 | Train Loss: 0.8069 | Val Loss: 0.8542\n",
      "Epoch 23 | Train Loss: 0.7874 | Val Loss: 0.8423\n",
      "Epoch 24 | Train Loss: 0.7866 | Val Loss: 0.8347\n",
      "Epoch 25 | Train Loss: 0.7899 | Val Loss: 0.8308\n",
      "Epoch 26 | Train Loss: 0.7810 | Val Loss: 0.8287\n",
      "Epoch 27 | Train Loss: 0.7826 | Val Loss: 0.8405\n",
      "Epoch 28 | Train Loss: 0.7631 | Val Loss: 0.8371\n",
      "Epoch 29 | Train Loss: 0.7830 | Val Loss: 0.8375\n",
      "Epoch 30 | Train Loss: 0.7646 | Val Loss: 0.8227\n",
      "Epoch 31 | Train Loss: 0.7740 | Val Loss: 0.8414\n",
      "Epoch 32 | Train Loss: 0.7750 | Val Loss: 0.8223\n",
      "Epoch 33 | Train Loss: 0.7660 | Val Loss: 0.8186\n",
      "Epoch 34 | Train Loss: 0.7783 | Val Loss: 0.8278\n",
      "Epoch 35 | Train Loss: 0.7525 | Val Loss: 0.8161\n",
      "Epoch 36 | Train Loss: 0.7487 | Val Loss: 0.8266\n",
      "Epoch 37 | Train Loss: 0.7756 | Val Loss: 0.8311\n",
      "Epoch 38 | Train Loss: 0.7491 | Val Loss: 0.8421\n",
      "Epoch 39 | Train Loss: 0.7743 | Val Loss: 0.8164\n",
      "Epoch 40 | Train Loss: 0.7757 | Val Loss: 0.8180\n",
      "Epoch 41 | Train Loss: 0.7546 | Val Loss: 0.8239\n",
      "Epoch 42 | Train Loss: 0.7592 | Val Loss: 0.8090\n",
      "Epoch 43 | Train Loss: 0.7563 | Val Loss: 0.8169\n",
      "Epoch 44 | Train Loss: 0.7592 | Val Loss: 0.8093\n",
      "Epoch 45 | Train Loss: 0.7651 | Val Loss: 0.8178\n",
      "Epoch 46 | Train Loss: 0.7396 | Val Loss: 0.8046\n",
      "Epoch 47 | Train Loss: 0.7585 | Val Loss: 0.8335\n",
      "Epoch 48 | Train Loss: 0.7380 | Val Loss: 0.7981\n",
      "Epoch 49 | Train Loss: 0.7550 | Val Loss: 0.7971\n",
      "Epoch 50 | Train Loss: 0.7342 | Val Loss: 0.7951\n",
      "Fold 9 ‚ñ∂ AUC: 0.703, Balanced Acc: 0.451\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9561 | Val Loss: 0.8826\n",
      "Epoch 02 | Train Loss: 0.8777 | Val Loss: 0.8772\n",
      "Epoch 03 | Train Loss: 0.8740 | Val Loss: 0.8685\n",
      "Epoch 04 | Train Loss: 0.8783 | Val Loss: 0.8662\n",
      "Epoch 05 | Train Loss: 0.8603 | Val Loss: 0.8643\n",
      "Epoch 06 | Train Loss: 0.8543 | Val Loss: 0.8604\n",
      "Epoch 07 | Train Loss: 0.8567 | Val Loss: 0.8589\n",
      "Epoch 08 | Train Loss: 0.8565 | Val Loss: 0.8601\n",
      "Epoch 09 | Train Loss: 0.8524 | Val Loss: 0.8557\n",
      "Epoch 10 | Train Loss: 0.8680 | Val Loss: 0.8526\n",
      "Epoch 11 | Train Loss: 0.8482 | Val Loss: 0.8496\n",
      "Epoch 12 | Train Loss: 0.8626 | Val Loss: 0.8476\n",
      "Epoch 13 | Train Loss: 0.8520 | Val Loss: 0.8446\n",
      "Epoch 14 | Train Loss: 0.8457 | Val Loss: 0.8469\n",
      "Epoch 15 | Train Loss: 0.8660 | Val Loss: 0.8420\n",
      "Epoch 16 | Train Loss: 0.8373 | Val Loss: 0.8403\n",
      "Epoch 17 | Train Loss: 0.8524 | Val Loss: 0.8378\n",
      "Epoch 18 | Train Loss: 0.8451 | Val Loss: 0.8340\n",
      "Epoch 19 | Train Loss: 0.8426 | Val Loss: 0.8342\n",
      "Epoch 20 | Train Loss: 0.8326 | Val Loss: 0.8307\n",
      "Epoch 21 | Train Loss: 0.8366 | Val Loss: 0.8257\n",
      "Epoch 22 | Train Loss: 0.8220 | Val Loss: 0.8364\n",
      "Epoch 23 | Train Loss: 0.8482 | Val Loss: 0.8190\n",
      "Epoch 24 | Train Loss: 0.8589 | Val Loss: 0.8168\n",
      "Epoch 25 | Train Loss: 0.8220 | Val Loss: 0.8264\n",
      "Epoch 26 | Train Loss: 0.8269 | Val Loss: 0.8171\n",
      "Epoch 27 | Train Loss: 0.8316 | Val Loss: 0.8131\n",
      "Epoch 28 | Train Loss: 0.8341 | Val Loss: 0.8437\n",
      "Epoch 29 | Train Loss: 0.8174 | Val Loss: 0.8044\n",
      "Epoch 30 | Train Loss: 0.8084 | Val Loss: 0.8041\n",
      "Epoch 31 | Train Loss: 0.8021 | Val Loss: 0.7974\n",
      "Epoch 32 | Train Loss: 0.8156 | Val Loss: 0.7952\n",
      "Epoch 33 | Train Loss: 0.7993 | Val Loss: 0.7954\n",
      "Epoch 34 | Train Loss: 0.7810 | Val Loss: 0.7866\n",
      "Epoch 35 | Train Loss: 0.7910 | Val Loss: 0.7947\n",
      "Epoch 36 | Train Loss: 0.7801 | Val Loss: 0.7915\n",
      "Epoch 37 | Train Loss: 0.7880 | Val Loss: 0.7831\n",
      "Epoch 38 | Train Loss: 0.8262 | Val Loss: 0.7768\n",
      "Epoch 39 | Train Loss: 0.7938 | Val Loss: 0.8180\n",
      "Epoch 40 | Train Loss: 0.7761 | Val Loss: 0.7759\n",
      "Epoch 41 | Train Loss: 0.7995 | Val Loss: 0.7725\n",
      "Epoch 42 | Train Loss: 0.7610 | Val Loss: 0.7822\n",
      "Epoch 43 | Train Loss: 0.7664 | Val Loss: 0.7834\n",
      "Epoch 44 | Train Loss: 0.7808 | Val Loss: 0.7652\n",
      "Epoch 45 | Train Loss: 0.7647 | Val Loss: 0.8163\n",
      "Epoch 46 | Train Loss: 0.7715 | Val Loss: 0.7605\n",
      "Epoch 47 | Train Loss: 0.7654 | Val Loss: 0.7607\n",
      "Epoch 48 | Train Loss: 0.7486 | Val Loss: 0.7713\n",
      "Epoch 49 | Train Loss: 0.7536 | Val Loss: 0.7700\n",
      "Epoch 50 | Train Loss: 0.7392 | Val Loss: 0.7649\n",
      "Fold 10 ‚ñ∂ AUC: 0.719, Balanced Acc: 0.443\n",
      "üîç Summary for hd=128, dp=0.4, lr=0.0001 ‚Üí AUC: 0.7264¬±0.0468 | BalAcc: 0.4811¬±0.0405\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.0, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9900 | Val Loss: 0.8668\n",
      "Epoch 02 | Train Loss: 0.8863 | Val Loss: 0.8565\n",
      "Epoch 03 | Train Loss: 0.8499 | Val Loss: 0.8649\n",
      "Epoch 04 | Train Loss: 0.8473 | Val Loss: 0.8390\n",
      "Epoch 05 | Train Loss: 0.8166 | Val Loss: 0.7986\n",
      "Epoch 06 | Train Loss: 0.8261 | Val Loss: 0.8771\n",
      "Epoch 07 | Train Loss: 0.8246 | Val Loss: 0.8144\n",
      "Epoch 08 | Train Loss: 0.8000 | Val Loss: 0.7522\n",
      "Epoch 09 | Train Loss: 0.7816 | Val Loss: 0.7478\n",
      "Epoch 10 | Train Loss: 0.7627 | Val Loss: 0.7225\n",
      "Epoch 11 | Train Loss: 0.7372 | Val Loss: 0.8071\n",
      "Epoch 12 | Train Loss: 0.8009 | Val Loss: 0.7549\n",
      "Epoch 13 | Train Loss: 0.7550 | Val Loss: 0.7371\n",
      "Epoch 14 | Train Loss: 0.7423 | Val Loss: 0.7049\n",
      "Epoch 15 | Train Loss: 0.7271 | Val Loss: 0.7143\n",
      "Epoch 16 | Train Loss: 0.7486 | Val Loss: 0.6946\n",
      "Epoch 17 | Train Loss: 0.7504 | Val Loss: 0.6883\n",
      "Epoch 18 | Train Loss: 0.7269 | Val Loss: 0.6939\n",
      "Epoch 19 | Train Loss: 0.7260 | Val Loss: 0.7122\n",
      "Epoch 20 | Train Loss: 0.7645 | Val Loss: 0.7166\n",
      "Epoch 21 | Train Loss: 0.7398 | Val Loss: 0.6939\n",
      "Epoch 22 | Train Loss: 0.7313 | Val Loss: 0.6916\n",
      "Epoch 23 | Train Loss: 0.7479 | Val Loss: 0.6972\n",
      "Epoch 24 | Train Loss: 0.7435 | Val Loss: 0.6842\n",
      "Epoch 25 | Train Loss: 0.7437 | Val Loss: 0.7050\n",
      "Epoch 26 | Train Loss: 0.7349 | Val Loss: 0.7116\n",
      "Epoch 27 | Train Loss: 0.7481 | Val Loss: 0.7117\n",
      "Epoch 28 | Train Loss: 0.7810 | Val Loss: 0.6914\n",
      "Epoch 29 | Train Loss: 0.7345 | Val Loss: 0.6990\n",
      "Epoch 30 | Train Loss: 0.7180 | Val Loss: 0.6805\n",
      "Epoch 31 | Train Loss: 0.7135 | Val Loss: 0.7122\n",
      "Epoch 32 | Train Loss: 0.7274 | Val Loss: 0.6943\n",
      "Epoch 33 | Train Loss: 0.7427 | Val Loss: 0.6904\n",
      "Epoch 34 | Train Loss: 0.7247 | Val Loss: 0.6975\n",
      "Epoch 35 | Train Loss: 0.7316 | Val Loss: 0.6880\n",
      "Epoch 36 | Train Loss: 0.7209 | Val Loss: 0.7163\n",
      "Epoch 37 | Train Loss: 0.7135 | Val Loss: 0.6863\n",
      "Epoch 38 | Train Loss: 0.7498 | Val Loss: 0.7022\n",
      "Epoch 39 | Train Loss: 0.7311 | Val Loss: 0.7144\n",
      "Epoch 40 | Train Loss: 0.7129 | Val Loss: 0.7015\n",
      "Epoch 41 | Train Loss: 0.7413 | Val Loss: 0.7104\n",
      "Epoch 42 | Train Loss: 0.7250 | Val Loss: 0.7124\n",
      "Epoch 43 | Train Loss: 0.7092 | Val Loss: 0.7298\n",
      "Epoch 44 | Train Loss: 0.7478 | Val Loss: 0.7074\n",
      "Epoch 45 | Train Loss: 0.7214 | Val Loss: 0.7102\n",
      "Epoch 46 | Train Loss: 0.7199 | Val Loss: 0.7736\n",
      "Epoch 47 | Train Loss: 0.7249 | Val Loss: 0.7220\n",
      "Epoch 48 | Train Loss: 0.7288 | Val Loss: 0.7011\n",
      "Epoch 49 | Train Loss: 0.7064 | Val Loss: 0.7086\n",
      "Epoch 50 | Train Loss: 0.7014 | Val Loss: 0.7170\n",
      "Fold 1 ‚ñ∂ AUC: 0.780, Balanced Acc: 0.484\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9771 | Val Loss: 0.8950\n",
      "Epoch 02 | Train Loss: 0.8868 | Val Loss: 0.8523\n",
      "Epoch 03 | Train Loss: 0.8648 | Val Loss: 0.8506\n",
      "Epoch 04 | Train Loss: 0.8397 | Val Loss: 0.8499\n",
      "Epoch 05 | Train Loss: 0.8318 | Val Loss: 0.8078\n",
      "Epoch 06 | Train Loss: 0.8066 | Val Loss: 0.8810\n",
      "Epoch 07 | Train Loss: 0.8172 | Val Loss: 0.7547\n",
      "Epoch 08 | Train Loss: 0.7921 | Val Loss: 0.7645\n",
      "Epoch 09 | Train Loss: 0.7930 | Val Loss: 0.7621\n",
      "Epoch 10 | Train Loss: 0.7916 | Val Loss: 0.7462\n",
      "Epoch 11 | Train Loss: 0.7735 | Val Loss: 0.7393\n",
      "Epoch 12 | Train Loss: 0.7522 | Val Loss: 0.7398\n",
      "Epoch 13 | Train Loss: 0.7783 | Val Loss: 0.7495\n",
      "Epoch 14 | Train Loss: 0.7754 | Val Loss: 0.7386\n",
      "Epoch 15 | Train Loss: 0.7709 | Val Loss: 0.7314\n",
      "Epoch 16 | Train Loss: 0.7738 | Val Loss: 0.8347\n",
      "Epoch 17 | Train Loss: 0.7474 | Val Loss: 0.7800\n",
      "Epoch 18 | Train Loss: 0.7553 | Val Loss: 0.7220\n",
      "Epoch 19 | Train Loss: 0.7383 | Val Loss: 0.7327\n",
      "Epoch 20 | Train Loss: 0.7422 | Val Loss: 0.7157\n",
      "Epoch 21 | Train Loss: 0.7359 | Val Loss: 0.7280\n",
      "Epoch 22 | Train Loss: 0.7156 | Val Loss: 0.7417\n",
      "Epoch 23 | Train Loss: 0.7342 | Val Loss: 0.7065\n",
      "Epoch 24 | Train Loss: 0.7349 | Val Loss: 0.7067\n",
      "Epoch 25 | Train Loss: 0.7571 | Val Loss: 0.7176\n",
      "Epoch 26 | Train Loss: 0.7402 | Val Loss: 0.7149\n",
      "Epoch 27 | Train Loss: 0.7325 | Val Loss: 0.7259\n",
      "Epoch 28 | Train Loss: 0.7458 | Val Loss: 0.7019\n",
      "Epoch 29 | Train Loss: 0.7232 | Val Loss: 0.7153\n",
      "Epoch 30 | Train Loss: 0.7344 | Val Loss: 0.8496\n",
      "Epoch 31 | Train Loss: 0.7571 | Val Loss: 0.8113\n",
      "Epoch 32 | Train Loss: 0.7488 | Val Loss: 0.7884\n",
      "Epoch 33 | Train Loss: 0.7413 | Val Loss: 0.7171\n",
      "Epoch 34 | Train Loss: 0.7550 | Val Loss: 0.6894\n",
      "Epoch 35 | Train Loss: 0.7395 | Val Loss: 0.7182\n",
      "Epoch 36 | Train Loss: 0.7257 | Val Loss: 0.6965\n",
      "Epoch 37 | Train Loss: 0.7192 | Val Loss: 0.7288\n",
      "Epoch 38 | Train Loss: 0.7171 | Val Loss: 0.7021\n",
      "Epoch 39 | Train Loss: 0.7324 | Val Loss: 0.7609\n",
      "Epoch 40 | Train Loss: 0.7135 | Val Loss: 0.7420\n",
      "Epoch 41 | Train Loss: 0.7122 | Val Loss: 0.7263\n",
      "Epoch 42 | Train Loss: 0.7135 | Val Loss: 0.7506\n",
      "Epoch 43 | Train Loss: 0.7230 | Val Loss: 0.7866\n",
      "Epoch 44 | Train Loss: 0.7223 | Val Loss: 0.7321\n",
      "Epoch 45 | Train Loss: 0.7113 | Val Loss: 0.6897\n",
      "Epoch 46 | Train Loss: 0.7374 | Val Loss: 0.6999\n",
      "Epoch 47 | Train Loss: 0.7483 | Val Loss: 0.6991\n",
      "Epoch 48 | Train Loss: 0.7178 | Val Loss: 0.7062\n",
      "Epoch 49 | Train Loss: 0.6973 | Val Loss: 0.6890\n",
      "Epoch 50 | Train Loss: 0.7137 | Val Loss: 0.7130\n",
      "Fold 2 ‚ñ∂ AUC: 0.723, Balanced Acc: 0.536\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 1.0174 | Val Loss: 0.8656\n",
      "Epoch 02 | Train Loss: 0.8856 | Val Loss: 0.8589\n",
      "Epoch 03 | Train Loss: 0.8674 | Val Loss: 0.8463\n",
      "Epoch 04 | Train Loss: 0.8628 | Val Loss: 0.8219\n",
      "Epoch 05 | Train Loss: 0.8346 | Val Loss: 0.8111\n",
      "Epoch 06 | Train Loss: 0.8190 | Val Loss: 0.8980\n",
      "Epoch 07 | Train Loss: 0.8860 | Val Loss: 0.8174\n",
      "Epoch 08 | Train Loss: 0.8478 | Val Loss: 0.7929\n",
      "Epoch 09 | Train Loss: 0.8136 | Val Loss: 0.7962\n",
      "Epoch 10 | Train Loss: 0.8056 | Val Loss: 0.7697\n",
      "Epoch 11 | Train Loss: 0.7632 | Val Loss: 0.7840\n",
      "Epoch 12 | Train Loss: 0.7540 | Val Loss: 0.7676\n",
      "Epoch 13 | Train Loss: 0.7341 | Val Loss: 0.7675\n",
      "Epoch 14 | Train Loss: 0.7371 | Val Loss: 0.7890\n",
      "Epoch 15 | Train Loss: 0.7473 | Val Loss: 0.7381\n",
      "Epoch 16 | Train Loss: 0.7310 | Val Loss: 0.7415\n",
      "Epoch 17 | Train Loss: 0.7265 | Val Loss: 0.7317\n",
      "Epoch 18 | Train Loss: 0.7389 | Val Loss: 0.7315\n",
      "Epoch 19 | Train Loss: 0.7394 | Val Loss: 0.7312\n",
      "Epoch 20 | Train Loss: 0.7459 | Val Loss: 0.7319\n",
      "Epoch 21 | Train Loss: 0.7387 | Val Loss: 0.7277\n",
      "Epoch 22 | Train Loss: 0.7133 | Val Loss: 0.7309\n",
      "Epoch 23 | Train Loss: 0.7590 | Val Loss: 0.7219\n",
      "Epoch 24 | Train Loss: 0.7475 | Val Loss: 0.7464\n",
      "Epoch 25 | Train Loss: 0.7293 | Val Loss: 0.7704\n",
      "Epoch 26 | Train Loss: 0.7328 | Val Loss: 0.7770\n",
      "Epoch 27 | Train Loss: 0.7412 | Val Loss: 0.7282\n",
      "Epoch 28 | Train Loss: 0.7193 | Val Loss: 0.7225\n",
      "Epoch 29 | Train Loss: 0.7374 | Val Loss: 0.7439\n",
      "Epoch 30 | Train Loss: 0.7289 | Val Loss: 0.7188\n",
      "Epoch 31 | Train Loss: 0.7315 | Val Loss: 0.7196\n",
      "Epoch 32 | Train Loss: 0.7203 | Val Loss: 0.7327\n",
      "Epoch 33 | Train Loss: 0.7314 | Val Loss: 0.7864\n",
      "Epoch 34 | Train Loss: 0.7674 | Val Loss: 0.7618\n",
      "Epoch 35 | Train Loss: 0.7263 | Val Loss: 0.7324\n",
      "Epoch 36 | Train Loss: 0.7178 | Val Loss: 0.7149\n",
      "Epoch 37 | Train Loss: 0.7203 | Val Loss: 0.7169\n",
      "Epoch 38 | Train Loss: 0.7353 | Val Loss: 0.7184\n",
      "Epoch 39 | Train Loss: 0.7405 | Val Loss: 0.7167\n",
      "Epoch 40 | Train Loss: 0.7414 | Val Loss: 0.7214\n",
      "Epoch 41 | Train Loss: 0.7356 | Val Loss: 0.7277\n",
      "Epoch 42 | Train Loss: 0.7189 | Val Loss: 0.7227\n",
      "Epoch 43 | Train Loss: 0.7182 | Val Loss: 0.7110\n",
      "Epoch 44 | Train Loss: 0.7125 | Val Loss: 0.7234\n",
      "Epoch 45 | Train Loss: 0.7187 | Val Loss: 0.8067\n",
      "Epoch 46 | Train Loss: 0.7536 | Val Loss: 0.7342\n",
      "Epoch 47 | Train Loss: 0.7435 | Val Loss: 0.7295\n",
      "Epoch 48 | Train Loss: 0.7224 | Val Loss: 0.7265\n",
      "Epoch 49 | Train Loss: 0.7567 | Val Loss: 0.7162\n",
      "Epoch 50 | Train Loss: 0.7231 | Val Loss: 0.7122\n",
      "Fold 3 ‚ñ∂ AUC: 0.773, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9573 | Val Loss: 0.8486\n",
      "Epoch 02 | Train Loss: 0.8976 | Val Loss: 0.8446\n",
      "Epoch 03 | Train Loss: 0.8717 | Val Loss: 0.8500\n",
      "Epoch 04 | Train Loss: 0.8419 | Val Loss: 0.8440\n",
      "Epoch 05 | Train Loss: 0.8407 | Val Loss: 0.7850\n",
      "Epoch 06 | Train Loss: 0.8105 | Val Loss: 0.8276\n",
      "Epoch 07 | Train Loss: 0.7673 | Val Loss: 0.7489\n",
      "Epoch 08 | Train Loss: 0.8035 | Val Loss: 0.7036\n",
      "Epoch 09 | Train Loss: 0.7742 | Val Loss: 0.6894\n",
      "Epoch 10 | Train Loss: 0.7774 | Val Loss: 0.7691\n",
      "Epoch 11 | Train Loss: 0.8488 | Val Loss: 0.7237\n",
      "Epoch 12 | Train Loss: 0.7652 | Val Loss: 0.6956\n",
      "Epoch 13 | Train Loss: 0.7592 | Val Loss: 0.6931\n",
      "Epoch 14 | Train Loss: 0.7689 | Val Loss: 0.6877\n",
      "Epoch 15 | Train Loss: 0.7886 | Val Loss: 0.7370\n",
      "Epoch 16 | Train Loss: 0.7641 | Val Loss: 0.6950\n",
      "Epoch 17 | Train Loss: 0.7440 | Val Loss: 0.6717\n",
      "Epoch 18 | Train Loss: 0.7564 | Val Loss: 0.6780\n",
      "Epoch 19 | Train Loss: 0.7518 | Val Loss: 0.6802\n",
      "Epoch 20 | Train Loss: 0.7326 | Val Loss: 0.6886\n",
      "Epoch 21 | Train Loss: 0.7487 | Val Loss: 0.6701\n",
      "Epoch 22 | Train Loss: 0.7334 | Val Loss: 0.6724\n",
      "Epoch 23 | Train Loss: 0.7341 | Val Loss: 0.6682\n",
      "Epoch 24 | Train Loss: 0.7445 | Val Loss: 0.6746\n",
      "Epoch 25 | Train Loss: 0.7444 | Val Loss: 0.7114\n",
      "Epoch 26 | Train Loss: 0.7377 | Val Loss: 0.6786\n",
      "Epoch 27 | Train Loss: 0.7516 | Val Loss: 0.6784\n",
      "Epoch 28 | Train Loss: 0.7331 | Val Loss: 0.6732\n",
      "Epoch 29 | Train Loss: 0.7378 | Val Loss: 0.6667\n",
      "Epoch 30 | Train Loss: 0.7284 | Val Loss: 0.6632\n",
      "Epoch 31 | Train Loss: 0.7278 | Val Loss: 0.6906\n",
      "Epoch 32 | Train Loss: 0.7421 | Val Loss: 0.7085\n",
      "Epoch 33 | Train Loss: 0.7718 | Val Loss: 0.6933\n",
      "Epoch 34 | Train Loss: 0.7439 | Val Loss: 0.6840\n",
      "Epoch 35 | Train Loss: 0.7298 | Val Loss: 0.7073\n",
      "Epoch 36 | Train Loss: 0.7234 | Val Loss: 0.6988\n",
      "Epoch 37 | Train Loss: 0.7358 | Val Loss: 0.7190\n",
      "Epoch 38 | Train Loss: 0.7192 | Val Loss: 0.6643\n",
      "Epoch 39 | Train Loss: 0.7593 | Val Loss: 0.7432\n",
      "Epoch 40 | Train Loss: 0.7258 | Val Loss: 0.6653\n",
      "Epoch 41 | Train Loss: 0.7279 | Val Loss: 0.6950\n",
      "Epoch 42 | Train Loss: 0.7161 | Val Loss: 0.6741\n",
      "Epoch 43 | Train Loss: 0.7163 | Val Loss: 0.6980\n",
      "Epoch 44 | Train Loss: 0.7245 | Val Loss: 0.6941\n",
      "Epoch 45 | Train Loss: 0.7237 | Val Loss: 0.7132\n",
      "Epoch 46 | Train Loss: 0.7321 | Val Loss: 0.6669\n",
      "Epoch 47 | Train Loss: 0.7013 | Val Loss: 0.6843\n",
      "Epoch 48 | Train Loss: 0.7083 | Val Loss: 0.6992\n",
      "Epoch 49 | Train Loss: 0.7096 | Val Loss: 0.6893\n",
      "Epoch 50 | Train Loss: 0.7123 | Val Loss: 0.6907\n",
      "Fold 4 ‚ñ∂ AUC: 0.754, Balanced Acc: 0.524\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9369 | Val Loss: 0.9115\n",
      "Epoch 02 | Train Loss: 0.8860 | Val Loss: 0.9575\n",
      "Epoch 03 | Train Loss: 0.8988 | Val Loss: 0.8911\n",
      "Epoch 04 | Train Loss: 0.8998 | Val Loss: 0.8769\n",
      "Epoch 05 | Train Loss: 0.8843 | Val Loss: 0.8968\n",
      "Epoch 06 | Train Loss: 0.8513 | Val Loss: 0.8779\n",
      "Epoch 07 | Train Loss: 0.8070 | Val Loss: 0.9493\n",
      "Epoch 08 | Train Loss: 0.7788 | Val Loss: 1.0157\n",
      "Epoch 09 | Train Loss: 0.8161 | Val Loss: 0.8533\n",
      "Epoch 10 | Train Loss: 0.8086 | Val Loss: 0.8420\n",
      "Epoch 11 | Train Loss: 0.7427 | Val Loss: 0.8596\n",
      "Epoch 12 | Train Loss: 0.7555 | Val Loss: 0.8713\n",
      "Epoch 13 | Train Loss: 0.7538 | Val Loss: 0.8272\n",
      "Epoch 14 | Train Loss: 0.7436 | Val Loss: 0.8138\n",
      "Epoch 15 | Train Loss: 0.7486 | Val Loss: 0.8304\n",
      "Epoch 16 | Train Loss: 0.7342 | Val Loss: 0.8263\n",
      "Epoch 17 | Train Loss: 0.7696 | Val Loss: 0.8241\n",
      "Epoch 18 | Train Loss: 0.7642 | Val Loss: 0.8160\n",
      "Epoch 19 | Train Loss: 0.7438 | Val Loss: 0.8441\n",
      "Epoch 20 | Train Loss: 0.7540 | Val Loss: 0.8100\n",
      "Epoch 21 | Train Loss: 0.7301 | Val Loss: 0.8136\n",
      "Epoch 22 | Train Loss: 0.7198 | Val Loss: 0.8188\n",
      "Epoch 23 | Train Loss: 0.7165 | Val Loss: 0.8344\n",
      "Epoch 24 | Train Loss: 0.7216 | Val Loss: 0.8614\n",
      "Epoch 25 | Train Loss: 0.7511 | Val Loss: 0.8020\n",
      "Epoch 26 | Train Loss: 0.7375 | Val Loss: 0.8025\n",
      "Epoch 27 | Train Loss: 0.7173 | Val Loss: 0.7984\n",
      "Epoch 28 | Train Loss: 0.7274 | Val Loss: 0.8023\n",
      "Epoch 29 | Train Loss: 0.7169 | Val Loss: 0.8011\n",
      "Epoch 30 | Train Loss: 0.7294 | Val Loss: 0.8025\n",
      "Epoch 31 | Train Loss: 0.7167 | Val Loss: 0.7982\n",
      "Epoch 32 | Train Loss: 0.7083 | Val Loss: 0.8513\n",
      "Epoch 33 | Train Loss: 0.7251 | Val Loss: 0.8484\n",
      "Epoch 34 | Train Loss: 0.7029 | Val Loss: 0.7998\n",
      "Epoch 35 | Train Loss: 0.7148 | Val Loss: 0.8017\n",
      "Epoch 36 | Train Loss: 0.7009 | Val Loss: 0.8021\n",
      "Epoch 37 | Train Loss: 0.7000 | Val Loss: 0.8218\n",
      "Epoch 38 | Train Loss: 0.7308 | Val Loss: 0.7949\n",
      "Epoch 39 | Train Loss: 0.7235 | Val Loss: 0.8137\n",
      "Epoch 40 | Train Loss: 0.6962 | Val Loss: 0.8090\n",
      "Epoch 41 | Train Loss: 0.7116 | Val Loss: 0.8035\n",
      "Epoch 42 | Train Loss: 0.6920 | Val Loss: 0.7998\n",
      "Epoch 43 | Train Loss: 0.7080 | Val Loss: 0.7950\n",
      "Epoch 44 | Train Loss: 0.7089 | Val Loss: 0.8288\n",
      "Epoch 45 | Train Loss: 0.7235 | Val Loss: 0.8338\n",
      "Epoch 46 | Train Loss: 0.7074 | Val Loss: 0.8021\n",
      "Epoch 47 | Train Loss: 0.6956 | Val Loss: 0.8567\n",
      "Epoch 48 | Train Loss: 0.7183 | Val Loss: 0.8422\n",
      "Epoch 49 | Train Loss: 0.6960 | Val Loss: 0.8420\n",
      "Epoch 50 | Train Loss: 0.7105 | Val Loss: 0.9143\n",
      "Fold 5 ‚ñ∂ AUC: 0.719, Balanced Acc: 0.436\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9639 | Val Loss: 0.9231\n",
      "Epoch 02 | Train Loss: 0.8921 | Val Loss: 0.8973\n",
      "Epoch 03 | Train Loss: 0.8810 | Val Loss: 0.8819\n",
      "Epoch 04 | Train Loss: 0.8376 | Val Loss: 0.9115\n",
      "Epoch 05 | Train Loss: 0.8392 | Val Loss: 0.8671\n",
      "Epoch 06 | Train Loss: 0.7902 | Val Loss: 0.8715\n",
      "Epoch 07 | Train Loss: 0.7671 | Val Loss: 0.9343\n",
      "Epoch 08 | Train Loss: 0.8137 | Val Loss: 0.8112\n",
      "Epoch 09 | Train Loss: 0.7935 | Val Loss: 0.8683\n",
      "Epoch 10 | Train Loss: 0.7913 | Val Loss: 0.8330\n",
      "Epoch 11 | Train Loss: 0.7635 | Val Loss: 0.8482\n",
      "Epoch 12 | Train Loss: 0.7563 | Val Loss: 0.8189\n",
      "Epoch 13 | Train Loss: 0.7397 | Val Loss: 0.8104\n",
      "Epoch 14 | Train Loss: 0.7253 | Val Loss: 0.8175\n",
      "Epoch 15 | Train Loss: 0.7220 | Val Loss: 0.8220\n",
      "Epoch 16 | Train Loss: 0.7183 | Val Loss: 0.8345\n",
      "Epoch 17 | Train Loss: 0.7421 | Val Loss: 0.8165\n",
      "Epoch 18 | Train Loss: 0.7389 | Val Loss: 0.8387\n",
      "Epoch 19 | Train Loss: 0.7278 | Val Loss: 0.8302\n",
      "Epoch 20 | Train Loss: 0.7349 | Val Loss: 0.8312\n",
      "Epoch 21 | Train Loss: 0.7323 | Val Loss: 0.8581\n",
      "Epoch 22 | Train Loss: 0.7341 | Val Loss: 0.8286\n",
      "Epoch 23 | Train Loss: 0.7344 | Val Loss: 0.8192\n",
      "Epoch 24 | Train Loss: 0.7259 | Val Loss: 0.8235\n",
      "Epoch 25 | Train Loss: 0.7005 | Val Loss: 0.8285\n",
      "Epoch 26 | Train Loss: 0.7165 | Val Loss: 0.8283\n",
      "Epoch 27 | Train Loss: 0.7218 | Val Loss: 0.8312\n",
      "Epoch 28 | Train Loss: 0.7158 | Val Loss: 0.8401\n",
      "Epoch 29 | Train Loss: 0.7299 | Val Loss: 0.8238\n",
      "Epoch 30 | Train Loss: 0.7052 | Val Loss: 0.8301\n",
      "Epoch 31 | Train Loss: 0.7162 | Val Loss: 0.8340\n",
      "Epoch 32 | Train Loss: 0.7325 | Val Loss: 0.8286\n",
      "Epoch 33 | Train Loss: 0.7325 | Val Loss: 0.8334\n",
      "Epoch 34 | Train Loss: 0.7351 | Val Loss: 0.8320\n",
      "Epoch 35 | Train Loss: 0.7204 | Val Loss: 0.8227\n",
      "Epoch 36 | Train Loss: 0.7085 | Val Loss: 0.8335\n",
      "Epoch 37 | Train Loss: 0.7313 | Val Loss: 0.8837\n",
      "Epoch 38 | Train Loss: 0.7181 | Val Loss: 0.8078\n",
      "Epoch 39 | Train Loss: 0.7291 | Val Loss: 0.8403\n",
      "Epoch 40 | Train Loss: 0.7604 | Val Loss: 0.8115\n",
      "Epoch 41 | Train Loss: 0.7177 | Val Loss: 0.8148\n",
      "Epoch 42 | Train Loss: 0.6859 | Val Loss: 0.8564\n",
      "Epoch 43 | Train Loss: 0.7107 | Val Loss: 0.8142\n",
      "Epoch 44 | Train Loss: 0.7089 | Val Loss: 0.8174\n",
      "Epoch 45 | Train Loss: 0.7046 | Val Loss: 0.8280\n",
      "Epoch 46 | Train Loss: 0.6896 | Val Loss: 0.8157\n",
      "Epoch 47 | Train Loss: 0.7237 | Val Loss: 0.8163\n",
      "Epoch 48 | Train Loss: 0.7312 | Val Loss: 0.8391\n",
      "Epoch 49 | Train Loss: 0.7080 | Val Loss: 0.8055\n",
      "Epoch 50 | Train Loss: 0.7095 | Val Loss: 0.8236\n",
      "Fold 6 ‚ñ∂ AUC: 0.724, Balanced Acc: 0.479\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9602 | Val Loss: 0.8723\n",
      "Epoch 02 | Train Loss: 0.8960 | Val Loss: 0.8789\n",
      "Epoch 03 | Train Loss: 0.8921 | Val Loss: 0.8563\n",
      "Epoch 04 | Train Loss: 0.8610 | Val Loss: 0.8413\n",
      "Epoch 05 | Train Loss: 0.8417 | Val Loss: 0.8109\n",
      "Epoch 06 | Train Loss: 0.8497 | Val Loss: 0.8197\n",
      "Epoch 07 | Train Loss: 0.8200 | Val Loss: 0.7633\n",
      "Epoch 08 | Train Loss: 0.8566 | Val Loss: 0.7520\n",
      "Epoch 09 | Train Loss: 0.7849 | Val Loss: 0.8025\n",
      "Epoch 10 | Train Loss: 0.7925 | Val Loss: 0.7389\n",
      "Epoch 11 | Train Loss: 0.7791 | Val Loss: 0.7408\n",
      "Epoch 12 | Train Loss: 0.7735 | Val Loss: 0.7289\n",
      "Epoch 13 | Train Loss: 0.7573 | Val Loss: 0.7059\n",
      "Epoch 14 | Train Loss: 0.7669 | Val Loss: 0.7091\n",
      "Epoch 15 | Train Loss: 0.7649 | Val Loss: 0.7153\n",
      "Epoch 16 | Train Loss: 0.7597 | Val Loss: 0.7180\n",
      "Epoch 17 | Train Loss: 0.7566 | Val Loss: 0.7130\n",
      "Epoch 18 | Train Loss: 0.7360 | Val Loss: 0.7055\n",
      "Epoch 19 | Train Loss: 0.7247 | Val Loss: 0.7338\n",
      "Epoch 20 | Train Loss: 0.7420 | Val Loss: 0.7311\n",
      "Epoch 21 | Train Loss: 0.7485 | Val Loss: 0.7267\n",
      "Epoch 22 | Train Loss: 0.7301 | Val Loss: 0.7154\n",
      "Epoch 23 | Train Loss: 0.7439 | Val Loss: 0.6984\n",
      "Epoch 24 | Train Loss: 0.7146 | Val Loss: 0.7168\n",
      "Epoch 25 | Train Loss: 0.7204 | Val Loss: 0.7042\n",
      "Epoch 26 | Train Loss: 0.7186 | Val Loss: 0.7158\n",
      "Epoch 27 | Train Loss: 0.7518 | Val Loss: 0.7165\n",
      "Epoch 28 | Train Loss: 0.7125 | Val Loss: 0.6924\n",
      "Epoch 29 | Train Loss: 0.7338 | Val Loss: 0.7112\n",
      "Epoch 30 | Train Loss: 0.7138 | Val Loss: 0.7003\n",
      "Epoch 31 | Train Loss: 0.7082 | Val Loss: 0.7767\n",
      "Epoch 32 | Train Loss: 0.7244 | Val Loss: 0.7018\n",
      "Epoch 33 | Train Loss: 0.7182 | Val Loss: 0.6977\n",
      "Epoch 34 | Train Loss: 0.7246 | Val Loss: 0.7194\n",
      "Epoch 35 | Train Loss: 0.7091 | Val Loss: 0.7067\n",
      "Epoch 36 | Train Loss: 0.7141 | Val Loss: 0.7143\n",
      "Epoch 37 | Train Loss: 0.7070 | Val Loss: 0.7195\n",
      "Epoch 38 | Train Loss: 0.7080 | Val Loss: 0.7055\n",
      "Epoch 39 | Train Loss: 0.7058 | Val Loss: 0.7099\n",
      "Epoch 40 | Train Loss: 0.7241 | Val Loss: 0.7504\n",
      "Epoch 41 | Train Loss: 0.7215 | Val Loss: 0.7355\n",
      "Epoch 42 | Train Loss: 0.7357 | Val Loss: 0.7035\n",
      "Epoch 43 | Train Loss: 0.7324 | Val Loss: 0.8349\n",
      "Epoch 44 | Train Loss: 0.7419 | Val Loss: 0.7180\n",
      "Epoch 45 | Train Loss: 0.7392 | Val Loss: 0.7210\n",
      "Epoch 46 | Train Loss: 0.7096 | Val Loss: 0.7045\n",
      "Epoch 47 | Train Loss: 0.7167 | Val Loss: 0.7066\n",
      "Epoch 48 | Train Loss: 0.7140 | Val Loss: 0.7290\n",
      "Epoch 49 | Train Loss: 0.7064 | Val Loss: 0.7090\n",
      "Epoch 50 | Train Loss: 0.7186 | Val Loss: 0.7018\n",
      "Fold 7 ‚ñ∂ AUC: 0.773, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 1.0533 | Val Loss: 0.9132\n",
      "Epoch 02 | Train Loss: 0.8788 | Val Loss: 0.8770\n",
      "Epoch 03 | Train Loss: 0.8681 | Val Loss: 0.8707\n",
      "Epoch 04 | Train Loss: 0.8608 | Val Loss: 0.8724\n",
      "Epoch 05 | Train Loss: 0.8414 | Val Loss: 0.8389\n",
      "Epoch 06 | Train Loss: 0.8426 | Val Loss: 0.8937\n",
      "Epoch 07 | Train Loss: 0.8231 | Val Loss: 0.8196\n",
      "Epoch 08 | Train Loss: 0.8344 | Val Loss: 0.8325\n",
      "Epoch 09 | Train Loss: 0.8123 | Val Loss: 0.8149\n",
      "Epoch 10 | Train Loss: 0.7811 | Val Loss: 0.8233\n",
      "Epoch 11 | Train Loss: 0.7905 | Val Loss: 0.8028\n",
      "Epoch 12 | Train Loss: 0.7582 | Val Loss: 0.8067\n",
      "Epoch 13 | Train Loss: 0.7657 | Val Loss: 0.8645\n",
      "Epoch 14 | Train Loss: 0.7724 | Val Loss: 0.8146\n",
      "Epoch 15 | Train Loss: 0.7318 | Val Loss: 0.8086\n",
      "Epoch 16 | Train Loss: 0.7292 | Val Loss: 0.7974\n",
      "Epoch 17 | Train Loss: 0.7348 | Val Loss: 0.8132\n",
      "Epoch 18 | Train Loss: 0.7273 | Val Loss: 0.8120\n",
      "Epoch 19 | Train Loss: 0.7308 | Val Loss: 0.8115\n",
      "Epoch 20 | Train Loss: 0.7139 | Val Loss: 0.8192\n",
      "Epoch 21 | Train Loss: 0.7188 | Val Loss: 0.8225\n",
      "Epoch 22 | Train Loss: 0.7345 | Val Loss: 0.8110\n",
      "Epoch 23 | Train Loss: 0.7334 | Val Loss: 0.8139\n",
      "Epoch 24 | Train Loss: 0.7102 | Val Loss: 0.8594\n",
      "Epoch 25 | Train Loss: 0.7413 | Val Loss: 0.8086\n",
      "Epoch 26 | Train Loss: 0.7446 | Val Loss: 0.8224\n",
      "Epoch 27 | Train Loss: 0.7225 | Val Loss: 0.8339\n",
      "Epoch 28 | Train Loss: 0.7165 | Val Loss: 0.8357\n",
      "Epoch 29 | Train Loss: 0.7272 | Val Loss: 0.8258\n",
      "Epoch 30 | Train Loss: 0.7036 | Val Loss: 0.8182\n",
      "Epoch 31 | Train Loss: 0.7111 | Val Loss: 0.8296\n",
      "Epoch 32 | Train Loss: 0.7054 | Val Loss: 0.8307\n",
      "Epoch 33 | Train Loss: 0.7092 | Val Loss: 0.8361\n",
      "Epoch 34 | Train Loss: 0.7161 | Val Loss: 0.8221\n",
      "Epoch 35 | Train Loss: 0.7045 | Val Loss: 0.8552\n",
      "Epoch 36 | Train Loss: 0.7207 | Val Loss: 0.8248\n",
      "Epoch 37 | Train Loss: 0.7100 | Val Loss: 0.8388\n",
      "Epoch 38 | Train Loss: 0.7158 | Val Loss: 0.8341\n",
      "Epoch 39 | Train Loss: 0.7186 | Val Loss: 0.8295\n",
      "Epoch 40 | Train Loss: 0.7224 | Val Loss: 0.8164\n",
      "Epoch 41 | Train Loss: 0.7007 | Val Loss: 0.8427\n",
      "Epoch 42 | Train Loss: 0.7008 | Val Loss: 0.8364\n",
      "Epoch 43 | Train Loss: 0.7019 | Val Loss: 0.8811\n",
      "Epoch 44 | Train Loss: 0.7309 | Val Loss: 0.8190\n",
      "Epoch 45 | Train Loss: 0.6997 | Val Loss: 0.8172\n",
      "Epoch 46 | Train Loss: 0.6997 | Val Loss: 0.8127\n",
      "Epoch 47 | Train Loss: 0.7094 | Val Loss: 0.8238\n",
      "Epoch 48 | Train Loss: 0.7131 | Val Loss: 0.8398\n",
      "Epoch 49 | Train Loss: 0.7192 | Val Loss: 0.8020\n",
      "Epoch 50 | Train Loss: 0.7081 | Val Loss: 0.8306\n",
      "Fold 8 ‚ñ∂ AUC: 0.706, Balanced Acc: 0.455\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9923 | Val Loss: 0.8839\n",
      "Epoch 02 | Train Loss: 0.8774 | Val Loss: 0.9002\n",
      "Epoch 03 | Train Loss: 0.8719 | Val Loss: 0.8868\n",
      "Epoch 04 | Train Loss: 0.8402 | Val Loss: 0.8436\n",
      "Epoch 05 | Train Loss: 0.8058 | Val Loss: 0.9414\n",
      "Epoch 06 | Train Loss: 0.8508 | Val Loss: 0.8108\n",
      "Epoch 07 | Train Loss: 0.7839 | Val Loss: 0.8228\n",
      "Epoch 08 | Train Loss: 0.7651 | Val Loss: 0.7868\n",
      "Epoch 09 | Train Loss: 0.7526 | Val Loss: 0.8082\n",
      "Epoch 10 | Train Loss: 0.7758 | Val Loss: 0.7778\n",
      "Epoch 11 | Train Loss: 0.8194 | Val Loss: 0.7919\n",
      "Epoch 12 | Train Loss: 0.7805 | Val Loss: 0.7930\n",
      "Epoch 13 | Train Loss: 0.7786 | Val Loss: 0.7622\n",
      "Epoch 14 | Train Loss: 0.7829 | Val Loss: 0.8133\n",
      "Epoch 15 | Train Loss: 0.7340 | Val Loss: 0.7576\n",
      "Epoch 16 | Train Loss: 0.7401 | Val Loss: 0.7540\n",
      "Epoch 17 | Train Loss: 0.7234 | Val Loss: 0.7776\n",
      "Epoch 18 | Train Loss: 0.7311 | Val Loss: 0.7518\n",
      "Epoch 19 | Train Loss: 0.7515 | Val Loss: 0.7420\n",
      "Epoch 20 | Train Loss: 0.7503 | Val Loss: 0.7356\n",
      "Epoch 21 | Train Loss: 0.7498 | Val Loss: 0.7442\n",
      "Epoch 22 | Train Loss: 0.7244 | Val Loss: 0.7392\n",
      "Epoch 23 | Train Loss: 0.7350 | Val Loss: 0.7424\n",
      "Epoch 24 | Train Loss: 0.7629 | Val Loss: 0.7399\n",
      "Epoch 25 | Train Loss: 0.7189 | Val Loss: 0.7423\n",
      "Epoch 26 | Train Loss: 0.7244 | Val Loss: 0.7537\n",
      "Epoch 27 | Train Loss: 0.7210 | Val Loss: 0.7571\n",
      "Epoch 28 | Train Loss: 0.7147 | Val Loss: 0.7534\n",
      "Epoch 29 | Train Loss: 0.7415 | Val Loss: 0.7475\n",
      "Epoch 30 | Train Loss: 0.7134 | Val Loss: 0.7482\n",
      "Epoch 31 | Train Loss: 0.7145 | Val Loss: 0.8005\n",
      "Epoch 32 | Train Loss: 0.7521 | Val Loss: 0.7514\n",
      "Epoch 33 | Train Loss: 0.7528 | Val Loss: 0.7461\n",
      "Epoch 34 | Train Loss: 0.7109 | Val Loss: 0.7446\n",
      "Epoch 35 | Train Loss: 0.7167 | Val Loss: 0.7351\n",
      "Epoch 36 | Train Loss: 0.7223 | Val Loss: 0.7393\n",
      "Epoch 37 | Train Loss: 0.7320 | Val Loss: 0.7529\n",
      "Epoch 38 | Train Loss: 0.7244 | Val Loss: 0.7258\n",
      "Epoch 39 | Train Loss: 0.7065 | Val Loss: 0.7694\n",
      "Epoch 40 | Train Loss: 0.7099 | Val Loss: 0.7343\n",
      "Epoch 41 | Train Loss: 0.7139 | Val Loss: 0.7431\n",
      "Epoch 42 | Train Loss: 0.7054 | Val Loss: 0.7644\n",
      "Epoch 43 | Train Loss: 0.7011 | Val Loss: 0.7406\n",
      "Epoch 44 | Train Loss: 0.7216 | Val Loss: 0.7482\n",
      "Epoch 45 | Train Loss: 0.7243 | Val Loss: 0.7665\n",
      "Epoch 46 | Train Loss: 0.7387 | Val Loss: 0.7386\n",
      "Epoch 47 | Train Loss: 0.7046 | Val Loss: 0.7758\n",
      "Epoch 48 | Train Loss: 0.7032 | Val Loss: 0.7503\n",
      "Epoch 49 | Train Loss: 0.6971 | Val Loss: 0.7325\n",
      "Epoch 50 | Train Loss: 0.7024 | Val Loss: 0.7318\n",
      "Fold 9 ‚ñ∂ AUC: 0.757, Balanced Acc: 0.495\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9970 | Val Loss: 0.9247\n",
      "Epoch 02 | Train Loss: 0.8830 | Val Loss: 0.8764\n",
      "Epoch 03 | Train Loss: 0.8637 | Val Loss: 0.8560\n",
      "Epoch 04 | Train Loss: 0.8731 | Val Loss: 0.8696\n",
      "Epoch 05 | Train Loss: 0.8551 | Val Loss: 0.8281\n",
      "Epoch 06 | Train Loss: 0.8573 | Val Loss: 0.8368\n",
      "Epoch 07 | Train Loss: 0.8433 | Val Loss: 0.8119\n",
      "Epoch 08 | Train Loss: 0.8069 | Val Loss: 0.7793\n",
      "Epoch 09 | Train Loss: 0.8230 | Val Loss: 0.8109\n",
      "Epoch 10 | Train Loss: 0.7773 | Val Loss: 0.8157\n",
      "Epoch 11 | Train Loss: 0.7895 | Val Loss: 0.7644\n",
      "Epoch 12 | Train Loss: 0.7738 | Val Loss: 0.7697\n",
      "Epoch 13 | Train Loss: 0.7629 | Val Loss: 0.7818\n",
      "Epoch 14 | Train Loss: 0.7479 | Val Loss: 0.8075\n",
      "Epoch 15 | Train Loss: 0.7484 | Val Loss: 0.7695\n",
      "Epoch 16 | Train Loss: 0.7726 | Val Loss: 0.7803\n",
      "Epoch 17 | Train Loss: 0.7642 | Val Loss: 0.7743\n",
      "Epoch 18 | Train Loss: 0.7530 | Val Loss: 0.7780\n",
      "Epoch 19 | Train Loss: 0.7433 | Val Loss: 0.7761\n",
      "Epoch 20 | Train Loss: 0.7213 | Val Loss: 0.7962\n",
      "Epoch 21 | Train Loss: 0.7196 | Val Loss: 0.8650\n",
      "Epoch 22 | Train Loss: 0.7485 | Val Loss: 0.7971\n",
      "Epoch 23 | Train Loss: 0.7283 | Val Loss: 0.7765\n",
      "Epoch 24 | Train Loss: 0.7206 | Val Loss: 0.7853\n",
      "Epoch 25 | Train Loss: 0.7216 | Val Loss: 0.7794\n",
      "Epoch 26 | Train Loss: 0.7373 | Val Loss: 0.8484\n",
      "Epoch 27 | Train Loss: 0.7411 | Val Loss: 0.8173\n",
      "Epoch 28 | Train Loss: 0.7311 | Val Loss: 0.7890\n",
      "Epoch 29 | Train Loss: 0.7270 | Val Loss: 0.8022\n",
      "Epoch 30 | Train Loss: 0.7299 | Val Loss: 0.7892\n",
      "Epoch 31 | Train Loss: 0.7474 | Val Loss: 0.8053\n",
      "Epoch 32 | Train Loss: 0.7949 | Val Loss: 0.7671\n",
      "Epoch 33 | Train Loss: 0.7628 | Val Loss: 0.7897\n",
      "Epoch 34 | Train Loss: 0.7251 | Val Loss: 0.8045\n",
      "Epoch 35 | Train Loss: 0.7113 | Val Loss: 0.7657\n",
      "Epoch 36 | Train Loss: 0.7248 | Val Loss: 0.7744\n",
      "Epoch 37 | Train Loss: 0.7201 | Val Loss: 0.8041\n",
      "Epoch 38 | Train Loss: 0.7259 | Val Loss: 0.8475\n",
      "Epoch 39 | Train Loss: 0.7421 | Val Loss: 0.7942\n",
      "Epoch 40 | Train Loss: 0.7261 | Val Loss: 0.7697\n",
      "Epoch 41 | Train Loss: 0.7046 | Val Loss: 0.8377\n",
      "Epoch 42 | Train Loss: 0.7519 | Val Loss: 0.7885\n",
      "Epoch 43 | Train Loss: 0.7167 | Val Loss: 0.7930\n",
      "Epoch 44 | Train Loss: 0.7382 | Val Loss: 0.7903\n",
      "Epoch 45 | Train Loss: 0.7234 | Val Loss: 0.8596\n",
      "Epoch 46 | Train Loss: 0.7406 | Val Loss: 0.8199\n",
      "Epoch 47 | Train Loss: 0.7197 | Val Loss: 0.7581\n",
      "Epoch 48 | Train Loss: 0.7265 | Val Loss: 0.7625\n",
      "Epoch 49 | Train Loss: 0.6923 | Val Loss: 0.7974\n",
      "Epoch 50 | Train Loss: 0.7270 | Val Loss: 0.7753\n",
      "Fold 10 ‚ñ∂ AUC: 0.703, Balanced Acc: 0.469\n",
      "üîç Summary for hd=256, dp=0.0, lr=0.001 ‚Üí AUC: 0.7412¬±0.0278 | BalAcc: 0.4837¬±0.0281\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.0, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9303 | Val Loss: 0.8619\n",
      "Epoch 02 | Train Loss: 0.8609 | Val Loss: 0.8394\n",
      "Epoch 03 | Train Loss: 0.8590 | Val Loss: 0.8357\n",
      "Epoch 04 | Train Loss: 0.8594 | Val Loss: 0.8279\n",
      "Epoch 05 | Train Loss: 0.8446 | Val Loss: 0.8077\n",
      "Epoch 06 | Train Loss: 0.8419 | Val Loss: 0.8459\n",
      "Epoch 07 | Train Loss: 0.8275 | Val Loss: 0.7912\n",
      "Epoch 08 | Train Loss: 0.7800 | Val Loss: 0.7641\n",
      "Epoch 09 | Train Loss: 0.7779 | Val Loss: 0.7453\n",
      "Epoch 10 | Train Loss: 0.7985 | Val Loss: 0.7787\n",
      "Epoch 11 | Train Loss: 0.7586 | Val Loss: 0.7362\n",
      "Epoch 12 | Train Loss: 0.7588 | Val Loss: 0.7254\n",
      "Epoch 13 | Train Loss: 0.7461 | Val Loss: 0.7185\n",
      "Epoch 14 | Train Loss: 0.7507 | Val Loss: 0.7105\n",
      "Epoch 15 | Train Loss: 0.7495 | Val Loss: 0.7099\n",
      "Epoch 16 | Train Loss: 0.7395 | Val Loss: 0.7093\n",
      "Epoch 17 | Train Loss: 0.7387 | Val Loss: 0.6999\n",
      "Epoch 18 | Train Loss: 0.7427 | Val Loss: 0.7013\n",
      "Epoch 19 | Train Loss: 0.7334 | Val Loss: 0.6922\n",
      "Epoch 20 | Train Loss: 0.7227 | Val Loss: 0.6889\n",
      "Epoch 21 | Train Loss: 0.7318 | Val Loss: 0.6974\n",
      "Epoch 22 | Train Loss: 0.7132 | Val Loss: 0.7387\n",
      "Epoch 23 | Train Loss: 0.7347 | Val Loss: 0.6881\n",
      "Epoch 24 | Train Loss: 0.7078 | Val Loss: 0.6910\n",
      "Epoch 25 | Train Loss: 0.7265 | Val Loss: 0.7114\n",
      "Epoch 26 | Train Loss: 0.7160 | Val Loss: 0.6922\n",
      "Epoch 27 | Train Loss: 0.7240 | Val Loss: 0.6857\n",
      "Epoch 28 | Train Loss: 0.7164 | Val Loss: 0.6812\n",
      "Epoch 29 | Train Loss: 0.7143 | Val Loss: 0.6830\n",
      "Epoch 30 | Train Loss: 0.7342 | Val Loss: 0.6885\n",
      "Epoch 31 | Train Loss: 0.7244 | Val Loss: 0.6743\n",
      "Epoch 32 | Train Loss: 0.7194 | Val Loss: 0.6750\n",
      "Epoch 33 | Train Loss: 0.7265 | Val Loss: 0.6945\n",
      "Epoch 34 | Train Loss: 0.7322 | Val Loss: 0.6798\n",
      "Epoch 35 | Train Loss: 0.7128 | Val Loss: 0.7171\n",
      "Epoch 36 | Train Loss: 0.7161 | Val Loss: 0.6996\n",
      "Epoch 37 | Train Loss: 0.6997 | Val Loss: 0.6733\n",
      "Epoch 38 | Train Loss: 0.7090 | Val Loss: 0.6799\n",
      "Epoch 39 | Train Loss: 0.7099 | Val Loss: 0.6788\n",
      "Epoch 40 | Train Loss: 0.6975 | Val Loss: 0.6950\n",
      "Epoch 41 | Train Loss: 0.7329 | Val Loss: 0.6676\n",
      "Epoch 42 | Train Loss: 0.7267 | Val Loss: 0.6940\n",
      "Epoch 43 | Train Loss: 0.7214 | Val Loss: 0.6723\n",
      "Epoch 44 | Train Loss: 0.7020 | Val Loss: 0.6783\n",
      "Epoch 45 | Train Loss: 0.6776 | Val Loss: 0.6838\n",
      "Epoch 46 | Train Loss: 0.6879 | Val Loss: 0.6917\n",
      "Epoch 47 | Train Loss: 0.7458 | Val Loss: 0.6885\n",
      "Epoch 48 | Train Loss: 0.7324 | Val Loss: 0.6642\n",
      "Epoch 49 | Train Loss: 0.7448 | Val Loss: 0.7014\n",
      "Epoch 50 | Train Loss: 0.7172 | Val Loss: 0.6765\n",
      "Fold 1 ‚ñ∂ AUC: 0.801, Balanced Acc: 0.518\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9398 | Val Loss: 0.9063\n",
      "Epoch 02 | Train Loss: 0.8895 | Val Loss: 0.8522\n",
      "Epoch 03 | Train Loss: 0.8564 | Val Loss: 0.8350\n",
      "Epoch 04 | Train Loss: 0.8407 | Val Loss: 0.8160\n",
      "Epoch 05 | Train Loss: 0.8100 | Val Loss: 0.8170\n",
      "Epoch 06 | Train Loss: 0.8138 | Val Loss: 0.7757\n",
      "Epoch 07 | Train Loss: 0.7883 | Val Loss: 0.7600\n",
      "Epoch 08 | Train Loss: 0.7802 | Val Loss: 0.7504\n",
      "Epoch 09 | Train Loss: 0.7605 | Val Loss: 0.7845\n",
      "Epoch 10 | Train Loss: 0.7713 | Val Loss: 0.7304\n",
      "Epoch 11 | Train Loss: 0.7788 | Val Loss: 0.7233\n",
      "Epoch 12 | Train Loss: 0.7638 | Val Loss: 0.7245\n",
      "Epoch 13 | Train Loss: 0.7663 | Val Loss: 0.7715\n",
      "Epoch 14 | Train Loss: 0.7413 | Val Loss: 0.7114\n",
      "Epoch 15 | Train Loss: 0.7470 | Val Loss: 0.7153\n",
      "Epoch 16 | Train Loss: 0.7333 | Val Loss: 0.7229\n",
      "Epoch 17 | Train Loss: 0.7490 | Val Loss: 0.7386\n",
      "Epoch 18 | Train Loss: 0.7370 | Val Loss: 0.6998\n",
      "Epoch 19 | Train Loss: 0.7474 | Val Loss: 0.6999\n",
      "Epoch 20 | Train Loss: 0.7499 | Val Loss: 0.7185\n",
      "Epoch 21 | Train Loss: 0.7472 | Val Loss: 0.7045\n",
      "Epoch 22 | Train Loss: 0.7267 | Val Loss: 0.7011\n",
      "Epoch 23 | Train Loss: 0.7408 | Val Loss: 0.7066\n",
      "Epoch 24 | Train Loss: 0.7402 | Val Loss: 0.7073\n",
      "Epoch 25 | Train Loss: 0.7419 | Val Loss: 0.6955\n",
      "Epoch 26 | Train Loss: 0.7359 | Val Loss: 0.7045\n",
      "Epoch 27 | Train Loss: 0.7398 | Val Loss: 0.6910\n",
      "Epoch 28 | Train Loss: 0.7512 | Val Loss: 0.7943\n",
      "Epoch 29 | Train Loss: 0.7441 | Val Loss: 0.7617\n",
      "Epoch 30 | Train Loss: 0.7174 | Val Loss: 0.7229\n",
      "Epoch 31 | Train Loss: 0.7356 | Val Loss: 0.7541\n",
      "Epoch 32 | Train Loss: 0.7252 | Val Loss: 0.7168\n",
      "Epoch 33 | Train Loss: 0.7125 | Val Loss: 0.7575\n",
      "Epoch 34 | Train Loss: 0.7284 | Val Loss: 0.7268\n",
      "Epoch 35 | Train Loss: 0.7197 | Val Loss: 0.7522\n",
      "Epoch 36 | Train Loss: 0.7327 | Val Loss: 0.7893\n",
      "Epoch 37 | Train Loss: 0.7279 | Val Loss: 0.7861\n",
      "Epoch 38 | Train Loss: 0.7103 | Val Loss: 0.7533\n",
      "Epoch 39 | Train Loss: 0.7153 | Val Loss: 0.7174\n",
      "Epoch 40 | Train Loss: 0.7335 | Val Loss: 0.7374\n",
      "Epoch 41 | Train Loss: 0.7296 | Val Loss: 0.8515\n",
      "Epoch 42 | Train Loss: 0.7454 | Val Loss: 0.7134\n",
      "Epoch 43 | Train Loss: 0.7221 | Val Loss: 0.7250\n",
      "Epoch 44 | Train Loss: 0.7199 | Val Loss: 0.7106\n",
      "Epoch 45 | Train Loss: 0.7132 | Val Loss: 0.7755\n",
      "Epoch 46 | Train Loss: 0.7380 | Val Loss: 0.8370\n",
      "Epoch 47 | Train Loss: 0.7189 | Val Loss: 0.7565\n",
      "Epoch 48 | Train Loss: 0.7017 | Val Loss: 0.7054\n",
      "Epoch 49 | Train Loss: 0.7069 | Val Loss: 0.6987\n",
      "Epoch 50 | Train Loss: 0.6987 | Val Loss: 0.7143\n",
      "Fold 2 ‚ñ∂ AUC: 0.699, Balanced Acc: 0.528\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9356 | Val Loss: 0.8710\n",
      "Epoch 02 | Train Loss: 0.8686 | Val Loss: 0.8499\n",
      "Epoch 03 | Train Loss: 0.8510 | Val Loss: 0.8593\n",
      "Epoch 04 | Train Loss: 0.8409 | Val Loss: 0.7997\n",
      "Epoch 05 | Train Loss: 0.8160 | Val Loss: 0.7826\n",
      "Epoch 06 | Train Loss: 0.7867 | Val Loss: 0.7658\n",
      "Epoch 07 | Train Loss: 0.7827 | Val Loss: 0.7740\n",
      "Epoch 08 | Train Loss: 0.7779 | Val Loss: 0.7438\n",
      "Epoch 09 | Train Loss: 0.7841 | Val Loss: 0.8220\n",
      "Epoch 10 | Train Loss: 0.7850 | Val Loss: 0.7760\n",
      "Epoch 11 | Train Loss: 0.7458 | Val Loss: 0.7644\n",
      "Epoch 12 | Train Loss: 0.7436 | Val Loss: 0.7454\n",
      "Epoch 13 | Train Loss: 0.7639 | Val Loss: 0.7917\n",
      "Epoch 14 | Train Loss: 0.7609 | Val Loss: 0.7500\n",
      "Epoch 15 | Train Loss: 0.7212 | Val Loss: 0.7423\n",
      "Epoch 16 | Train Loss: 0.7279 | Val Loss: 0.7279\n",
      "Epoch 17 | Train Loss: 0.7293 | Val Loss: 0.7297\n",
      "Epoch 18 | Train Loss: 0.7270 | Val Loss: 0.7174\n",
      "Epoch 19 | Train Loss: 0.7157 | Val Loss: 0.7213\n",
      "Epoch 20 | Train Loss: 0.7176 | Val Loss: 0.7226\n",
      "Epoch 21 | Train Loss: 0.7318 | Val Loss: 0.7223\n",
      "Epoch 22 | Train Loss: 0.7054 | Val Loss: 0.7458\n",
      "Epoch 23 | Train Loss: 0.7418 | Val Loss: 0.7226\n",
      "Epoch 24 | Train Loss: 0.7201 | Val Loss: 0.7207\n",
      "Epoch 25 | Train Loss: 0.7081 | Val Loss: 0.7226\n",
      "Epoch 26 | Train Loss: 0.7073 | Val Loss: 0.7263\n",
      "Epoch 27 | Train Loss: 0.7142 | Val Loss: 0.7222\n",
      "Epoch 28 | Train Loss: 0.6964 | Val Loss: 0.7465\n",
      "Epoch 29 | Train Loss: 0.7697 | Val Loss: 0.7614\n",
      "Epoch 30 | Train Loss: 0.7469 | Val Loss: 0.7897\n",
      "Epoch 31 | Train Loss: 0.7234 | Val Loss: 0.7229\n",
      "Epoch 32 | Train Loss: 0.7075 | Val Loss: 0.7244\n",
      "Epoch 33 | Train Loss: 0.7070 | Val Loss: 0.7264\n",
      "Epoch 34 | Train Loss: 0.7289 | Val Loss: 0.7305\n",
      "Epoch 35 | Train Loss: 0.7407 | Val Loss: 0.7198\n",
      "Epoch 36 | Train Loss: 0.6979 | Val Loss: 0.7345\n",
      "Epoch 37 | Train Loss: 0.7127 | Val Loss: 0.7284\n",
      "Epoch 38 | Train Loss: 0.6994 | Val Loss: 0.7174\n",
      "Epoch 39 | Train Loss: 0.7168 | Val Loss: 0.7279\n",
      "Epoch 40 | Train Loss: 0.7246 | Val Loss: 0.7726\n",
      "Epoch 41 | Train Loss: 0.7482 | Val Loss: 0.7475\n",
      "Epoch 42 | Train Loss: 0.6962 | Val Loss: 0.7203\n",
      "Epoch 43 | Train Loss: 0.7091 | Val Loss: 0.7299\n",
      "Epoch 44 | Train Loss: 0.7071 | Val Loss: 0.7364\n",
      "Epoch 45 | Train Loss: 0.6974 | Val Loss: 0.7524\n",
      "Epoch 46 | Train Loss: 0.7035 | Val Loss: 0.7151\n",
      "Epoch 47 | Train Loss: 0.6884 | Val Loss: 0.7092\n",
      "Epoch 48 | Train Loss: 0.6787 | Val Loss: 0.7187\n",
      "Epoch 49 | Train Loss: 0.6953 | Val Loss: 0.7347\n",
      "Epoch 50 | Train Loss: 0.7053 | Val Loss: 0.7549\n",
      "Fold 3 ‚ñ∂ AUC: 0.781, Balanced Acc: 0.507\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9056 | Val Loss: 0.8833\n",
      "Epoch 02 | Train Loss: 0.8830 | Val Loss: 0.8414\n",
      "Epoch 03 | Train Loss: 0.8588 | Val Loss: 0.8790\n",
      "Epoch 04 | Train Loss: 0.8531 | Val Loss: 0.8150\n",
      "Epoch 05 | Train Loss: 0.8192 | Val Loss: 0.7807\n",
      "Epoch 06 | Train Loss: 0.7980 | Val Loss: 0.7633\n",
      "Epoch 07 | Train Loss: 0.7897 | Val Loss: 0.7569\n",
      "Epoch 08 | Train Loss: 0.8029 | Val Loss: 0.7250\n",
      "Epoch 09 | Train Loss: 0.8069 | Val Loss: 0.7328\n",
      "Epoch 10 | Train Loss: 0.7790 | Val Loss: 0.7214\n",
      "Epoch 11 | Train Loss: 0.7699 | Val Loss: 0.7007\n",
      "Epoch 12 | Train Loss: 0.7564 | Val Loss: 0.7030\n",
      "Epoch 13 | Train Loss: 0.7480 | Val Loss: 0.7074\n",
      "Epoch 14 | Train Loss: 0.7712 | Val Loss: 0.6900\n",
      "Epoch 15 | Train Loss: 0.7727 | Val Loss: 0.6820\n",
      "Epoch 16 | Train Loss: 0.7387 | Val Loss: 0.6844\n",
      "Epoch 17 | Train Loss: 0.7391 | Val Loss: 0.6845\n",
      "Epoch 18 | Train Loss: 0.7359 | Val Loss: 0.6737\n",
      "Epoch 19 | Train Loss: 0.7357 | Val Loss: 0.7011\n",
      "Epoch 20 | Train Loss: 0.7421 | Val Loss: 0.6972\n",
      "Epoch 21 | Train Loss: 0.7789 | Val Loss: 0.6705\n",
      "Epoch 22 | Train Loss: 0.7434 | Val Loss: 0.7023\n",
      "Epoch 23 | Train Loss: 0.7562 | Val Loss: 0.6793\n",
      "Epoch 24 | Train Loss: 0.7277 | Val Loss: 0.7172\n",
      "Epoch 25 | Train Loss: 0.7428 | Val Loss: 0.7034\n",
      "Epoch 26 | Train Loss: 0.7239 | Val Loss: 0.7203\n",
      "Epoch 27 | Train Loss: 0.7331 | Val Loss: 0.7133\n",
      "Epoch 28 | Train Loss: 0.7360 | Val Loss: 0.6672\n",
      "Epoch 29 | Train Loss: 0.7246 | Val Loss: 0.6838\n",
      "Epoch 30 | Train Loss: 0.7193 | Val Loss: 0.7173\n",
      "Epoch 31 | Train Loss: 0.7300 | Val Loss: 0.7362\n",
      "Epoch 32 | Train Loss: 0.7430 | Val Loss: 0.7245\n",
      "Epoch 33 | Train Loss: 0.7098 | Val Loss: 0.6669\n",
      "Epoch 34 | Train Loss: 0.7275 | Val Loss: 0.7485\n",
      "Epoch 35 | Train Loss: 0.7198 | Val Loss: 0.7034\n",
      "Epoch 36 | Train Loss: 0.7163 | Val Loss: 0.6747\n",
      "Epoch 37 | Train Loss: 0.7298 | Val Loss: 0.7082\n",
      "Epoch 38 | Train Loss: 0.7113 | Val Loss: 0.6774\n",
      "Epoch 39 | Train Loss: 0.7230 | Val Loss: 0.6784\n",
      "Epoch 40 | Train Loss: 0.7088 | Val Loss: 0.6918\n",
      "Epoch 41 | Train Loss: 0.7266 | Val Loss: 0.7057\n",
      "Epoch 42 | Train Loss: 0.7228 | Val Loss: 0.7091\n",
      "Epoch 43 | Train Loss: 0.7198 | Val Loss: 0.7295\n",
      "Epoch 44 | Train Loss: 0.7103 | Val Loss: 0.6891\n",
      "Epoch 45 | Train Loss: 0.7270 | Val Loss: 0.7067\n",
      "Epoch 46 | Train Loss: 0.7218 | Val Loss: 0.6534\n",
      "Epoch 47 | Train Loss: 0.7156 | Val Loss: 0.6886\n",
      "Epoch 48 | Train Loss: 0.6991 | Val Loss: 0.6785\n",
      "Epoch 49 | Train Loss: 0.6926 | Val Loss: 0.7016\n",
      "Epoch 50 | Train Loss: 0.7009 | Val Loss: 0.7243\n",
      "Fold 4 ‚ñ∂ AUC: 0.723, Balanced Acc: 0.507\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9144 | Val Loss: 0.8897\n",
      "Epoch 02 | Train Loss: 0.8697 | Val Loss: 0.8921\n",
      "Epoch 03 | Train Loss: 0.8645 | Val Loss: 0.8719\n",
      "Epoch 04 | Train Loss: 0.8279 | Val Loss: 0.9330\n",
      "Epoch 05 | Train Loss: 0.8503 | Val Loss: 0.8751\n",
      "Epoch 06 | Train Loss: 0.8086 | Val Loss: 0.8422\n",
      "Epoch 07 | Train Loss: 0.8119 | Val Loss: 0.8337\n",
      "Epoch 08 | Train Loss: 0.7989 | Val Loss: 0.8629\n",
      "Epoch 09 | Train Loss: 0.8111 | Val Loss: 0.8676\n",
      "Epoch 10 | Train Loss: 0.7471 | Val Loss: 0.8445\n",
      "Epoch 11 | Train Loss: 0.7684 | Val Loss: 0.8468\n",
      "Epoch 12 | Train Loss: 0.7494 | Val Loss: 0.8833\n",
      "Epoch 13 | Train Loss: 0.7807 | Val Loss: 0.8354\n",
      "Epoch 14 | Train Loss: 0.7389 | Val Loss: 0.8325\n",
      "Epoch 15 | Train Loss: 0.7355 | Val Loss: 0.8177\n",
      "Epoch 16 | Train Loss: 0.7254 | Val Loss: 0.8230\n",
      "Epoch 17 | Train Loss: 0.7477 | Val Loss: 0.8076\n",
      "Epoch 18 | Train Loss: 0.7236 | Val Loss: 0.8085\n",
      "Epoch 19 | Train Loss: 0.7365 | Val Loss: 0.8577\n",
      "Epoch 20 | Train Loss: 0.7406 | Val Loss: 0.8160\n",
      "Epoch 21 | Train Loss: 0.7361 | Val Loss: 0.8090\n",
      "Epoch 22 | Train Loss: 0.7140 | Val Loss: 0.7949\n",
      "Epoch 23 | Train Loss: 0.7168 | Val Loss: 0.7964\n",
      "Epoch 24 | Train Loss: 0.7241 | Val Loss: 0.8021\n",
      "Epoch 25 | Train Loss: 0.7216 | Val Loss: 0.8142\n",
      "Epoch 26 | Train Loss: 0.7407 | Val Loss: 0.8074\n",
      "Epoch 27 | Train Loss: 0.7336 | Val Loss: 0.8196\n",
      "Epoch 28 | Train Loss: 0.7223 | Val Loss: 0.8117\n",
      "Epoch 29 | Train Loss: 0.7110 | Val Loss: 0.8197\n",
      "Epoch 30 | Train Loss: 0.7199 | Val Loss: 0.7987\n",
      "Epoch 31 | Train Loss: 0.7067 | Val Loss: 0.8025\n",
      "Epoch 32 | Train Loss: 0.7283 | Val Loss: 0.7998\n",
      "Epoch 33 | Train Loss: 0.7458 | Val Loss: 0.7831\n",
      "Epoch 34 | Train Loss: 0.7411 | Val Loss: 0.7888\n",
      "Epoch 35 | Train Loss: 0.7105 | Val Loss: 0.7852\n",
      "Epoch 36 | Train Loss: 0.7036 | Val Loss: 0.7822\n",
      "Epoch 37 | Train Loss: 0.7043 | Val Loss: 0.8037\n",
      "Epoch 38 | Train Loss: 0.7327 | Val Loss: 0.8080\n",
      "Epoch 39 | Train Loss: 0.7182 | Val Loss: 0.7902\n",
      "Epoch 40 | Train Loss: 0.6963 | Val Loss: 0.7943\n",
      "Epoch 41 | Train Loss: 0.7001 | Val Loss: 0.7887\n",
      "Epoch 42 | Train Loss: 0.6915 | Val Loss: 0.8103\n",
      "Epoch 43 | Train Loss: 0.7087 | Val Loss: 0.7880\n",
      "Epoch 44 | Train Loss: 0.6987 | Val Loss: 0.7865\n",
      "Epoch 45 | Train Loss: 0.6961 | Val Loss: 0.8193\n",
      "Epoch 46 | Train Loss: 0.7174 | Val Loss: 0.7811\n",
      "Epoch 47 | Train Loss: 0.6849 | Val Loss: 0.7911\n",
      "Epoch 48 | Train Loss: 0.6906 | Val Loss: 0.7834\n",
      "Epoch 49 | Train Loss: 0.7076 | Val Loss: 0.7797\n",
      "Epoch 50 | Train Loss: 0.6783 | Val Loss: 0.7760\n",
      "Fold 5 ‚ñ∂ AUC: 0.741, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9445 | Val Loss: 0.9175\n",
      "Epoch 02 | Train Loss: 0.8802 | Val Loss: 0.9526\n",
      "Epoch 03 | Train Loss: 0.8974 | Val Loss: 0.8983\n",
      "Epoch 04 | Train Loss: 0.8586 | Val Loss: 0.8914\n",
      "Epoch 05 | Train Loss: 0.8318 | Val Loss: 0.8968\n",
      "Epoch 06 | Train Loss: 0.8386 | Val Loss: 0.9074\n",
      "Epoch 07 | Train Loss: 0.8159 | Val Loss: 0.8668\n",
      "Epoch 08 | Train Loss: 0.7897 | Val Loss: 0.8641\n",
      "Epoch 09 | Train Loss: 0.7879 | Val Loss: 0.8357\n",
      "Epoch 10 | Train Loss: 0.7669 | Val Loss: 0.8618\n",
      "Epoch 11 | Train Loss: 0.7516 | Val Loss: 0.8328\n",
      "Epoch 12 | Train Loss: 0.7648 | Val Loss: 0.8658\n",
      "Epoch 13 | Train Loss: 0.7768 | Val Loss: 0.8448\n",
      "Epoch 14 | Train Loss: 0.7444 | Val Loss: 0.8211\n",
      "Epoch 15 | Train Loss: 0.7437 | Val Loss: 0.8281\n",
      "Epoch 16 | Train Loss: 0.7410 | Val Loss: 0.8276\n",
      "Epoch 17 | Train Loss: 0.7341 | Val Loss: 0.8199\n",
      "Epoch 18 | Train Loss: 0.7386 | Val Loss: 0.8341\n",
      "Epoch 19 | Train Loss: 0.7154 | Val Loss: 0.8491\n",
      "Epoch 20 | Train Loss: 0.7388 | Val Loss: 0.8224\n",
      "Epoch 21 | Train Loss: 0.7140 | Val Loss: 0.8261\n",
      "Epoch 22 | Train Loss: 0.7244 | Val Loss: 0.8306\n",
      "Epoch 23 | Train Loss: 0.7137 | Val Loss: 0.8215\n",
      "Epoch 24 | Train Loss: 0.7232 | Val Loss: 0.8394\n",
      "Epoch 25 | Train Loss: 0.7335 | Val Loss: 0.8262\n",
      "Epoch 26 | Train Loss: 0.7109 | Val Loss: 0.8372\n",
      "Epoch 27 | Train Loss: 0.7541 | Val Loss: 0.8206\n",
      "Epoch 28 | Train Loss: 0.7346 | Val Loss: 0.8118\n",
      "Epoch 29 | Train Loss: 0.7142 | Val Loss: 0.8536\n",
      "Epoch 30 | Train Loss: 0.7434 | Val Loss: 0.8430\n",
      "Epoch 31 | Train Loss: 0.7182 | Val Loss: 0.8600\n",
      "Epoch 32 | Train Loss: 0.7235 | Val Loss: 0.8488\n",
      "Epoch 33 | Train Loss: 0.7256 | Val Loss: 0.8294\n",
      "Epoch 34 | Train Loss: 0.7045 | Val Loss: 0.8258\n",
      "Epoch 35 | Train Loss: 0.7088 | Val Loss: 0.8278\n",
      "Epoch 36 | Train Loss: 0.7157 | Val Loss: 0.8228\n",
      "Epoch 37 | Train Loss: 0.7163 | Val Loss: 0.8249\n",
      "Epoch 38 | Train Loss: 0.7281 | Val Loss: 0.8254\n",
      "Epoch 39 | Train Loss: 0.7248 | Val Loss: 0.8199\n",
      "Epoch 40 | Train Loss: 0.7682 | Val Loss: 0.8076\n",
      "Epoch 41 | Train Loss: 0.7230 | Val Loss: 0.8136\n",
      "Epoch 42 | Train Loss: 0.6969 | Val Loss: 0.8141\n",
      "Epoch 43 | Train Loss: 0.7182 | Val Loss: 0.8221\n",
      "Epoch 44 | Train Loss: 0.6845 | Val Loss: 0.8100\n",
      "Epoch 45 | Train Loss: 0.7020 | Val Loss: 0.8296\n",
      "Epoch 46 | Train Loss: 0.6970 | Val Loss: 0.8074\n",
      "Epoch 47 | Train Loss: 0.6817 | Val Loss: 0.8346\n",
      "Epoch 48 | Train Loss: 0.7030 | Val Loss: 0.8089\n",
      "Epoch 49 | Train Loss: 0.6866 | Val Loss: 0.8293\n",
      "Epoch 50 | Train Loss: 0.7066 | Val Loss: 0.8154\n",
      "Fold 6 ‚ñ∂ AUC: 0.729, Balanced Acc: 0.440\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9276 | Val Loss: 0.8823\n",
      "Epoch 02 | Train Loss: 0.8674 | Val Loss: 0.8523\n",
      "Epoch 03 | Train Loss: 0.8664 | Val Loss: 0.8120\n",
      "Epoch 04 | Train Loss: 0.8033 | Val Loss: 1.0098\n",
      "Epoch 05 | Train Loss: 0.8736 | Val Loss: 0.7975\n",
      "Epoch 06 | Train Loss: 0.8160 | Val Loss: 0.7651\n",
      "Epoch 07 | Train Loss: 0.8131 | Val Loss: 0.7380\n",
      "Epoch 08 | Train Loss: 0.7867 | Val Loss: 0.7199\n",
      "Epoch 09 | Train Loss: 0.8062 | Val Loss: 0.7728\n",
      "Epoch 10 | Train Loss: 0.7871 | Val Loss: 0.7274\n",
      "Epoch 11 | Train Loss: 0.7673 | Val Loss: 0.7281\n",
      "Epoch 12 | Train Loss: 0.7805 | Val Loss: 0.7462\n",
      "Epoch 13 | Train Loss: 0.7611 | Val Loss: 0.7259\n",
      "Epoch 14 | Train Loss: 0.7292 | Val Loss: 0.7186\n",
      "Epoch 15 | Train Loss: 0.7398 | Val Loss: 0.7332\n",
      "Epoch 16 | Train Loss: 0.7232 | Val Loss: 0.7377\n",
      "Epoch 17 | Train Loss: 0.7337 | Val Loss: 0.7432\n",
      "Epoch 18 | Train Loss: 0.7397 | Val Loss: 0.7237\n",
      "Epoch 19 | Train Loss: 0.7311 | Val Loss: 0.7326\n",
      "Epoch 20 | Train Loss: 0.7421 | Val Loss: 0.7306\n",
      "Epoch 21 | Train Loss: 0.7303 | Val Loss: 0.7726\n",
      "Epoch 22 | Train Loss: 0.7424 | Val Loss: 0.7328\n",
      "Epoch 23 | Train Loss: 0.7274 | Val Loss: 0.7344\n",
      "Epoch 24 | Train Loss: 0.7402 | Val Loss: 0.7388\n",
      "Epoch 25 | Train Loss: 0.7291 | Val Loss: 0.7439\n",
      "Epoch 26 | Train Loss: 0.7500 | Val Loss: 0.7317\n",
      "Epoch 27 | Train Loss: 0.7124 | Val Loss: 0.7242\n",
      "Epoch 28 | Train Loss: 0.7122 | Val Loss: 0.7236\n",
      "Epoch 29 | Train Loss: 0.7188 | Val Loss: 0.7332\n",
      "Epoch 30 | Train Loss: 0.7150 | Val Loss: 0.7227\n",
      "Epoch 31 | Train Loss: 0.7291 | Val Loss: 0.7564\n",
      "Epoch 32 | Train Loss: 0.7057 | Val Loss: 0.7189\n",
      "Epoch 33 | Train Loss: 0.7156 | Val Loss: 0.7228\n",
      "Epoch 34 | Train Loss: 0.7029 | Val Loss: 0.7402\n",
      "Epoch 35 | Train Loss: 0.7134 | Val Loss: 0.7335\n",
      "Epoch 36 | Train Loss: 0.7556 | Val Loss: 0.7282\n",
      "Epoch 37 | Train Loss: 0.7310 | Val Loss: 0.7243\n",
      "Epoch 38 | Train Loss: 0.7234 | Val Loss: 0.7322\n",
      "Epoch 39 | Train Loss: 0.7227 | Val Loss: 0.7456\n",
      "Epoch 40 | Train Loss: 0.7332 | Val Loss: 0.7338\n",
      "Epoch 41 | Train Loss: 0.7293 | Val Loss: 0.7351\n",
      "Epoch 42 | Train Loss: 0.7120 | Val Loss: 0.7334\n",
      "Epoch 43 | Train Loss: 0.7175 | Val Loss: 0.7300\n",
      "Epoch 44 | Train Loss: 0.7213 | Val Loss: 0.7511\n",
      "Epoch 45 | Train Loss: 0.7041 | Val Loss: 0.7375\n",
      "Epoch 46 | Train Loss: 0.7306 | Val Loss: 0.7258\n",
      "Epoch 47 | Train Loss: 0.7081 | Val Loss: 0.7376\n",
      "Epoch 48 | Train Loss: 0.7131 | Val Loss: 0.7505\n",
      "Epoch 49 | Train Loss: 0.7055 | Val Loss: 0.7888\n",
      "Epoch 50 | Train Loss: 0.6851 | Val Loss: 0.7464\n",
      "Fold 7 ‚ñ∂ AUC: 0.737, Balanced Acc: 0.510\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9067 | Val Loss: 0.8821\n",
      "Epoch 02 | Train Loss: 0.8642 | Val Loss: 0.8509\n",
      "Epoch 03 | Train Loss: 0.8541 | Val Loss: 0.8479\n",
      "Epoch 04 | Train Loss: 0.8453 | Val Loss: 0.8531\n",
      "Epoch 05 | Train Loss: 0.8503 | Val Loss: 0.8320\n",
      "Epoch 06 | Train Loss: 0.8124 | Val Loss: 0.8148\n",
      "Epoch 07 | Train Loss: 0.8093 | Val Loss: 0.8637\n",
      "Epoch 08 | Train Loss: 0.7981 | Val Loss: 0.7976\n",
      "Epoch 09 | Train Loss: 0.7708 | Val Loss: 0.7970\n",
      "Epoch 10 | Train Loss: 0.7743 | Val Loss: 0.8113\n",
      "Epoch 11 | Train Loss: 0.7621 | Val Loss: 0.8046\n",
      "Epoch 12 | Train Loss: 0.7462 | Val Loss: 0.8021\n",
      "Epoch 13 | Train Loss: 0.7726 | Val Loss: 0.8036\n",
      "Epoch 14 | Train Loss: 0.7326 | Val Loss: 0.8016\n",
      "Epoch 15 | Train Loss: 0.7182 | Val Loss: 0.8338\n",
      "Epoch 16 | Train Loss: 0.7686 | Val Loss: 0.8375\n",
      "Epoch 17 | Train Loss: 0.7269 | Val Loss: 0.8113\n",
      "Epoch 18 | Train Loss: 0.7212 | Val Loss: 0.8554\n",
      "Epoch 19 | Train Loss: 0.7530 | Val Loss: 0.8101\n",
      "Epoch 20 | Train Loss: 0.7115 | Val Loss: 0.8091\n",
      "Epoch 21 | Train Loss: 0.7274 | Val Loss: 0.8144\n",
      "Epoch 22 | Train Loss: 0.7308 | Val Loss: 0.8159\n",
      "Epoch 23 | Train Loss: 0.7281 | Val Loss: 0.8035\n",
      "Epoch 24 | Train Loss: 0.7106 | Val Loss: 0.8221\n",
      "Epoch 25 | Train Loss: 0.7171 | Val Loss: 0.8180\n",
      "Epoch 26 | Train Loss: 0.7114 | Val Loss: 0.8000\n",
      "Epoch 27 | Train Loss: 0.7151 | Val Loss: 0.8267\n",
      "Epoch 28 | Train Loss: 0.6943 | Val Loss: 0.8269\n",
      "Epoch 29 | Train Loss: 0.7121 | Val Loss: 0.8140\n",
      "Epoch 30 | Train Loss: 0.6906 | Val Loss: 0.8164\n",
      "Epoch 31 | Train Loss: 0.7200 | Val Loss: 0.8067\n",
      "Epoch 32 | Train Loss: 0.7035 | Val Loss: 0.8210\n",
      "Epoch 33 | Train Loss: 0.7034 | Val Loss: 0.8251\n",
      "Epoch 34 | Train Loss: 0.7093 | Val Loss: 0.8092\n",
      "Epoch 35 | Train Loss: 0.7082 | Val Loss: 0.8069\n",
      "Epoch 36 | Train Loss: 0.6818 | Val Loss: 0.8190\n",
      "Epoch 37 | Train Loss: 0.7033 | Val Loss: 0.8079\n",
      "Epoch 38 | Train Loss: 0.6983 | Val Loss: 0.8342\n",
      "Epoch 39 | Train Loss: 0.7129 | Val Loss: 0.8268\n",
      "Epoch 40 | Train Loss: 0.7000 | Val Loss: 0.8244\n",
      "Epoch 41 | Train Loss: 0.6842 | Val Loss: 0.8009\n",
      "Epoch 42 | Train Loss: 0.6926 | Val Loss: 0.8173\n",
      "Epoch 43 | Train Loss: 0.7002 | Val Loss: 0.8136\n",
      "Epoch 44 | Train Loss: 0.7223 | Val Loss: 0.8403\n",
      "Epoch 45 | Train Loss: 0.7571 | Val Loss: 0.8361\n",
      "Epoch 46 | Train Loss: 0.7028 | Val Loss: 0.8216\n",
      "Epoch 47 | Train Loss: 0.6932 | Val Loss: 0.7984\n",
      "Epoch 48 | Train Loss: 0.6833 | Val Loss: 0.8058\n",
      "Epoch 49 | Train Loss: 0.6762 | Val Loss: 0.8102\n",
      "Epoch 50 | Train Loss: 0.6768 | Val Loss: 0.8095\n",
      "Fold 8 ‚ñ∂ AUC: 0.721, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9162 | Val Loss: 0.8838\n",
      "Epoch 02 | Train Loss: 0.8788 | Val Loss: 0.8879\n",
      "Epoch 03 | Train Loss: 0.8639 | Val Loss: 0.8573\n",
      "Epoch 04 | Train Loss: 0.8544 | Val Loss: 0.8517\n",
      "Epoch 05 | Train Loss: 0.8195 | Val Loss: 0.8809\n",
      "Epoch 06 | Train Loss: 0.8248 | Val Loss: 0.8426\n",
      "Epoch 07 | Train Loss: 0.8283 | Val Loss: 0.8167\n",
      "Epoch 08 | Train Loss: 0.8311 | Val Loss: 0.8103\n",
      "Epoch 09 | Train Loss: 0.7904 | Val Loss: 0.8051\n",
      "Epoch 10 | Train Loss: 0.7731 | Val Loss: 0.8171\n",
      "Epoch 11 | Train Loss: 0.7589 | Val Loss: 0.7966\n",
      "Epoch 12 | Train Loss: 0.7508 | Val Loss: 0.8037\n",
      "Epoch 13 | Train Loss: 0.7654 | Val Loss: 0.7771\n",
      "Epoch 14 | Train Loss: 0.7517 | Val Loss: 0.7728\n",
      "Epoch 15 | Train Loss: 0.7432 | Val Loss: 0.7868\n",
      "Epoch 16 | Train Loss: 0.7417 | Val Loss: 0.8753\n",
      "Epoch 17 | Train Loss: 0.7694 | Val Loss: 0.7634\n",
      "Epoch 18 | Train Loss: 0.7310 | Val Loss: 0.7655\n",
      "Epoch 19 | Train Loss: 0.7273 | Val Loss: 0.7484\n",
      "Epoch 20 | Train Loss: 0.7317 | Val Loss: 0.8003\n",
      "Epoch 21 | Train Loss: 0.7330 | Val Loss: 0.7451\n",
      "Epoch 22 | Train Loss: 0.7295 | Val Loss: 0.7381\n",
      "Epoch 23 | Train Loss: 0.7068 | Val Loss: 0.7338\n",
      "Epoch 24 | Train Loss: 0.7262 | Val Loss: 0.7591\n",
      "Epoch 25 | Train Loss: 0.7750 | Val Loss: 0.7509\n",
      "Epoch 26 | Train Loss: 0.7742 | Val Loss: 0.7588\n",
      "Epoch 27 | Train Loss: 0.7367 | Val Loss: 0.7918\n",
      "Epoch 28 | Train Loss: 0.7365 | Val Loss: 0.7539\n",
      "Epoch 29 | Train Loss: 0.7399 | Val Loss: 0.7274\n",
      "Epoch 30 | Train Loss: 0.7081 | Val Loss: 0.7385\n",
      "Epoch 31 | Train Loss: 0.7174 | Val Loss: 0.7437\n",
      "Epoch 32 | Train Loss: 0.7084 | Val Loss: 0.7191\n",
      "Epoch 33 | Train Loss: 0.6949 | Val Loss: 0.7132\n",
      "Epoch 34 | Train Loss: 0.7177 | Val Loss: 0.7308\n",
      "Epoch 35 | Train Loss: 0.7172 | Val Loss: 0.7030\n",
      "Epoch 36 | Train Loss: 0.7552 | Val Loss: 0.7108\n",
      "Epoch 37 | Train Loss: 0.7048 | Val Loss: 0.7098\n",
      "Epoch 38 | Train Loss: 0.7012 | Val Loss: 0.7258\n",
      "Epoch 39 | Train Loss: 0.6948 | Val Loss: 0.7208\n",
      "Epoch 40 | Train Loss: 0.6943 | Val Loss: 0.6912\n",
      "Epoch 41 | Train Loss: 0.6968 | Val Loss: 0.7537\n",
      "Epoch 42 | Train Loss: 0.7083 | Val Loss: 0.7466\n",
      "Epoch 43 | Train Loss: 0.6976 | Val Loss: 0.7335\n",
      "Epoch 44 | Train Loss: 0.7038 | Val Loss: 0.6896\n",
      "Epoch 45 | Train Loss: 0.7168 | Val Loss: 0.9988\n",
      "Epoch 46 | Train Loss: 0.7339 | Val Loss: 0.7028\n",
      "Epoch 47 | Train Loss: 0.7018 | Val Loss: 0.7315\n",
      "Epoch 48 | Train Loss: 0.7308 | Val Loss: 0.7184\n",
      "Epoch 49 | Train Loss: 0.6988 | Val Loss: 0.7243\n",
      "Epoch 50 | Train Loss: 0.6961 | Val Loss: 0.7868\n",
      "Fold 9 ‚ñ∂ AUC: 0.761, Balanced Acc: 0.636\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9028 | Val Loss: 0.8716\n",
      "Epoch 02 | Train Loss: 0.8701 | Val Loss: 0.8493\n",
      "Epoch 03 | Train Loss: 0.8377 | Val Loss: 0.8491\n",
      "Epoch 04 | Train Loss: 0.8615 | Val Loss: 0.8160\n",
      "Epoch 05 | Train Loss: 0.8081 | Val Loss: 0.8316\n",
      "Epoch 06 | Train Loss: 0.8154 | Val Loss: 0.7844\n",
      "Epoch 07 | Train Loss: 0.7767 | Val Loss: 0.7670\n",
      "Epoch 08 | Train Loss: 0.7751 | Val Loss: 0.7699\n",
      "Epoch 09 | Train Loss: 0.7616 | Val Loss: 0.7562\n",
      "Epoch 10 | Train Loss: 0.7553 | Val Loss: 0.8897\n",
      "Epoch 11 | Train Loss: 0.7914 | Val Loss: 0.7707\n",
      "Epoch 12 | Train Loss: 0.7617 | Val Loss: 0.7941\n",
      "Epoch 13 | Train Loss: 0.7357 | Val Loss: 0.7741\n",
      "Epoch 14 | Train Loss: 0.7291 | Val Loss: 0.7737\n",
      "Epoch 15 | Train Loss: 0.7368 | Val Loss: 0.7681\n",
      "Epoch 16 | Train Loss: 0.7248 | Val Loss: 0.7635\n",
      "Epoch 17 | Train Loss: 0.7329 | Val Loss: 0.7879\n",
      "Epoch 18 | Train Loss: 0.7325 | Val Loss: 0.8342\n",
      "Epoch 19 | Train Loss: 0.7313 | Val Loss: 0.7955\n",
      "Epoch 20 | Train Loss: 0.7163 | Val Loss: 0.7614\n",
      "Epoch 21 | Train Loss: 0.7127 | Val Loss: 0.7905\n",
      "Epoch 22 | Train Loss: 0.7248 | Val Loss: 0.7800\n",
      "Epoch 23 | Train Loss: 0.7383 | Val Loss: 0.7811\n",
      "Epoch 24 | Train Loss: 0.7262 | Val Loss: 0.7686\n",
      "Epoch 25 | Train Loss: 0.7194 | Val Loss: 0.7854\n",
      "Epoch 26 | Train Loss: 0.7496 | Val Loss: 0.7645\n",
      "Epoch 27 | Train Loss: 0.7352 | Val Loss: 0.7708\n",
      "Epoch 28 | Train Loss: 0.7258 | Val Loss: 0.7638\n",
      "Epoch 29 | Train Loss: 0.7179 | Val Loss: 0.7742\n",
      "Epoch 30 | Train Loss: 0.7125 | Val Loss: 0.7710\n",
      "Epoch 31 | Train Loss: 0.7393 | Val Loss: 0.7663\n",
      "Epoch 32 | Train Loss: 0.7153 | Val Loss: 0.7855\n",
      "Epoch 33 | Train Loss: 0.7006 | Val Loss: 0.8555\n",
      "Epoch 34 | Train Loss: 0.7158 | Val Loss: 0.8195\n",
      "Epoch 35 | Train Loss: 0.7244 | Val Loss: 0.7927\n",
      "Epoch 36 | Train Loss: 0.7236 | Val Loss: 0.7717\n",
      "Epoch 37 | Train Loss: 0.7102 | Val Loss: 0.7890\n",
      "Epoch 38 | Train Loss: 0.7013 | Val Loss: 0.8958\n",
      "Epoch 39 | Train Loss: 0.7738 | Val Loss: 0.8398\n",
      "Epoch 40 | Train Loss: 0.7300 | Val Loss: 0.7659\n",
      "Epoch 41 | Train Loss: 0.7236 | Val Loss: 0.7809\n",
      "Epoch 42 | Train Loss: 0.7218 | Val Loss: 0.7724\n",
      "Epoch 43 | Train Loss: 0.7064 | Val Loss: 0.8093\n",
      "Epoch 44 | Train Loss: 0.6984 | Val Loss: 0.7762\n",
      "Epoch 45 | Train Loss: 0.6913 | Val Loss: 0.7792\n",
      "Epoch 46 | Train Loss: 0.6955 | Val Loss: 0.7864\n",
      "Epoch 47 | Train Loss: 0.7033 | Val Loss: 0.8094\n",
      "Epoch 48 | Train Loss: 0.7221 | Val Loss: 0.7813\n",
      "Epoch 49 | Train Loss: 0.6885 | Val Loss: 0.8022\n",
      "Epoch 50 | Train Loss: 0.7341 | Val Loss: 0.8060\n",
      "Fold 10 ‚ñ∂ AUC: 0.720, Balanced Acc: 0.416\n",
      "üîç Summary for hd=256, dp=0.0, lr=0.0005 ‚Üí AUC: 0.7413¬±0.0294 | BalAcc: 0.4949¬±0.0617\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.0, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9438 | Val Loss: 0.8548\n",
      "Epoch 02 | Train Loss: 0.8819 | Val Loss: 0.8642\n",
      "Epoch 03 | Train Loss: 0.8625 | Val Loss: 0.8620\n",
      "Epoch 04 | Train Loss: 0.8549 | Val Loss: 0.8428\n",
      "Epoch 05 | Train Loss: 0.8563 | Val Loss: 0.8357\n",
      "Epoch 06 | Train Loss: 0.8458 | Val Loss: 0.8375\n",
      "Epoch 07 | Train Loss: 0.8450 | Val Loss: 0.8277\n",
      "Epoch 08 | Train Loss: 0.8460 | Val Loss: 0.8230\n",
      "Epoch 09 | Train Loss: 0.8390 | Val Loss: 0.8189\n",
      "Epoch 10 | Train Loss: 0.8217 | Val Loss: 0.8186\n",
      "Epoch 11 | Train Loss: 0.8161 | Val Loss: 0.8112\n",
      "Epoch 12 | Train Loss: 0.8214 | Val Loss: 0.8065\n",
      "Epoch 13 | Train Loss: 0.8091 | Val Loss: 0.8548\n",
      "Epoch 14 | Train Loss: 0.8157 | Val Loss: 0.7934\n",
      "Epoch 15 | Train Loss: 0.7954 | Val Loss: 0.7861\n",
      "Epoch 16 | Train Loss: 0.8071 | Val Loss: 0.7794\n",
      "Epoch 17 | Train Loss: 0.8017 | Val Loss: 0.7805\n",
      "Epoch 18 | Train Loss: 0.7894 | Val Loss: 0.7804\n",
      "Epoch 19 | Train Loss: 0.8339 | Val Loss: 0.7796\n",
      "Epoch 20 | Train Loss: 0.7917 | Val Loss: 0.7663\n",
      "Epoch 21 | Train Loss: 0.7817 | Val Loss: 0.7567\n",
      "Epoch 22 | Train Loss: 0.7722 | Val Loss: 0.7499\n",
      "Epoch 23 | Train Loss: 0.7702 | Val Loss: 0.7441\n",
      "Epoch 24 | Train Loss: 0.7588 | Val Loss: 0.7396\n",
      "Epoch 25 | Train Loss: 0.7727 | Val Loss: 0.7518\n",
      "Epoch 26 | Train Loss: 0.7705 | Val Loss: 0.7325\n",
      "Epoch 27 | Train Loss: 0.7665 | Val Loss: 0.7347\n",
      "Epoch 28 | Train Loss: 0.7666 | Val Loss: 0.7194\n",
      "Epoch 29 | Train Loss: 0.7564 | Val Loss: 0.7203\n",
      "Epoch 30 | Train Loss: 0.7456 | Val Loss: 0.7320\n",
      "Epoch 31 | Train Loss: 0.7442 | Val Loss: 0.7164\n",
      "Epoch 32 | Train Loss: 0.7406 | Val Loss: 0.7096\n",
      "Epoch 33 | Train Loss: 0.7517 | Val Loss: 0.7095\n",
      "Epoch 34 | Train Loss: 0.7507 | Val Loss: 0.7029\n",
      "Epoch 35 | Train Loss: 0.7433 | Val Loss: 0.7001\n",
      "Epoch 36 | Train Loss: 0.7312 | Val Loss: 0.7239\n",
      "Epoch 37 | Train Loss: 0.7295 | Val Loss: 0.7007\n",
      "Epoch 38 | Train Loss: 0.7419 | Val Loss: 0.6916\n",
      "Epoch 39 | Train Loss: 0.7255 | Val Loss: 0.6892\n",
      "Epoch 40 | Train Loss: 0.7242 | Val Loss: 0.7435\n",
      "Epoch 41 | Train Loss: 0.7395 | Val Loss: 0.6975\n",
      "Epoch 42 | Train Loss: 0.7358 | Val Loss: 0.6892\n",
      "Epoch 43 | Train Loss: 0.7320 | Val Loss: 0.7014\n",
      "Epoch 44 | Train Loss: 0.7325 | Val Loss: 0.6842\n",
      "Epoch 45 | Train Loss: 0.7528 | Val Loss: 0.6882\n",
      "Epoch 46 | Train Loss: 0.7152 | Val Loss: 0.6867\n",
      "Epoch 47 | Train Loss: 0.7290 | Val Loss: 0.6880\n",
      "Epoch 48 | Train Loss: 0.7499 | Val Loss: 0.6750\n",
      "Epoch 49 | Train Loss: 0.7071 | Val Loss: 0.6780\n",
      "Epoch 50 | Train Loss: 0.7261 | Val Loss: 0.6722\n",
      "Fold 1 ‚ñ∂ AUC: 0.795, Balanced Acc: 0.505\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.8998 | Val Loss: 0.8719\n",
      "Epoch 02 | Train Loss: 0.8822 | Val Loss: 0.8597\n",
      "Epoch 03 | Train Loss: 0.8748 | Val Loss: 0.8558\n",
      "Epoch 04 | Train Loss: 0.8696 | Val Loss: 0.8570\n",
      "Epoch 05 | Train Loss: 0.8490 | Val Loss: 0.8457\n",
      "Epoch 06 | Train Loss: 0.8530 | Val Loss: 0.8448\n",
      "Epoch 07 | Train Loss: 0.8595 | Val Loss: 0.8378\n",
      "Epoch 08 | Train Loss: 0.8452 | Val Loss: 0.8321\n",
      "Epoch 09 | Train Loss: 0.8359 | Val Loss: 0.8646\n",
      "Epoch 10 | Train Loss: 0.8745 | Val Loss: 0.8455\n",
      "Epoch 11 | Train Loss: 0.8562 | Val Loss: 0.8244\n",
      "Epoch 12 | Train Loss: 0.8625 | Val Loss: 0.8324\n",
      "Epoch 13 | Train Loss: 0.8195 | Val Loss: 0.8133\n",
      "Epoch 14 | Train Loss: 0.8248 | Val Loss: 0.8293\n",
      "Epoch 15 | Train Loss: 0.8059 | Val Loss: 0.8081\n",
      "Epoch 16 | Train Loss: 0.8059 | Val Loss: 0.7963\n",
      "Epoch 17 | Train Loss: 0.7932 | Val Loss: 0.7886\n",
      "Epoch 18 | Train Loss: 0.7927 | Val Loss: 0.7880\n",
      "Epoch 19 | Train Loss: 0.8014 | Val Loss: 0.7816\n",
      "Epoch 20 | Train Loss: 0.7775 | Val Loss: 0.7721\n",
      "Epoch 21 | Train Loss: 0.7760 | Val Loss: 0.7756\n",
      "Epoch 22 | Train Loss: 0.7774 | Val Loss: 0.7644\n",
      "Epoch 23 | Train Loss: 0.7626 | Val Loss: 0.7636\n",
      "Epoch 24 | Train Loss: 0.7899 | Val Loss: 0.7600\n",
      "Epoch 25 | Train Loss: 0.7583 | Val Loss: 0.7631\n",
      "Epoch 26 | Train Loss: 0.7617 | Val Loss: 0.7776\n",
      "Epoch 27 | Train Loss: 0.7631 | Val Loss: 0.8038\n",
      "Epoch 28 | Train Loss: 0.7750 | Val Loss: 0.7523\n",
      "Epoch 29 | Train Loss: 0.7471 | Val Loss: 0.7481\n",
      "Epoch 30 | Train Loss: 0.7358 | Val Loss: 0.7383\n",
      "Epoch 31 | Train Loss: 0.7440 | Val Loss: 0.7696\n",
      "Epoch 32 | Train Loss: 0.7541 | Val Loss: 0.7468\n",
      "Epoch 33 | Train Loss: 0.7902 | Val Loss: 0.7350\n",
      "Epoch 34 | Train Loss: 0.7746 | Val Loss: 0.7314\n",
      "Epoch 35 | Train Loss: 0.7465 | Val Loss: 0.7669\n",
      "Epoch 36 | Train Loss: 0.7337 | Val Loss: 0.7337\n",
      "Epoch 37 | Train Loss: 0.7409 | Val Loss: 0.7245\n",
      "Epoch 38 | Train Loss: 0.7555 | Val Loss: 0.7296\n",
      "Epoch 39 | Train Loss: 0.7545 | Val Loss: 0.7595\n",
      "Epoch 40 | Train Loss: 0.7387 | Val Loss: 0.7226\n",
      "Epoch 41 | Train Loss: 0.7319 | Val Loss: 0.7406\n",
      "Epoch 42 | Train Loss: 0.7242 | Val Loss: 0.7432\n",
      "Epoch 43 | Train Loss: 0.7464 | Val Loss: 0.7930\n",
      "Epoch 44 | Train Loss: 0.7485 | Val Loss: 0.7385\n",
      "Epoch 45 | Train Loss: 0.7284 | Val Loss: 0.7250\n",
      "Epoch 46 | Train Loss: 0.7261 | Val Loss: 0.7396\n",
      "Epoch 47 | Train Loss: 0.7407 | Val Loss: 0.7161\n",
      "Epoch 48 | Train Loss: 0.7231 | Val Loss: 0.7203\n",
      "Epoch 49 | Train Loss: 0.7329 | Val Loss: 0.7227\n",
      "Epoch 50 | Train Loss: 0.7405 | Val Loss: 0.7278\n",
      "Fold 2 ‚ñ∂ AUC: 0.663, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9138 | Val Loss: 0.8626\n",
      "Epoch 02 | Train Loss: 0.8882 | Val Loss: 0.8650\n",
      "Epoch 03 | Train Loss: 0.8578 | Val Loss: 0.8488\n",
      "Epoch 04 | Train Loss: 0.8696 | Val Loss: 0.8448\n",
      "Epoch 05 | Train Loss: 0.8440 | Val Loss: 0.8325\n",
      "Epoch 06 | Train Loss: 0.8525 | Val Loss: 0.8321\n",
      "Epoch 07 | Train Loss: 0.8541 | Val Loss: 0.8128\n",
      "Epoch 08 | Train Loss: 0.8370 | Val Loss: 0.8022\n",
      "Epoch 09 | Train Loss: 0.8207 | Val Loss: 0.7991\n",
      "Epoch 10 | Train Loss: 0.8131 | Val Loss: 0.7924\n",
      "Epoch 11 | Train Loss: 0.7964 | Val Loss: 0.7798\n",
      "Epoch 12 | Train Loss: 0.8348 | Val Loss: 0.7737\n",
      "Epoch 13 | Train Loss: 0.7943 | Val Loss: 0.7730\n",
      "Epoch 14 | Train Loss: 0.7993 | Val Loss: 0.8162\n",
      "Epoch 15 | Train Loss: 0.7883 | Val Loss: 0.7572\n",
      "Epoch 16 | Train Loss: 0.7801 | Val Loss: 0.7529\n",
      "Epoch 17 | Train Loss: 0.7824 | Val Loss: 0.7536\n",
      "Epoch 18 | Train Loss: 0.7656 | Val Loss: 0.7520\n",
      "Epoch 19 | Train Loss: 0.7568 | Val Loss: 0.7584\n",
      "Epoch 20 | Train Loss: 0.7764 | Val Loss: 0.7546\n",
      "Epoch 21 | Train Loss: 0.7540 | Val Loss: 0.7575\n",
      "Epoch 22 | Train Loss: 0.7594 | Val Loss: 0.7461\n",
      "Epoch 23 | Train Loss: 0.7776 | Val Loss: 0.7637\n",
      "Epoch 24 | Train Loss: 0.7553 | Val Loss: 0.7491\n",
      "Epoch 25 | Train Loss: 0.7541 | Val Loss: 0.7297\n",
      "Epoch 26 | Train Loss: 0.7497 | Val Loss: 0.7756\n",
      "Epoch 27 | Train Loss: 0.7536 | Val Loss: 0.7437\n",
      "Epoch 28 | Train Loss: 0.7488 | Val Loss: 0.7727\n",
      "Epoch 29 | Train Loss: 0.7782 | Val Loss: 0.7245\n",
      "Epoch 30 | Train Loss: 0.7364 | Val Loss: 0.7289\n",
      "Epoch 31 | Train Loss: 0.7270 | Val Loss: 0.7434\n",
      "Epoch 32 | Train Loss: 0.7313 | Val Loss: 0.7518\n",
      "Epoch 33 | Train Loss: 0.7356 | Val Loss: 0.7328\n",
      "Epoch 34 | Train Loss: 0.7265 | Val Loss: 0.7222\n",
      "Epoch 35 | Train Loss: 0.7260 | Val Loss: 0.7172\n",
      "Epoch 36 | Train Loss: 0.7275 | Val Loss: 0.7232\n",
      "Epoch 37 | Train Loss: 0.7347 | Val Loss: 0.7434\n",
      "Epoch 38 | Train Loss: 0.7448 | Val Loss: 0.7205\n",
      "Epoch 39 | Train Loss: 0.7278 | Val Loss: 0.7194\n",
      "Epoch 40 | Train Loss: 0.7362 | Val Loss: 0.7186\n",
      "Epoch 41 | Train Loss: 0.7292 | Val Loss: 0.7296\n",
      "Epoch 42 | Train Loss: 0.7181 | Val Loss: 0.7171\n",
      "Epoch 43 | Train Loss: 0.7287 | Val Loss: 0.7209\n",
      "Epoch 44 | Train Loss: 0.7108 | Val Loss: 0.7172\n",
      "Epoch 45 | Train Loss: 0.7388 | Val Loss: 0.7829\n",
      "Epoch 46 | Train Loss: 0.7157 | Val Loss: 0.7180\n",
      "Epoch 47 | Train Loss: 0.7490 | Val Loss: 0.7577\n",
      "Epoch 48 | Train Loss: 0.7249 | Val Loss: 0.7198\n",
      "Epoch 49 | Train Loss: 0.7088 | Val Loss: 0.7168\n",
      "Epoch 50 | Train Loss: 0.7203 | Val Loss: 0.7240\n",
      "Fold 3 ‚ñ∂ AUC: 0.767, Balanced Acc: 0.476\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9376 | Val Loss: 0.8659\n",
      "Epoch 02 | Train Loss: 0.8963 | Val Loss: 0.8295\n",
      "Epoch 03 | Train Loss: 0.8745 | Val Loss: 0.8365\n",
      "Epoch 04 | Train Loss: 0.8597 | Val Loss: 0.8284\n",
      "Epoch 05 | Train Loss: 0.8505 | Val Loss: 0.8152\n",
      "Epoch 06 | Train Loss: 0.8524 | Val Loss: 0.8091\n",
      "Epoch 07 | Train Loss: 0.8523 | Val Loss: 0.8264\n",
      "Epoch 08 | Train Loss: 0.8302 | Val Loss: 0.8029\n",
      "Epoch 09 | Train Loss: 0.8226 | Val Loss: 0.7917\n",
      "Epoch 10 | Train Loss: 0.8097 | Val Loss: 0.8059\n",
      "Epoch 11 | Train Loss: 0.8123 | Val Loss: 0.7877\n",
      "Epoch 12 | Train Loss: 0.8126 | Val Loss: 0.7700\n",
      "Epoch 13 | Train Loss: 0.8148 | Val Loss: 0.7691\n",
      "Epoch 14 | Train Loss: 0.7892 | Val Loss: 0.7734\n",
      "Epoch 15 | Train Loss: 0.7831 | Val Loss: 0.7657\n",
      "Epoch 16 | Train Loss: 0.7796 | Val Loss: 0.7604\n",
      "Epoch 17 | Train Loss: 0.7832 | Val Loss: 0.7386\n",
      "Epoch 18 | Train Loss: 0.7673 | Val Loss: 0.7313\n",
      "Epoch 19 | Train Loss: 0.7822 | Val Loss: 0.7273\n",
      "Epoch 20 | Train Loss: 0.8184 | Val Loss: 0.7421\n",
      "Epoch 21 | Train Loss: 0.7667 | Val Loss: 0.7246\n",
      "Epoch 22 | Train Loss: 0.7610 | Val Loss: 0.7177\n",
      "Epoch 23 | Train Loss: 0.7673 | Val Loss: 0.7364\n",
      "Epoch 24 | Train Loss: 0.7561 | Val Loss: 0.7118\n",
      "Epoch 25 | Train Loss: 0.7552 | Val Loss: 0.7060\n",
      "Epoch 26 | Train Loss: 0.7733 | Val Loss: 0.7223\n",
      "Epoch 27 | Train Loss: 0.7558 | Val Loss: 0.7059\n",
      "Epoch 28 | Train Loss: 0.7490 | Val Loss: 0.6960\n",
      "Epoch 29 | Train Loss: 0.7479 | Val Loss: 0.6886\n",
      "Epoch 30 | Train Loss: 0.7412 | Val Loss: 0.7024\n",
      "Epoch 31 | Train Loss: 0.7629 | Val Loss: 0.6996\n",
      "Epoch 32 | Train Loss: 0.7367 | Val Loss: 0.7234\n",
      "Epoch 33 | Train Loss: 0.7571 | Val Loss: 0.6871\n",
      "Epoch 34 | Train Loss: 0.7492 | Val Loss: 0.6833\n",
      "Epoch 35 | Train Loss: 0.7735 | Val Loss: 0.6855\n",
      "Epoch 36 | Train Loss: 0.7547 | Val Loss: 0.6855\n",
      "Epoch 37 | Train Loss: 0.7406 | Val Loss: 0.6842\n",
      "Epoch 38 | Train Loss: 0.7391 | Val Loss: 0.6932\n",
      "Epoch 39 | Train Loss: 0.7290 | Val Loss: 0.6974\n",
      "Epoch 40 | Train Loss: 0.7356 | Val Loss: 0.6710\n",
      "Epoch 41 | Train Loss: 0.7377 | Val Loss: 0.6775\n",
      "Epoch 42 | Train Loss: 0.7274 | Val Loss: 0.6659\n",
      "Epoch 43 | Train Loss: 0.7230 | Val Loss: 0.6643\n",
      "Epoch 44 | Train Loss: 0.7303 | Val Loss: 0.6694\n",
      "Epoch 45 | Train Loss: 0.7318 | Val Loss: 0.6704\n",
      "Epoch 46 | Train Loss: 0.7456 | Val Loss: 0.7127\n",
      "Epoch 47 | Train Loss: 0.7500 | Val Loss: 0.6876\n",
      "Epoch 48 | Train Loss: 0.7216 | Val Loss: 0.6649\n",
      "Epoch 49 | Train Loss: 0.7463 | Val Loss: 0.6643\n",
      "Epoch 50 | Train Loss: 0.7229 | Val Loss: 0.6661\n",
      "Fold 4 ‚ñ∂ AUC: 0.798, Balanced Acc: 0.553\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9238 | Val Loss: 0.9072\n",
      "Epoch 02 | Train Loss: 0.8634 | Val Loss: 0.9175\n",
      "Epoch 03 | Train Loss: 0.8684 | Val Loss: 0.8889\n",
      "Epoch 04 | Train Loss: 0.8608 | Val Loss: 0.8805\n",
      "Epoch 05 | Train Loss: 0.8504 | Val Loss: 0.8719\n",
      "Epoch 06 | Train Loss: 0.8398 | Val Loss: 0.8638\n",
      "Epoch 07 | Train Loss: 0.8321 | Val Loss: 0.8601\n",
      "Epoch 08 | Train Loss: 0.8180 | Val Loss: 0.8537\n",
      "Epoch 09 | Train Loss: 0.8085 | Val Loss: 0.8523\n",
      "Epoch 10 | Train Loss: 0.7934 | Val Loss: 0.8452\n",
      "Epoch 11 | Train Loss: 0.8003 | Val Loss: 0.8409\n",
      "Epoch 12 | Train Loss: 0.7955 | Val Loss: 0.8316\n",
      "Epoch 13 | Train Loss: 0.8013 | Val Loss: 0.8529\n",
      "Epoch 14 | Train Loss: 0.7708 | Val Loss: 0.8273\n",
      "Epoch 15 | Train Loss: 0.7754 | Val Loss: 0.8205\n",
      "Epoch 16 | Train Loss: 0.8023 | Val Loss: 0.8164\n",
      "Epoch 17 | Train Loss: 0.7563 | Val Loss: 0.8141\n",
      "Epoch 18 | Train Loss: 0.7593 | Val Loss: 0.8133\n",
      "Epoch 19 | Train Loss: 0.7579 | Val Loss: 0.8148\n",
      "Epoch 20 | Train Loss: 0.7597 | Val Loss: 0.8093\n",
      "Epoch 21 | Train Loss: 0.7638 | Val Loss: 0.8149\n",
      "Epoch 22 | Train Loss: 0.7636 | Val Loss: 0.8269\n",
      "Epoch 23 | Train Loss: 0.7459 | Val Loss: 0.8034\n",
      "Epoch 24 | Train Loss: 0.7550 | Val Loss: 0.7932\n",
      "Epoch 25 | Train Loss: 0.7411 | Val Loss: 0.7913\n",
      "Epoch 26 | Train Loss: 0.7495 | Val Loss: 0.7903\n",
      "Epoch 27 | Train Loss: 0.7380 | Val Loss: 0.7896\n",
      "Epoch 28 | Train Loss: 0.7424 | Val Loss: 0.7888\n",
      "Epoch 29 | Train Loss: 0.7396 | Val Loss: 0.7991\n",
      "Epoch 30 | Train Loss: 0.7325 | Val Loss: 0.7824\n",
      "Epoch 31 | Train Loss: 0.7317 | Val Loss: 0.8114\n",
      "Epoch 32 | Train Loss: 0.7515 | Val Loss: 0.7829\n",
      "Epoch 33 | Train Loss: 0.7474 | Val Loss: 0.7855\n",
      "Epoch 34 | Train Loss: 0.7582 | Val Loss: 0.8201\n",
      "Epoch 35 | Train Loss: 0.7467 | Val Loss: 0.7873\n",
      "Epoch 36 | Train Loss: 0.7499 | Val Loss: 0.7930\n",
      "Epoch 37 | Train Loss: 0.7330 | Val Loss: 0.7810\n",
      "Epoch 38 | Train Loss: 0.7175 | Val Loss: 0.7886\n",
      "Epoch 39 | Train Loss: 0.7331 | Val Loss: 0.7807\n",
      "Epoch 40 | Train Loss: 0.7418 | Val Loss: 0.7806\n",
      "Epoch 41 | Train Loss: 0.7174 | Val Loss: 0.7778\n",
      "Epoch 42 | Train Loss: 0.7138 | Val Loss: 0.7840\n",
      "Epoch 43 | Train Loss: 0.7079 | Val Loss: 0.7846\n",
      "Epoch 44 | Train Loss: 0.7335 | Val Loss: 0.7756\n",
      "Epoch 45 | Train Loss: 0.7010 | Val Loss: 0.7935\n",
      "Epoch 46 | Train Loss: 0.7377 | Val Loss: 0.7788\n",
      "Epoch 47 | Train Loss: 0.7291 | Val Loss: 0.7889\n",
      "Epoch 48 | Train Loss: 0.7299 | Val Loss: 0.8081\n",
      "Epoch 49 | Train Loss: 0.7317 | Val Loss: 0.7704\n",
      "Epoch 50 | Train Loss: 0.7196 | Val Loss: 0.7829\n",
      "Fold 5 ‚ñ∂ AUC: 0.750, Balanced Acc: 0.490\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9865 | Val Loss: 0.9059\n",
      "Epoch 02 | Train Loss: 0.8724 | Val Loss: 0.8991\n",
      "Epoch 03 | Train Loss: 0.8572 | Val Loss: 0.8874\n",
      "Epoch 04 | Train Loss: 0.8705 | Val Loss: 0.8863\n",
      "Epoch 05 | Train Loss: 0.8554 | Val Loss: 0.8787\n",
      "Epoch 06 | Train Loss: 0.8472 | Val Loss: 0.8872\n",
      "Epoch 07 | Train Loss: 0.8434 | Val Loss: 0.8752\n",
      "Epoch 08 | Train Loss: 0.8322 | Val Loss: 0.8876\n",
      "Epoch 09 | Train Loss: 0.8429 | Val Loss: 0.8697\n",
      "Epoch 10 | Train Loss: 0.8384 | Val Loss: 0.8765\n",
      "Epoch 11 | Train Loss: 0.8306 | Val Loss: 0.8952\n",
      "Epoch 12 | Train Loss: 0.8348 | Val Loss: 0.8595\n",
      "Epoch 13 | Train Loss: 0.8263 | Val Loss: 0.8593\n",
      "Epoch 14 | Train Loss: 0.7884 | Val Loss: 0.8533\n",
      "Epoch 15 | Train Loss: 0.7983 | Val Loss: 0.8550\n",
      "Epoch 16 | Train Loss: 0.7818 | Val Loss: 0.8480\n",
      "Epoch 17 | Train Loss: 0.7817 | Val Loss: 0.8472\n",
      "Epoch 18 | Train Loss: 0.7969 | Val Loss: 0.8527\n",
      "Epoch 19 | Train Loss: 0.7600 | Val Loss: 0.8413\n",
      "Epoch 20 | Train Loss: 0.7566 | Val Loss: 0.8482\n",
      "Epoch 21 | Train Loss: 0.7667 | Val Loss: 0.8818\n",
      "Epoch 22 | Train Loss: 0.7727 | Val Loss: 0.8487\n",
      "Epoch 23 | Train Loss: 0.7584 | Val Loss: 0.8839\n",
      "Epoch 24 | Train Loss: 0.7564 | Val Loss: 0.8398\n",
      "Epoch 25 | Train Loss: 0.7889 | Val Loss: 0.8998\n",
      "Epoch 26 | Train Loss: 0.7589 | Val Loss: 0.8383\n",
      "Epoch 27 | Train Loss: 0.7459 | Val Loss: 0.8427\n",
      "Epoch 28 | Train Loss: 0.7364 | Val Loss: 0.8336\n",
      "Epoch 29 | Train Loss: 0.7361 | Val Loss: 0.8309\n",
      "Epoch 30 | Train Loss: 0.7279 | Val Loss: 0.8296\n",
      "Epoch 31 | Train Loss: 0.7295 | Val Loss: 0.8291\n",
      "Epoch 32 | Train Loss: 0.7217 | Val Loss: 0.8314\n",
      "Epoch 33 | Train Loss: 0.7407 | Val Loss: 0.8400\n",
      "Epoch 34 | Train Loss: 0.7579 | Val Loss: 0.8378\n",
      "Epoch 35 | Train Loss: 0.7335 | Val Loss: 0.8247\n",
      "Epoch 36 | Train Loss: 0.7155 | Val Loss: 0.8190\n",
      "Epoch 37 | Train Loss: 0.7259 | Val Loss: 0.8288\n",
      "Epoch 38 | Train Loss: 0.7455 | Val Loss: 0.8313\n",
      "Epoch 39 | Train Loss: 0.7105 | Val Loss: 0.8226\n",
      "Epoch 40 | Train Loss: 0.7255 | Val Loss: 0.8282\n",
      "Epoch 41 | Train Loss: 0.7430 | Val Loss: 0.8253\n",
      "Epoch 42 | Train Loss: 0.7219 | Val Loss: 0.8487\n",
      "Epoch 43 | Train Loss: 0.7273 | Val Loss: 0.8187\n",
      "Epoch 44 | Train Loss: 0.7074 | Val Loss: 0.8286\n",
      "Epoch 45 | Train Loss: 0.7190 | Val Loss: 0.8363\n",
      "Epoch 46 | Train Loss: 0.7334 | Val Loss: 0.8192\n",
      "Epoch 47 | Train Loss: 0.7148 | Val Loss: 0.8155\n",
      "Epoch 48 | Train Loss: 0.7229 | Val Loss: 0.8364\n",
      "Epoch 49 | Train Loss: 0.7308 | Val Loss: 0.8476\n",
      "Epoch 50 | Train Loss: 0.7302 | Val Loss: 0.8326\n",
      "Fold 6 ‚ñ∂ AUC: 0.727, Balanced Acc: 0.449\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 1.0039 | Val Loss: 0.8559\n",
      "Epoch 02 | Train Loss: 0.8774 | Val Loss: 0.8614\n",
      "Epoch 03 | Train Loss: 0.8665 | Val Loss: 0.8519\n",
      "Epoch 04 | Train Loss: 0.8531 | Val Loss: 0.8445\n",
      "Epoch 05 | Train Loss: 0.8481 | Val Loss: 0.8432\n",
      "Epoch 06 | Train Loss: 0.8406 | Val Loss: 0.8365\n",
      "Epoch 07 | Train Loss: 0.8389 | Val Loss: 0.8428\n",
      "Epoch 08 | Train Loss: 0.8405 | Val Loss: 0.8328\n",
      "Epoch 09 | Train Loss: 0.8550 | Val Loss: 0.8211\n",
      "Epoch 10 | Train Loss: 0.8321 | Val Loss: 0.8163\n",
      "Epoch 11 | Train Loss: 0.8324 | Val Loss: 0.8097\n",
      "Epoch 12 | Train Loss: 0.8212 | Val Loss: 0.8084\n",
      "Epoch 13 | Train Loss: 0.8014 | Val Loss: 0.7966\n",
      "Epoch 14 | Train Loss: 0.8058 | Val Loss: 0.8276\n",
      "Epoch 15 | Train Loss: 0.8076 | Val Loss: 0.7809\n",
      "Epoch 16 | Train Loss: 0.7941 | Val Loss: 0.7796\n",
      "Epoch 17 | Train Loss: 0.8096 | Val Loss: 0.7815\n",
      "Epoch 18 | Train Loss: 0.8027 | Val Loss: 0.7834\n",
      "Epoch 19 | Train Loss: 0.7916 | Val Loss: 0.7616\n",
      "Epoch 20 | Train Loss: 0.7967 | Val Loss: 0.7557\n",
      "Epoch 21 | Train Loss: 0.7841 | Val Loss: 0.7685\n",
      "Epoch 22 | Train Loss: 0.7799 | Val Loss: 0.7982\n",
      "Epoch 23 | Train Loss: 0.7942 | Val Loss: 0.7625\n",
      "Epoch 24 | Train Loss: 0.7547 | Val Loss: 0.7486\n",
      "Epoch 25 | Train Loss: 0.7623 | Val Loss: 0.7423\n",
      "Epoch 26 | Train Loss: 0.7662 | Val Loss: 0.7514\n",
      "Epoch 27 | Train Loss: 0.7471 | Val Loss: 0.7462\n",
      "Epoch 28 | Train Loss: 0.7510 | Val Loss: 0.7438\n",
      "Epoch 29 | Train Loss: 0.7516 | Val Loss: 0.7413\n",
      "Epoch 30 | Train Loss: 0.7429 | Val Loss: 0.7732\n",
      "Epoch 31 | Train Loss: 0.7716 | Val Loss: 0.7707\n",
      "Epoch 32 | Train Loss: 0.7535 | Val Loss: 0.7433\n",
      "Epoch 33 | Train Loss: 0.7411 | Val Loss: 0.7417\n",
      "Epoch 34 | Train Loss: 0.7557 | Val Loss: 0.7450\n",
      "Epoch 35 | Train Loss: 0.7571 | Val Loss: 0.7514\n",
      "Epoch 36 | Train Loss: 0.7482 | Val Loss: 0.7394\n",
      "Epoch 37 | Train Loss: 0.7341 | Val Loss: 0.7470\n",
      "Epoch 38 | Train Loss: 0.7378 | Val Loss: 0.7648\n",
      "Epoch 39 | Train Loss: 0.7297 | Val Loss: 0.7452\n",
      "Epoch 40 | Train Loss: 0.7411 | Val Loss: 0.7433\n",
      "Epoch 41 | Train Loss: 0.7442 | Val Loss: 0.7430\n",
      "Epoch 42 | Train Loss: 0.7407 | Val Loss: 0.7390\n",
      "Epoch 43 | Train Loss: 0.7373 | Val Loss: 0.7485\n",
      "Epoch 44 | Train Loss: 0.7154 | Val Loss: 0.7375\n",
      "Epoch 45 | Train Loss: 0.7400 | Val Loss: 0.7493\n",
      "Epoch 46 | Train Loss: 0.7271 | Val Loss: 0.7427\n",
      "Epoch 47 | Train Loss: 0.7214 | Val Loss: 0.7468\n",
      "Epoch 48 | Train Loss: 0.7149 | Val Loss: 0.7377\n",
      "Epoch 49 | Train Loss: 0.7159 | Val Loss: 0.7366\n",
      "Epoch 50 | Train Loss: 0.7257 | Val Loss: 0.7387\n",
      "Fold 7 ‚ñ∂ AUC: 0.752, Balanced Acc: 0.462\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9124 | Val Loss: 0.8668\n",
      "Epoch 02 | Train Loss: 0.8669 | Val Loss: 0.8544\n",
      "Epoch 03 | Train Loss: 0.8715 | Val Loss: 0.8512\n",
      "Epoch 04 | Train Loss: 0.8449 | Val Loss: 0.8459\n",
      "Epoch 05 | Train Loss: 0.8509 | Val Loss: 0.8404\n",
      "Epoch 06 | Train Loss: 0.8440 | Val Loss: 0.8374\n",
      "Epoch 07 | Train Loss: 0.8480 | Val Loss: 0.8405\n",
      "Epoch 08 | Train Loss: 0.8190 | Val Loss: 0.8267\n",
      "Epoch 09 | Train Loss: 0.8190 | Val Loss: 0.8198\n",
      "Epoch 10 | Train Loss: 0.8173 | Val Loss: 0.8218\n",
      "Epoch 11 | Train Loss: 0.8251 | Val Loss: 0.8103\n",
      "Epoch 12 | Train Loss: 0.8161 | Val Loss: 0.8135\n",
      "Epoch 13 | Train Loss: 0.8176 | Val Loss: 0.8019\n",
      "Epoch 14 | Train Loss: 0.8106 | Val Loss: 0.8025\n",
      "Epoch 15 | Train Loss: 0.7947 | Val Loss: 0.7959\n",
      "Epoch 16 | Train Loss: 0.7809 | Val Loss: 0.8025\n",
      "Epoch 17 | Train Loss: 0.7971 | Val Loss: 0.7927\n",
      "Epoch 18 | Train Loss: 0.7761 | Val Loss: 0.7864\n",
      "Epoch 19 | Train Loss: 0.7672 | Val Loss: 0.7825\n",
      "Epoch 20 | Train Loss: 0.7497 | Val Loss: 0.7834\n",
      "Epoch 21 | Train Loss: 0.7614 | Val Loss: 0.7836\n",
      "Epoch 22 | Train Loss: 0.7681 | Val Loss: 0.7824\n",
      "Epoch 23 | Train Loss: 0.7353 | Val Loss: 0.7991\n",
      "Epoch 24 | Train Loss: 0.7361 | Val Loss: 0.8008\n",
      "Epoch 25 | Train Loss: 0.7354 | Val Loss: 0.8026\n",
      "Epoch 26 | Train Loss: 0.7644 | Val Loss: 0.7856\n",
      "Epoch 27 | Train Loss: 0.7481 | Val Loss: 0.8130\n",
      "Epoch 28 | Train Loss: 0.7473 | Val Loss: 0.7899\n",
      "Epoch 29 | Train Loss: 0.7361 | Val Loss: 0.7859\n",
      "Epoch 30 | Train Loss: 0.7325 | Val Loss: 0.7930\n",
      "Epoch 31 | Train Loss: 0.7273 | Val Loss: 0.8275\n",
      "Epoch 32 | Train Loss: 0.7237 | Val Loss: 0.7924\n",
      "Epoch 33 | Train Loss: 0.7404 | Val Loss: 0.7904\n",
      "Epoch 34 | Train Loss: 0.7459 | Val Loss: 0.7903\n",
      "Epoch 35 | Train Loss: 0.7568 | Val Loss: 0.7897\n",
      "Epoch 36 | Train Loss: 0.7193 | Val Loss: 0.8020\n",
      "Epoch 37 | Train Loss: 0.7260 | Val Loss: 0.8213\n",
      "Epoch 38 | Train Loss: 0.7437 | Val Loss: 0.8085\n",
      "Epoch 39 | Train Loss: 0.7561 | Val Loss: 0.7923\n",
      "Epoch 40 | Train Loss: 0.7255 | Val Loss: 0.7962\n",
      "Epoch 41 | Train Loss: 0.7108 | Val Loss: 0.8022\n",
      "Epoch 42 | Train Loss: 0.7465 | Val Loss: 0.8536\n",
      "Epoch 43 | Train Loss: 0.7248 | Val Loss: 0.8015\n",
      "Epoch 44 | Train Loss: 0.7479 | Val Loss: 0.8007\n",
      "Epoch 45 | Train Loss: 0.7232 | Val Loss: 0.7965\n",
      "Epoch 46 | Train Loss: 0.7006 | Val Loss: 0.7974\n",
      "Epoch 47 | Train Loss: 0.7158 | Val Loss: 0.8058\n",
      "Epoch 48 | Train Loss: 0.7160 | Val Loss: 0.8131\n",
      "Epoch 49 | Train Loss: 0.7027 | Val Loss: 0.8011\n",
      "Epoch 50 | Train Loss: 0.7025 | Val Loss: 0.8045\n",
      "Fold 8 ‚ñ∂ AUC: 0.703, Balanced Acc: 0.415\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9822 | Val Loss: 0.8844\n",
      "Epoch 02 | Train Loss: 0.8768 | Val Loss: 0.8697\n",
      "Epoch 03 | Train Loss: 0.8654 | Val Loss: 0.8654\n",
      "Epoch 04 | Train Loss: 0.8652 | Val Loss: 0.8637\n",
      "Epoch 05 | Train Loss: 0.8516 | Val Loss: 0.8576\n",
      "Epoch 06 | Train Loss: 0.8438 | Val Loss: 0.8534\n",
      "Epoch 07 | Train Loss: 0.8343 | Val Loss: 0.8521\n",
      "Epoch 08 | Train Loss: 0.8326 | Val Loss: 0.8555\n",
      "Epoch 09 | Train Loss: 0.8251 | Val Loss: 0.8488\n",
      "Epoch 10 | Train Loss: 0.8184 | Val Loss: 0.8459\n",
      "Epoch 11 | Train Loss: 0.8093 | Val Loss: 0.8396\n",
      "Epoch 12 | Train Loss: 0.7990 | Val Loss: 0.8517\n",
      "Epoch 13 | Train Loss: 0.8148 | Val Loss: 0.8514\n",
      "Epoch 14 | Train Loss: 0.7933 | Val Loss: 0.8293\n",
      "Epoch 15 | Train Loss: 0.8029 | Val Loss: 0.8789\n",
      "Epoch 16 | Train Loss: 0.8134 | Val Loss: 0.8340\n",
      "Epoch 17 | Train Loss: 0.7810 | Val Loss: 0.8444\n",
      "Epoch 18 | Train Loss: 0.7907 | Val Loss: 0.8191\n",
      "Epoch 19 | Train Loss: 0.7741 | Val Loss: 0.8174\n",
      "Epoch 20 | Train Loss: 0.7724 | Val Loss: 0.8143\n",
      "Epoch 21 | Train Loss: 0.7643 | Val Loss: 0.8608\n",
      "Epoch 22 | Train Loss: 0.7709 | Val Loss: 0.8292\n",
      "Epoch 23 | Train Loss: 0.7591 | Val Loss: 0.8126\n",
      "Epoch 24 | Train Loss: 0.7587 | Val Loss: 0.8190\n",
      "Epoch 25 | Train Loss: 0.7557 | Val Loss: 0.8446\n",
      "Epoch 26 | Train Loss: 0.7828 | Val Loss: 0.8189\n",
      "Epoch 27 | Train Loss: 0.7728 | Val Loss: 0.8000\n",
      "Epoch 28 | Train Loss: 0.7445 | Val Loss: 0.8194\n",
      "Epoch 29 | Train Loss: 0.7523 | Val Loss: 0.7949\n",
      "Epoch 30 | Train Loss: 0.7364 | Val Loss: 0.7935\n",
      "Epoch 31 | Train Loss: 0.7443 | Val Loss: 0.7933\n",
      "Epoch 32 | Train Loss: 0.7276 | Val Loss: 0.8027\n",
      "Epoch 33 | Train Loss: 0.7439 | Val Loss: 0.7933\n",
      "Epoch 34 | Train Loss: 0.7499 | Val Loss: 0.7996\n",
      "Epoch 35 | Train Loss: 0.7398 | Val Loss: 0.8212\n",
      "Epoch 36 | Train Loss: 0.7351 | Val Loss: 0.8108\n",
      "Epoch 37 | Train Loss: 0.7231 | Val Loss: 0.7889\n",
      "Epoch 38 | Train Loss: 0.7548 | Val Loss: 0.7875\n",
      "Epoch 39 | Train Loss: 0.7443 | Val Loss: 0.7817\n",
      "Epoch 40 | Train Loss: 0.7257 | Val Loss: 0.7923\n",
      "Epoch 41 | Train Loss: 0.7328 | Val Loss: 0.8115\n",
      "Epoch 42 | Train Loss: 0.7312 | Val Loss: 0.8015\n",
      "Epoch 43 | Train Loss: 0.7506 | Val Loss: 0.7780\n",
      "Epoch 44 | Train Loss: 0.7366 | Val Loss: 0.7768\n",
      "Epoch 45 | Train Loss: 0.7195 | Val Loss: 0.7741\n",
      "Epoch 46 | Train Loss: 0.7301 | Val Loss: 0.7768\n",
      "Epoch 47 | Train Loss: 0.7330 | Val Loss: 0.7711\n",
      "Epoch 48 | Train Loss: 0.7222 | Val Loss: 0.7725\n",
      "Epoch 49 | Train Loss: 0.7366 | Val Loss: 0.7828\n",
      "Epoch 50 | Train Loss: 0.7215 | Val Loss: 0.7937\n",
      "Fold 9 ‚ñ∂ AUC: 0.751, Balanced Acc: 0.490\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9425 | Val Loss: 0.8882\n",
      "Epoch 02 | Train Loss: 0.9070 | Val Loss: 0.8761\n",
      "Epoch 03 | Train Loss: 0.8636 | Val Loss: 0.8638\n",
      "Epoch 04 | Train Loss: 0.8684 | Val Loss: 0.8529\n",
      "Epoch 05 | Train Loss: 0.8628 | Val Loss: 0.8498\n",
      "Epoch 06 | Train Loss: 0.8539 | Val Loss: 0.8475\n",
      "Epoch 07 | Train Loss: 0.8497 | Val Loss: 0.8440\n",
      "Epoch 08 | Train Loss: 0.8436 | Val Loss: 0.8332\n",
      "Epoch 09 | Train Loss: 0.8549 | Val Loss: 0.8352\n",
      "Epoch 10 | Train Loss: 0.8401 | Val Loss: 0.8313\n",
      "Epoch 11 | Train Loss: 0.8244 | Val Loss: 0.8197\n",
      "Epoch 12 | Train Loss: 0.8305 | Val Loss: 0.8175\n",
      "Epoch 13 | Train Loss: 0.8395 | Val Loss: 0.8095\n",
      "Epoch 14 | Train Loss: 0.8301 | Val Loss: 0.8201\n",
      "Epoch 15 | Train Loss: 0.8126 | Val Loss: 0.8303\n",
      "Epoch 16 | Train Loss: 0.8070 | Val Loss: 0.8121\n",
      "Epoch 17 | Train Loss: 0.7950 | Val Loss: 0.7977\n",
      "Epoch 18 | Train Loss: 0.7985 | Val Loss: 0.7960\n",
      "Epoch 19 | Train Loss: 0.7809 | Val Loss: 0.8325\n",
      "Epoch 20 | Train Loss: 0.7935 | Val Loss: 0.8485\n",
      "Epoch 21 | Train Loss: 0.8045 | Val Loss: 0.7772\n",
      "Epoch 22 | Train Loss: 0.7835 | Val Loss: 0.7770\n",
      "Epoch 23 | Train Loss: 0.7676 | Val Loss: 0.7922\n",
      "Epoch 24 | Train Loss: 0.7688 | Val Loss: 0.7666\n",
      "Epoch 25 | Train Loss: 0.7680 | Val Loss: 0.7817\n",
      "Epoch 26 | Train Loss: 0.7737 | Val Loss: 0.8095\n",
      "Epoch 27 | Train Loss: 0.7986 | Val Loss: 0.8147\n",
      "Epoch 28 | Train Loss: 0.7548 | Val Loss: 0.7699\n",
      "Epoch 29 | Train Loss: 0.7496 | Val Loss: 0.7702\n",
      "Epoch 30 | Train Loss: 0.7646 | Val Loss: 0.7539\n",
      "Epoch 31 | Train Loss: 0.7518 | Val Loss: 0.7583\n",
      "Epoch 32 | Train Loss: 0.7432 | Val Loss: 0.7758\n",
      "Epoch 33 | Train Loss: 0.7319 | Val Loss: 0.7618\n",
      "Epoch 34 | Train Loss: 0.7498 | Val Loss: 0.7507\n",
      "Epoch 35 | Train Loss: 0.7554 | Val Loss: 0.7667\n",
      "Epoch 36 | Train Loss: 0.7485 | Val Loss: 0.8295\n",
      "Epoch 37 | Train Loss: 0.7314 | Val Loss: 0.7535\n",
      "Epoch 38 | Train Loss: 0.7585 | Val Loss: 0.7531\n",
      "Epoch 39 | Train Loss: 0.7449 | Val Loss: 0.7544\n",
      "Epoch 40 | Train Loss: 0.7533 | Val Loss: 0.7752\n",
      "Epoch 41 | Train Loss: 0.7565 | Val Loss: 0.8030\n",
      "Epoch 42 | Train Loss: 0.7247 | Val Loss: 0.7814\n",
      "Epoch 43 | Train Loss: 0.7412 | Val Loss: 0.7583\n",
      "Epoch 44 | Train Loss: 0.7300 | Val Loss: 0.7524\n",
      "Epoch 45 | Train Loss: 0.7211 | Val Loss: 0.7702\n",
      "Epoch 46 | Train Loss: 0.7229 | Val Loss: 0.7717\n",
      "Epoch 47 | Train Loss: 0.7215 | Val Loss: 0.8287\n",
      "Epoch 48 | Train Loss: 0.7406 | Val Loss: 0.7607\n",
      "Epoch 49 | Train Loss: 0.7298 | Val Loss: 0.7644\n",
      "Epoch 50 | Train Loss: 0.7139 | Val Loss: 0.7899\n",
      "Fold 10 ‚ñ∂ AUC: 0.718, Balanced Acc: 0.429\n",
      "üîç Summary for hd=256, dp=0.0, lr=0.0001 ‚Üí AUC: 0.7424¬±0.0392 | BalAcc: 0.4832¬±0.0456\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.2, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9748 | Val Loss: 0.8668\n",
      "Epoch 02 | Train Loss: 0.8804 | Val Loss: 0.8513\n",
      "Epoch 03 | Train Loss: 0.8815 | Val Loss: 0.8291\n",
      "Epoch 04 | Train Loss: 0.8367 | Val Loss: 0.8032\n",
      "Epoch 05 | Train Loss: 0.8352 | Val Loss: 0.7706\n",
      "Epoch 06 | Train Loss: 0.7952 | Val Loss: 0.7890\n",
      "Epoch 07 | Train Loss: 0.8281 | Val Loss: 0.8123\n",
      "Epoch 08 | Train Loss: 0.7825 | Val Loss: 0.7438\n",
      "Epoch 09 | Train Loss: 0.7682 | Val Loss: 0.7599\n",
      "Epoch 10 | Train Loss: 0.7750 | Val Loss: 0.7267\n",
      "Epoch 11 | Train Loss: 0.7671 | Val Loss: 0.7366\n",
      "Epoch 12 | Train Loss: 0.7704 | Val Loss: 0.7233\n",
      "Epoch 13 | Train Loss: 0.7453 | Val Loss: 0.7274\n",
      "Epoch 14 | Train Loss: 0.7821 | Val Loss: 0.7058\n",
      "Epoch 15 | Train Loss: 0.7862 | Val Loss: 0.7149\n",
      "Epoch 16 | Train Loss: 0.7418 | Val Loss: 0.6984\n",
      "Epoch 17 | Train Loss: 0.7414 | Val Loss: 0.7017\n",
      "Epoch 18 | Train Loss: 0.7453 | Val Loss: 0.6926\n",
      "Epoch 19 | Train Loss: 0.7637 | Val Loss: 0.6965\n",
      "Epoch 20 | Train Loss: 0.7448 | Val Loss: 0.6857\n",
      "Epoch 21 | Train Loss: 0.7503 | Val Loss: 0.6871\n",
      "Epoch 22 | Train Loss: 0.7409 | Val Loss: 0.7260\n",
      "Epoch 23 | Train Loss: 0.7071 | Val Loss: 0.6928\n",
      "Epoch 24 | Train Loss: 0.7421 | Val Loss: 0.6950\n",
      "Epoch 25 | Train Loss: 0.7386 | Val Loss: 0.6847\n",
      "Epoch 26 | Train Loss: 0.7576 | Val Loss: 0.6896\n",
      "Epoch 27 | Train Loss: 0.7586 | Val Loss: 0.7253\n",
      "Epoch 28 | Train Loss: 0.7330 | Val Loss: 0.7201\n",
      "Epoch 29 | Train Loss: 0.7470 | Val Loss: 0.7000\n",
      "Epoch 30 | Train Loss: 0.7353 | Val Loss: 0.7358\n",
      "Epoch 31 | Train Loss: 0.7784 | Val Loss: 0.7220\n",
      "Epoch 32 | Train Loss: 0.7426 | Val Loss: 0.7059\n",
      "Epoch 33 | Train Loss: 0.7354 | Val Loss: 0.7497\n",
      "Epoch 34 | Train Loss: 0.7495 | Val Loss: 0.6981\n",
      "Epoch 35 | Train Loss: 0.7566 | Val Loss: 0.6813\n",
      "Epoch 36 | Train Loss: 0.7204 | Val Loss: 0.6897\n",
      "Epoch 37 | Train Loss: 0.7311 | Val Loss: 0.6906\n",
      "Epoch 38 | Train Loss: 0.7222 | Val Loss: 0.6889\n",
      "Epoch 39 | Train Loss: 0.7136 | Val Loss: 0.7044\n",
      "Epoch 40 | Train Loss: 0.7240 | Val Loss: 0.6890\n",
      "Epoch 41 | Train Loss: 0.7170 | Val Loss: 0.7236\n",
      "Epoch 42 | Train Loss: 0.7390 | Val Loss: 0.6900\n",
      "Epoch 43 | Train Loss: 0.7447 | Val Loss: 0.7211\n",
      "Epoch 44 | Train Loss: 0.7265 | Val Loss: 0.7239\n",
      "Epoch 45 | Train Loss: 0.7118 | Val Loss: 0.7025\n",
      "Epoch 46 | Train Loss: 0.7210 | Val Loss: 0.7095\n",
      "Epoch 47 | Train Loss: 0.7351 | Val Loss: 0.7404\n",
      "Epoch 48 | Train Loss: 0.7340 | Val Loss: 0.6975\n",
      "Epoch 49 | Train Loss: 0.7184 | Val Loss: 0.7147\n",
      "Epoch 50 | Train Loss: 0.7418 | Val Loss: 0.6987\n",
      "Fold 1 ‚ñ∂ AUC: 0.785, Balanced Acc: 0.475\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9509 | Val Loss: 0.8685\n",
      "Epoch 02 | Train Loss: 0.8911 | Val Loss: 0.8622\n",
      "Epoch 03 | Train Loss: 0.8535 | Val Loss: 0.8430\n",
      "Epoch 04 | Train Loss: 0.8327 | Val Loss: 0.8326\n",
      "Epoch 05 | Train Loss: 0.8476 | Val Loss: 0.7929\n",
      "Epoch 06 | Train Loss: 0.8409 | Val Loss: 0.8318\n",
      "Epoch 07 | Train Loss: 0.7857 | Val Loss: 0.8041\n",
      "Epoch 08 | Train Loss: 0.7953 | Val Loss: 0.8061\n",
      "Epoch 09 | Train Loss: 0.7696 | Val Loss: 0.7291\n",
      "Epoch 10 | Train Loss: 0.7866 | Val Loss: 0.7495\n",
      "Epoch 11 | Train Loss: 0.7777 | Val Loss: 0.7421\n",
      "Epoch 12 | Train Loss: 0.7468 | Val Loss: 0.7289\n",
      "Epoch 13 | Train Loss: 0.7400 | Val Loss: 0.7323\n",
      "Epoch 14 | Train Loss: 0.7589 | Val Loss: 0.8343\n",
      "Epoch 15 | Train Loss: 0.7452 | Val Loss: 0.7791\n",
      "Epoch 16 | Train Loss: 0.7566 | Val Loss: 0.7141\n",
      "Epoch 17 | Train Loss: 0.7499 | Val Loss: 0.7120\n",
      "Epoch 18 | Train Loss: 0.7680 | Val Loss: 0.7173\n",
      "Epoch 19 | Train Loss: 0.7674 | Val Loss: 0.7189\n",
      "Epoch 20 | Train Loss: 0.7284 | Val Loss: 0.7414\n",
      "Epoch 21 | Train Loss: 0.7301 | Val Loss: 0.7210\n",
      "Epoch 22 | Train Loss: 0.7329 | Val Loss: 0.7737\n",
      "Epoch 23 | Train Loss: 0.7581 | Val Loss: 0.7002\n",
      "Epoch 24 | Train Loss: 0.7450 | Val Loss: 0.7050\n",
      "Epoch 25 | Train Loss: 0.7328 | Val Loss: 0.7006\n",
      "Epoch 26 | Train Loss: 0.7388 | Val Loss: 0.7143\n",
      "Epoch 27 | Train Loss: 0.7453 | Val Loss: 0.7554\n",
      "Epoch 28 | Train Loss: 0.7388 | Val Loss: 0.7831\n",
      "Epoch 29 | Train Loss: 0.7380 | Val Loss: 0.7427\n",
      "Epoch 30 | Train Loss: 0.7231 | Val Loss: 0.6998\n",
      "Epoch 31 | Train Loss: 0.7423 | Val Loss: 0.7042\n",
      "Epoch 32 | Train Loss: 0.7481 | Val Loss: 0.6833\n",
      "Epoch 33 | Train Loss: 0.7434 | Val Loss: 0.7249\n",
      "Epoch 34 | Train Loss: 0.7551 | Val Loss: 0.6858\n",
      "Epoch 35 | Train Loss: 0.7444 | Val Loss: 0.7002\n",
      "Epoch 36 | Train Loss: 0.7388 | Val Loss: 0.6836\n",
      "Epoch 37 | Train Loss: 0.7946 | Val Loss: 0.7160\n",
      "Epoch 38 | Train Loss: 0.7616 | Val Loss: 0.7656\n",
      "Epoch 39 | Train Loss: 0.7395 | Val Loss: 0.7196\n",
      "Epoch 40 | Train Loss: 0.7442 | Val Loss: 0.7044\n",
      "Epoch 41 | Train Loss: 0.7109 | Val Loss: 0.7348\n",
      "Epoch 42 | Train Loss: 0.7508 | Val Loss: 0.7058\n",
      "Epoch 43 | Train Loss: 0.7349 | Val Loss: 0.7064\n",
      "Epoch 44 | Train Loss: 0.7150 | Val Loss: 0.7190\n",
      "Epoch 45 | Train Loss: 0.7121 | Val Loss: 0.7075\n",
      "Epoch 46 | Train Loss: 0.7160 | Val Loss: 0.6991\n",
      "Epoch 47 | Train Loss: 0.7229 | Val Loss: 0.7276\n",
      "Epoch 48 | Train Loss: 0.7318 | Val Loss: 0.6812\n",
      "Epoch 49 | Train Loss: 0.7211 | Val Loss: 0.6625\n",
      "Epoch 50 | Train Loss: 0.7143 | Val Loss: 0.7451\n",
      "Fold 2 ‚ñ∂ AUC: 0.727, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9742 | Val Loss: 0.8793\n",
      "Epoch 02 | Train Loss: 0.9043 | Val Loss: 0.8581\n",
      "Epoch 03 | Train Loss: 0.8842 | Val Loss: 0.8779\n",
      "Epoch 04 | Train Loss: 0.8760 | Val Loss: 0.8343\n",
      "Epoch 05 | Train Loss: 0.8269 | Val Loss: 0.7949\n",
      "Epoch 06 | Train Loss: 0.8121 | Val Loss: 0.7967\n",
      "Epoch 07 | Train Loss: 0.7834 | Val Loss: 0.8004\n",
      "Epoch 08 | Train Loss: 0.8101 | Val Loss: 0.7991\n",
      "Epoch 09 | Train Loss: 0.7820 | Val Loss: 0.7507\n",
      "Epoch 10 | Train Loss: 0.7457 | Val Loss: 0.8156\n",
      "Epoch 11 | Train Loss: 0.7443 | Val Loss: 0.7425\n",
      "Epoch 12 | Train Loss: 0.8207 | Val Loss: 0.7394\n",
      "Epoch 13 | Train Loss: 0.7976 | Val Loss: 0.7617\n",
      "Epoch 14 | Train Loss: 0.7552 | Val Loss: 0.7389\n",
      "Epoch 15 | Train Loss: 0.7639 | Val Loss: 0.7422\n",
      "Epoch 16 | Train Loss: 0.7425 | Val Loss: 0.7349\n",
      "Epoch 17 | Train Loss: 0.7197 | Val Loss: 0.7310\n",
      "Epoch 18 | Train Loss: 0.7386 | Val Loss: 0.7253\n",
      "Epoch 19 | Train Loss: 0.7288 | Val Loss: 0.7316\n",
      "Epoch 20 | Train Loss: 0.7302 | Val Loss: 0.7559\n",
      "Epoch 21 | Train Loss: 0.7507 | Val Loss: 0.7654\n",
      "Epoch 22 | Train Loss: 0.7427 | Val Loss: 0.7713\n",
      "Epoch 23 | Train Loss: 0.7216 | Val Loss: 0.7328\n",
      "Epoch 24 | Train Loss: 0.7353 | Val Loss: 0.7220\n",
      "Epoch 25 | Train Loss: 0.7300 | Val Loss: 0.7197\n",
      "Epoch 26 | Train Loss: 0.7466 | Val Loss: 0.7551\n",
      "Epoch 27 | Train Loss: 0.7661 | Val Loss: 0.7207\n",
      "Epoch 28 | Train Loss: 0.7159 | Val Loss: 0.7203\n",
      "Epoch 29 | Train Loss: 0.7119 | Val Loss: 0.7268\n",
      "Epoch 30 | Train Loss: 0.7382 | Val Loss: 0.7131\n",
      "Epoch 31 | Train Loss: 0.7234 | Val Loss: 0.7481\n",
      "Epoch 32 | Train Loss: 0.7428 | Val Loss: 0.7338\n",
      "Epoch 33 | Train Loss: 0.7422 | Val Loss: 0.7282\n",
      "Epoch 34 | Train Loss: 0.7424 | Val Loss: 0.7274\n",
      "Epoch 35 | Train Loss: 0.7344 | Val Loss: 0.7367\n",
      "Epoch 36 | Train Loss: 0.7627 | Val Loss: 0.7243\n",
      "Epoch 37 | Train Loss: 0.7420 | Val Loss: 0.7390\n",
      "Epoch 38 | Train Loss: 0.7311 | Val Loss: 0.7216\n",
      "Epoch 39 | Train Loss: 0.7351 | Val Loss: 0.7148\n",
      "Epoch 40 | Train Loss: 0.7418 | Val Loss: 0.7197\n",
      "Epoch 41 | Train Loss: 0.7130 | Val Loss: 0.7134\n",
      "Epoch 42 | Train Loss: 0.7234 | Val Loss: 0.7115\n",
      "Epoch 43 | Train Loss: 0.7460 | Val Loss: 0.7282\n",
      "Epoch 44 | Train Loss: 0.7163 | Val Loss: 0.7073\n",
      "Epoch 45 | Train Loss: 0.7420 | Val Loss: 0.7055\n",
      "Epoch 46 | Train Loss: 0.7036 | Val Loss: 0.7343\n",
      "Epoch 47 | Train Loss: 0.7130 | Val Loss: 0.7184\n",
      "Epoch 48 | Train Loss: 0.7110 | Val Loss: 0.7113\n",
      "Epoch 49 | Train Loss: 0.7395 | Val Loss: 0.7224\n",
      "Epoch 50 | Train Loss: 0.7356 | Val Loss: 0.7629\n",
      "Fold 3 ‚ñ∂ AUC: 0.775, Balanced Acc: 0.516\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9606 | Val Loss: 0.8455\n",
      "Epoch 02 | Train Loss: 0.8860 | Val Loss: 0.8355\n",
      "Epoch 03 | Train Loss: 0.8683 | Val Loss: 0.8152\n",
      "Epoch 04 | Train Loss: 0.8562 | Val Loss: 0.8000\n",
      "Epoch 05 | Train Loss: 0.8143 | Val Loss: 0.7508\n",
      "Epoch 06 | Train Loss: 0.7922 | Val Loss: 0.7326\n",
      "Epoch 07 | Train Loss: 0.7569 | Val Loss: 0.7092\n",
      "Epoch 08 | Train Loss: 0.7680 | Val Loss: 0.6916\n",
      "Epoch 09 | Train Loss: 0.7715 | Val Loss: 0.6960\n",
      "Epoch 10 | Train Loss: 0.7457 | Val Loss: 0.8117\n",
      "Epoch 11 | Train Loss: 0.8133 | Val Loss: 0.7045\n",
      "Epoch 12 | Train Loss: 0.7601 | Val Loss: 0.7027\n",
      "Epoch 13 | Train Loss: 0.8051 | Val Loss: 0.6834\n",
      "Epoch 14 | Train Loss: 0.7828 | Val Loss: 0.7251\n",
      "Epoch 15 | Train Loss: 0.7820 | Val Loss: 0.7123\n",
      "Epoch 16 | Train Loss: 0.7536 | Val Loss: 0.7428\n",
      "Epoch 17 | Train Loss: 0.7706 | Val Loss: 0.6989\n",
      "Epoch 18 | Train Loss: 0.7313 | Val Loss: 0.6729\n",
      "Epoch 19 | Train Loss: 0.7597 | Val Loss: 0.7090\n",
      "Epoch 20 | Train Loss: 0.7244 | Val Loss: 0.6628\n",
      "Epoch 21 | Train Loss: 0.7225 | Val Loss: 0.6631\n",
      "Epoch 22 | Train Loss: 0.7729 | Val Loss: 0.7060\n",
      "Epoch 23 | Train Loss: 0.7611 | Val Loss: 0.6692\n",
      "Epoch 24 | Train Loss: 0.7411 | Val Loss: 0.6705\n",
      "Epoch 25 | Train Loss: 0.7344 | Val Loss: 0.6685\n",
      "Epoch 26 | Train Loss: 0.7313 | Val Loss: 0.6761\n",
      "Epoch 27 | Train Loss: 0.7365 | Val Loss: 0.6701\n",
      "Epoch 28 | Train Loss: 0.7266 | Val Loss: 0.6620\n",
      "Epoch 29 | Train Loss: 0.7547 | Val Loss: 0.6898\n",
      "Epoch 30 | Train Loss: 0.7677 | Val Loss: 0.7086\n",
      "Epoch 31 | Train Loss: 0.7543 | Val Loss: 0.7631\n",
      "Epoch 32 | Train Loss: 0.7626 | Val Loss: 0.6911\n",
      "Epoch 33 | Train Loss: 0.7371 | Val Loss: 0.6617\n",
      "Epoch 34 | Train Loss: 0.7256 | Val Loss: 0.6741\n",
      "Epoch 35 | Train Loss: 0.7301 | Val Loss: 0.6771\n",
      "Epoch 36 | Train Loss: 0.7189 | Val Loss: 0.6695\n",
      "Epoch 37 | Train Loss: 0.7524 | Val Loss: 0.6714\n",
      "Epoch 38 | Train Loss: 0.7599 | Val Loss: 0.6703\n",
      "Epoch 39 | Train Loss: 0.7364 | Val Loss: 0.6527\n",
      "Epoch 40 | Train Loss: 0.7542 | Val Loss: 0.6874\n",
      "Epoch 41 | Train Loss: 0.7335 | Val Loss: 0.6974\n",
      "Epoch 42 | Train Loss: 0.7177 | Val Loss: 0.6804\n",
      "Epoch 43 | Train Loss: 0.7227 | Val Loss: 0.6781\n",
      "Epoch 44 | Train Loss: 0.7287 | Val Loss: 0.6633\n",
      "Epoch 45 | Train Loss: 0.7212 | Val Loss: 0.6809\n",
      "Epoch 46 | Train Loss: 0.7220 | Val Loss: 0.6637\n",
      "Epoch 47 | Train Loss: 0.7276 | Val Loss: 0.6730\n",
      "Epoch 48 | Train Loss: 0.7579 | Val Loss: 0.7061\n",
      "Epoch 49 | Train Loss: 0.7394 | Val Loss: 0.6776\n",
      "Epoch 50 | Train Loss: 0.7269 | Val Loss: 0.6735\n",
      "Fold 4 ‚ñ∂ AUC: 0.753, Balanced Acc: 0.520\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 1.0065 | Val Loss: 0.9350\n",
      "Epoch 02 | Train Loss: 0.8955 | Val Loss: 0.9141\n",
      "Epoch 03 | Train Loss: 0.8713 | Val Loss: 0.9128\n",
      "Epoch 04 | Train Loss: 0.8615 | Val Loss: 0.8872\n",
      "Epoch 05 | Train Loss: 0.8314 | Val Loss: 0.8659\n",
      "Epoch 06 | Train Loss: 0.8219 | Val Loss: 0.9148\n",
      "Epoch 07 | Train Loss: 0.8155 | Val Loss: 0.9598\n",
      "Epoch 08 | Train Loss: 0.8243 | Val Loss: 0.8683\n",
      "Epoch 09 | Train Loss: 0.7784 | Val Loss: 0.8530\n",
      "Epoch 10 | Train Loss: 0.7525 | Val Loss: 0.8614\n",
      "Epoch 11 | Train Loss: 0.7482 | Val Loss: 0.8877\n",
      "Epoch 12 | Train Loss: 0.8099 | Val Loss: 0.8386\n",
      "Epoch 13 | Train Loss: 0.7533 | Val Loss: 0.8502\n",
      "Epoch 14 | Train Loss: 0.7514 | Val Loss: 0.8415\n",
      "Epoch 15 | Train Loss: 0.7362 | Val Loss: 0.8674\n",
      "Epoch 16 | Train Loss: 0.7539 | Val Loss: 0.8269\n",
      "Epoch 17 | Train Loss: 0.7465 | Val Loss: 0.8581\n",
      "Epoch 18 | Train Loss: 0.7239 | Val Loss: 0.8668\n",
      "Epoch 19 | Train Loss: 0.7278 | Val Loss: 0.8470\n",
      "Epoch 20 | Train Loss: 0.7492 | Val Loss: 0.8282\n",
      "Epoch 21 | Train Loss: 0.7349 | Val Loss: 0.8380\n",
      "Epoch 22 | Train Loss: 0.7371 | Val Loss: 0.8444\n",
      "Epoch 23 | Train Loss: 0.7298 | Val Loss: 0.8729\n",
      "Epoch 24 | Train Loss: 0.7238 | Val Loss: 0.8285\n",
      "Epoch 25 | Train Loss: 0.7206 | Val Loss: 0.8249\n",
      "Epoch 26 | Train Loss: 0.7242 | Val Loss: 0.8206\n",
      "Epoch 27 | Train Loss: 0.7317 | Val Loss: 0.8078\n",
      "Epoch 28 | Train Loss: 0.7404 | Val Loss: 0.8091\n",
      "Epoch 29 | Train Loss: 0.7244 | Val Loss: 0.8273\n",
      "Epoch 30 | Train Loss: 0.7236 | Val Loss: 0.8225\n",
      "Epoch 31 | Train Loss: 0.7520 | Val Loss: 0.8231\n",
      "Epoch 32 | Train Loss: 0.7268 | Val Loss: 0.8107\n",
      "Epoch 33 | Train Loss: 0.7105 | Val Loss: 0.8274\n",
      "Epoch 34 | Train Loss: 0.7843 | Val Loss: 0.8320\n",
      "Epoch 35 | Train Loss: 0.7096 | Val Loss: 0.8233\n",
      "Epoch 36 | Train Loss: 0.7144 | Val Loss: 0.9314\n",
      "Epoch 37 | Train Loss: 0.7612 | Val Loss: 0.8655\n",
      "Epoch 38 | Train Loss: 0.7220 | Val Loss: 0.8211\n",
      "Epoch 39 | Train Loss: 0.7550 | Val Loss: 0.8200\n",
      "Epoch 40 | Train Loss: 0.7477 | Val Loss: 0.8342\n",
      "Epoch 41 | Train Loss: 0.7023 | Val Loss: 0.8195\n",
      "Epoch 42 | Train Loss: 0.7075 | Val Loss: 0.8167\n",
      "Epoch 43 | Train Loss: 0.7063 | Val Loss: 0.8072\n",
      "Epoch 44 | Train Loss: 0.7318 | Val Loss: 0.8041\n",
      "Epoch 45 | Train Loss: 0.7345 | Val Loss: 0.8156\n",
      "Epoch 46 | Train Loss: 0.7293 | Val Loss: 0.8012\n",
      "Epoch 47 | Train Loss: 0.7227 | Val Loss: 0.8247\n",
      "Epoch 48 | Train Loss: 0.7133 | Val Loss: 0.8446\n",
      "Epoch 49 | Train Loss: 0.7158 | Val Loss: 0.8179\n",
      "Epoch 50 | Train Loss: 0.7102 | Val Loss: 0.8635\n",
      "Fold 5 ‚ñ∂ AUC: 0.712, Balanced Acc: 0.442\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9297 | Val Loss: 0.9002\n",
      "Epoch 02 | Train Loss: 0.8926 | Val Loss: 0.9092\n",
      "Epoch 03 | Train Loss: 0.8782 | Val Loss: 0.8928\n",
      "Epoch 04 | Train Loss: 0.8349 | Val Loss: 0.8613\n",
      "Epoch 05 | Train Loss: 0.8145 | Val Loss: 0.8471\n",
      "Epoch 06 | Train Loss: 0.8355 | Val Loss: 0.8364\n",
      "Epoch 07 | Train Loss: 0.7917 | Val Loss: 0.8397\n",
      "Epoch 08 | Train Loss: 0.7530 | Val Loss: 0.8209\n",
      "Epoch 09 | Train Loss: 0.7389 | Val Loss: 0.8305\n",
      "Epoch 10 | Train Loss: 0.8035 | Val Loss: 0.8228\n",
      "Epoch 11 | Train Loss: 0.7754 | Val Loss: 0.8269\n",
      "Epoch 12 | Train Loss: 0.7099 | Val Loss: 0.8239\n",
      "Epoch 13 | Train Loss: 0.7340 | Val Loss: 0.8254\n",
      "Epoch 14 | Train Loss: 0.7183 | Val Loss: 0.8381\n",
      "Epoch 15 | Train Loss: 0.7361 | Val Loss: 0.8172\n",
      "Epoch 16 | Train Loss: 0.7520 | Val Loss: 0.8085\n",
      "Epoch 17 | Train Loss: 0.7391 | Val Loss: 0.8346\n",
      "Epoch 18 | Train Loss: 0.7202 | Val Loss: 0.8184\n",
      "Epoch 19 | Train Loss: 0.7395 | Val Loss: 0.8233\n",
      "Epoch 20 | Train Loss: 0.7325 | Val Loss: 0.8308\n",
      "Epoch 21 | Train Loss: 0.7444 | Val Loss: 0.8283\n",
      "Epoch 22 | Train Loss: 0.7331 | Val Loss: 0.8178\n",
      "Epoch 23 | Train Loss: 0.7113 | Val Loss: 0.8534\n",
      "Epoch 24 | Train Loss: 0.7253 | Val Loss: 0.8362\n",
      "Epoch 25 | Train Loss: 0.7069 | Val Loss: 0.8164\n",
      "Epoch 26 | Train Loss: 0.7292 | Val Loss: 0.8326\n",
      "Epoch 27 | Train Loss: 0.7121 | Val Loss: 0.8176\n",
      "Epoch 28 | Train Loss: 0.6992 | Val Loss: 0.8414\n",
      "Epoch 29 | Train Loss: 0.7241 | Val Loss: 0.8144\n",
      "Epoch 30 | Train Loss: 0.7152 | Val Loss: 0.8305\n",
      "Epoch 31 | Train Loss: 0.6909 | Val Loss: 0.8730\n",
      "Epoch 32 | Train Loss: 0.7001 | Val Loss: 0.8523\n",
      "Epoch 33 | Train Loss: 0.7200 | Val Loss: 0.8282\n",
      "Epoch 34 | Train Loss: 0.7346 | Val Loss: 0.8620\n",
      "Epoch 35 | Train Loss: 0.7429 | Val Loss: 0.8629\n",
      "Epoch 36 | Train Loss: 0.7185 | Val Loss: 0.8701\n",
      "Epoch 37 | Train Loss: 0.7277 | Val Loss: 0.8398\n",
      "Epoch 38 | Train Loss: 0.7348 | Val Loss: 0.8362\n",
      "Epoch 39 | Train Loss: 0.7149 | Val Loss: 0.8158\n",
      "Epoch 40 | Train Loss: 0.7009 | Val Loss: 0.8269\n",
      "Epoch 41 | Train Loss: 0.7381 | Val Loss: 0.8052\n",
      "Epoch 42 | Train Loss: 0.6898 | Val Loss: 0.8259\n",
      "Epoch 43 | Train Loss: 0.6901 | Val Loss: 0.8323\n",
      "Epoch 44 | Train Loss: 0.6957 | Val Loss: 0.8259\n",
      "Epoch 45 | Train Loss: 0.7181 | Val Loss: 0.8263\n",
      "Epoch 46 | Train Loss: 0.7069 | Val Loss: 0.8288\n",
      "Epoch 47 | Train Loss: 0.7071 | Val Loss: 0.8863\n",
      "Epoch 48 | Train Loss: 0.7027 | Val Loss: 0.8040\n",
      "Epoch 49 | Train Loss: 0.7010 | Val Loss: 0.8363\n",
      "Epoch 50 | Train Loss: 0.7084 | Val Loss: 0.8740\n",
      "Fold 6 ‚ñ∂ AUC: 0.728, Balanced Acc: 0.440\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9730 | Val Loss: 0.8773\n",
      "Epoch 02 | Train Loss: 0.8842 | Val Loss: 0.8495\n",
      "Epoch 03 | Train Loss: 0.8580 | Val Loss: 0.8774\n",
      "Epoch 04 | Train Loss: 0.8497 | Val Loss: 0.8097\n",
      "Epoch 05 | Train Loss: 0.8247 | Val Loss: 0.8027\n",
      "Epoch 06 | Train Loss: 0.8130 | Val Loss: 0.7748\n",
      "Epoch 07 | Train Loss: 0.8449 | Val Loss: 0.7686\n",
      "Epoch 08 | Train Loss: 0.7914 | Val Loss: 0.7267\n",
      "Epoch 09 | Train Loss: 0.7678 | Val Loss: 0.7392\n",
      "Epoch 10 | Train Loss: 0.7774 | Val Loss: 0.7146\n",
      "Epoch 11 | Train Loss: 0.7605 | Val Loss: 0.7853\n",
      "Epoch 12 | Train Loss: 0.7695 | Val Loss: 0.7626\n",
      "Epoch 13 | Train Loss: 0.7699 | Val Loss: 0.7139\n",
      "Epoch 14 | Train Loss: 0.7382 | Val Loss: 0.7935\n",
      "Epoch 15 | Train Loss: 0.7620 | Val Loss: 0.7595\n",
      "Epoch 16 | Train Loss: 0.7511 | Val Loss: 0.6920\n",
      "Epoch 17 | Train Loss: 0.7588 | Val Loss: 0.7363\n",
      "Epoch 18 | Train Loss: 0.7582 | Val Loss: 0.7747\n",
      "Epoch 19 | Train Loss: 0.7803 | Val Loss: 0.7554\n",
      "Epoch 20 | Train Loss: 0.7529 | Val Loss: 0.7276\n",
      "Epoch 21 | Train Loss: 0.7377 | Val Loss: 0.7106\n",
      "Epoch 22 | Train Loss: 0.7369 | Val Loss: 0.7747\n",
      "Epoch 23 | Train Loss: 0.7518 | Val Loss: 0.7265\n",
      "Epoch 24 | Train Loss: 0.7408 | Val Loss: 0.7410\n",
      "Epoch 25 | Train Loss: 0.7321 | Val Loss: 0.7105\n",
      "Epoch 26 | Train Loss: 0.7380 | Val Loss: 0.7236\n",
      "Epoch 27 | Train Loss: 0.7140 | Val Loss: 0.7468\n",
      "Epoch 28 | Train Loss: 0.7533 | Val Loss: 0.7460\n",
      "Epoch 29 | Train Loss: 0.7455 | Val Loss: 0.7158\n",
      "Epoch 30 | Train Loss: 0.7183 | Val Loss: 0.7069\n",
      "Epoch 31 | Train Loss: 0.7307 | Val Loss: 0.7296\n",
      "Epoch 32 | Train Loss: 0.7248 | Val Loss: 0.7244\n",
      "Epoch 33 | Train Loss: 0.7294 | Val Loss: 0.7184\n",
      "Epoch 34 | Train Loss: 0.7438 | Val Loss: 0.7149\n",
      "Epoch 35 | Train Loss: 0.7240 | Val Loss: 0.7271\n",
      "Epoch 36 | Train Loss: 0.7132 | Val Loss: 0.7233\n",
      "Epoch 37 | Train Loss: 0.7318 | Val Loss: 0.7247\n",
      "Epoch 38 | Train Loss: 0.7059 | Val Loss: 0.7330\n",
      "Epoch 39 | Train Loss: 0.7217 | Val Loss: 0.8041\n",
      "Epoch 40 | Train Loss: 0.7340 | Val Loss: 0.7134\n",
      "Epoch 41 | Train Loss: 0.7469 | Val Loss: 0.7388\n",
      "Epoch 42 | Train Loss: 0.7177 | Val Loss: 0.7375\n",
      "Epoch 43 | Train Loss: 0.7722 | Val Loss: 0.7519\n",
      "Epoch 44 | Train Loss: 0.7661 | Val Loss: 0.7406\n",
      "Epoch 45 | Train Loss: 0.7137 | Val Loss: 0.7122\n",
      "Epoch 46 | Train Loss: 0.6988 | Val Loss: 0.7261\n",
      "Epoch 47 | Train Loss: 0.7124 | Val Loss: 0.7279\n",
      "Epoch 48 | Train Loss: 0.7308 | Val Loss: 0.7230\n",
      "Epoch 49 | Train Loss: 0.7149 | Val Loss: 0.7569\n",
      "Epoch 50 | Train Loss: 0.7411 | Val Loss: 0.7390\n",
      "Fold 7 ‚ñ∂ AUC: 0.780, Balanced Acc: 0.456\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9564 | Val Loss: 0.8892\n",
      "Epoch 02 | Train Loss: 0.8828 | Val Loss: 0.8681\n",
      "Epoch 03 | Train Loss: 0.8687 | Val Loss: 0.8713\n",
      "Epoch 04 | Train Loss: 0.8565 | Val Loss: 0.8485\n",
      "Epoch 05 | Train Loss: 0.7957 | Val Loss: 0.8468\n",
      "Epoch 06 | Train Loss: 0.7680 | Val Loss: 0.8753\n",
      "Epoch 07 | Train Loss: 0.8124 | Val Loss: 0.8603\n",
      "Epoch 08 | Train Loss: 0.7925 | Val Loss: 0.8090\n",
      "Epoch 09 | Train Loss: 0.7677 | Val Loss: 0.8086\n",
      "Epoch 10 | Train Loss: 0.7415 | Val Loss: 0.7982\n",
      "Epoch 11 | Train Loss: 0.7511 | Val Loss: 0.8109\n",
      "Epoch 12 | Train Loss: 0.7301 | Val Loss: 0.8016\n",
      "Epoch 13 | Train Loss: 0.7295 | Val Loss: 0.8046\n",
      "Epoch 14 | Train Loss: 0.7347 | Val Loss: 0.8280\n",
      "Epoch 15 | Train Loss: 0.7435 | Val Loss: 0.8792\n",
      "Epoch 16 | Train Loss: 0.8048 | Val Loss: 0.8293\n",
      "Epoch 17 | Train Loss: 0.7465 | Val Loss: 0.8204\n",
      "Epoch 18 | Train Loss: 0.7360 | Val Loss: 0.8359\n",
      "Epoch 19 | Train Loss: 0.7479 | Val Loss: 0.7967\n",
      "Epoch 20 | Train Loss: 0.7326 | Val Loss: 0.8270\n",
      "Epoch 21 | Train Loss: 0.7264 | Val Loss: 0.8249\n",
      "Epoch 22 | Train Loss: 0.7370 | Val Loss: 0.8259\n",
      "Epoch 23 | Train Loss: 0.7329 | Val Loss: 0.8131\n",
      "Epoch 24 | Train Loss: 0.7497 | Val Loss: 0.8165\n",
      "Epoch 25 | Train Loss: 0.7645 | Val Loss: 0.8611\n",
      "Epoch 26 | Train Loss: 0.7215 | Val Loss: 0.8122\n",
      "Epoch 27 | Train Loss: 0.7370 | Val Loss: 0.8384\n",
      "Epoch 28 | Train Loss: 0.7169 | Val Loss: 0.8119\n",
      "Epoch 29 | Train Loss: 0.7197 | Val Loss: 0.8152\n",
      "Epoch 30 | Train Loss: 0.7202 | Val Loss: 0.8315\n",
      "Epoch 31 | Train Loss: 0.7275 | Val Loss: 0.8141\n",
      "Epoch 32 | Train Loss: 0.7737 | Val Loss: 0.8239\n",
      "Epoch 33 | Train Loss: 0.7195 | Val Loss: 0.8220\n",
      "Epoch 34 | Train Loss: 0.7382 | Val Loss: 0.8151\n",
      "Epoch 35 | Train Loss: 0.7233 | Val Loss: 0.8131\n",
      "Epoch 36 | Train Loss: 0.7262 | Val Loss: 0.8344\n",
      "Epoch 37 | Train Loss: 0.7305 | Val Loss: 0.8220\n",
      "Epoch 38 | Train Loss: 0.7172 | Val Loss: 0.8332\n",
      "Epoch 39 | Train Loss: 0.7517 | Val Loss: 0.8200\n",
      "Epoch 40 | Train Loss: 0.7207 | Val Loss: 0.8173\n",
      "Epoch 41 | Train Loss: 0.7104 | Val Loss: 0.8197\n",
      "Epoch 42 | Train Loss: 0.7199 | Val Loss: 0.8566\n",
      "Epoch 43 | Train Loss: 0.7131 | Val Loss: 0.8255\n",
      "Epoch 44 | Train Loss: 0.7247 | Val Loss: 0.8243\n",
      "Epoch 45 | Train Loss: 0.7049 | Val Loss: 0.8206\n",
      "Epoch 46 | Train Loss: 0.7167 | Val Loss: 0.8271\n",
      "Epoch 47 | Train Loss: 0.7109 | Val Loss: 0.8314\n",
      "Epoch 48 | Train Loss: 0.7073 | Val Loss: 0.8540\n",
      "Epoch 49 | Train Loss: 0.7213 | Val Loss: 0.8538\n",
      "Epoch 50 | Train Loss: 0.7399 | Val Loss: 0.8325\n",
      "Fold 8 ‚ñ∂ AUC: 0.681, Balanced Acc: 0.420\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 1.0185 | Val Loss: 0.8755\n",
      "Epoch 02 | Train Loss: 0.8792 | Val Loss: 0.8685\n",
      "Epoch 03 | Train Loss: 0.8927 | Val Loss: 0.8656\n",
      "Epoch 04 | Train Loss: 0.8450 | Val Loss: 0.8519\n",
      "Epoch 05 | Train Loss: 0.8372 | Val Loss: 0.8513\n",
      "Epoch 06 | Train Loss: 0.8205 | Val Loss: 0.8302\n",
      "Epoch 07 | Train Loss: 0.8103 | Val Loss: 0.9324\n",
      "Epoch 08 | Train Loss: 0.8118 | Val Loss: 0.8228\n",
      "Epoch 09 | Train Loss: 0.7961 | Val Loss: 0.7895\n",
      "Epoch 10 | Train Loss: 0.7707 | Val Loss: 0.7858\n",
      "Epoch 11 | Train Loss: 0.7746 | Val Loss: 0.8214\n",
      "Epoch 12 | Train Loss: 0.7802 | Val Loss: 0.7741\n",
      "Epoch 13 | Train Loss: 0.7665 | Val Loss: 0.7841\n",
      "Epoch 14 | Train Loss: 0.7444 | Val Loss: 0.7688\n",
      "Epoch 15 | Train Loss: 0.7809 | Val Loss: 0.7519\n",
      "Epoch 16 | Train Loss: 0.7533 | Val Loss: 0.7770\n",
      "Epoch 17 | Train Loss: 0.7720 | Val Loss: 0.8231\n",
      "Epoch 18 | Train Loss: 0.7806 | Val Loss: 0.7453\n",
      "Epoch 19 | Train Loss: 0.7621 | Val Loss: 0.7396\n",
      "Epoch 20 | Train Loss: 0.7402 | Val Loss: 0.7538\n",
      "Epoch 21 | Train Loss: 0.7364 | Val Loss: 0.7687\n",
      "Epoch 22 | Train Loss: 0.7500 | Val Loss: 0.7437\n",
      "Epoch 23 | Train Loss: 0.7418 | Val Loss: 0.8014\n",
      "Epoch 24 | Train Loss: 0.7473 | Val Loss: 0.7667\n",
      "Epoch 25 | Train Loss: 0.7194 | Val Loss: 0.7401\n",
      "Epoch 26 | Train Loss: 0.7714 | Val Loss: 0.7253\n",
      "Epoch 27 | Train Loss: 0.7320 | Val Loss: 0.7465\n",
      "Epoch 28 | Train Loss: 0.7457 | Val Loss: 0.7537\n",
      "Epoch 29 | Train Loss: 0.7462 | Val Loss: 0.7492\n",
      "Epoch 30 | Train Loss: 0.7219 | Val Loss: 0.7390\n",
      "Epoch 31 | Train Loss: 0.7266 | Val Loss: 0.7642\n",
      "Epoch 32 | Train Loss: 0.7156 | Val Loss: 0.7216\n",
      "Epoch 33 | Train Loss: 0.7135 | Val Loss: 0.7551\n",
      "Epoch 34 | Train Loss: 0.7306 | Val Loss: 0.7513\n",
      "Epoch 35 | Train Loss: 0.7446 | Val Loss: 0.7615\n",
      "Epoch 36 | Train Loss: 0.7125 | Val Loss: 0.7281\n",
      "Epoch 37 | Train Loss: 0.7225 | Val Loss: 0.7394\n",
      "Epoch 38 | Train Loss: 0.7189 | Val Loss: 0.7514\n",
      "Epoch 39 | Train Loss: 0.7413 | Val Loss: 0.7829\n",
      "Epoch 40 | Train Loss: 0.7440 | Val Loss: 0.7543\n",
      "Epoch 41 | Train Loss: 0.7253 | Val Loss: 0.7273\n",
      "Epoch 42 | Train Loss: 0.7472 | Val Loss: 0.7675\n",
      "Epoch 43 | Train Loss: 0.7217 | Val Loss: 0.7288\n",
      "Epoch 44 | Train Loss: 0.7112 | Val Loss: 0.7802\n",
      "Epoch 45 | Train Loss: 0.7379 | Val Loss: 0.7438\n",
      "Epoch 46 | Train Loss: 0.7337 | Val Loss: 0.7656\n",
      "Epoch 47 | Train Loss: 0.7068 | Val Loss: 0.7534\n",
      "Epoch 48 | Train Loss: 0.7198 | Val Loss: 0.7278\n",
      "Epoch 49 | Train Loss: 0.7087 | Val Loss: 0.7369\n",
      "Epoch 50 | Train Loss: 0.7270 | Val Loss: 0.7480\n",
      "Fold 9 ‚ñ∂ AUC: 0.768, Balanced Acc: 0.481\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9403 | Val Loss: 0.8646\n",
      "Epoch 02 | Train Loss: 0.9077 | Val Loss: 0.8604\n",
      "Epoch 03 | Train Loss: 0.8668 | Val Loss: 0.8358\n",
      "Epoch 04 | Train Loss: 0.8255 | Val Loss: 0.9208\n",
      "Epoch 05 | Train Loss: 0.8984 | Val Loss: 0.8871\n",
      "Epoch 06 | Train Loss: 0.8627 | Val Loss: 0.8071\n",
      "Epoch 07 | Train Loss: 0.7840 | Val Loss: 0.8257\n",
      "Epoch 08 | Train Loss: 0.7997 | Val Loss: 0.8742\n",
      "Epoch 09 | Train Loss: 0.8238 | Val Loss: 0.7864\n",
      "Epoch 10 | Train Loss: 0.7719 | Val Loss: 0.7766\n",
      "Epoch 11 | Train Loss: 0.7690 | Val Loss: 0.7888\n",
      "Epoch 12 | Train Loss: 0.7508 | Val Loss: 0.7684\n",
      "Epoch 13 | Train Loss: 0.7484 | Val Loss: 0.7871\n",
      "Epoch 14 | Train Loss: 0.7593 | Val Loss: 0.7664\n",
      "Epoch 15 | Train Loss: 0.7296 | Val Loss: 0.8071\n",
      "Epoch 16 | Train Loss: 0.7370 | Val Loss: 0.7805\n",
      "Epoch 17 | Train Loss: 0.7519 | Val Loss: 0.7705\n",
      "Epoch 18 | Train Loss: 0.7454 | Val Loss: 0.7827\n",
      "Epoch 19 | Train Loss: 0.7317 | Val Loss: 0.8028\n",
      "Epoch 20 | Train Loss: 0.7548 | Val Loss: 0.7764\n",
      "Epoch 21 | Train Loss: 0.7396 | Val Loss: 0.7683\n",
      "Epoch 22 | Train Loss: 0.7194 | Val Loss: 0.7788\n",
      "Epoch 23 | Train Loss: 0.7380 | Val Loss: 0.7686\n",
      "Epoch 24 | Train Loss: 0.7307 | Val Loss: 0.8345\n",
      "Epoch 25 | Train Loss: 0.7455 | Val Loss: 0.7804\n",
      "Epoch 26 | Train Loss: 0.7165 | Val Loss: 0.7764\n",
      "Epoch 27 | Train Loss: 0.7168 | Val Loss: 0.7754\n",
      "Epoch 28 | Train Loss: 0.7133 | Val Loss: 0.7963\n",
      "Epoch 29 | Train Loss: 0.7200 | Val Loss: 0.8055\n",
      "Epoch 30 | Train Loss: 0.7362 | Val Loss: 0.8131\n",
      "Epoch 31 | Train Loss: 0.7264 | Val Loss: 0.7765\n",
      "Epoch 32 | Train Loss: 0.7152 | Val Loss: 0.7688\n",
      "Epoch 33 | Train Loss: 0.7135 | Val Loss: 0.7751\n",
      "Epoch 34 | Train Loss: 0.7190 | Val Loss: 0.8034\n",
      "Epoch 35 | Train Loss: 0.7123 | Val Loss: 0.7893\n",
      "Epoch 36 | Train Loss: 0.7185 | Val Loss: 0.7805\n",
      "Epoch 37 | Train Loss: 0.7206 | Val Loss: 0.7642\n",
      "Epoch 38 | Train Loss: 0.7183 | Val Loss: 0.8222\n",
      "Epoch 39 | Train Loss: 0.7155 | Val Loss: 0.8096\n",
      "Epoch 40 | Train Loss: 0.7206 | Val Loss: 0.7671\n",
      "Epoch 41 | Train Loss: 0.7191 | Val Loss: 0.7820\n",
      "Epoch 42 | Train Loss: 0.7186 | Val Loss: 0.7734\n",
      "Epoch 43 | Train Loss: 0.7236 | Val Loss: 0.7769\n",
      "Epoch 44 | Train Loss: 0.7102 | Val Loss: 0.7688\n",
      "Epoch 45 | Train Loss: 0.6953 | Val Loss: 0.7663\n",
      "Epoch 46 | Train Loss: 0.7357 | Val Loss: 0.7709\n",
      "Epoch 47 | Train Loss: 0.7241 | Val Loss: 0.7907\n",
      "Epoch 48 | Train Loss: 0.7071 | Val Loss: 0.7584\n",
      "Epoch 49 | Train Loss: 0.7143 | Val Loss: 0.8098\n",
      "Epoch 50 | Train Loss: 0.7022 | Val Loss: 0.7762\n",
      "Fold 10 ‚ñ∂ AUC: 0.727, Balanced Acc: 0.434\n",
      "üîç Summary for hd=256, dp=0.2, lr=0.001 ‚Üí AUC: 0.7438¬±0.0323 | BalAcc: 0.4745¬±0.0432\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.2, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9103 | Val Loss: 0.9196\n",
      "Epoch 02 | Train Loss: 0.8805 | Val Loss: 0.8470\n",
      "Epoch 03 | Train Loss: 0.8511 | Val Loss: 0.8324\n",
      "Epoch 04 | Train Loss: 0.8432 | Val Loss: 0.8169\n",
      "Epoch 05 | Train Loss: 0.8285 | Val Loss: 0.9052\n",
      "Epoch 06 | Train Loss: 0.8651 | Val Loss: 0.7971\n",
      "Epoch 07 | Train Loss: 0.8206 | Val Loss: 0.7879\n",
      "Epoch 08 | Train Loss: 0.8106 | Val Loss: 0.8144\n",
      "Epoch 09 | Train Loss: 0.8093 | Val Loss: 0.7658\n",
      "Epoch 10 | Train Loss: 0.7795 | Val Loss: 0.7494\n",
      "Epoch 11 | Train Loss: 0.7625 | Val Loss: 0.7296\n",
      "Epoch 12 | Train Loss: 0.7799 | Val Loss: 0.7284\n",
      "Epoch 13 | Train Loss: 0.7942 | Val Loss: 0.7234\n",
      "Epoch 14 | Train Loss: 0.8530 | Val Loss: 0.7693\n",
      "Epoch 15 | Train Loss: 0.7660 | Val Loss: 0.7306\n",
      "Epoch 16 | Train Loss: 0.7437 | Val Loss: 0.7090\n",
      "Epoch 17 | Train Loss: 0.7286 | Val Loss: 0.7047\n",
      "Epoch 18 | Train Loss: 0.7423 | Val Loss: 0.6962\n",
      "Epoch 19 | Train Loss: 0.7377 | Val Loss: 0.7255\n",
      "Epoch 20 | Train Loss: 0.7466 | Val Loss: 0.6868\n",
      "Epoch 21 | Train Loss: 0.7614 | Val Loss: 0.6916\n",
      "Epoch 22 | Train Loss: 0.7747 | Val Loss: 0.7506\n",
      "Epoch 23 | Train Loss: 0.7304 | Val Loss: 0.6921\n",
      "Epoch 24 | Train Loss: 0.7489 | Val Loss: 0.6841\n",
      "Epoch 25 | Train Loss: 0.7340 | Val Loss: 0.6864\n",
      "Epoch 26 | Train Loss: 0.7477 | Val Loss: 0.7006\n",
      "Epoch 27 | Train Loss: 0.7530 | Val Loss: 0.6846\n",
      "Epoch 28 | Train Loss: 0.7380 | Val Loss: 0.6815\n",
      "Epoch 29 | Train Loss: 0.7371 | Val Loss: 0.6803\n",
      "Epoch 30 | Train Loss: 0.7378 | Val Loss: 0.6893\n",
      "Epoch 31 | Train Loss: 0.7399 | Val Loss: 0.6883\n",
      "Epoch 32 | Train Loss: 0.7518 | Val Loss: 0.6993\n",
      "Epoch 33 | Train Loss: 0.7291 | Val Loss: 0.6903\n",
      "Epoch 34 | Train Loss: 0.7284 | Val Loss: 0.6787\n",
      "Epoch 35 | Train Loss: 0.7472 | Val Loss: 0.6930\n",
      "Epoch 36 | Train Loss: 0.7517 | Val Loss: 0.7034\n",
      "Epoch 37 | Train Loss: 0.7357 | Val Loss: 0.7031\n",
      "Epoch 38 | Train Loss: 0.7398 | Val Loss: 0.7134\n",
      "Epoch 39 | Train Loss: 0.7263 | Val Loss: 0.6723\n",
      "Epoch 40 | Train Loss: 0.7285 | Val Loss: 0.6723\n",
      "Epoch 41 | Train Loss: 0.7012 | Val Loss: 0.6776\n",
      "Epoch 42 | Train Loss: 0.7314 | Val Loss: 0.6792\n",
      "Epoch 43 | Train Loss: 0.7310 | Val Loss: 0.6759\n",
      "Epoch 44 | Train Loss: 0.7203 | Val Loss: 0.6775\n",
      "Epoch 45 | Train Loss: 0.7164 | Val Loss: 0.6790\n",
      "Epoch 46 | Train Loss: 0.7184 | Val Loss: 0.6726\n",
      "Epoch 47 | Train Loss: 0.7049 | Val Loss: 0.6703\n",
      "Epoch 48 | Train Loss: 0.7093 | Val Loss: 0.7170\n",
      "Epoch 49 | Train Loss: 0.7280 | Val Loss: 0.6817\n",
      "Epoch 50 | Train Loss: 0.7303 | Val Loss: 0.6731\n",
      "Fold 1 ‚ñ∂ AUC: 0.799, Balanced Acc: 0.510\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9510 | Val Loss: 0.8720\n",
      "Epoch 02 | Train Loss: 0.8785 | Val Loss: 0.8568\n",
      "Epoch 03 | Train Loss: 0.8750 | Val Loss: 0.8472\n",
      "Epoch 04 | Train Loss: 0.8490 | Val Loss: 0.8352\n",
      "Epoch 05 | Train Loss: 0.8397 | Val Loss: 0.8153\n",
      "Epoch 06 | Train Loss: 0.8143 | Val Loss: 0.7977\n",
      "Epoch 07 | Train Loss: 0.8253 | Val Loss: 0.7673\n",
      "Epoch 08 | Train Loss: 0.8036 | Val Loss: 0.8377\n",
      "Epoch 09 | Train Loss: 0.8155 | Val Loss: 0.8756\n",
      "Epoch 10 | Train Loss: 0.8019 | Val Loss: 0.8174\n",
      "Epoch 11 | Train Loss: 0.7829 | Val Loss: 0.7274\n",
      "Epoch 12 | Train Loss: 0.7623 | Val Loss: 0.7198\n",
      "Epoch 13 | Train Loss: 0.7848 | Val Loss: 0.7069\n",
      "Epoch 14 | Train Loss: 0.7483 | Val Loss: 0.7088\n",
      "Epoch 15 | Train Loss: 0.7463 | Val Loss: 0.7083\n",
      "Epoch 16 | Train Loss: 0.7633 | Val Loss: 0.6993\n",
      "Epoch 17 | Train Loss: 0.7460 | Val Loss: 0.7136\n",
      "Epoch 18 | Train Loss: 0.7541 | Val Loss: 0.7071\n",
      "Epoch 19 | Train Loss: 0.7334 | Val Loss: 0.7387\n",
      "Epoch 20 | Train Loss: 0.7507 | Val Loss: 0.8617\n",
      "Epoch 21 | Train Loss: 0.7520 | Val Loss: 0.7446\n",
      "Epoch 22 | Train Loss: 0.7556 | Val Loss: 0.7473\n",
      "Epoch 23 | Train Loss: 0.7321 | Val Loss: 0.8405\n",
      "Epoch 24 | Train Loss: 0.7507 | Val Loss: 0.7289\n",
      "Epoch 25 | Train Loss: 0.7409 | Val Loss: 0.7007\n",
      "Epoch 26 | Train Loss: 0.7187 | Val Loss: 0.7129\n",
      "Epoch 27 | Train Loss: 0.7221 | Val Loss: 0.7422\n",
      "Epoch 28 | Train Loss: 0.7438 | Val Loss: 0.7064\n",
      "Epoch 29 | Train Loss: 0.7413 | Val Loss: 0.7152\n",
      "Epoch 30 | Train Loss: 0.7520 | Val Loss: 0.6878\n",
      "Epoch 31 | Train Loss: 0.7188 | Val Loss: 0.7247\n",
      "Epoch 32 | Train Loss: 0.7130 | Val Loss: 0.7642\n",
      "Epoch 33 | Train Loss: 0.7295 | Val Loss: 0.7047\n",
      "Epoch 34 | Train Loss: 0.7378 | Val Loss: 0.7220\n",
      "Epoch 35 | Train Loss: 0.7469 | Val Loss: 0.7535\n",
      "Epoch 36 | Train Loss: 0.7393 | Val Loss: 0.7424\n",
      "Epoch 37 | Train Loss: 0.7249 | Val Loss: 0.7265\n",
      "Epoch 38 | Train Loss: 0.7101 | Val Loss: 0.7325\n",
      "Epoch 39 | Train Loss: 0.7209 | Val Loss: 0.7273\n",
      "Epoch 40 | Train Loss: 0.7404 | Val Loss: 0.7750\n",
      "Epoch 41 | Train Loss: 0.7360 | Val Loss: 0.7495\n",
      "Epoch 42 | Train Loss: 0.7249 | Val Loss: 0.7017\n",
      "Epoch 43 | Train Loss: 0.7151 | Val Loss: 0.7060\n",
      "Epoch 44 | Train Loss: 0.7192 | Val Loss: 0.7326\n",
      "Epoch 45 | Train Loss: 0.7184 | Val Loss: 0.7284\n",
      "Epoch 46 | Train Loss: 0.7157 | Val Loss: 0.7371\n",
      "Epoch 47 | Train Loss: 0.7125 | Val Loss: 0.7379\n",
      "Epoch 48 | Train Loss: 0.7333 | Val Loss: 0.6867\n",
      "Epoch 49 | Train Loss: 0.7349 | Val Loss: 0.8144\n",
      "Epoch 50 | Train Loss: 0.7249 | Val Loss: 0.8259\n",
      "Fold 2 ‚ñ∂ AUC: 0.664, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9075 | Val Loss: 0.8683\n",
      "Epoch 02 | Train Loss: 0.8713 | Val Loss: 0.8390\n",
      "Epoch 03 | Train Loss: 0.8769 | Val Loss: 0.8528\n",
      "Epoch 04 | Train Loss: 0.8584 | Val Loss: 0.8821\n",
      "Epoch 05 | Train Loss: 0.8563 | Val Loss: 0.8181\n",
      "Epoch 06 | Train Loss: 0.8476 | Val Loss: 0.8086\n",
      "Epoch 07 | Train Loss: 0.8218 | Val Loss: 0.8193\n",
      "Epoch 08 | Train Loss: 0.8151 | Val Loss: 0.8393\n",
      "Epoch 09 | Train Loss: 0.7799 | Val Loss: 0.7579\n",
      "Epoch 10 | Train Loss: 0.7526 | Val Loss: 0.7613\n",
      "Epoch 11 | Train Loss: 0.7676 | Val Loss: 0.7417\n",
      "Epoch 12 | Train Loss: 0.7401 | Val Loss: 0.7405\n",
      "Epoch 13 | Train Loss: 0.7473 | Val Loss: 0.7484\n",
      "Epoch 14 | Train Loss: 0.7323 | Val Loss: 0.8375\n",
      "Epoch 15 | Train Loss: 0.7505 | Val Loss: 0.7857\n",
      "Epoch 16 | Train Loss: 0.7551 | Val Loss: 0.7387\n",
      "Epoch 17 | Train Loss: 0.7659 | Val Loss: 0.7474\n",
      "Epoch 18 | Train Loss: 0.7399 | Val Loss: 0.7520\n",
      "Epoch 19 | Train Loss: 0.7541 | Val Loss: 0.7325\n",
      "Epoch 20 | Train Loss: 0.7316 | Val Loss: 0.7545\n",
      "Epoch 21 | Train Loss: 0.7480 | Val Loss: 0.7188\n",
      "Epoch 22 | Train Loss: 0.7212 | Val Loss: 0.7135\n",
      "Epoch 23 | Train Loss: 0.7198 | Val Loss: 0.7177\n",
      "Epoch 24 | Train Loss: 0.7613 | Val Loss: 0.7411\n",
      "Epoch 25 | Train Loss: 0.7560 | Val Loss: 0.7252\n",
      "Epoch 26 | Train Loss: 0.7270 | Val Loss: 0.7360\n",
      "Epoch 27 | Train Loss: 0.7466 | Val Loss: 0.7278\n",
      "Epoch 28 | Train Loss: 0.7322 | Val Loss: 0.7387\n",
      "Epoch 29 | Train Loss: 0.7282 | Val Loss: 0.8062\n",
      "Epoch 30 | Train Loss: 0.7494 | Val Loss: 0.7210\n",
      "Epoch 31 | Train Loss: 0.7361 | Val Loss: 0.7178\n",
      "Epoch 32 | Train Loss: 0.7324 | Val Loss: 0.7171\n",
      "Epoch 33 | Train Loss: 0.7333 | Val Loss: 0.7217\n",
      "Epoch 34 | Train Loss: 0.7006 | Val Loss: 0.7144\n",
      "Epoch 35 | Train Loss: 0.7241 | Val Loss: 0.7113\n",
      "Epoch 36 | Train Loss: 0.7382 | Val Loss: 0.8063\n",
      "Epoch 37 | Train Loss: 0.7147 | Val Loss: 0.7176\n",
      "Epoch 38 | Train Loss: 0.7050 | Val Loss: 0.7122\n",
      "Epoch 39 | Train Loss: 0.7066 | Val Loss: 0.7107\n",
      "Epoch 40 | Train Loss: 0.7190 | Val Loss: 0.7186\n",
      "Epoch 41 | Train Loss: 0.7331 | Val Loss: 0.7258\n",
      "Epoch 42 | Train Loss: 0.7155 | Val Loss: 0.7234\n",
      "Epoch 43 | Train Loss: 0.6947 | Val Loss: 0.7282\n",
      "Epoch 44 | Train Loss: 0.7200 | Val Loss: 0.7180\n",
      "Epoch 45 | Train Loss: 0.7155 | Val Loss: 0.7195\n",
      "Epoch 46 | Train Loss: 0.7008 | Val Loss: 0.7332\n",
      "Epoch 47 | Train Loss: 0.7183 | Val Loss: 0.7199\n",
      "Epoch 48 | Train Loss: 0.7105 | Val Loss: 0.7073\n",
      "Epoch 49 | Train Loss: 0.6976 | Val Loss: 0.7129\n",
      "Epoch 50 | Train Loss: 0.6888 | Val Loss: 0.7075\n",
      "Fold 3 ‚ñ∂ AUC: 0.780, Balanced Acc: 0.480\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9429 | Val Loss: 0.8380\n",
      "Epoch 02 | Train Loss: 0.8786 | Val Loss: 0.8496\n",
      "Epoch 03 | Train Loss: 0.8823 | Val Loss: 0.8567\n",
      "Epoch 04 | Train Loss: 0.8425 | Val Loss: 0.8163\n",
      "Epoch 05 | Train Loss: 0.8229 | Val Loss: 0.8055\n",
      "Epoch 06 | Train Loss: 0.8500 | Val Loss: 0.7792\n",
      "Epoch 07 | Train Loss: 0.7942 | Val Loss: 0.7787\n",
      "Epoch 08 | Train Loss: 0.7809 | Val Loss: 0.7504\n",
      "Epoch 09 | Train Loss: 0.7773 | Val Loss: 0.7638\n",
      "Epoch 10 | Train Loss: 0.7954 | Val Loss: 0.7264\n",
      "Epoch 11 | Train Loss: 0.7738 | Val Loss: 0.7097\n",
      "Epoch 12 | Train Loss: 0.7677 | Val Loss: 0.7009\n",
      "Epoch 13 | Train Loss: 0.8110 | Val Loss: 0.7644\n",
      "Epoch 14 | Train Loss: 0.7639 | Val Loss: 0.6978\n",
      "Epoch 15 | Train Loss: 0.7477 | Val Loss: 0.6799\n",
      "Epoch 16 | Train Loss: 0.7373 | Val Loss: 0.6825\n",
      "Epoch 17 | Train Loss: 0.7441 | Val Loss: 0.6769\n",
      "Epoch 18 | Train Loss: 0.7558 | Val Loss: 0.6741\n",
      "Epoch 19 | Train Loss: 0.7415 | Val Loss: 0.6746\n",
      "Epoch 20 | Train Loss: 0.7374 | Val Loss: 0.6713\n",
      "Epoch 21 | Train Loss: 0.7275 | Val Loss: 0.6930\n",
      "Epoch 22 | Train Loss: 0.7746 | Val Loss: 0.6690\n",
      "Epoch 23 | Train Loss: 0.7425 | Val Loss: 0.6856\n",
      "Epoch 24 | Train Loss: 0.7410 | Val Loss: 0.6714\n",
      "Epoch 25 | Train Loss: 0.7444 | Val Loss: 0.6862\n",
      "Epoch 26 | Train Loss: 0.7746 | Val Loss: 0.7810\n",
      "Epoch 27 | Train Loss: 0.7320 | Val Loss: 0.6819\n",
      "Epoch 28 | Train Loss: 0.7286 | Val Loss: 0.6724\n",
      "Epoch 29 | Train Loss: 0.7225 | Val Loss: 0.6820\n",
      "Epoch 30 | Train Loss: 0.7329 | Val Loss: 0.7062\n",
      "Epoch 31 | Train Loss: 0.7297 | Val Loss: 0.6803\n",
      "Epoch 32 | Train Loss: 0.7253 | Val Loss: 0.7047\n",
      "Epoch 33 | Train Loss: 0.7500 | Val Loss: 0.6752\n",
      "Epoch 34 | Train Loss: 0.7217 | Val Loss: 0.6852\n",
      "Epoch 35 | Train Loss: 0.7266 | Val Loss: 0.6616\n",
      "Epoch 36 | Train Loss: 0.7321 | Val Loss: 0.7157\n",
      "Epoch 37 | Train Loss: 0.7447 | Val Loss: 0.6921\n",
      "Epoch 38 | Train Loss: 0.7197 | Val Loss: 0.7042\n",
      "Epoch 39 | Train Loss: 0.7374 | Val Loss: 0.7076\n",
      "Epoch 40 | Train Loss: 0.7151 | Val Loss: 0.6747\n",
      "Epoch 41 | Train Loss: 0.7498 | Val Loss: 0.7092\n",
      "Epoch 42 | Train Loss: 0.7214 | Val Loss: 0.6775\n",
      "Epoch 43 | Train Loss: 0.7194 | Val Loss: 0.7009\n",
      "Epoch 44 | Train Loss: 0.7139 | Val Loss: 0.7093\n",
      "Epoch 45 | Train Loss: 0.7115 | Val Loss: 0.7026\n",
      "Epoch 46 | Train Loss: 0.7390 | Val Loss: 0.7168\n",
      "Epoch 47 | Train Loss: 0.7463 | Val Loss: 0.6858\n",
      "Epoch 48 | Train Loss: 0.7011 | Val Loss: 0.6923\n",
      "Epoch 49 | Train Loss: 0.7151 | Val Loss: 0.6934\n",
      "Epoch 50 | Train Loss: 0.7086 | Val Loss: 0.6933\n",
      "Fold 4 ‚ñ∂ AUC: 0.767, Balanced Acc: 0.540\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9177 | Val Loss: 0.8911\n",
      "Epoch 02 | Train Loss: 0.8758 | Val Loss: 0.8874\n",
      "Epoch 03 | Train Loss: 0.8599 | Val Loss: 0.8705\n",
      "Epoch 04 | Train Loss: 0.8702 | Val Loss: 0.8644\n",
      "Epoch 05 | Train Loss: 0.8219 | Val Loss: 0.8590\n",
      "Epoch 06 | Train Loss: 0.8205 | Val Loss: 0.8386\n",
      "Epoch 07 | Train Loss: 0.7852 | Val Loss: 0.8492\n",
      "Epoch 08 | Train Loss: 0.7889 | Val Loss: 0.8491\n",
      "Epoch 09 | Train Loss: 0.7823 | Val Loss: 0.8642\n",
      "Epoch 10 | Train Loss: 0.7931 | Val Loss: 0.8603\n",
      "Epoch 11 | Train Loss: 0.7490 | Val Loss: 0.8538\n",
      "Epoch 12 | Train Loss: 0.7951 | Val Loss: 0.8914\n",
      "Epoch 13 | Train Loss: 0.7795 | Val Loss: 0.8381\n",
      "Epoch 14 | Train Loss: 0.7984 | Val Loss: 0.8312\n",
      "Epoch 15 | Train Loss: 0.7379 | Val Loss: 0.8270\n",
      "Epoch 16 | Train Loss: 0.7777 | Val Loss: 0.8213\n",
      "Epoch 17 | Train Loss: 0.7372 | Val Loss: 0.8215\n",
      "Epoch 18 | Train Loss: 0.7204 | Val Loss: 0.8158\n",
      "Epoch 19 | Train Loss: 0.7290 | Val Loss: 0.8043\n",
      "Epoch 20 | Train Loss: 0.7265 | Val Loss: 0.8356\n",
      "Epoch 21 | Train Loss: 0.7201 | Val Loss: 0.8335\n",
      "Epoch 22 | Train Loss: 0.7344 | Val Loss: 0.8062\n",
      "Epoch 23 | Train Loss: 0.7228 | Val Loss: 0.8037\n",
      "Epoch 24 | Train Loss: 0.7065 | Val Loss: 0.7932\n",
      "Epoch 25 | Train Loss: 0.7203 | Val Loss: 0.8147\n",
      "Epoch 26 | Train Loss: 0.7351 | Val Loss: 0.7892\n",
      "Epoch 27 | Train Loss: 0.7168 | Val Loss: 0.7923\n",
      "Epoch 28 | Train Loss: 0.7148 | Val Loss: 0.7967\n",
      "Epoch 29 | Train Loss: 0.7457 | Val Loss: 0.7793\n",
      "Epoch 30 | Train Loss: 0.7332 | Val Loss: 0.7911\n",
      "Epoch 31 | Train Loss: 0.7274 | Val Loss: 0.7817\n",
      "Epoch 32 | Train Loss: 0.7099 | Val Loss: 0.7794\n",
      "Epoch 33 | Train Loss: 0.7248 | Val Loss: 0.7863\n",
      "Epoch 34 | Train Loss: 0.6980 | Val Loss: 0.7801\n",
      "Epoch 35 | Train Loss: 0.7042 | Val Loss: 0.7814\n",
      "Epoch 36 | Train Loss: 0.7288 | Val Loss: 0.7767\n",
      "Epoch 37 | Train Loss: 0.7139 | Val Loss: 0.7886\n",
      "Epoch 38 | Train Loss: 0.7179 | Val Loss: 0.7857\n",
      "Epoch 39 | Train Loss: 0.6882 | Val Loss: 0.7835\n",
      "Epoch 40 | Train Loss: 0.7113 | Val Loss: 0.7726\n",
      "Epoch 41 | Train Loss: 0.6927 | Val Loss: 0.7824\n",
      "Epoch 42 | Train Loss: 0.6963 | Val Loss: 0.7578\n",
      "Epoch 43 | Train Loss: 0.7131 | Val Loss: 0.8039\n",
      "Epoch 44 | Train Loss: 0.7199 | Val Loss: 0.7636\n",
      "Epoch 45 | Train Loss: 0.6951 | Val Loss: 0.8122\n",
      "Epoch 46 | Train Loss: 0.6983 | Val Loss: 0.8052\n",
      "Epoch 47 | Train Loss: 0.7063 | Val Loss: 0.7947\n",
      "Epoch 48 | Train Loss: 0.7049 | Val Loss: 0.8052\n",
      "Epoch 49 | Train Loss: 0.7051 | Val Loss: 0.8482\n",
      "Epoch 50 | Train Loss: 0.7139 | Val Loss: 0.7815\n",
      "Fold 5 ‚ñ∂ AUC: 0.745, Balanced Acc: 0.466\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9259 | Val Loss: 1.0306\n",
      "Epoch 02 | Train Loss: 0.9022 | Val Loss: 0.9532\n",
      "Epoch 03 | Train Loss: 0.8814 | Val Loss: 0.8885\n",
      "Epoch 04 | Train Loss: 0.8543 | Val Loss: 0.8699\n",
      "Epoch 05 | Train Loss: 0.8415 | Val Loss: 0.8575\n",
      "Epoch 06 | Train Loss: 0.7982 | Val Loss: 0.8804\n",
      "Epoch 07 | Train Loss: 0.8118 | Val Loss: 0.9016\n",
      "Epoch 08 | Train Loss: 0.8218 | Val Loss: 0.8430\n",
      "Epoch 09 | Train Loss: 0.8023 | Val Loss: 0.8542\n",
      "Epoch 10 | Train Loss: 0.8014 | Val Loss: 0.8257\n",
      "Epoch 11 | Train Loss: 0.7674 | Val Loss: 0.8255\n",
      "Epoch 12 | Train Loss: 0.7447 | Val Loss: 0.8437\n",
      "Epoch 13 | Train Loss: 0.7708 | Val Loss: 0.8157\n",
      "Epoch 14 | Train Loss: 0.7573 | Val Loss: 0.8228\n",
      "Epoch 15 | Train Loss: 0.7405 | Val Loss: 0.8295\n",
      "Epoch 16 | Train Loss: 0.7454 | Val Loss: 0.8169\n",
      "Epoch 17 | Train Loss: 0.7139 | Val Loss: 0.8270\n",
      "Epoch 18 | Train Loss: 0.7339 | Val Loss: 0.8390\n",
      "Epoch 19 | Train Loss: 0.7558 | Val Loss: 0.8163\n",
      "Epoch 20 | Train Loss: 0.7381 | Val Loss: 0.8277\n",
      "Epoch 21 | Train Loss: 0.7245 | Val Loss: 0.8288\n",
      "Epoch 22 | Train Loss: 0.7259 | Val Loss: 0.8226\n",
      "Epoch 23 | Train Loss: 0.7275 | Val Loss: 0.8461\n",
      "Epoch 24 | Train Loss: 0.7266 | Val Loss: 0.8278\n",
      "Epoch 25 | Train Loss: 0.7357 | Val Loss: 0.8150\n",
      "Epoch 26 | Train Loss: 0.7204 | Val Loss: 0.8260\n",
      "Epoch 27 | Train Loss: 0.7766 | Val Loss: 0.8206\n",
      "Epoch 28 | Train Loss: 0.7099 | Val Loss: 0.8349\n",
      "Epoch 29 | Train Loss: 0.7185 | Val Loss: 0.8453\n",
      "Epoch 30 | Train Loss: 0.7243 | Val Loss: 0.8356\n",
      "Epoch 31 | Train Loss: 0.7082 | Val Loss: 0.8435\n",
      "Epoch 32 | Train Loss: 0.7042 | Val Loss: 0.8264\n",
      "Epoch 33 | Train Loss: 0.7171 | Val Loss: 0.8477\n",
      "Epoch 34 | Train Loss: 0.7011 | Val Loss: 0.8366\n",
      "Epoch 35 | Train Loss: 0.7135 | Val Loss: 0.8386\n",
      "Epoch 36 | Train Loss: 0.7160 | Val Loss: 0.8465\n",
      "Epoch 37 | Train Loss: 0.7275 | Val Loss: 0.8539\n",
      "Epoch 38 | Train Loss: 0.7388 | Val Loss: 0.8151\n",
      "Epoch 39 | Train Loss: 0.7039 | Val Loss: 0.8518\n",
      "Epoch 40 | Train Loss: 0.7243 | Val Loss: 0.8291\n",
      "Epoch 41 | Train Loss: 0.7189 | Val Loss: 0.8263\n",
      "Epoch 42 | Train Loss: 0.6910 | Val Loss: 0.8312\n",
      "Epoch 43 | Train Loss: 0.7262 | Val Loss: 0.8446\n",
      "Epoch 44 | Train Loss: 0.7312 | Val Loss: 0.8305\n",
      "Epoch 45 | Train Loss: 0.7225 | Val Loss: 0.8292\n",
      "Epoch 46 | Train Loss: 0.7303 | Val Loss: 0.8234\n",
      "Epoch 47 | Train Loss: 0.7185 | Val Loss: 0.8291\n",
      "Epoch 48 | Train Loss: 0.6869 | Val Loss: 0.8421\n",
      "Epoch 49 | Train Loss: 0.7114 | Val Loss: 0.8247\n",
      "Epoch 50 | Train Loss: 0.7212 | Val Loss: 0.8300\n",
      "Fold 6 ‚ñ∂ AUC: 0.719, Balanced Acc: 0.473\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9830 | Val Loss: 0.9414\n",
      "Epoch 02 | Train Loss: 0.9074 | Val Loss: 0.8765\n",
      "Epoch 03 | Train Loss: 0.8663 | Val Loss: 0.8450\n",
      "Epoch 04 | Train Loss: 0.8661 | Val Loss: 0.8316\n",
      "Epoch 05 | Train Loss: 0.8661 | Val Loss: 0.8292\n",
      "Epoch 06 | Train Loss: 0.8382 | Val Loss: 0.8174\n",
      "Epoch 07 | Train Loss: 0.8104 | Val Loss: 0.7749\n",
      "Epoch 08 | Train Loss: 0.8094 | Val Loss: 0.7399\n",
      "Epoch 09 | Train Loss: 0.7932 | Val Loss: 0.7765\n",
      "Epoch 10 | Train Loss: 0.8051 | Val Loss: 0.7261\n",
      "Epoch 11 | Train Loss: 0.7613 | Val Loss: 0.7050\n",
      "Epoch 12 | Train Loss: 0.7672 | Val Loss: 0.7113\n",
      "Epoch 13 | Train Loss: 0.7572 | Val Loss: 0.7001\n",
      "Epoch 14 | Train Loss: 0.7868 | Val Loss: 0.7724\n",
      "Epoch 15 | Train Loss: 0.7821 | Val Loss: 0.7128\n",
      "Epoch 16 | Train Loss: 0.7488 | Val Loss: 0.7232\n",
      "Epoch 17 | Train Loss: 0.7500 | Val Loss: 0.7037\n",
      "Epoch 18 | Train Loss: 0.7386 | Val Loss: 0.7301\n",
      "Epoch 19 | Train Loss: 0.7266 | Val Loss: 0.7063\n",
      "Epoch 20 | Train Loss: 0.7297 | Val Loss: 0.7153\n",
      "Epoch 21 | Train Loss: 0.7443 | Val Loss: 0.7379\n",
      "Epoch 22 | Train Loss: 0.7530 | Val Loss: 0.7375\n",
      "Epoch 23 | Train Loss: 0.7268 | Val Loss: 0.7171\n",
      "Epoch 24 | Train Loss: 0.7211 | Val Loss: 0.7256\n",
      "Epoch 25 | Train Loss: 0.7363 | Val Loss: 0.7076\n",
      "Epoch 26 | Train Loss: 0.7345 | Val Loss: 0.7451\n",
      "Epoch 27 | Train Loss: 0.7307 | Val Loss: 0.7278\n",
      "Epoch 28 | Train Loss: 0.7411 | Val Loss: 0.7210\n",
      "Epoch 29 | Train Loss: 0.7350 | Val Loss: 0.7210\n",
      "Epoch 30 | Train Loss: 0.7250 | Val Loss: 0.7362\n",
      "Epoch 31 | Train Loss: 0.7309 | Val Loss: 0.7277\n",
      "Epoch 32 | Train Loss: 0.7138 | Val Loss: 0.7275\n",
      "Epoch 33 | Train Loss: 0.7243 | Val Loss: 0.7170\n",
      "Epoch 34 | Train Loss: 0.7249 | Val Loss: 0.7209\n",
      "Epoch 35 | Train Loss: 0.7268 | Val Loss: 0.7162\n",
      "Epoch 36 | Train Loss: 0.7040 | Val Loss: 0.7313\n",
      "Epoch 37 | Train Loss: 0.7436 | Val Loss: 0.7435\n",
      "Epoch 38 | Train Loss: 0.7334 | Val Loss: 0.7109\n",
      "Epoch 39 | Train Loss: 0.7333 | Val Loss: 0.7067\n",
      "Epoch 40 | Train Loss: 0.7052 | Val Loss: 0.7329\n",
      "Epoch 41 | Train Loss: 0.7270 | Val Loss: 0.7163\n",
      "Epoch 42 | Train Loss: 0.7278 | Val Loss: 0.7363\n",
      "Epoch 43 | Train Loss: 0.7253 | Val Loss: 0.7174\n",
      "Epoch 44 | Train Loss: 0.7260 | Val Loss: 0.7318\n",
      "Epoch 45 | Train Loss: 0.7404 | Val Loss: 0.7187\n",
      "Epoch 46 | Train Loss: 0.7201 | Val Loss: 0.7126\n",
      "Epoch 47 | Train Loss: 0.7514 | Val Loss: 0.7703\n",
      "Epoch 48 | Train Loss: 0.7441 | Val Loss: 0.7666\n",
      "Epoch 49 | Train Loss: 0.7380 | Val Loss: 0.7292\n",
      "Epoch 50 | Train Loss: 0.7148 | Val Loss: 0.7259\n",
      "Fold 7 ‚ñ∂ AUC: 0.764, Balanced Acc: 0.462\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9480 | Val Loss: 0.8862\n",
      "Epoch 02 | Train Loss: 0.8822 | Val Loss: 0.8509\n",
      "Epoch 03 | Train Loss: 0.8651 | Val Loss: 0.9173\n",
      "Epoch 04 | Train Loss: 0.8724 | Val Loss: 0.8382\n",
      "Epoch 05 | Train Loss: 0.8380 | Val Loss: 0.8297\n",
      "Epoch 06 | Train Loss: 0.8311 | Val Loss: 0.8209\n",
      "Epoch 07 | Train Loss: 0.7954 | Val Loss: 0.8029\n",
      "Epoch 08 | Train Loss: 0.7826 | Val Loss: 0.7960\n",
      "Epoch 09 | Train Loss: 0.7854 | Val Loss: 0.7982\n",
      "Epoch 10 | Train Loss: 0.7822 | Val Loss: 0.8073\n",
      "Epoch 11 | Train Loss: 0.7649 | Val Loss: 0.8025\n",
      "Epoch 12 | Train Loss: 0.7412 | Val Loss: 0.8664\n",
      "Epoch 13 | Train Loss: 0.7840 | Val Loss: 0.8334\n",
      "Epoch 14 | Train Loss: 0.7530 | Val Loss: 0.8499\n",
      "Epoch 15 | Train Loss: 0.7516 | Val Loss: 0.8272\n",
      "Epoch 16 | Train Loss: 0.7714 | Val Loss: 0.8039\n",
      "Epoch 17 | Train Loss: 0.7376 | Val Loss: 0.7950\n",
      "Epoch 18 | Train Loss: 0.7280 | Val Loss: 0.8064\n",
      "Epoch 19 | Train Loss: 0.7367 | Val Loss: 0.8185\n",
      "Epoch 20 | Train Loss: 0.7344 | Val Loss: 0.7948\n",
      "Epoch 21 | Train Loss: 0.7133 | Val Loss: 0.7962\n",
      "Epoch 22 | Train Loss: 0.7205 | Val Loss: 0.8025\n",
      "Epoch 23 | Train Loss: 0.7262 | Val Loss: 0.7916\n",
      "Epoch 24 | Train Loss: 0.7178 | Val Loss: 0.7946\n",
      "Epoch 25 | Train Loss: 0.7300 | Val Loss: 0.8074\n",
      "Epoch 26 | Train Loss: 0.7193 | Val Loss: 0.8024\n",
      "Epoch 27 | Train Loss: 0.7047 | Val Loss: 0.8220\n",
      "Epoch 28 | Train Loss: 0.7014 | Val Loss: 0.8563\n",
      "Epoch 29 | Train Loss: 0.7378 | Val Loss: 0.7989\n",
      "Epoch 30 | Train Loss: 0.7103 | Val Loss: 0.8020\n",
      "Epoch 31 | Train Loss: 0.7126 | Val Loss: 0.8051\n",
      "Epoch 32 | Train Loss: 0.7156 | Val Loss: 0.8000\n",
      "Epoch 33 | Train Loss: 0.7214 | Val Loss: 0.8084\n",
      "Epoch 34 | Train Loss: 0.7150 | Val Loss: 0.8060\n",
      "Epoch 35 | Train Loss: 0.7397 | Val Loss: 0.8162\n",
      "Epoch 36 | Train Loss: 0.7181 | Val Loss: 0.8019\n",
      "Epoch 37 | Train Loss: 0.7149 | Val Loss: 0.8099\n",
      "Epoch 38 | Train Loss: 0.7227 | Val Loss: 0.8172\n",
      "Epoch 39 | Train Loss: 0.7294 | Val Loss: 0.8074\n",
      "Epoch 40 | Train Loss: 0.7056 | Val Loss: 0.8215\n",
      "Epoch 41 | Train Loss: 0.7464 | Val Loss: 0.8174\n",
      "Epoch 42 | Train Loss: 0.7269 | Val Loss: 0.8320\n",
      "Epoch 43 | Train Loss: 0.7328 | Val Loss: 0.8387\n",
      "Epoch 44 | Train Loss: 0.6982 | Val Loss: 0.8201\n",
      "Epoch 45 | Train Loss: 0.7165 | Val Loss: 0.8078\n",
      "Epoch 46 | Train Loss: 0.6975 | Val Loss: 0.8170\n",
      "Epoch 47 | Train Loss: 0.7000 | Val Loss: 0.8098\n",
      "Epoch 48 | Train Loss: 0.7003 | Val Loss: 0.8159\n",
      "Epoch 49 | Train Loss: 0.6948 | Val Loss: 0.8260\n",
      "Epoch 50 | Train Loss: 0.7099 | Val Loss: 0.8233\n",
      "Fold 8 ‚ñ∂ AUC: 0.721, Balanced Acc: 0.380\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9037 | Val Loss: 0.8870\n",
      "Epoch 02 | Train Loss: 0.8767 | Val Loss: 0.8761\n",
      "Epoch 03 | Train Loss: 0.8615 | Val Loss: 0.8515\n",
      "Epoch 04 | Train Loss: 0.8374 | Val Loss: 0.8679\n",
      "Epoch 05 | Train Loss: 0.8522 | Val Loss: 0.8569\n",
      "Epoch 06 | Train Loss: 0.8102 | Val Loss: 0.8221\n",
      "Epoch 07 | Train Loss: 0.7901 | Val Loss: 0.8261\n",
      "Epoch 08 | Train Loss: 0.7710 | Val Loss: 0.8527\n",
      "Epoch 09 | Train Loss: 0.7793 | Val Loss: 0.8076\n",
      "Epoch 10 | Train Loss: 0.7512 | Val Loss: 0.8233\n",
      "Epoch 11 | Train Loss: 0.7489 | Val Loss: 0.7994\n",
      "Epoch 12 | Train Loss: 0.8013 | Val Loss: 0.7983\n",
      "Epoch 13 | Train Loss: 0.7525 | Val Loss: 0.7833\n",
      "Epoch 14 | Train Loss: 0.7646 | Val Loss: 0.7873\n",
      "Epoch 15 | Train Loss: 0.7314 | Val Loss: 0.7897\n",
      "Epoch 16 | Train Loss: 0.7556 | Val Loss: 0.7794\n",
      "Epoch 17 | Train Loss: 0.7412 | Val Loss: 0.7684\n",
      "Epoch 18 | Train Loss: 0.7189 | Val Loss: 0.7626\n",
      "Epoch 19 | Train Loss: 0.7298 | Val Loss: 0.7549\n",
      "Epoch 20 | Train Loss: 0.7399 | Val Loss: 0.7539\n",
      "Epoch 21 | Train Loss: 0.7442 | Val Loss: 0.7520\n",
      "Epoch 22 | Train Loss: 0.7334 | Val Loss: 0.7490\n",
      "Epoch 23 | Train Loss: 0.7264 | Val Loss: 0.7516\n",
      "Epoch 24 | Train Loss: 0.7309 | Val Loss: 0.7420\n",
      "Epoch 25 | Train Loss: 0.7143 | Val Loss: 0.7531\n",
      "Epoch 26 | Train Loss: 0.7315 | Val Loss: 0.7840\n",
      "Epoch 27 | Train Loss: 0.7344 | Val Loss: 0.7936\n",
      "Epoch 28 | Train Loss: 0.7268 | Val Loss: 0.7575\n",
      "Epoch 29 | Train Loss: 0.7217 | Val Loss: 0.7609\n",
      "Epoch 30 | Train Loss: 0.7673 | Val Loss: 0.7470\n",
      "Epoch 31 | Train Loss: 0.7383 | Val Loss: 0.7363\n",
      "Epoch 32 | Train Loss: 0.7223 | Val Loss: 0.7585\n",
      "Epoch 33 | Train Loss: 0.7294 | Val Loss: 0.7416\n",
      "Epoch 34 | Train Loss: 0.7101 | Val Loss: 0.7365\n",
      "Epoch 35 | Train Loss: 0.7109 | Val Loss: 0.7860\n",
      "Epoch 36 | Train Loss: 0.7103 | Val Loss: 0.7352\n",
      "Epoch 37 | Train Loss: 0.7083 | Val Loss: 0.7330\n",
      "Epoch 38 | Train Loss: 0.7441 | Val Loss: 0.7554\n",
      "Epoch 39 | Train Loss: 0.7176 | Val Loss: 0.7377\n",
      "Epoch 40 | Train Loss: 0.7270 | Val Loss: 0.7653\n",
      "Epoch 41 | Train Loss: 0.7354 | Val Loss: 0.8207\n",
      "Epoch 42 | Train Loss: 0.7301 | Val Loss: 0.8081\n",
      "Epoch 43 | Train Loss: 0.7206 | Val Loss: 0.7301\n",
      "Epoch 44 | Train Loss: 0.7043 | Val Loss: 0.7242\n",
      "Epoch 45 | Train Loss: 0.7163 | Val Loss: 0.7198\n",
      "Epoch 46 | Train Loss: 0.7014 | Val Loss: 0.7513\n",
      "Epoch 47 | Train Loss: 0.7219 | Val Loss: 0.7482\n",
      "Epoch 48 | Train Loss: 0.7225 | Val Loss: 0.7623\n",
      "Epoch 49 | Train Loss: 0.7028 | Val Loss: 0.7452\n",
      "Epoch 50 | Train Loss: 0.7209 | Val Loss: 0.7726\n",
      "Fold 9 ‚ñ∂ AUC: 0.761, Balanced Acc: 0.512\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9383 | Val Loss: 0.8819\n",
      "Epoch 02 | Train Loss: 0.8854 | Val Loss: 0.8604\n",
      "Epoch 03 | Train Loss: 0.8542 | Val Loss: 0.8387\n",
      "Epoch 04 | Train Loss: 0.8334 | Val Loss: 0.8081\n",
      "Epoch 05 | Train Loss: 0.8282 | Val Loss: 0.7828\n",
      "Epoch 06 | Train Loss: 0.7866 | Val Loss: 0.8329\n",
      "Epoch 07 | Train Loss: 0.8450 | Val Loss: 0.7717\n",
      "Epoch 08 | Train Loss: 0.8337 | Val Loss: 0.7862\n",
      "Epoch 09 | Train Loss: 0.7771 | Val Loss: 0.7770\n",
      "Epoch 10 | Train Loss: 0.7679 | Val Loss: 0.7579\n",
      "Epoch 11 | Train Loss: 0.7761 | Val Loss: 0.7634\n",
      "Epoch 12 | Train Loss: 0.7695 | Val Loss: 0.7837\n",
      "Epoch 13 | Train Loss: 0.7555 | Val Loss: 0.7640\n",
      "Epoch 14 | Train Loss: 0.7295 | Val Loss: 0.8071\n",
      "Epoch 15 | Train Loss: 0.7278 | Val Loss: 0.7983\n",
      "Epoch 16 | Train Loss: 0.7425 | Val Loss: 0.8060\n",
      "Epoch 17 | Train Loss: 0.7522 | Val Loss: 0.7586\n",
      "Epoch 18 | Train Loss: 0.7321 | Val Loss: 0.7641\n",
      "Epoch 19 | Train Loss: 0.7440 | Val Loss: 0.7611\n",
      "Epoch 20 | Train Loss: 0.7220 | Val Loss: 0.7651\n",
      "Epoch 21 | Train Loss: 0.7254 | Val Loss: 0.7666\n",
      "Epoch 22 | Train Loss: 0.7236 | Val Loss: 0.7914\n",
      "Epoch 23 | Train Loss: 0.7475 | Val Loss: 0.7697\n",
      "Epoch 24 | Train Loss: 0.7417 | Val Loss: 0.7628\n",
      "Epoch 25 | Train Loss: 0.7219 | Val Loss: 0.7656\n",
      "Epoch 26 | Train Loss: 0.7180 | Val Loss: 0.7662\n",
      "Epoch 27 | Train Loss: 0.7129 | Val Loss: 0.7720\n",
      "Epoch 28 | Train Loss: 0.7473 | Val Loss: 0.8022\n",
      "Epoch 29 | Train Loss: 0.7123 | Val Loss: 0.7889\n",
      "Epoch 30 | Train Loss: 0.7242 | Val Loss: 0.7702\n",
      "Epoch 31 | Train Loss: 0.7351 | Val Loss: 0.7689\n",
      "Epoch 32 | Train Loss: 0.7204 | Val Loss: 0.7642\n",
      "Epoch 33 | Train Loss: 0.7350 | Val Loss: 0.7812\n",
      "Epoch 34 | Train Loss: 0.7197 | Val Loss: 0.7931\n",
      "Epoch 35 | Train Loss: 0.7184 | Val Loss: 0.7664\n",
      "Epoch 36 | Train Loss: 0.7080 | Val Loss: 0.7660\n",
      "Epoch 37 | Train Loss: 0.7124 | Val Loss: 0.7924\n",
      "Epoch 38 | Train Loss: 0.7187 | Val Loss: 0.7681\n",
      "Epoch 39 | Train Loss: 0.7044 | Val Loss: 0.7597\n",
      "Epoch 40 | Train Loss: 0.7261 | Val Loss: 0.7688\n",
      "Epoch 41 | Train Loss: 0.7265 | Val Loss: 0.8058\n",
      "Epoch 42 | Train Loss: 0.7242 | Val Loss: 0.7695\n",
      "Epoch 43 | Train Loss: 0.7120 | Val Loss: 0.7838\n",
      "Epoch 44 | Train Loss: 0.7137 | Val Loss: 0.7895\n",
      "Epoch 45 | Train Loss: 0.6936 | Val Loss: 0.7748\n",
      "Epoch 46 | Train Loss: 0.7048 | Val Loss: 0.7619\n",
      "Epoch 47 | Train Loss: 0.7032 | Val Loss: 0.7715\n",
      "Epoch 48 | Train Loss: 0.6952 | Val Loss: 0.7748\n",
      "Epoch 49 | Train Loss: 0.6989 | Val Loss: 0.7581\n",
      "Epoch 50 | Train Loss: 0.6978 | Val Loss: 0.7720\n",
      "Fold 10 ‚ñ∂ AUC: 0.710, Balanced Acc: 0.451\n",
      "üîç Summary for hd=256, dp=0.2, lr=0.0005 ‚Üí AUC: 0.7431¬±0.0377 | BalAcc: 0.4835¬±0.0484\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.2, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9157 | Val Loss: 0.8692\n",
      "Epoch 02 | Train Loss: 0.8760 | Val Loss: 0.8611\n",
      "Epoch 03 | Train Loss: 0.8707 | Val Loss: 0.8587\n",
      "Epoch 04 | Train Loss: 0.8680 | Val Loss: 0.8559\n",
      "Epoch 05 | Train Loss: 0.8845 | Val Loss: 0.8544\n",
      "Epoch 06 | Train Loss: 0.8511 | Val Loss: 0.8461\n",
      "Epoch 07 | Train Loss: 0.8477 | Val Loss: 0.8393\n",
      "Epoch 08 | Train Loss: 0.8424 | Val Loss: 0.8366\n",
      "Epoch 09 | Train Loss: 0.8438 | Val Loss: 0.8351\n",
      "Epoch 10 | Train Loss: 0.8318 | Val Loss: 0.8200\n",
      "Epoch 11 | Train Loss: 0.8245 | Val Loss: 0.8143\n",
      "Epoch 12 | Train Loss: 0.8189 | Val Loss: 0.8142\n",
      "Epoch 13 | Train Loss: 0.8105 | Val Loss: 0.8038\n",
      "Epoch 14 | Train Loss: 0.8163 | Val Loss: 0.7901\n",
      "Epoch 15 | Train Loss: 0.7869 | Val Loss: 0.7806\n",
      "Epoch 16 | Train Loss: 0.7914 | Val Loss: 0.7796\n",
      "Epoch 17 | Train Loss: 0.7979 | Val Loss: 0.7648\n",
      "Epoch 18 | Train Loss: 0.7708 | Val Loss: 0.7772\n",
      "Epoch 19 | Train Loss: 0.7934 | Val Loss: 0.7633\n",
      "Epoch 20 | Train Loss: 0.7685 | Val Loss: 0.7600\n",
      "Epoch 21 | Train Loss: 0.7926 | Val Loss: 0.7473\n",
      "Epoch 22 | Train Loss: 0.7838 | Val Loss: 0.7429\n",
      "Epoch 23 | Train Loss: 0.7710 | Val Loss: 0.7383\n",
      "Epoch 24 | Train Loss: 0.7651 | Val Loss: 0.7338\n",
      "Epoch 25 | Train Loss: 0.7850 | Val Loss: 0.7500\n",
      "Epoch 26 | Train Loss: 0.7714 | Val Loss: 0.7226\n",
      "Epoch 27 | Train Loss: 0.7730 | Val Loss: 0.7379\n",
      "Epoch 28 | Train Loss: 0.7612 | Val Loss: 0.7217\n",
      "Epoch 29 | Train Loss: 0.7564 | Val Loss: 0.7134\n",
      "Epoch 30 | Train Loss: 0.7665 | Val Loss: 0.7097\n",
      "Epoch 31 | Train Loss: 0.7662 | Val Loss: 0.7072\n",
      "Epoch 32 | Train Loss: 0.7418 | Val Loss: 0.7111\n",
      "Epoch 33 | Train Loss: 0.7354 | Val Loss: 0.7061\n",
      "Epoch 34 | Train Loss: 0.7399 | Val Loss: 0.7072\n",
      "Epoch 35 | Train Loss: 0.7658 | Val Loss: 0.7310\n",
      "Epoch 36 | Train Loss: 0.7489 | Val Loss: 0.7363\n",
      "Epoch 37 | Train Loss: 0.7578 | Val Loss: 0.7094\n",
      "Epoch 38 | Train Loss: 0.7230 | Val Loss: 0.6972\n",
      "Epoch 39 | Train Loss: 0.7292 | Val Loss: 0.6987\n",
      "Epoch 40 | Train Loss: 0.7343 | Val Loss: 0.6921\n",
      "Epoch 41 | Train Loss: 0.7263 | Val Loss: 0.6989\n",
      "Epoch 42 | Train Loss: 0.7395 | Val Loss: 0.6930\n",
      "Epoch 43 | Train Loss: 0.7281 | Val Loss: 0.7168\n",
      "Epoch 44 | Train Loss: 0.7217 | Val Loss: 0.7382\n",
      "Epoch 45 | Train Loss: 0.7628 | Val Loss: 0.6904\n",
      "Epoch 46 | Train Loss: 0.7438 | Val Loss: 0.6986\n",
      "Epoch 47 | Train Loss: 0.7268 | Val Loss: 0.7630\n",
      "Epoch 48 | Train Loss: 0.7685 | Val Loss: 0.6973\n",
      "Epoch 49 | Train Loss: 0.7474 | Val Loss: 0.6991\n",
      "Epoch 50 | Train Loss: 0.7400 | Val Loss: 0.7009\n",
      "Fold 1 ‚ñ∂ AUC: 0.782, Balanced Acc: 0.513\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9155 | Val Loss: 0.8708\n",
      "Epoch 02 | Train Loss: 0.8895 | Val Loss: 0.9028\n",
      "Epoch 03 | Train Loss: 0.8797 | Val Loss: 0.8633\n",
      "Epoch 04 | Train Loss: 0.8654 | Val Loss: 0.8468\n",
      "Epoch 05 | Train Loss: 0.8516 | Val Loss: 0.8420\n",
      "Epoch 06 | Train Loss: 0.8415 | Val Loss: 0.8636\n",
      "Epoch 07 | Train Loss: 0.8600 | Val Loss: 0.8419\n",
      "Epoch 08 | Train Loss: 0.8504 | Val Loss: 0.8277\n",
      "Epoch 09 | Train Loss: 0.8440 | Val Loss: 0.8219\n",
      "Epoch 10 | Train Loss: 0.8280 | Val Loss: 0.8338\n",
      "Epoch 11 | Train Loss: 0.8429 | Val Loss: 0.8140\n",
      "Epoch 12 | Train Loss: 0.8327 | Val Loss: 0.8087\n",
      "Epoch 13 | Train Loss: 0.8352 | Val Loss: 0.8050\n",
      "Epoch 14 | Train Loss: 0.8126 | Val Loss: 0.7967\n",
      "Epoch 15 | Train Loss: 0.8039 | Val Loss: 0.7984\n",
      "Epoch 16 | Train Loss: 0.7895 | Val Loss: 0.7829\n",
      "Epoch 17 | Train Loss: 0.7958 | Val Loss: 0.7770\n",
      "Epoch 18 | Train Loss: 0.7834 | Val Loss: 0.7669\n",
      "Epoch 19 | Train Loss: 0.7797 | Val Loss: 0.7624\n",
      "Epoch 20 | Train Loss: 0.7788 | Val Loss: 0.7687\n",
      "Epoch 21 | Train Loss: 0.7706 | Val Loss: 0.7522\n",
      "Epoch 22 | Train Loss: 0.7754 | Val Loss: 0.7505\n",
      "Epoch 23 | Train Loss: 0.8211 | Val Loss: 0.7686\n",
      "Epoch 24 | Train Loss: 0.7671 | Val Loss: 0.7478\n",
      "Epoch 25 | Train Loss: 0.8283 | Val Loss: 0.8171\n",
      "Epoch 26 | Train Loss: 0.7674 | Val Loss: 0.7550\n",
      "Epoch 27 | Train Loss: 0.7572 | Val Loss: 0.7368\n",
      "Epoch 28 | Train Loss: 0.7593 | Val Loss: 0.7466\n",
      "Epoch 29 | Train Loss: 0.7734 | Val Loss: 0.7895\n",
      "Epoch 30 | Train Loss: 0.7570 | Val Loss: 0.7491\n",
      "Epoch 31 | Train Loss: 0.7411 | Val Loss: 0.7508\n",
      "Epoch 32 | Train Loss: 0.7476 | Val Loss: 0.7482\n",
      "Epoch 33 | Train Loss: 0.7911 | Val Loss: 0.7398\n",
      "Epoch 34 | Train Loss: 0.7485 | Val Loss: 0.7806\n",
      "Epoch 35 | Train Loss: 0.7515 | Val Loss: 0.7297\n",
      "Epoch 36 | Train Loss: 0.7432 | Val Loss: 0.7644\n",
      "Epoch 37 | Train Loss: 0.7303 | Val Loss: 0.7264\n",
      "Epoch 38 | Train Loss: 0.7573 | Val Loss: 0.7263\n",
      "Epoch 39 | Train Loss: 0.7225 | Val Loss: 0.7359\n",
      "Epoch 40 | Train Loss: 0.7261 | Val Loss: 0.7445\n",
      "Epoch 41 | Train Loss: 0.7709 | Val Loss: 0.7419\n",
      "Epoch 42 | Train Loss: 0.7263 | Val Loss: 0.7297\n",
      "Epoch 43 | Train Loss: 0.7331 | Val Loss: 0.7235\n",
      "Epoch 44 | Train Loss: 0.7534 | Val Loss: 0.7381\n",
      "Epoch 45 | Train Loss: 0.7087 | Val Loss: 0.7586\n",
      "Epoch 46 | Train Loss: 0.7481 | Val Loss: 0.7115\n",
      "Epoch 47 | Train Loss: 0.7617 | Val Loss: 0.7091\n",
      "Epoch 48 | Train Loss: 0.7489 | Val Loss: 0.7174\n",
      "Epoch 49 | Train Loss: 0.7624 | Val Loss: 0.7177\n",
      "Epoch 50 | Train Loss: 0.7431 | Val Loss: 0.7307\n",
      "Fold 2 ‚ñ∂ AUC: 0.651, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9587 | Val Loss: 0.8568\n",
      "Epoch 02 | Train Loss: 0.9074 | Val Loss: 0.8538\n",
      "Epoch 03 | Train Loss: 0.8686 | Val Loss: 0.8486\n",
      "Epoch 04 | Train Loss: 0.8586 | Val Loss: 0.8407\n",
      "Epoch 05 | Train Loss: 0.8507 | Val Loss: 0.8322\n",
      "Epoch 06 | Train Loss: 0.8488 | Val Loss: 0.8296\n",
      "Epoch 07 | Train Loss: 0.8477 | Val Loss: 0.8217\n",
      "Epoch 08 | Train Loss: 0.8394 | Val Loss: 0.8147\n",
      "Epoch 09 | Train Loss: 0.8436 | Val Loss: 0.8087\n",
      "Epoch 10 | Train Loss: 0.8257 | Val Loss: 0.8017\n",
      "Epoch 11 | Train Loss: 0.8337 | Val Loss: 0.8343\n",
      "Epoch 12 | Train Loss: 0.8298 | Val Loss: 0.7939\n",
      "Epoch 13 | Train Loss: 0.8123 | Val Loss: 0.7790\n",
      "Epoch 14 | Train Loss: 0.8075 | Val Loss: 0.7820\n",
      "Epoch 15 | Train Loss: 0.7911 | Val Loss: 0.7657\n",
      "Epoch 16 | Train Loss: 0.8006 | Val Loss: 0.7725\n",
      "Epoch 17 | Train Loss: 0.7967 | Val Loss: 0.7534\n",
      "Epoch 18 | Train Loss: 0.7677 | Val Loss: 0.7543\n",
      "Epoch 19 | Train Loss: 0.8054 | Val Loss: 0.7737\n",
      "Epoch 20 | Train Loss: 0.7830 | Val Loss: 0.7478\n",
      "Epoch 21 | Train Loss: 0.7708 | Val Loss: 0.7447\n",
      "Epoch 22 | Train Loss: 0.7548 | Val Loss: 0.7433\n",
      "Epoch 23 | Train Loss: 0.7667 | Val Loss: 0.7558\n",
      "Epoch 24 | Train Loss: 0.7459 | Val Loss: 0.7373\n",
      "Epoch 25 | Train Loss: 0.7533 | Val Loss: 0.7338\n",
      "Epoch 26 | Train Loss: 0.7583 | Val Loss: 0.7637\n",
      "Epoch 27 | Train Loss: 0.7756 | Val Loss: 0.7437\n",
      "Epoch 28 | Train Loss: 0.7597 | Val Loss: 0.7397\n",
      "Epoch 29 | Train Loss: 0.7454 | Val Loss: 0.7389\n",
      "Epoch 30 | Train Loss: 0.7287 | Val Loss: 0.7506\n",
      "Epoch 31 | Train Loss: 0.7346 | Val Loss: 0.7479\n",
      "Epoch 32 | Train Loss: 0.7403 | Val Loss: 0.7297\n",
      "Epoch 33 | Train Loss: 0.7448 | Val Loss: 0.7285\n",
      "Epoch 34 | Train Loss: 0.7487 | Val Loss: 0.7342\n",
      "Epoch 35 | Train Loss: 0.7536 | Val Loss: 0.7333\n",
      "Epoch 36 | Train Loss: 0.7460 | Val Loss: 0.7354\n",
      "Epoch 37 | Train Loss: 0.7404 | Val Loss: 0.7499\n",
      "Epoch 38 | Train Loss: 0.7431 | Val Loss: 0.7405\n",
      "Epoch 39 | Train Loss: 0.7284 | Val Loss: 0.7490\n",
      "Epoch 40 | Train Loss: 0.7312 | Val Loss: 0.7261\n",
      "Epoch 41 | Train Loss: 0.7504 | Val Loss: 0.7278\n",
      "Epoch 42 | Train Loss: 0.7470 | Val Loss: 0.7238\n",
      "Epoch 43 | Train Loss: 0.7454 | Val Loss: 0.7508\n",
      "Epoch 44 | Train Loss: 0.7222 | Val Loss: 0.7382\n",
      "Epoch 45 | Train Loss: 0.7225 | Val Loss: 0.7251\n",
      "Epoch 46 | Train Loss: 0.7363 | Val Loss: 0.7446\n",
      "Epoch 47 | Train Loss: 0.7112 | Val Loss: 0.7936\n",
      "Epoch 48 | Train Loss: 0.7416 | Val Loss: 0.7318\n",
      "Epoch 49 | Train Loss: 0.7092 | Val Loss: 0.7239\n",
      "Epoch 50 | Train Loss: 0.7061 | Val Loss: 0.7287\n",
      "Fold 3 ‚ñ∂ AUC: 0.769, Balanced Acc: 0.497\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9205 | Val Loss: 0.8675\n",
      "Epoch 02 | Train Loss: 0.8804 | Val Loss: 0.8437\n",
      "Epoch 03 | Train Loss: 0.8685 | Val Loss: 0.8435\n",
      "Epoch 04 | Train Loss: 0.8550 | Val Loss: 0.8396\n",
      "Epoch 05 | Train Loss: 0.8662 | Val Loss: 0.8468\n",
      "Epoch 06 | Train Loss: 0.8536 | Val Loss: 0.8284\n",
      "Epoch 07 | Train Loss: 0.8553 | Val Loss: 0.8251\n",
      "Epoch 08 | Train Loss: 0.8444 | Val Loss: 0.8174\n",
      "Epoch 09 | Train Loss: 0.8440 | Val Loss: 0.8199\n",
      "Epoch 10 | Train Loss: 0.8302 | Val Loss: 0.8077\n",
      "Epoch 11 | Train Loss: 0.8183 | Val Loss: 0.8053\n",
      "Epoch 12 | Train Loss: 0.8345 | Val Loss: 0.7929\n",
      "Epoch 13 | Train Loss: 0.8138 | Val Loss: 0.7955\n",
      "Epoch 14 | Train Loss: 0.8101 | Val Loss: 0.7893\n",
      "Epoch 15 | Train Loss: 0.8072 | Val Loss: 0.7782\n",
      "Epoch 16 | Train Loss: 0.8196 | Val Loss: 0.7724\n",
      "Epoch 17 | Train Loss: 0.8059 | Val Loss: 0.7661\n",
      "Epoch 18 | Train Loss: 0.8101 | Val Loss: 0.7639\n",
      "Epoch 19 | Train Loss: 0.8011 | Val Loss: 0.7589\n",
      "Epoch 20 | Train Loss: 0.8085 | Val Loss: 0.7833\n",
      "Epoch 21 | Train Loss: 0.7882 | Val Loss: 0.7659\n",
      "Epoch 22 | Train Loss: 0.7545 | Val Loss: 0.7530\n",
      "Epoch 23 | Train Loss: 0.8125 | Val Loss: 0.7355\n",
      "Epoch 24 | Train Loss: 0.7997 | Val Loss: 0.7362\n",
      "Epoch 25 | Train Loss: 0.7755 | Val Loss: 0.7371\n",
      "Epoch 26 | Train Loss: 0.7694 | Val Loss: 0.7241\n",
      "Epoch 27 | Train Loss: 0.7692 | Val Loss: 0.7192\n",
      "Epoch 28 | Train Loss: 0.7832 | Val Loss: 0.7144\n",
      "Epoch 29 | Train Loss: 0.7571 | Val Loss: 0.7145\n",
      "Epoch 30 | Train Loss: 0.7611 | Val Loss: 0.7094\n",
      "Epoch 31 | Train Loss: 0.7770 | Val Loss: 0.7068\n",
      "Epoch 32 | Train Loss: 0.7757 | Val Loss: 0.7231\n",
      "Epoch 33 | Train Loss: 0.7698 | Val Loss: 0.7210\n",
      "Epoch 34 | Train Loss: 0.7679 | Val Loss: 0.7022\n",
      "Epoch 35 | Train Loss: 0.7644 | Val Loss: 0.7037\n",
      "Epoch 36 | Train Loss: 0.7618 | Val Loss: 0.7149\n",
      "Epoch 37 | Train Loss: 0.7847 | Val Loss: 0.6929\n",
      "Epoch 38 | Train Loss: 0.7872 | Val Loss: 0.7197\n",
      "Epoch 39 | Train Loss: 0.7629 | Val Loss: 0.7025\n",
      "Epoch 40 | Train Loss: 0.7541 | Val Loss: 0.7059\n",
      "Epoch 41 | Train Loss: 0.7511 | Val Loss: 0.6926\n",
      "Epoch 42 | Train Loss: 0.7486 | Val Loss: 0.6902\n",
      "Epoch 43 | Train Loss: 0.7468 | Val Loss: 0.6933\n",
      "Epoch 44 | Train Loss: 0.7391 | Val Loss: 0.6835\n",
      "Epoch 45 | Train Loss: 0.7476 | Val Loss: 0.6864\n",
      "Epoch 46 | Train Loss: 0.7421 | Val Loss: 0.6848\n",
      "Epoch 47 | Train Loss: 0.7412 | Val Loss: 0.6794\n",
      "Epoch 48 | Train Loss: 0.7282 | Val Loss: 0.6881\n",
      "Epoch 49 | Train Loss: 0.7385 | Val Loss: 0.6756\n",
      "Epoch 50 | Train Loss: 0.7493 | Val Loss: 0.6770\n",
      "Fold 4 ‚ñ∂ AUC: 0.780, Balanced Acc: 0.553\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9801 | Val Loss: 0.9211\n",
      "Epoch 02 | Train Loss: 0.8584 | Val Loss: 0.8948\n",
      "Epoch 03 | Train Loss: 0.8656 | Val Loss: 0.8848\n",
      "Epoch 04 | Train Loss: 0.8461 | Val Loss: 0.8764\n",
      "Epoch 05 | Train Loss: 0.8368 | Val Loss: 0.8726\n",
      "Epoch 06 | Train Loss: 0.8403 | Val Loss: 0.8631\n",
      "Epoch 07 | Train Loss: 0.8360 | Val Loss: 0.8647\n",
      "Epoch 08 | Train Loss: 0.8385 | Val Loss: 0.8726\n",
      "Epoch 09 | Train Loss: 0.8220 | Val Loss: 0.8513\n",
      "Epoch 10 | Train Loss: 0.8361 | Val Loss: 0.8533\n",
      "Epoch 11 | Train Loss: 0.8280 | Val Loss: 0.8400\n",
      "Epoch 12 | Train Loss: 0.8186 | Val Loss: 0.8271\n",
      "Epoch 13 | Train Loss: 0.8031 | Val Loss: 0.8427\n",
      "Epoch 14 | Train Loss: 0.7963 | Val Loss: 0.8415\n",
      "Epoch 15 | Train Loss: 0.7897 | Val Loss: 0.8235\n",
      "Epoch 16 | Train Loss: 0.7955 | Val Loss: 0.8176\n",
      "Epoch 17 | Train Loss: 0.7794 | Val Loss: 0.8150\n",
      "Epoch 18 | Train Loss: 0.7681 | Val Loss: 0.8064\n",
      "Epoch 19 | Train Loss: 0.7517 | Val Loss: 0.8103\n",
      "Epoch 20 | Train Loss: 0.7774 | Val Loss: 0.8023\n",
      "Epoch 21 | Train Loss: 0.7760 | Val Loss: 0.7971\n",
      "Epoch 22 | Train Loss: 0.7573 | Val Loss: 0.8073\n",
      "Epoch 23 | Train Loss: 0.7563 | Val Loss: 0.8544\n",
      "Epoch 24 | Train Loss: 0.8153 | Val Loss: 0.8039\n",
      "Epoch 25 | Train Loss: 0.7664 | Val Loss: 0.8174\n",
      "Epoch 26 | Train Loss: 0.7605 | Val Loss: 0.7980\n",
      "Epoch 27 | Train Loss: 0.7428 | Val Loss: 0.7987\n",
      "Epoch 28 | Train Loss: 0.7244 | Val Loss: 0.7989\n",
      "Epoch 29 | Train Loss: 0.7466 | Val Loss: 0.8175\n",
      "Epoch 30 | Train Loss: 0.7363 | Val Loss: 0.7976\n",
      "Epoch 31 | Train Loss: 0.7282 | Val Loss: 0.7949\n",
      "Epoch 32 | Train Loss: 0.7484 | Val Loss: 0.8131\n",
      "Epoch 33 | Train Loss: 0.7458 | Val Loss: 0.7892\n",
      "Epoch 34 | Train Loss: 0.7264 | Val Loss: 0.7875\n",
      "Epoch 35 | Train Loss: 0.7465 | Val Loss: 0.7904\n",
      "Epoch 36 | Train Loss: 0.7291 | Val Loss: 0.7874\n",
      "Epoch 37 | Train Loss: 0.7408 | Val Loss: 0.7869\n",
      "Epoch 38 | Train Loss: 0.7323 | Val Loss: 0.7839\n",
      "Epoch 39 | Train Loss: 0.7180 | Val Loss: 0.7789\n",
      "Epoch 40 | Train Loss: 0.7448 | Val Loss: 0.7824\n",
      "Epoch 41 | Train Loss: 0.7313 | Val Loss: 0.7824\n",
      "Epoch 42 | Train Loss: 0.7254 | Val Loss: 0.7759\n",
      "Epoch 43 | Train Loss: 0.7259 | Val Loss: 0.7841\n",
      "Epoch 44 | Train Loss: 0.7272 | Val Loss: 0.7870\n",
      "Epoch 45 | Train Loss: 0.7395 | Val Loss: 0.7890\n",
      "Epoch 46 | Train Loss: 0.7340 | Val Loss: 0.7767\n",
      "Epoch 47 | Train Loss: 0.7314 | Val Loss: 0.7911\n",
      "Epoch 48 | Train Loss: 0.7200 | Val Loss: 0.8583\n",
      "Epoch 49 | Train Loss: 0.7632 | Val Loss: 0.7757\n",
      "Epoch 50 | Train Loss: 0.7352 | Val Loss: 0.7792\n",
      "Fold 5 ‚ñ∂ AUC: 0.752, Balanced Acc: 0.484\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9354 | Val Loss: 0.9146\n",
      "Epoch 02 | Train Loss: 0.8731 | Val Loss: 0.8978\n",
      "Epoch 03 | Train Loss: 0.8786 | Val Loss: 0.8907\n",
      "Epoch 04 | Train Loss: 0.8490 | Val Loss: 0.8832\n",
      "Epoch 05 | Train Loss: 0.8436 | Val Loss: 0.8897\n",
      "Epoch 06 | Train Loss: 0.8504 | Val Loss: 0.8774\n",
      "Epoch 07 | Train Loss: 0.8324 | Val Loss: 0.8757\n",
      "Epoch 08 | Train Loss: 0.8246 | Val Loss: 0.8671\n",
      "Epoch 09 | Train Loss: 0.8372 | Val Loss: 0.8826\n",
      "Epoch 10 | Train Loss: 0.8192 | Val Loss: 0.8711\n",
      "Epoch 11 | Train Loss: 0.8158 | Val Loss: 0.8568\n",
      "Epoch 12 | Train Loss: 0.8044 | Val Loss: 0.8562\n",
      "Epoch 13 | Train Loss: 0.7904 | Val Loss: 0.8583\n",
      "Epoch 14 | Train Loss: 0.7897 | Val Loss: 0.8470\n",
      "Epoch 15 | Train Loss: 0.7711 | Val Loss: 0.8664\n",
      "Epoch 16 | Train Loss: 0.7882 | Val Loss: 0.8569\n",
      "Epoch 17 | Train Loss: 0.7742 | Val Loss: 0.8489\n",
      "Epoch 18 | Train Loss: 0.7715 | Val Loss: 0.8480\n",
      "Epoch 19 | Train Loss: 0.7573 | Val Loss: 0.8470\n",
      "Epoch 20 | Train Loss: 0.7695 | Val Loss: 0.8391\n",
      "Epoch 21 | Train Loss: 0.7459 | Val Loss: 0.8369\n",
      "Epoch 22 | Train Loss: 0.7410 | Val Loss: 0.8563\n",
      "Epoch 23 | Train Loss: 0.7544 | Val Loss: 0.8401\n",
      "Epoch 24 | Train Loss: 0.7484 | Val Loss: 0.8364\n",
      "Epoch 25 | Train Loss: 0.7433 | Val Loss: 0.9019\n",
      "Epoch 26 | Train Loss: 0.7706 | Val Loss: 0.8422\n",
      "Epoch 27 | Train Loss: 0.7820 | Val Loss: 0.8369\n",
      "Epoch 28 | Train Loss: 0.7480 | Val Loss: 0.8985\n",
      "Epoch 29 | Train Loss: 0.7491 | Val Loss: 0.8288\n",
      "Epoch 30 | Train Loss: 0.7270 | Val Loss: 0.8551\n",
      "Epoch 31 | Train Loss: 0.7447 | Val Loss: 0.8668\n",
      "Epoch 32 | Train Loss: 0.7519 | Val Loss: 0.8675\n",
      "Epoch 33 | Train Loss: 0.7749 | Val Loss: 0.8263\n",
      "Epoch 34 | Train Loss: 0.7553 | Val Loss: 0.8605\n",
      "Epoch 35 | Train Loss: 0.7268 | Val Loss: 0.8366\n",
      "Epoch 36 | Train Loss: 0.7419 | Val Loss: 0.8253\n",
      "Epoch 37 | Train Loss: 0.7206 | Val Loss: 0.8243\n",
      "Epoch 38 | Train Loss: 0.7170 | Val Loss: 0.8291\n",
      "Epoch 39 | Train Loss: 0.7320 | Val Loss: 0.8438\n",
      "Epoch 40 | Train Loss: 0.7340 | Val Loss: 0.8210\n",
      "Epoch 41 | Train Loss: 0.7218 | Val Loss: 0.8470\n",
      "Epoch 42 | Train Loss: 0.7277 | Val Loss: 0.8219\n",
      "Epoch 43 | Train Loss: 0.7313 | Val Loss: 0.8199\n",
      "Epoch 44 | Train Loss: 0.7373 | Val Loss: 0.8211\n",
      "Epoch 45 | Train Loss: 0.7124 | Val Loss: 0.8271\n",
      "Epoch 46 | Train Loss: 0.7190 | Val Loss: 0.8179\n",
      "Epoch 47 | Train Loss: 0.7117 | Val Loss: 0.8343\n",
      "Epoch 48 | Train Loss: 0.7390 | Val Loss: 0.8374\n",
      "Epoch 49 | Train Loss: 0.7237 | Val Loss: 0.8146\n",
      "Epoch 50 | Train Loss: 0.7107 | Val Loss: 0.8278\n",
      "Fold 6 ‚ñ∂ AUC: 0.720, Balanced Acc: 0.449\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9561 | Val Loss: 0.8605\n",
      "Epoch 02 | Train Loss: 0.8955 | Val Loss: 0.8624\n",
      "Epoch 03 | Train Loss: 0.8699 | Val Loss: 0.8449\n",
      "Epoch 04 | Train Loss: 0.8512 | Val Loss: 0.8388\n",
      "Epoch 05 | Train Loss: 0.8717 | Val Loss: 0.8356\n",
      "Epoch 06 | Train Loss: 0.8558 | Val Loss: 0.8315\n",
      "Epoch 07 | Train Loss: 0.8433 | Val Loss: 0.8273\n",
      "Epoch 08 | Train Loss: 0.8554 | Val Loss: 0.8206\n",
      "Epoch 09 | Train Loss: 0.8439 | Val Loss: 0.8452\n",
      "Epoch 10 | Train Loss: 0.8484 | Val Loss: 0.8216\n",
      "Epoch 11 | Train Loss: 0.8235 | Val Loss: 0.8048\n",
      "Epoch 12 | Train Loss: 0.8390 | Val Loss: 0.8386\n",
      "Epoch 13 | Train Loss: 0.8221 | Val Loss: 0.7980\n",
      "Epoch 14 | Train Loss: 0.8292 | Val Loss: 0.7880\n",
      "Epoch 15 | Train Loss: 0.8109 | Val Loss: 0.8727\n",
      "Epoch 16 | Train Loss: 0.8228 | Val Loss: 0.7786\n",
      "Epoch 17 | Train Loss: 0.8006 | Val Loss: 0.7701\n",
      "Epoch 18 | Train Loss: 0.8024 | Val Loss: 0.7866\n",
      "Epoch 19 | Train Loss: 0.7937 | Val Loss: 0.7839\n",
      "Epoch 20 | Train Loss: 0.7892 | Val Loss: 0.7674\n",
      "Epoch 21 | Train Loss: 0.7775 | Val Loss: 0.7471\n",
      "Epoch 22 | Train Loss: 0.7862 | Val Loss: 0.7566\n",
      "Epoch 23 | Train Loss: 0.7787 | Val Loss: 0.8093\n",
      "Epoch 24 | Train Loss: 0.7953 | Val Loss: 0.7646\n",
      "Epoch 25 | Train Loss: 0.7754 | Val Loss: 0.7469\n",
      "Epoch 26 | Train Loss: 0.7642 | Val Loss: 0.7717\n",
      "Epoch 27 | Train Loss: 0.7871 | Val Loss: 0.7535\n",
      "Epoch 28 | Train Loss: 0.7967 | Val Loss: 0.7459\n",
      "Epoch 29 | Train Loss: 0.7614 | Val Loss: 0.7468\n",
      "Epoch 30 | Train Loss: 0.7555 | Val Loss: 0.7384\n",
      "Epoch 31 | Train Loss: 0.7512 | Val Loss: 0.7339\n",
      "Epoch 32 | Train Loss: 0.7545 | Val Loss: 0.7521\n",
      "Epoch 33 | Train Loss: 0.8029 | Val Loss: 0.7992\n",
      "Epoch 34 | Train Loss: 0.7422 | Val Loss: 0.7481\n",
      "Epoch 35 | Train Loss: 0.7356 | Val Loss: 0.7401\n",
      "Epoch 36 | Train Loss: 0.7379 | Val Loss: 0.7442\n",
      "Epoch 37 | Train Loss: 0.7460 | Val Loss: 0.7283\n",
      "Epoch 38 | Train Loss: 0.7516 | Val Loss: 0.7294\n",
      "Epoch 39 | Train Loss: 0.7280 | Val Loss: 0.7497\n",
      "Epoch 40 | Train Loss: 0.7353 | Val Loss: 0.7532\n",
      "Epoch 41 | Train Loss: 0.7684 | Val Loss: 0.7317\n",
      "Epoch 42 | Train Loss: 0.7453 | Val Loss: 0.7422\n",
      "Epoch 43 | Train Loss: 0.7324 | Val Loss: 0.7462\n",
      "Epoch 44 | Train Loss: 0.7531 | Val Loss: 0.7796\n",
      "Epoch 45 | Train Loss: 0.7469 | Val Loss: 0.7958\n",
      "Epoch 46 | Train Loss: 0.7424 | Val Loss: 0.7266\n",
      "Epoch 47 | Train Loss: 0.7321 | Val Loss: 0.7765\n",
      "Epoch 48 | Train Loss: 0.7547 | Val Loss: 0.7370\n",
      "Epoch 49 | Train Loss: 0.7306 | Val Loss: 0.7493\n",
      "Epoch 50 | Train Loss: 0.7269 | Val Loss: 0.7669\n",
      "Fold 7 ‚ñ∂ AUC: 0.779, Balanced Acc: 0.437\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9152 | Val Loss: 0.8806\n",
      "Epoch 02 | Train Loss: 0.8800 | Val Loss: 0.8635\n",
      "Epoch 03 | Train Loss: 0.8672 | Val Loss: 0.8538\n",
      "Epoch 04 | Train Loss: 0.8600 | Val Loss: 0.8542\n",
      "Epoch 05 | Train Loss: 0.8442 | Val Loss: 0.8405\n",
      "Epoch 06 | Train Loss: 0.8466 | Val Loss: 0.8335\n",
      "Epoch 07 | Train Loss: 0.8335 | Val Loss: 0.8415\n",
      "Epoch 08 | Train Loss: 0.8351 | Val Loss: 0.8334\n",
      "Epoch 09 | Train Loss: 0.8279 | Val Loss: 0.8234\n",
      "Epoch 10 | Train Loss: 0.8183 | Val Loss: 0.8220\n",
      "Epoch 11 | Train Loss: 0.8116 | Val Loss: 0.8062\n",
      "Epoch 12 | Train Loss: 0.8082 | Val Loss: 0.8020\n",
      "Epoch 13 | Train Loss: 0.8024 | Val Loss: 0.8029\n",
      "Epoch 14 | Train Loss: 0.8193 | Val Loss: 0.7954\n",
      "Epoch 15 | Train Loss: 0.8191 | Val Loss: 0.7984\n",
      "Epoch 16 | Train Loss: 0.7904 | Val Loss: 0.8156\n",
      "Epoch 17 | Train Loss: 0.7854 | Val Loss: 0.8008\n",
      "Epoch 18 | Train Loss: 0.7835 | Val Loss: 0.7902\n",
      "Epoch 19 | Train Loss: 0.7983 | Val Loss: 0.7958\n",
      "Epoch 20 | Train Loss: 0.7675 | Val Loss: 0.8234\n",
      "Epoch 21 | Train Loss: 0.7798 | Val Loss: 0.7889\n",
      "Epoch 22 | Train Loss: 0.7589 | Val Loss: 0.7861\n",
      "Epoch 23 | Train Loss: 0.7478 | Val Loss: 0.7876\n",
      "Epoch 24 | Train Loss: 0.7603 | Val Loss: 0.8183\n",
      "Epoch 25 | Train Loss: 0.7493 | Val Loss: 0.7947\n",
      "Epoch 26 | Train Loss: 0.7674 | Val Loss: 0.7986\n",
      "Epoch 27 | Train Loss: 0.7541 | Val Loss: 0.7912\n",
      "Epoch 28 | Train Loss: 0.7431 | Val Loss: 0.7883\n",
      "Epoch 29 | Train Loss: 0.7457 | Val Loss: 0.7914\n",
      "Epoch 30 | Train Loss: 0.7404 | Val Loss: 0.8031\n",
      "Epoch 31 | Train Loss: 0.7429 | Val Loss: 0.8112\n",
      "Epoch 32 | Train Loss: 0.7387 | Val Loss: 0.7934\n",
      "Epoch 33 | Train Loss: 0.7489 | Val Loss: 0.8032\n",
      "Epoch 34 | Train Loss: 0.7209 | Val Loss: 0.8034\n",
      "Epoch 35 | Train Loss: 0.7190 | Val Loss: 0.7962\n",
      "Epoch 36 | Train Loss: 0.7101 | Val Loss: 0.8490\n",
      "Epoch 37 | Train Loss: 0.7539 | Val Loss: 0.7995\n",
      "Epoch 38 | Train Loss: 0.7432 | Val Loss: 0.8098\n",
      "Epoch 39 | Train Loss: 0.7228 | Val Loss: 0.8263\n",
      "Epoch 40 | Train Loss: 0.7281 | Val Loss: 0.8122\n",
      "Epoch 41 | Train Loss: 0.7141 | Val Loss: 0.8024\n",
      "Epoch 42 | Train Loss: 0.7211 | Val Loss: 0.8095\n",
      "Epoch 43 | Train Loss: 0.7263 | Val Loss: 0.8170\n",
      "Epoch 44 | Train Loss: 0.7118 | Val Loss: 0.8254\n",
      "Epoch 45 | Train Loss: 0.7297 | Val Loss: 0.8117\n",
      "Epoch 46 | Train Loss: 0.7127 | Val Loss: 0.8108\n",
      "Epoch 47 | Train Loss: 0.7017 | Val Loss: 0.8149\n",
      "Epoch 48 | Train Loss: 0.7171 | Val Loss: 0.8483\n",
      "Epoch 49 | Train Loss: 0.7186 | Val Loss: 0.8043\n",
      "Epoch 50 | Train Loss: 0.7076 | Val Loss: 0.8126\n",
      "Fold 8 ‚ñ∂ AUC: 0.708, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9157 | Val Loss: 0.8856\n",
      "Epoch 02 | Train Loss: 0.8640 | Val Loss: 0.8621\n",
      "Epoch 03 | Train Loss: 0.8448 | Val Loss: 0.8628\n",
      "Epoch 04 | Train Loss: 0.8581 | Val Loss: 0.8555\n",
      "Epoch 05 | Train Loss: 0.8410 | Val Loss: 0.8494\n",
      "Epoch 06 | Train Loss: 0.8509 | Val Loss: 0.8478\n",
      "Epoch 07 | Train Loss: 0.8404 | Val Loss: 0.8429\n",
      "Epoch 08 | Train Loss: 0.8259 | Val Loss: 0.8639\n",
      "Epoch 09 | Train Loss: 0.8448 | Val Loss: 0.8439\n",
      "Epoch 10 | Train Loss: 0.8173 | Val Loss: 0.8387\n",
      "Epoch 11 | Train Loss: 0.8119 | Val Loss: 0.8474\n",
      "Epoch 12 | Train Loss: 0.7882 | Val Loss: 0.8269\n",
      "Epoch 13 | Train Loss: 0.8022 | Val Loss: 0.8237\n",
      "Epoch 14 | Train Loss: 0.7991 | Val Loss: 0.8217\n",
      "Epoch 15 | Train Loss: 0.7940 | Val Loss: 0.8546\n",
      "Epoch 16 | Train Loss: 0.8142 | Val Loss: 0.8141\n",
      "Epoch 17 | Train Loss: 0.7693 | Val Loss: 0.8273\n",
      "Epoch 18 | Train Loss: 0.7800 | Val Loss: 0.8129\n",
      "Epoch 19 | Train Loss: 0.7592 | Val Loss: 0.8151\n",
      "Epoch 20 | Train Loss: 0.7780 | Val Loss: 0.8199\n",
      "Epoch 21 | Train Loss: 0.7470 | Val Loss: 0.8459\n",
      "Epoch 22 | Train Loss: 0.7593 | Val Loss: 0.8084\n",
      "Epoch 23 | Train Loss: 0.7493 | Val Loss: 0.8051\n",
      "Epoch 24 | Train Loss: 0.7456 | Val Loss: 0.8139\n",
      "Epoch 25 | Train Loss: 0.7468 | Val Loss: 0.8090\n",
      "Epoch 26 | Train Loss: 0.7402 | Val Loss: 0.8006\n",
      "Epoch 27 | Train Loss: 0.7486 | Val Loss: 0.8430\n",
      "Epoch 28 | Train Loss: 0.7672 | Val Loss: 0.8469\n",
      "Epoch 29 | Train Loss: 0.7336 | Val Loss: 0.7978\n",
      "Epoch 30 | Train Loss: 0.7260 | Val Loss: 0.8273\n",
      "Epoch 31 | Train Loss: 0.7432 | Val Loss: 0.8346\n",
      "Epoch 32 | Train Loss: 0.7587 | Val Loss: 0.7970\n",
      "Epoch 33 | Train Loss: 0.7256 | Val Loss: 0.8040\n",
      "Epoch 34 | Train Loss: 0.7272 | Val Loss: 0.8055\n",
      "Epoch 35 | Train Loss: 0.7454 | Val Loss: 0.7953\n",
      "Epoch 36 | Train Loss: 0.7269 | Val Loss: 0.8332\n",
      "Epoch 37 | Train Loss: 0.7363 | Val Loss: 0.8115\n",
      "Epoch 38 | Train Loss: 0.7070 | Val Loss: 0.7993\n",
      "Epoch 39 | Train Loss: 0.7367 | Val Loss: 0.7873\n",
      "Epoch 40 | Train Loss: 0.7174 | Val Loss: 0.8092\n",
      "Epoch 41 | Train Loss: 0.7101 | Val Loss: 0.7897\n",
      "Epoch 42 | Train Loss: 0.7319 | Val Loss: 0.7928\n",
      "Epoch 43 | Train Loss: 0.7132 | Val Loss: 0.7820\n",
      "Epoch 44 | Train Loss: 0.7365 | Val Loss: 0.7789\n",
      "Epoch 45 | Train Loss: 0.7306 | Val Loss: 0.7900\n",
      "Epoch 46 | Train Loss: 0.7269 | Val Loss: 0.7872\n",
      "Epoch 47 | Train Loss: 0.7421 | Val Loss: 0.7907\n",
      "Epoch 48 | Train Loss: 0.7501 | Val Loss: 0.8108\n",
      "Epoch 49 | Train Loss: 0.7353 | Val Loss: 0.8278\n",
      "Epoch 50 | Train Loss: 0.7516 | Val Loss: 0.7773\n",
      "Fold 9 ‚ñ∂ AUC: 0.729, Balanced Acc: 0.486\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9647 | Val Loss: 0.8809\n",
      "Epoch 02 | Train Loss: 0.8790 | Val Loss: 0.8723\n",
      "Epoch 03 | Train Loss: 0.8814 | Val Loss: 0.8753\n",
      "Epoch 04 | Train Loss: 0.8670 | Val Loss: 0.8573\n",
      "Epoch 05 | Train Loss: 0.8711 | Val Loss: 0.8551\n",
      "Epoch 06 | Train Loss: 0.8664 | Val Loss: 0.8514\n",
      "Epoch 07 | Train Loss: 0.8513 | Val Loss: 0.8459\n",
      "Epoch 08 | Train Loss: 0.8411 | Val Loss: 0.8403\n",
      "Epoch 09 | Train Loss: 0.8462 | Val Loss: 0.8388\n",
      "Epoch 10 | Train Loss: 0.8380 | Val Loss: 0.8435\n",
      "Epoch 11 | Train Loss: 0.8320 | Val Loss: 0.8263\n",
      "Epoch 12 | Train Loss: 0.8375 | Val Loss: 0.8135\n",
      "Epoch 13 | Train Loss: 0.8409 | Val Loss: 0.8520\n",
      "Epoch 14 | Train Loss: 0.8495 | Val Loss: 0.8265\n",
      "Epoch 15 | Train Loss: 0.8245 | Val Loss: 0.8078\n",
      "Epoch 16 | Train Loss: 0.8086 | Val Loss: 0.8000\n",
      "Epoch 17 | Train Loss: 0.7921 | Val Loss: 0.7863\n",
      "Epoch 18 | Train Loss: 0.8005 | Val Loss: 0.7925\n",
      "Epoch 19 | Train Loss: 0.7977 | Val Loss: 0.7759\n",
      "Epoch 20 | Train Loss: 0.7970 | Val Loss: 0.7715\n",
      "Epoch 21 | Train Loss: 0.7732 | Val Loss: 0.7839\n",
      "Epoch 22 | Train Loss: 0.7718 | Val Loss: 0.7796\n",
      "Epoch 23 | Train Loss: 0.7645 | Val Loss: 0.8504\n",
      "Epoch 24 | Train Loss: 0.7900 | Val Loss: 0.8037\n",
      "Epoch 25 | Train Loss: 0.7672 | Val Loss: 0.7931\n",
      "Epoch 26 | Train Loss: 0.7569 | Val Loss: 0.7543\n",
      "Epoch 27 | Train Loss: 0.7662 | Val Loss: 0.7530\n",
      "Epoch 28 | Train Loss: 0.7619 | Val Loss: 0.7684\n",
      "Epoch 29 | Train Loss: 0.7555 | Val Loss: 0.7795\n",
      "Epoch 30 | Train Loss: 0.7533 | Val Loss: 0.7904\n",
      "Epoch 31 | Train Loss: 0.7398 | Val Loss: 0.7713\n",
      "Epoch 32 | Train Loss: 0.8104 | Val Loss: 0.8132\n",
      "Epoch 33 | Train Loss: 0.7893 | Val Loss: 0.7603\n",
      "Epoch 34 | Train Loss: 0.7515 | Val Loss: 0.7635\n",
      "Epoch 35 | Train Loss: 0.7484 | Val Loss: 0.7908\n",
      "Epoch 36 | Train Loss: 0.7544 | Val Loss: 0.7520\n",
      "Epoch 37 | Train Loss: 0.7449 | Val Loss: 0.7682\n",
      "Epoch 38 | Train Loss: 0.7478 | Val Loss: 0.7748\n",
      "Epoch 39 | Train Loss: 0.7501 | Val Loss: 0.8101\n",
      "Epoch 40 | Train Loss: 0.7276 | Val Loss: 0.7608\n",
      "Epoch 41 | Train Loss: 0.7369 | Val Loss: 0.7537\n",
      "Epoch 42 | Train Loss: 0.7222 | Val Loss: 0.7896\n",
      "Epoch 43 | Train Loss: 0.7224 | Val Loss: 0.7668\n",
      "Epoch 44 | Train Loss: 0.7226 | Val Loss: 0.7999\n",
      "Epoch 45 | Train Loss: 0.7320 | Val Loss: 0.7553\n",
      "Epoch 46 | Train Loss: 0.7203 | Val Loss: 0.7522\n",
      "Epoch 47 | Train Loss: 0.7339 | Val Loss: 0.7620\n",
      "Epoch 48 | Train Loss: 0.7250 | Val Loss: 0.7501\n",
      "Epoch 49 | Train Loss: 0.7247 | Val Loss: 0.7550\n",
      "Epoch 50 | Train Loss: 0.7285 | Val Loss: 0.8166\n",
      "Fold 10 ‚ñ∂ AUC: 0.718, Balanced Acc: 0.443\n",
      "üîç Summary for hd=256, dp=0.2, lr=0.0001 ‚Üí AUC: 0.7388¬±0.0397 | BalAcc: 0.4822¬±0.0493\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.4, lr=0.001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 1.0048 | Val Loss: 0.8855\n",
      "Epoch 02 | Train Loss: 0.8868 | Val Loss: 0.8553\n",
      "Epoch 03 | Train Loss: 0.8489 | Val Loss: 0.8660\n",
      "Epoch 04 | Train Loss: 0.8609 | Val Loss: 0.9020\n",
      "Epoch 05 | Train Loss: 0.8856 | Val Loss: 0.8224\n",
      "Epoch 06 | Train Loss: 0.8343 | Val Loss: 0.7825\n",
      "Epoch 07 | Train Loss: 0.7906 | Val Loss: 0.7651\n",
      "Epoch 08 | Train Loss: 0.8254 | Val Loss: 0.7521\n",
      "Epoch 09 | Train Loss: 0.7958 | Val Loss: 0.7765\n",
      "Epoch 10 | Train Loss: 0.7868 | Val Loss: 0.7788\n",
      "Epoch 11 | Train Loss: 0.7711 | Val Loss: 0.7563\n",
      "Epoch 12 | Train Loss: 0.7622 | Val Loss: 0.7544\n",
      "Epoch 13 | Train Loss: 0.7802 | Val Loss: 0.7760\n",
      "Epoch 14 | Train Loss: 0.7558 | Val Loss: 0.7185\n",
      "Epoch 15 | Train Loss: 0.7212 | Val Loss: 0.7078\n",
      "Epoch 16 | Train Loss: 0.7536 | Val Loss: 0.7322\n",
      "Epoch 17 | Train Loss: 0.7572 | Val Loss: 0.6993\n",
      "Epoch 18 | Train Loss: 0.7441 | Val Loss: 0.7180\n",
      "Epoch 19 | Train Loss: 0.7561 | Val Loss: 0.6992\n",
      "Epoch 20 | Train Loss: 0.7364 | Val Loss: 0.7015\n",
      "Epoch 21 | Train Loss: 0.7344 | Val Loss: 0.7083\n",
      "Epoch 22 | Train Loss: 0.7741 | Val Loss: 0.7189\n",
      "Epoch 23 | Train Loss: 0.7749 | Val Loss: 0.6997\n",
      "Epoch 24 | Train Loss: 0.7601 | Val Loss: 0.7272\n",
      "Epoch 25 | Train Loss: 0.7681 | Val Loss: 0.7015\n",
      "Epoch 26 | Train Loss: 0.7487 | Val Loss: 0.6899\n",
      "Epoch 27 | Train Loss: 0.7351 | Val Loss: 0.7077\n",
      "Epoch 28 | Train Loss: 0.7527 | Val Loss: 0.6912\n",
      "Epoch 29 | Train Loss: 0.7112 | Val Loss: 0.6951\n",
      "Epoch 30 | Train Loss: 0.7566 | Val Loss: 0.7010\n",
      "Epoch 31 | Train Loss: 0.7360 | Val Loss: 0.7128\n",
      "Epoch 32 | Train Loss: 0.7537 | Val Loss: 0.7180\n",
      "Epoch 33 | Train Loss: 0.7361 | Val Loss: 0.7143\n",
      "Epoch 34 | Train Loss: 0.7523 | Val Loss: 0.6889\n",
      "Epoch 35 | Train Loss: 0.7384 | Val Loss: 0.7004\n",
      "Epoch 36 | Train Loss: 0.7299 | Val Loss: 0.7025\n",
      "Epoch 37 | Train Loss: 0.7242 | Val Loss: 0.7128\n",
      "Epoch 38 | Train Loss: 0.7407 | Val Loss: 0.6865\n",
      "Epoch 39 | Train Loss: 0.7273 | Val Loss: 0.6965\n",
      "Epoch 40 | Train Loss: 0.7401 | Val Loss: 0.6958\n",
      "Epoch 41 | Train Loss: 0.7407 | Val Loss: 0.7430\n",
      "Epoch 42 | Train Loss: 0.7285 | Val Loss: 0.7225\n",
      "Epoch 43 | Train Loss: 0.7538 | Val Loss: 0.6993\n",
      "Epoch 44 | Train Loss: 0.7338 | Val Loss: 0.7068\n",
      "Epoch 45 | Train Loss: 0.7261 | Val Loss: 0.7043\n",
      "Epoch 46 | Train Loss: 0.7145 | Val Loss: 0.7283\n",
      "Epoch 47 | Train Loss: 0.7089 | Val Loss: 0.7209\n",
      "Epoch 48 | Train Loss: 0.7418 | Val Loss: 0.7382\n",
      "Epoch 49 | Train Loss: 0.7383 | Val Loss: 0.7264\n",
      "Epoch 50 | Train Loss: 0.7187 | Val Loss: 0.7288\n",
      "Fold 1 ‚ñ∂ AUC: 0.768, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9282 | Val Loss: 0.8808\n",
      "Epoch 02 | Train Loss: 0.8976 | Val Loss: 0.8630\n",
      "Epoch 03 | Train Loss: 0.8906 | Val Loss: 0.8391\n",
      "Epoch 04 | Train Loss: 0.8502 | Val Loss: 0.8170\n",
      "Epoch 05 | Train Loss: 0.8164 | Val Loss: 0.7727\n",
      "Epoch 06 | Train Loss: 0.7961 | Val Loss: 0.7584\n",
      "Epoch 07 | Train Loss: 0.8060 | Val Loss: 0.7477\n",
      "Epoch 08 | Train Loss: 0.7810 | Val Loss: 0.7565\n",
      "Epoch 09 | Train Loss: 0.7690 | Val Loss: 0.7375\n",
      "Epoch 10 | Train Loss: 0.8069 | Val Loss: 0.7963\n",
      "Epoch 11 | Train Loss: 0.7811 | Val Loss: 0.7370\n",
      "Epoch 12 | Train Loss: 0.7552 | Val Loss: 0.7292\n",
      "Epoch 13 | Train Loss: 0.7489 | Val Loss: 0.7294\n",
      "Epoch 14 | Train Loss: 0.7643 | Val Loss: 0.7128\n",
      "Epoch 15 | Train Loss: 0.7770 | Val Loss: 0.7205\n",
      "Epoch 16 | Train Loss: 0.7680 | Val Loss: 0.7484\n",
      "Epoch 17 | Train Loss: 0.7552 | Val Loss: 0.7215\n",
      "Epoch 18 | Train Loss: 0.7452 | Val Loss: 0.7150\n",
      "Epoch 19 | Train Loss: 0.7654 | Val Loss: 0.7200\n",
      "Epoch 20 | Train Loss: 0.7507 | Val Loss: 0.7249\n",
      "Epoch 21 | Train Loss: 0.7694 | Val Loss: 0.7763\n",
      "Epoch 22 | Train Loss: 0.7673 | Val Loss: 0.7288\n",
      "Epoch 23 | Train Loss: 0.7459 | Val Loss: 0.7750\n",
      "Epoch 24 | Train Loss: 0.7465 | Val Loss: 0.8134\n",
      "Epoch 25 | Train Loss: 0.7300 | Val Loss: 0.7802\n",
      "Epoch 26 | Train Loss: 0.7300 | Val Loss: 0.7611\n",
      "Epoch 27 | Train Loss: 0.7290 | Val Loss: 0.7167\n",
      "Epoch 28 | Train Loss: 0.7368 | Val Loss: 0.6938\n",
      "Epoch 29 | Train Loss: 0.7366 | Val Loss: 0.7002\n",
      "Epoch 30 | Train Loss: 0.7679 | Val Loss: 0.7960\n",
      "Epoch 31 | Train Loss: 0.7475 | Val Loss: 0.7719\n",
      "Epoch 32 | Train Loss: 0.7421 | Val Loss: 0.7416\n",
      "Epoch 33 | Train Loss: 0.7408 | Val Loss: 0.7015\n",
      "Epoch 34 | Train Loss: 0.7528 | Val Loss: 0.7220\n",
      "Epoch 35 | Train Loss: 0.7563 | Val Loss: 0.7139\n",
      "Epoch 36 | Train Loss: 0.7531 | Val Loss: 0.7058\n",
      "Epoch 37 | Train Loss: 0.7355 | Val Loss: 0.7222\n",
      "Epoch 38 | Train Loss: 0.7269 | Val Loss: 0.7001\n",
      "Epoch 39 | Train Loss: 0.7283 | Val Loss: 0.7300\n",
      "Epoch 40 | Train Loss: 0.7347 | Val Loss: 0.7081\n",
      "Epoch 41 | Train Loss: 0.7425 | Val Loss: 0.7032\n",
      "Epoch 42 | Train Loss: 0.7496 | Val Loss: 0.7392\n",
      "Epoch 43 | Train Loss: 0.7171 | Val Loss: 0.7119\n",
      "Epoch 44 | Train Loss: 0.7143 | Val Loss: 0.8073\n",
      "Epoch 45 | Train Loss: 0.7377 | Val Loss: 0.7840\n",
      "Epoch 46 | Train Loss: 0.7607 | Val Loss: 0.7096\n",
      "Epoch 47 | Train Loss: 0.7626 | Val Loss: 0.7172\n",
      "Epoch 48 | Train Loss: 0.7870 | Val Loss: 0.7092\n",
      "Epoch 49 | Train Loss: 0.7225 | Val Loss: 0.7571\n",
      "Epoch 50 | Train Loss: 0.7228 | Val Loss: 0.7120\n",
      "Fold 2 ‚ñ∂ AUC: 0.736, Balanced Acc: 0.566\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9858 | Val Loss: 0.8657\n",
      "Epoch 02 | Train Loss: 0.8704 | Val Loss: 0.8544\n",
      "Epoch 03 | Train Loss: 0.8665 | Val Loss: 0.8461\n",
      "Epoch 04 | Train Loss: 0.8607 | Val Loss: 0.8243\n",
      "Epoch 05 | Train Loss: 0.8389 | Val Loss: 0.7936\n",
      "Epoch 06 | Train Loss: 0.8212 | Val Loss: 0.7945\n",
      "Epoch 07 | Train Loss: 0.8080 | Val Loss: 0.7611\n",
      "Epoch 08 | Train Loss: 0.7706 | Val Loss: 0.7398\n",
      "Epoch 09 | Train Loss: 0.7879 | Val Loss: 0.7983\n",
      "Epoch 10 | Train Loss: 0.8097 | Val Loss: 0.7627\n",
      "Epoch 11 | Train Loss: 0.7777 | Val Loss: 0.7519\n",
      "Epoch 12 | Train Loss: 0.7859 | Val Loss: 0.7536\n",
      "Epoch 13 | Train Loss: 0.7490 | Val Loss: 0.7894\n",
      "Epoch 14 | Train Loss: 0.7689 | Val Loss: 0.7348\n",
      "Epoch 15 | Train Loss: 0.7460 | Val Loss: 0.7318\n",
      "Epoch 16 | Train Loss: 0.7570 | Val Loss: 0.7424\n",
      "Epoch 17 | Train Loss: 0.7630 | Val Loss: 0.8121\n",
      "Epoch 18 | Train Loss: 0.7640 | Val Loss: 0.7873\n",
      "Epoch 19 | Train Loss: 0.7358 | Val Loss: 0.7732\n",
      "Epoch 20 | Train Loss: 0.7404 | Val Loss: 0.7167\n",
      "Epoch 21 | Train Loss: 0.7787 | Val Loss: 0.7323\n",
      "Epoch 22 | Train Loss: 0.7841 | Val Loss: 0.7209\n",
      "Epoch 23 | Train Loss: 0.7310 | Val Loss: 0.7168\n",
      "Epoch 24 | Train Loss: 0.7438 | Val Loss: 0.7247\n",
      "Epoch 25 | Train Loss: 0.7408 | Val Loss: 0.7173\n",
      "Epoch 26 | Train Loss: 0.7525 | Val Loss: 0.7262\n",
      "Epoch 27 | Train Loss: 0.7173 | Val Loss: 0.7224\n",
      "Epoch 28 | Train Loss: 0.7176 | Val Loss: 0.7176\n",
      "Epoch 29 | Train Loss: 0.7194 | Val Loss: 0.7376\n",
      "Epoch 30 | Train Loss: 0.7424 | Val Loss: 0.7182\n",
      "Epoch 31 | Train Loss: 0.7569 | Val Loss: 0.7228\n",
      "Epoch 32 | Train Loss: 0.7093 | Val Loss: 0.7289\n",
      "Epoch 33 | Train Loss: 0.7679 | Val Loss: 0.7308\n",
      "Epoch 34 | Train Loss: 0.7389 | Val Loss: 0.7209\n",
      "Epoch 35 | Train Loss: 0.7242 | Val Loss: 0.7202\n",
      "Epoch 36 | Train Loss: 0.7359 | Val Loss: 0.7146\n",
      "Epoch 37 | Train Loss: 0.7331 | Val Loss: 0.7266\n",
      "Epoch 38 | Train Loss: 0.7491 | Val Loss: 0.7270\n",
      "Epoch 39 | Train Loss: 0.7323 | Val Loss: 0.7184\n",
      "Epoch 40 | Train Loss: 0.7314 | Val Loss: 0.7241\n",
      "Epoch 41 | Train Loss: 0.7351 | Val Loss: 0.7113\n",
      "Epoch 42 | Train Loss: 0.7061 | Val Loss: 0.7166\n",
      "Epoch 43 | Train Loss: 0.7345 | Val Loss: 0.7327\n",
      "Epoch 44 | Train Loss: 0.7484 | Val Loss: 0.7207\n",
      "Epoch 45 | Train Loss: 0.7555 | Val Loss: 0.7257\n",
      "Epoch 46 | Train Loss: 0.7164 | Val Loss: 0.7206\n",
      "Epoch 47 | Train Loss: 0.7282 | Val Loss: 0.7350\n",
      "Epoch 48 | Train Loss: 0.7325 | Val Loss: 0.7186\n",
      "Epoch 49 | Train Loss: 0.7274 | Val Loss: 0.7317\n",
      "Epoch 50 | Train Loss: 0.7401 | Val Loss: 0.7358\n",
      "Fold 3 ‚ñ∂ AUC: 0.761, Balanced Acc: 0.476\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9620 | Val Loss: 0.8669\n",
      "Epoch 02 | Train Loss: 0.9109 | Val Loss: 0.8566\n",
      "Epoch 03 | Train Loss: 0.8711 | Val Loss: 0.8463\n",
      "Epoch 04 | Train Loss: 0.8528 | Val Loss: 0.8373\n",
      "Epoch 05 | Train Loss: 0.8370 | Val Loss: 0.8018\n",
      "Epoch 06 | Train Loss: 0.7964 | Val Loss: 0.7458\n",
      "Epoch 07 | Train Loss: 0.7802 | Val Loss: 0.7418\n",
      "Epoch 08 | Train Loss: 0.8009 | Val Loss: 0.7148\n",
      "Epoch 09 | Train Loss: 0.7741 | Val Loss: 0.7194\n",
      "Epoch 10 | Train Loss: 0.7822 | Val Loss: 0.8672\n",
      "Epoch 11 | Train Loss: 0.8154 | Val Loss: 0.7218\n",
      "Epoch 12 | Train Loss: 0.7900 | Val Loss: 0.7548\n",
      "Epoch 13 | Train Loss: 0.8073 | Val Loss: 0.7413\n",
      "Epoch 14 | Train Loss: 0.7417 | Val Loss: 0.6975\n",
      "Epoch 15 | Train Loss: 0.7595 | Val Loss: 0.6800\n",
      "Epoch 16 | Train Loss: 0.7620 | Val Loss: 0.6859\n",
      "Epoch 17 | Train Loss: 0.7558 | Val Loss: 0.6905\n",
      "Epoch 18 | Train Loss: 0.7494 | Val Loss: 0.6917\n",
      "Epoch 19 | Train Loss: 0.7907 | Val Loss: 0.6781\n",
      "Epoch 20 | Train Loss: 0.7481 | Val Loss: 0.6897\n",
      "Epoch 21 | Train Loss: 0.7647 | Val Loss: 0.6969\n",
      "Epoch 22 | Train Loss: 0.7704 | Val Loss: 0.7397\n",
      "Epoch 23 | Train Loss: 0.7588 | Val Loss: 0.6732\n",
      "Epoch 24 | Train Loss: 0.7462 | Val Loss: 0.6995\n",
      "Epoch 25 | Train Loss: 0.7529 | Val Loss: 0.6721\n",
      "Epoch 26 | Train Loss: 0.7693 | Val Loss: 0.7204\n",
      "Epoch 27 | Train Loss: 0.7523 | Val Loss: 0.6645\n",
      "Epoch 28 | Train Loss: 0.7488 | Val Loss: 0.6671\n",
      "Epoch 29 | Train Loss: 0.7394 | Val Loss: 0.6759\n",
      "Epoch 30 | Train Loss: 0.7549 | Val Loss: 0.6554\n",
      "Epoch 31 | Train Loss: 0.7714 | Val Loss: 0.6620\n",
      "Epoch 32 | Train Loss: 0.7529 | Val Loss: 0.6993\n",
      "Epoch 33 | Train Loss: 0.7534 | Val Loss: 0.6726\n",
      "Epoch 34 | Train Loss: 0.7423 | Val Loss: 0.6600\n",
      "Epoch 35 | Train Loss: 0.7441 | Val Loss: 0.6936\n",
      "Epoch 36 | Train Loss: 0.7407 | Val Loss: 0.6813\n",
      "Epoch 37 | Train Loss: 0.7333 | Val Loss: 0.6731\n",
      "Epoch 38 | Train Loss: 0.7296 | Val Loss: 0.6870\n",
      "Epoch 39 | Train Loss: 0.7706 | Val Loss: 0.6894\n",
      "Epoch 40 | Train Loss: 0.7682 | Val Loss: 0.7024\n",
      "Epoch 41 | Train Loss: 0.7216 | Val Loss: 0.6689\n",
      "Epoch 42 | Train Loss: 0.7347 | Val Loss: 0.6871\n",
      "Epoch 43 | Train Loss: 0.7480 | Val Loss: 0.6784\n",
      "Epoch 44 | Train Loss: 0.7284 | Val Loss: 0.6721\n",
      "Epoch 45 | Train Loss: 0.7434 | Val Loss: 0.6855\n",
      "Epoch 46 | Train Loss: 0.7430 | Val Loss: 0.6746\n",
      "Epoch 47 | Train Loss: 0.7594 | Val Loss: 0.6796\n",
      "Epoch 48 | Train Loss: 0.7254 | Val Loss: 0.6811\n",
      "Epoch 49 | Train Loss: 0.7319 | Val Loss: 0.6716\n",
      "Epoch 50 | Train Loss: 0.7531 | Val Loss: 0.6858\n",
      "Fold 4 ‚ñ∂ AUC: 0.751, Balanced Acc: 0.540\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9480 | Val Loss: 0.9265\n",
      "Epoch 02 | Train Loss: 0.9052 | Val Loss: 0.9152\n",
      "Epoch 03 | Train Loss: 0.8538 | Val Loss: 0.9052\n",
      "Epoch 04 | Train Loss: 0.8531 | Val Loss: 0.8650\n",
      "Epoch 05 | Train Loss: 0.8481 | Val Loss: 0.8602\n",
      "Epoch 06 | Train Loss: 0.8060 | Val Loss: 0.8408\n",
      "Epoch 07 | Train Loss: 0.7781 | Val Loss: 0.9015\n",
      "Epoch 08 | Train Loss: 0.8255 | Val Loss: 0.9557\n",
      "Epoch 09 | Train Loss: 0.7891 | Val Loss: 0.8649\n",
      "Epoch 10 | Train Loss: 0.7557 | Val Loss: 0.8226\n",
      "Epoch 11 | Train Loss: 0.7620 | Val Loss: 0.8199\n",
      "Epoch 12 | Train Loss: 0.7432 | Val Loss: 0.8167\n",
      "Epoch 13 | Train Loss: 0.7497 | Val Loss: 0.8466\n",
      "Epoch 14 | Train Loss: 0.8130 | Val Loss: 0.8619\n",
      "Epoch 15 | Train Loss: 0.7564 | Val Loss: 0.8330\n",
      "Epoch 16 | Train Loss: 0.7431 | Val Loss: 0.8175\n",
      "Epoch 17 | Train Loss: 0.7446 | Val Loss: 0.8588\n",
      "Epoch 18 | Train Loss: 0.7759 | Val Loss: 0.8114\n",
      "Epoch 19 | Train Loss: 0.7392 | Val Loss: 0.8203\n",
      "Epoch 20 | Train Loss: 0.7302 | Val Loss: 0.8067\n",
      "Epoch 21 | Train Loss: 0.7409 | Val Loss: 0.8023\n",
      "Epoch 22 | Train Loss: 0.7347 | Val Loss: 0.8101\n",
      "Epoch 23 | Train Loss: 0.7157 | Val Loss: 0.7962\n",
      "Epoch 24 | Train Loss: 0.7124 | Val Loss: 0.8098\n",
      "Epoch 25 | Train Loss: 0.7267 | Val Loss: 0.7935\n",
      "Epoch 26 | Train Loss: 0.7011 | Val Loss: 0.8272\n",
      "Epoch 27 | Train Loss: 0.7166 | Val Loss: 0.8611\n",
      "Epoch 28 | Train Loss: 0.7304 | Val Loss: 0.8100\n",
      "Epoch 29 | Train Loss: 0.7307 | Val Loss: 0.8087\n",
      "Epoch 30 | Train Loss: 0.7164 | Val Loss: 0.8034\n",
      "Epoch 31 | Train Loss: 0.7154 | Val Loss: 0.8029\n",
      "Epoch 32 | Train Loss: 0.7259 | Val Loss: 0.8240\n",
      "Epoch 33 | Train Loss: 0.7293 | Val Loss: 0.8272\n",
      "Epoch 34 | Train Loss: 0.7291 | Val Loss: 0.8709\n",
      "Epoch 35 | Train Loss: 0.7177 | Val Loss: 0.8338\n",
      "Epoch 36 | Train Loss: 0.7095 | Val Loss: 0.7991\n",
      "Epoch 37 | Train Loss: 0.7055 | Val Loss: 0.8274\n",
      "Epoch 38 | Train Loss: 0.7036 | Val Loss: 0.8094\n",
      "Epoch 39 | Train Loss: 0.7108 | Val Loss: 0.8076\n",
      "Epoch 40 | Train Loss: 0.7169 | Val Loss: 0.8261\n",
      "Epoch 41 | Train Loss: 0.7204 | Val Loss: 0.8121\n",
      "Epoch 42 | Train Loss: 0.7135 | Val Loss: 0.8127\n",
      "Epoch 43 | Train Loss: 0.7121 | Val Loss: 0.8280\n",
      "Epoch 44 | Train Loss: 0.7185 | Val Loss: 0.8126\n",
      "Epoch 45 | Train Loss: 0.7149 | Val Loss: 0.8450\n",
      "Epoch 46 | Train Loss: 0.7045 | Val Loss: 0.8281\n",
      "Epoch 47 | Train Loss: 0.6889 | Val Loss: 0.8252\n",
      "Epoch 48 | Train Loss: 0.7299 | Val Loss: 0.8208\n",
      "Epoch 49 | Train Loss: 0.7299 | Val Loss: 0.8287\n",
      "Epoch 50 | Train Loss: 0.7112 | Val Loss: 0.8101\n",
      "Fold 5 ‚ñ∂ AUC: 0.732, Balanced Acc: 0.460\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9577 | Val Loss: 0.9533\n",
      "Epoch 02 | Train Loss: 0.8807 | Val Loss: 0.8961\n",
      "Epoch 03 | Train Loss: 0.8583 | Val Loss: 0.8889\n",
      "Epoch 04 | Train Loss: 0.8592 | Val Loss: 0.8861\n",
      "Epoch 05 | Train Loss: 0.8172 | Val Loss: 0.8686\n",
      "Epoch 06 | Train Loss: 0.8365 | Val Loss: 0.9786\n",
      "Epoch 07 | Train Loss: 0.8273 | Val Loss: 0.8213\n",
      "Epoch 08 | Train Loss: 0.8152 | Val Loss: 0.8080\n",
      "Epoch 09 | Train Loss: 0.8533 | Val Loss: 0.8136\n",
      "Epoch 10 | Train Loss: 0.7590 | Val Loss: 0.8148\n",
      "Epoch 11 | Train Loss: 0.7559 | Val Loss: 0.8365\n",
      "Epoch 12 | Train Loss: 0.7603 | Val Loss: 0.8030\n",
      "Epoch 13 | Train Loss: 0.7482 | Val Loss: 0.8245\n",
      "Epoch 14 | Train Loss: 0.7614 | Val Loss: 0.8428\n",
      "Epoch 15 | Train Loss: 0.7480 | Val Loss: 0.8295\n",
      "Epoch 16 | Train Loss: 0.7596 | Val Loss: 0.8003\n",
      "Epoch 17 | Train Loss: 0.7322 | Val Loss: 0.8232\n",
      "Epoch 18 | Train Loss: 0.7363 | Val Loss: 0.8137\n",
      "Epoch 19 | Train Loss: 0.7191 | Val Loss: 0.8283\n",
      "Epoch 20 | Train Loss: 0.7383 | Val Loss: 0.8240\n",
      "Epoch 21 | Train Loss: 0.6989 | Val Loss: 0.8702\n",
      "Epoch 22 | Train Loss: 0.7436 | Val Loss: 0.8778\n",
      "Epoch 23 | Train Loss: 0.7929 | Val Loss: 0.8243\n",
      "Epoch 24 | Train Loss: 0.7380 | Val Loss: 0.8482\n",
      "Epoch 25 | Train Loss: 0.7703 | Val Loss: 0.8296\n",
      "Epoch 26 | Train Loss: 0.7350 | Val Loss: 0.8208\n",
      "Epoch 27 | Train Loss: 0.7121 | Val Loss: 0.8291\n",
      "Epoch 28 | Train Loss: 0.7141 | Val Loss: 0.8262\n",
      "Epoch 29 | Train Loss: 0.7248 | Val Loss: 0.8595\n",
      "Epoch 30 | Train Loss: 0.7273 | Val Loss: 0.8312\n",
      "Epoch 31 | Train Loss: 0.7541 | Val Loss: 0.8318\n",
      "Epoch 32 | Train Loss: 0.7272 | Val Loss: 0.8257\n",
      "Epoch 33 | Train Loss: 0.7241 | Val Loss: 0.8389\n",
      "Epoch 34 | Train Loss: 0.7053 | Val Loss: 0.8418\n",
      "Epoch 35 | Train Loss: 0.7251 | Val Loss: 0.8308\n",
      "Epoch 36 | Train Loss: 0.7142 | Val Loss: 0.8404\n",
      "Epoch 37 | Train Loss: 0.7256 | Val Loss: 0.8265\n",
      "Epoch 38 | Train Loss: 0.7282 | Val Loss: 0.8399\n",
      "Epoch 39 | Train Loss: 0.7645 | Val Loss: 0.8448\n",
      "Epoch 40 | Train Loss: 0.7231 | Val Loss: 0.8194\n",
      "Epoch 41 | Train Loss: 0.7123 | Val Loss: 0.8260\n",
      "Epoch 42 | Train Loss: 0.7320 | Val Loss: 0.8466\n",
      "Epoch 43 | Train Loss: 0.7086 | Val Loss: 0.8547\n",
      "Epoch 44 | Train Loss: 0.7148 | Val Loss: 0.8300\n",
      "Epoch 45 | Train Loss: 0.7142 | Val Loss: 0.8682\n",
      "Epoch 46 | Train Loss: 0.7258 | Val Loss: 0.8576\n",
      "Epoch 47 | Train Loss: 0.7135 | Val Loss: 0.8489\n",
      "Epoch 48 | Train Loss: 0.7033 | Val Loss: 0.8272\n",
      "Epoch 49 | Train Loss: 0.7111 | Val Loss: 0.8448\n",
      "Epoch 50 | Train Loss: 0.6931 | Val Loss: 0.8291\n",
      "Fold 6 ‚ñ∂ AUC: 0.721, Balanced Acc: 0.422\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9326 | Val Loss: 0.8514\n",
      "Epoch 02 | Train Loss: 0.8645 | Val Loss: 0.8378\n",
      "Epoch 03 | Train Loss: 0.8498 | Val Loss: 0.7971\n",
      "Epoch 04 | Train Loss: 0.8682 | Val Loss: 0.7700\n",
      "Epoch 05 | Train Loss: 0.8068 | Val Loss: 0.7323\n",
      "Epoch 06 | Train Loss: 0.7998 | Val Loss: 0.7878\n",
      "Epoch 07 | Train Loss: 0.7963 | Val Loss: 0.7065\n",
      "Epoch 08 | Train Loss: 0.8340 | Val Loss: 0.7967\n",
      "Epoch 09 | Train Loss: 0.8108 | Val Loss: 0.7016\n",
      "Epoch 10 | Train Loss: 0.7719 | Val Loss: 0.7030\n",
      "Epoch 11 | Train Loss: 0.7700 | Val Loss: 0.7104\n",
      "Epoch 12 | Train Loss: 0.7622 | Val Loss: 0.6994\n",
      "Epoch 13 | Train Loss: 0.7459 | Val Loss: 0.7045\n",
      "Epoch 14 | Train Loss: 0.7645 | Val Loss: 0.7602\n",
      "Epoch 15 | Train Loss: 0.7831 | Val Loss: 0.7127\n",
      "Epoch 16 | Train Loss: 0.7545 | Val Loss: 0.7198\n",
      "Epoch 17 | Train Loss: 0.7377 | Val Loss: 0.7035\n",
      "Epoch 18 | Train Loss: 0.7330 | Val Loss: 0.7091\n",
      "Epoch 19 | Train Loss: 0.7366 | Val Loss: 0.7208\n",
      "Epoch 20 | Train Loss: 0.7610 | Val Loss: 0.7729\n",
      "Epoch 21 | Train Loss: 0.7573 | Val Loss: 0.7410\n",
      "Epoch 22 | Train Loss: 0.7311 | Val Loss: 0.7159\n",
      "Epoch 23 | Train Loss: 0.7431 | Val Loss: 0.7188\n",
      "Epoch 24 | Train Loss: 0.7264 | Val Loss: 0.7472\n",
      "Epoch 25 | Train Loss: 0.7560 | Val Loss: 0.7229\n",
      "Epoch 26 | Train Loss: 0.7315 | Val Loss: 0.7162\n",
      "Epoch 27 | Train Loss: 0.7234 | Val Loss: 0.7231\n",
      "Epoch 28 | Train Loss: 0.7017 | Val Loss: 0.7133\n",
      "Epoch 29 | Train Loss: 0.7225 | Val Loss: 0.7279\n",
      "Epoch 30 | Train Loss: 0.7510 | Val Loss: 0.7163\n",
      "Epoch 31 | Train Loss: 0.7307 | Val Loss: 0.7268\n",
      "Epoch 32 | Train Loss: 0.7126 | Val Loss: 0.7747\n",
      "Epoch 33 | Train Loss: 0.7392 | Val Loss: 0.7600\n",
      "Epoch 34 | Train Loss: 0.7471 | Val Loss: 0.7178\n",
      "Epoch 35 | Train Loss: 0.7205 | Val Loss: 0.7070\n",
      "Epoch 36 | Train Loss: 0.7135 | Val Loss: 0.7547\n",
      "Epoch 37 | Train Loss: 0.7667 | Val Loss: 0.7666\n",
      "Epoch 38 | Train Loss: 0.7378 | Val Loss: 0.7289\n",
      "Epoch 39 | Train Loss: 0.7620 | Val Loss: 0.7199\n",
      "Epoch 40 | Train Loss: 0.7305 | Val Loss: 0.7142\n",
      "Epoch 41 | Train Loss: 0.7360 | Val Loss: 0.7099\n",
      "Epoch 42 | Train Loss: 0.7148 | Val Loss: 0.7362\n",
      "Epoch 43 | Train Loss: 0.7363 | Val Loss: 0.7376\n",
      "Epoch 44 | Train Loss: 0.7306 | Val Loss: 0.7236\n",
      "Epoch 45 | Train Loss: 0.7240 | Val Loss: 0.7444\n",
      "Epoch 46 | Train Loss: 0.7215 | Val Loss: 0.7521\n",
      "Epoch 47 | Train Loss: 0.7129 | Val Loss: 0.7457\n",
      "Epoch 48 | Train Loss: 0.7367 | Val Loss: 0.7285\n",
      "Epoch 49 | Train Loss: 0.7232 | Val Loss: 0.7670\n",
      "Epoch 50 | Train Loss: 0.7355 | Val Loss: 0.7257\n",
      "Fold 7 ‚ñ∂ AUC: 0.760, Balanced Acc: 0.462\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9906 | Val Loss: 0.9044\n",
      "Epoch 02 | Train Loss: 0.8783 | Val Loss: 0.8665\n",
      "Epoch 03 | Train Loss: 0.8935 | Val Loss: 0.8655\n",
      "Epoch 04 | Train Loss: 0.8753 | Val Loss: 0.8484\n",
      "Epoch 05 | Train Loss: 0.8275 | Val Loss: 0.8598\n",
      "Epoch 06 | Train Loss: 0.8407 | Val Loss: 0.8731\n",
      "Epoch 07 | Train Loss: 0.8222 | Val Loss: 0.8271\n",
      "Epoch 08 | Train Loss: 0.8261 | Val Loss: 0.8533\n",
      "Epoch 09 | Train Loss: 0.8462 | Val Loss: 0.8311\n",
      "Epoch 10 | Train Loss: 0.7680 | Val Loss: 0.8376\n",
      "Epoch 11 | Train Loss: 0.7855 | Val Loss: 0.8238\n",
      "Epoch 12 | Train Loss: 0.7446 | Val Loss: 0.8056\n",
      "Epoch 13 | Train Loss: 0.7829 | Val Loss: 0.7951\n",
      "Epoch 14 | Train Loss: 0.7550 | Val Loss: 0.8083\n",
      "Epoch 15 | Train Loss: 0.7428 | Val Loss: 0.7862\n",
      "Epoch 16 | Train Loss: 0.7701 | Val Loss: 0.7874\n",
      "Epoch 17 | Train Loss: 0.7419 | Val Loss: 0.7853\n",
      "Epoch 18 | Train Loss: 0.7239 | Val Loss: 0.8082\n",
      "Epoch 19 | Train Loss: 0.7308 | Val Loss: 0.9039\n",
      "Epoch 20 | Train Loss: 0.7647 | Val Loss: 0.8132\n",
      "Epoch 21 | Train Loss: 0.7442 | Val Loss: 0.7925\n",
      "Epoch 22 | Train Loss: 0.7405 | Val Loss: 0.7955\n",
      "Epoch 23 | Train Loss: 0.7229 | Val Loss: 0.7983\n",
      "Epoch 24 | Train Loss: 0.7498 | Val Loss: 0.8101\n",
      "Epoch 25 | Train Loss: 0.7186 | Val Loss: 0.8053\n",
      "Epoch 26 | Train Loss: 0.7294 | Val Loss: 0.8061\n",
      "Epoch 27 | Train Loss: 0.7318 | Val Loss: 0.8032\n",
      "Epoch 28 | Train Loss: 0.7376 | Val Loss: 0.8134\n",
      "Epoch 29 | Train Loss: 0.7235 | Val Loss: 0.7981\n",
      "Epoch 30 | Train Loss: 0.7259 | Val Loss: 0.8054\n",
      "Epoch 31 | Train Loss: 0.7201 | Val Loss: 0.8028\n",
      "Epoch 32 | Train Loss: 0.7600 | Val Loss: 0.8014\n",
      "Epoch 33 | Train Loss: 0.7356 | Val Loss: 0.7939\n",
      "Epoch 34 | Train Loss: 0.7267 | Val Loss: 0.8107\n",
      "Epoch 35 | Train Loss: 0.7106 | Val Loss: 0.8604\n",
      "Epoch 36 | Train Loss: 0.7251 | Val Loss: 0.8119\n",
      "Epoch 37 | Train Loss: 0.7270 | Val Loss: 0.8205\n",
      "Epoch 38 | Train Loss: 0.7159 | Val Loss: 0.8107\n",
      "Epoch 39 | Train Loss: 0.7051 | Val Loss: 0.8325\n",
      "Epoch 40 | Train Loss: 0.7392 | Val Loss: 0.8197\n",
      "Epoch 41 | Train Loss: 0.7111 | Val Loss: 0.8172\n",
      "Epoch 42 | Train Loss: 0.7265 | Val Loss: 0.8444\n",
      "Epoch 43 | Train Loss: 0.7272 | Val Loss: 0.8151\n",
      "Epoch 44 | Train Loss: 0.7318 | Val Loss: 0.8117\n",
      "Epoch 45 | Train Loss: 0.7391 | Val Loss: 0.8206\n",
      "Epoch 46 | Train Loss: 0.7204 | Val Loss: 0.8181\n",
      "Epoch 47 | Train Loss: 0.7103 | Val Loss: 0.8433\n",
      "Epoch 48 | Train Loss: 0.7075 | Val Loss: 0.8118\n",
      "Epoch 49 | Train Loss: 0.7195 | Val Loss: 0.8184\n",
      "Epoch 50 | Train Loss: 0.7137 | Val Loss: 0.8308\n",
      "Fold 8 ‚ñ∂ AUC: 0.679, Balanced Acc: 0.455\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 1.0081 | Val Loss: 0.8899\n",
      "Epoch 02 | Train Loss: 0.8724 | Val Loss: 0.8690\n",
      "Epoch 03 | Train Loss: 0.8827 | Val Loss: 0.8545\n",
      "Epoch 04 | Train Loss: 0.8632 | Val Loss: 0.8432\n",
      "Epoch 05 | Train Loss: 0.8409 | Val Loss: 0.8593\n",
      "Epoch 06 | Train Loss: 0.7986 | Val Loss: 0.8896\n",
      "Epoch 07 | Train Loss: 0.8515 | Val Loss: 0.7842\n",
      "Epoch 08 | Train Loss: 0.8121 | Val Loss: 0.7910\n",
      "Epoch 09 | Train Loss: 0.7976 | Val Loss: 0.8314\n",
      "Epoch 10 | Train Loss: 0.7879 | Val Loss: 0.7738\n",
      "Epoch 11 | Train Loss: 0.7767 | Val Loss: 0.7652\n",
      "Epoch 12 | Train Loss: 0.7604 | Val Loss: 0.7597\n",
      "Epoch 13 | Train Loss: 0.7483 | Val Loss: 0.7882\n",
      "Epoch 14 | Train Loss: 0.7628 | Val Loss: 0.7724\n",
      "Epoch 15 | Train Loss: 0.8015 | Val Loss: 0.7557\n",
      "Epoch 16 | Train Loss: 0.7491 | Val Loss: 0.7537\n",
      "Epoch 17 | Train Loss: 0.7596 | Val Loss: 0.7542\n",
      "Epoch 18 | Train Loss: 0.7266 | Val Loss: 0.7412\n",
      "Epoch 19 | Train Loss: 0.7395 | Val Loss: 0.7347\n",
      "Epoch 20 | Train Loss: 0.7657 | Val Loss: 0.7405\n",
      "Epoch 21 | Train Loss: 0.7323 | Val Loss: 0.7298\n",
      "Epoch 22 | Train Loss: 0.7389 | Val Loss: 0.7305\n",
      "Epoch 23 | Train Loss: 0.7383 | Val Loss: 0.7423\n",
      "Epoch 24 | Train Loss: 0.7119 | Val Loss: 0.7493\n",
      "Epoch 25 | Train Loss: 0.7467 | Val Loss: 0.7633\n",
      "Epoch 26 | Train Loss: 0.7488 | Val Loss: 0.7730\n",
      "Epoch 27 | Train Loss: 0.7298 | Val Loss: 0.7419\n",
      "Epoch 28 | Train Loss: 0.7138 | Val Loss: 0.7428\n",
      "Epoch 29 | Train Loss: 0.7573 | Val Loss: 0.8126\n",
      "Epoch 30 | Train Loss: 0.7405 | Val Loss: 0.7402\n",
      "Epoch 31 | Train Loss: 0.7323 | Val Loss: 0.7397\n",
      "Epoch 32 | Train Loss: 0.7325 | Val Loss: 0.7285\n",
      "Epoch 33 | Train Loss: 0.7190 | Val Loss: 0.7339\n",
      "Epoch 34 | Train Loss: 0.7348 | Val Loss: 0.7423\n",
      "Epoch 35 | Train Loss: 0.7280 | Val Loss: 0.7375\n",
      "Epoch 36 | Train Loss: 0.7179 | Val Loss: 0.8145\n",
      "Epoch 37 | Train Loss: 0.7254 | Val Loss: 0.7466\n",
      "Epoch 38 | Train Loss: 0.7037 | Val Loss: 0.7779\n",
      "Epoch 39 | Train Loss: 0.7391 | Val Loss: 0.7401\n",
      "Epoch 40 | Train Loss: 0.7318 | Val Loss: 0.7483\n",
      "Epoch 41 | Train Loss: 0.7297 | Val Loss: 0.7309\n",
      "Epoch 42 | Train Loss: 0.7409 | Val Loss: 0.7401\n",
      "Epoch 43 | Train Loss: 0.7162 | Val Loss: 0.7804\n",
      "Epoch 44 | Train Loss: 0.7354 | Val Loss: 0.7699\n",
      "Epoch 45 | Train Loss: 0.7240 | Val Loss: 0.7592\n",
      "Epoch 46 | Train Loss: 0.7314 | Val Loss: 0.7537\n",
      "Epoch 47 | Train Loss: 0.7091 | Val Loss: 0.7967\n",
      "Epoch 48 | Train Loss: 0.7373 | Val Loss: 0.7744\n",
      "Epoch 49 | Train Loss: 0.7001 | Val Loss: 0.7590\n",
      "Epoch 50 | Train Loss: 0.7079 | Val Loss: 0.7365\n",
      "Fold 9 ‚ñ∂ AUC: 0.757, Balanced Acc: 0.481\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9870 | Val Loss: 0.9064\n",
      "Epoch 02 | Train Loss: 0.8694 | Val Loss: 0.8579\n",
      "Epoch 03 | Train Loss: 0.8683 | Val Loss: 0.8504\n",
      "Epoch 04 | Train Loss: 0.8678 | Val Loss: 0.8364\n",
      "Epoch 05 | Train Loss: 0.8356 | Val Loss: 0.8098\n",
      "Epoch 06 | Train Loss: 0.8063 | Val Loss: 0.7797\n",
      "Epoch 07 | Train Loss: 0.7880 | Val Loss: 0.7930\n",
      "Epoch 08 | Train Loss: 0.7791 | Val Loss: 0.8389\n",
      "Epoch 09 | Train Loss: 0.8000 | Val Loss: 0.8043\n",
      "Epoch 10 | Train Loss: 0.7826 | Val Loss: 0.7885\n",
      "Epoch 11 | Train Loss: 0.7724 | Val Loss: 0.8069\n",
      "Epoch 12 | Train Loss: 0.7712 | Val Loss: 0.7723\n",
      "Epoch 13 | Train Loss: 0.7895 | Val Loss: 0.8194\n",
      "Epoch 14 | Train Loss: 0.7758 | Val Loss: 0.8066\n",
      "Epoch 15 | Train Loss: 0.7663 | Val Loss: 0.7749\n",
      "Epoch 16 | Train Loss: 0.7612 | Val Loss: 0.7645\n",
      "Epoch 17 | Train Loss: 0.7423 | Val Loss: 0.7825\n",
      "Epoch 18 | Train Loss: 0.7443 | Val Loss: 0.7819\n",
      "Epoch 19 | Train Loss: 0.7203 | Val Loss: 0.8855\n",
      "Epoch 20 | Train Loss: 0.7555 | Val Loss: 0.7690\n",
      "Epoch 21 | Train Loss: 0.7352 | Val Loss: 0.7836\n",
      "Epoch 22 | Train Loss: 0.7427 | Val Loss: 0.7686\n",
      "Epoch 23 | Train Loss: 0.7260 | Val Loss: 0.7861\n",
      "Epoch 24 | Train Loss: 0.7223 | Val Loss: 0.8405\n",
      "Epoch 25 | Train Loss: 0.7349 | Val Loss: 0.8294\n",
      "Epoch 26 | Train Loss: 0.7402 | Val Loss: 0.7737\n",
      "Epoch 27 | Train Loss: 0.7343 | Val Loss: 0.7658\n",
      "Epoch 28 | Train Loss: 0.7282 | Val Loss: 0.8033\n",
      "Epoch 29 | Train Loss: 0.7157 | Val Loss: 0.8297\n",
      "Epoch 30 | Train Loss: 0.7645 | Val Loss: 0.7805\n",
      "Epoch 31 | Train Loss: 0.7316 | Val Loss: 0.7816\n",
      "Epoch 32 | Train Loss: 0.7301 | Val Loss: 0.8118\n",
      "Epoch 33 | Train Loss: 0.7152 | Val Loss: 0.8391\n",
      "Epoch 34 | Train Loss: 0.7339 | Val Loss: 0.7769\n",
      "Epoch 35 | Train Loss: 0.7573 | Val Loss: 0.7922\n",
      "Epoch 36 | Train Loss: 0.7575 | Val Loss: 0.7765\n",
      "Epoch 37 | Train Loss: 0.7051 | Val Loss: 0.7919\n",
      "Epoch 38 | Train Loss: 0.7403 | Val Loss: 0.8041\n",
      "Epoch 39 | Train Loss: 0.7261 | Val Loss: 0.7759\n",
      "Epoch 40 | Train Loss: 0.7177 | Val Loss: 0.7672\n",
      "Epoch 41 | Train Loss: 0.7309 | Val Loss: 0.7720\n",
      "Epoch 42 | Train Loss: 0.7156 | Val Loss: 0.7753\n",
      "Epoch 43 | Train Loss: 0.7441 | Val Loss: 0.7724\n",
      "Epoch 44 | Train Loss: 0.7605 | Val Loss: 0.7837\n",
      "Epoch 45 | Train Loss: 0.7360 | Val Loss: 0.7847\n",
      "Epoch 46 | Train Loss: 0.7406 | Val Loss: 0.7701\n",
      "Epoch 47 | Train Loss: 0.7284 | Val Loss: 0.8077\n",
      "Epoch 48 | Train Loss: 0.7184 | Val Loss: 0.7774\n",
      "Epoch 49 | Train Loss: 0.7392 | Val Loss: 0.8345\n",
      "Epoch 50 | Train Loss: 0.7316 | Val Loss: 0.7910\n",
      "Fold 10 ‚ñ∂ AUC: 0.724, Balanced Acc: 0.469\n",
      "üîç Summary for hd=256, dp=0.4, lr=0.001 ‚Üí AUC: 0.7388¬±0.0254 | BalAcc: 0.4803¬±0.0401\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.4, lr=0.0005\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9464 | Val Loss: 0.8942\n",
      "Epoch 02 | Train Loss: 0.8720 | Val Loss: 0.8640\n",
      "Epoch 03 | Train Loss: 0.8578 | Val Loss: 0.8577\n",
      "Epoch 04 | Train Loss: 0.8438 | Val Loss: 0.8511\n",
      "Epoch 05 | Train Loss: 0.8711 | Val Loss: 0.8340\n",
      "Epoch 06 | Train Loss: 0.8469 | Val Loss: 0.8083\n",
      "Epoch 07 | Train Loss: 0.7990 | Val Loss: 0.8323\n",
      "Epoch 08 | Train Loss: 0.8410 | Val Loss: 0.8139\n",
      "Epoch 09 | Train Loss: 0.8011 | Val Loss: 0.8556\n",
      "Epoch 10 | Train Loss: 0.8379 | Val Loss: 0.7714\n",
      "Epoch 11 | Train Loss: 0.8152 | Val Loss: 0.7683\n",
      "Epoch 12 | Train Loss: 0.7760 | Val Loss: 0.7558\n",
      "Epoch 13 | Train Loss: 0.7784 | Val Loss: 0.7515\n",
      "Epoch 14 | Train Loss: 0.7639 | Val Loss: 0.7493\n",
      "Epoch 15 | Train Loss: 0.7552 | Val Loss: 0.7240\n",
      "Epoch 16 | Train Loss: 0.7853 | Val Loss: 0.7319\n",
      "Epoch 17 | Train Loss: 0.7860 | Val Loss: 0.7180\n",
      "Epoch 18 | Train Loss: 0.7498 | Val Loss: 0.7248\n",
      "Epoch 19 | Train Loss: 0.7625 | Val Loss: 0.7109\n",
      "Epoch 20 | Train Loss: 0.7385 | Val Loss: 0.7058\n",
      "Epoch 21 | Train Loss: 0.7471 | Val Loss: 0.7060\n",
      "Epoch 22 | Train Loss: 0.7388 | Val Loss: 0.7647\n",
      "Epoch 23 | Train Loss: 0.7554 | Val Loss: 0.6931\n",
      "Epoch 24 | Train Loss: 0.7570 | Val Loss: 0.6904\n",
      "Epoch 25 | Train Loss: 0.7397 | Val Loss: 0.7023\n",
      "Epoch 26 | Train Loss: 0.7452 | Val Loss: 0.6904\n",
      "Epoch 27 | Train Loss: 0.7297 | Val Loss: 0.6911\n",
      "Epoch 28 | Train Loss: 0.7354 | Val Loss: 0.6912\n",
      "Epoch 29 | Train Loss: 0.7386 | Val Loss: 0.6897\n",
      "Epoch 30 | Train Loss: 0.7098 | Val Loss: 0.7183\n",
      "Epoch 31 | Train Loss: 0.7382 | Val Loss: 0.7079\n",
      "Epoch 32 | Train Loss: 0.7418 | Val Loss: 0.6866\n",
      "Epoch 33 | Train Loss: 0.7391 | Val Loss: 0.7199\n",
      "Epoch 34 | Train Loss: 0.7405 | Val Loss: 0.6957\n",
      "Epoch 35 | Train Loss: 0.7315 | Val Loss: 0.6837\n",
      "Epoch 36 | Train Loss: 0.7176 | Val Loss: 0.6844\n",
      "Epoch 37 | Train Loss: 0.7339 | Val Loss: 0.6956\n",
      "Epoch 38 | Train Loss: 0.7336 | Val Loss: 0.6920\n",
      "Epoch 39 | Train Loss: 0.7174 | Val Loss: 0.6828\n",
      "Epoch 40 | Train Loss: 0.7101 | Val Loss: 0.6824\n",
      "Epoch 41 | Train Loss: 0.7500 | Val Loss: 0.6921\n",
      "Epoch 42 | Train Loss: 0.7523 | Val Loss: 0.7028\n",
      "Epoch 43 | Train Loss: 0.7395 | Val Loss: 0.6940\n",
      "Epoch 44 | Train Loss: 0.7348 | Val Loss: 0.7204\n",
      "Epoch 45 | Train Loss: 0.7323 | Val Loss: 0.7047\n",
      "Epoch 46 | Train Loss: 0.7107 | Val Loss: 0.7037\n",
      "Epoch 47 | Train Loss: 0.7439 | Val Loss: 0.6979\n",
      "Epoch 48 | Train Loss: 0.7363 | Val Loss: 0.6906\n",
      "Epoch 49 | Train Loss: 0.7443 | Val Loss: 0.7190\n",
      "Epoch 50 | Train Loss: 0.7399 | Val Loss: 0.6888\n",
      "Fold 1 ‚ñ∂ AUC: 0.785, Balanced Acc: 0.505\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.8983 | Val Loss: 0.8743\n",
      "Epoch 02 | Train Loss: 0.8705 | Val Loss: 0.8579\n",
      "Epoch 03 | Train Loss: 0.8695 | Val Loss: 0.8662\n",
      "Epoch 04 | Train Loss: 0.8618 | Val Loss: 0.8892\n",
      "Epoch 05 | Train Loss: 0.8897 | Val Loss: 0.8298\n",
      "Epoch 06 | Train Loss: 0.8403 | Val Loss: 0.8221\n",
      "Epoch 07 | Train Loss: 0.8205 | Val Loss: 0.8006\n",
      "Epoch 08 | Train Loss: 0.8095 | Val Loss: 0.8138\n",
      "Epoch 09 | Train Loss: 0.8131 | Val Loss: 0.8346\n",
      "Epoch 10 | Train Loss: 0.7847 | Val Loss: 0.7323\n",
      "Epoch 11 | Train Loss: 0.7605 | Val Loss: 0.7395\n",
      "Epoch 12 | Train Loss: 0.7512 | Val Loss: 0.7313\n",
      "Epoch 13 | Train Loss: 0.7394 | Val Loss: 0.7546\n",
      "Epoch 14 | Train Loss: 0.7565 | Val Loss: 0.8437\n",
      "Epoch 15 | Train Loss: 0.7827 | Val Loss: 0.7381\n",
      "Epoch 16 | Train Loss: 0.7587 | Val Loss: 0.7505\n",
      "Epoch 17 | Train Loss: 0.8016 | Val Loss: 0.7315\n",
      "Epoch 18 | Train Loss: 0.7733 | Val Loss: 0.7995\n",
      "Epoch 19 | Train Loss: 0.7874 | Val Loss: 0.7797\n",
      "Epoch 20 | Train Loss: 0.7731 | Val Loss: 0.7148\n",
      "Epoch 21 | Train Loss: 0.7304 | Val Loss: 0.7954\n",
      "Epoch 22 | Train Loss: 0.7378 | Val Loss: 0.7060\n",
      "Epoch 23 | Train Loss: 0.7414 | Val Loss: 0.7162\n",
      "Epoch 24 | Train Loss: 0.7373 | Val Loss: 0.7057\n",
      "Epoch 25 | Train Loss: 0.7137 | Val Loss: 0.8171\n",
      "Epoch 26 | Train Loss: 0.7643 | Val Loss: 0.6920\n",
      "Epoch 27 | Train Loss: 0.7554 | Val Loss: 0.6949\n",
      "Epoch 28 | Train Loss: 0.7715 | Val Loss: 0.7343\n",
      "Epoch 29 | Train Loss: 0.7462 | Val Loss: 0.7437\n",
      "Epoch 30 | Train Loss: 0.7379 | Val Loss: 0.7823\n",
      "Epoch 31 | Train Loss: 0.7296 | Val Loss: 0.7853\n",
      "Epoch 32 | Train Loss: 0.7440 | Val Loss: 0.7332\n",
      "Epoch 33 | Train Loss: 0.7193 | Val Loss: 0.7207\n",
      "Epoch 34 | Train Loss: 0.7560 | Val Loss: 0.7137\n",
      "Epoch 35 | Train Loss: 0.7726 | Val Loss: 0.7350\n",
      "Epoch 36 | Train Loss: 0.7404 | Val Loss: 0.7987\n",
      "Epoch 37 | Train Loss: 0.7528 | Val Loss: 0.6981\n",
      "Epoch 38 | Train Loss: 0.7298 | Val Loss: 0.7239\n",
      "Epoch 39 | Train Loss: 0.7333 | Val Loss: 0.7395\n",
      "Epoch 40 | Train Loss: 0.7341 | Val Loss: 0.7446\n",
      "Epoch 41 | Train Loss: 0.7405 | Val Loss: 0.6998\n",
      "Epoch 42 | Train Loss: 0.7218 | Val Loss: 0.7058\n",
      "Epoch 43 | Train Loss: 0.7294 | Val Loss: 0.7680\n",
      "Epoch 44 | Train Loss: 0.7338 | Val Loss: 0.7210\n",
      "Epoch 45 | Train Loss: 0.7209 | Val Loss: 0.6921\n",
      "Epoch 46 | Train Loss: 0.7435 | Val Loss: 0.8121\n",
      "Epoch 47 | Train Loss: 0.7302 | Val Loss: 0.7252\n",
      "Epoch 48 | Train Loss: 0.7224 | Val Loss: 0.6889\n",
      "Epoch 49 | Train Loss: 0.7272 | Val Loss: 0.7269\n",
      "Epoch 50 | Train Loss: 0.7226 | Val Loss: 0.7410\n",
      "Fold 2 ‚ñ∂ AUC: 0.703, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9196 | Val Loss: 0.8696\n",
      "Epoch 02 | Train Loss: 0.8859 | Val Loss: 0.8437\n",
      "Epoch 03 | Train Loss: 0.8601 | Val Loss: 0.8800\n",
      "Epoch 04 | Train Loss: 0.8646 | Val Loss: 0.8363\n",
      "Epoch 05 | Train Loss: 0.8522 | Val Loss: 0.8269\n",
      "Epoch 06 | Train Loss: 0.8503 | Val Loss: 0.8149\n",
      "Epoch 07 | Train Loss: 0.8154 | Val Loss: 0.7915\n",
      "Epoch 08 | Train Loss: 0.8056 | Val Loss: 0.8182\n",
      "Epoch 09 | Train Loss: 0.8216 | Val Loss: 0.7769\n",
      "Epoch 10 | Train Loss: 0.7756 | Val Loss: 0.7556\n",
      "Epoch 11 | Train Loss: 0.7856 | Val Loss: 0.7790\n",
      "Epoch 12 | Train Loss: 0.7566 | Val Loss: 0.7810\n",
      "Epoch 13 | Train Loss: 0.7519 | Val Loss: 0.7644\n",
      "Epoch 14 | Train Loss: 0.7651 | Val Loss: 0.7466\n",
      "Epoch 15 | Train Loss: 0.8109 | Val Loss: 0.7728\n",
      "Epoch 16 | Train Loss: 0.7549 | Val Loss: 0.7627\n",
      "Epoch 17 | Train Loss: 0.7415 | Val Loss: 0.7502\n",
      "Epoch 18 | Train Loss: 0.7525 | Val Loss: 0.7421\n",
      "Epoch 19 | Train Loss: 0.7555 | Val Loss: 0.7386\n",
      "Epoch 20 | Train Loss: 0.7277 | Val Loss: 0.7297\n",
      "Epoch 21 | Train Loss: 0.7551 | Val Loss: 0.7311\n",
      "Epoch 22 | Train Loss: 0.7401 | Val Loss: 0.7507\n",
      "Epoch 23 | Train Loss: 0.7579 | Val Loss: 0.7425\n",
      "Epoch 24 | Train Loss: 0.7222 | Val Loss: 0.7284\n",
      "Epoch 25 | Train Loss: 0.7431 | Val Loss: 0.7829\n",
      "Epoch 26 | Train Loss: 0.7427 | Val Loss: 0.7291\n",
      "Epoch 27 | Train Loss: 0.7543 | Val Loss: 0.7591\n",
      "Epoch 28 | Train Loss: 0.7410 | Val Loss: 0.7657\n",
      "Epoch 29 | Train Loss: 0.7379 | Val Loss: 0.7749\n",
      "Epoch 30 | Train Loss: 0.7527 | Val Loss: 0.7312\n",
      "Epoch 31 | Train Loss: 0.7220 | Val Loss: 0.7229\n",
      "Epoch 32 | Train Loss: 0.7262 | Val Loss: 0.7240\n",
      "Epoch 33 | Train Loss: 0.7294 | Val Loss: 0.7171\n",
      "Epoch 34 | Train Loss: 0.7458 | Val Loss: 0.7273\n",
      "Epoch 35 | Train Loss: 0.7428 | Val Loss: 0.7152\n",
      "Epoch 36 | Train Loss: 0.7293 | Val Loss: 0.7412\n",
      "Epoch 37 | Train Loss: 0.7243 | Val Loss: 0.7138\n",
      "Epoch 38 | Train Loss: 0.7521 | Val Loss: 0.7466\n",
      "Epoch 39 | Train Loss: 0.7695 | Val Loss: 0.7804\n",
      "Epoch 40 | Train Loss: 0.7370 | Val Loss: 0.7272\n",
      "Epoch 41 | Train Loss: 0.7209 | Val Loss: 0.7155\n",
      "Epoch 42 | Train Loss: 0.7227 | Val Loss: 0.7149\n",
      "Epoch 43 | Train Loss: 0.7371 | Val Loss: 0.7141\n",
      "Epoch 44 | Train Loss: 0.7516 | Val Loss: 0.7222\n",
      "Epoch 45 | Train Loss: 0.7094 | Val Loss: 0.7175\n",
      "Epoch 46 | Train Loss: 0.7468 | Val Loss: 0.7295\n",
      "Epoch 47 | Train Loss: 0.7031 | Val Loss: 0.7149\n",
      "Epoch 48 | Train Loss: 0.7291 | Val Loss: 0.7268\n",
      "Epoch 49 | Train Loss: 0.7131 | Val Loss: 0.7312\n",
      "Epoch 50 | Train Loss: 0.7143 | Val Loss: 0.7307\n",
      "Fold 3 ‚ñ∂ AUC: 0.778, Balanced Acc: 0.476\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.9108 | Val Loss: 0.8475\n",
      "Epoch 02 | Train Loss: 0.8631 | Val Loss: 0.8325\n",
      "Epoch 03 | Train Loss: 0.8481 | Val Loss: 0.8369\n",
      "Epoch 04 | Train Loss: 0.8346 | Val Loss: 0.7890\n",
      "Epoch 05 | Train Loss: 0.8387 | Val Loss: 0.8899\n",
      "Epoch 06 | Train Loss: 0.8182 | Val Loss: 0.7534\n",
      "Epoch 07 | Train Loss: 0.8015 | Val Loss: 0.7797\n",
      "Epoch 08 | Train Loss: 0.8439 | Val Loss: 0.7607\n",
      "Epoch 09 | Train Loss: 0.7957 | Val Loss: 0.7181\n",
      "Epoch 10 | Train Loss: 0.7789 | Val Loss: 0.7102\n",
      "Epoch 11 | Train Loss: 0.7599 | Val Loss: 0.6943\n",
      "Epoch 12 | Train Loss: 0.7754 | Val Loss: 0.7055\n",
      "Epoch 13 | Train Loss: 0.7977 | Val Loss: 0.6870\n",
      "Epoch 14 | Train Loss: 0.7594 | Val Loss: 0.7125\n",
      "Epoch 15 | Train Loss: 0.7645 | Val Loss: 0.6828\n",
      "Epoch 16 | Train Loss: 0.7534 | Val Loss: 0.7371\n",
      "Epoch 17 | Train Loss: 0.7976 | Val Loss: 0.7025\n",
      "Epoch 18 | Train Loss: 0.7441 | Val Loss: 0.6796\n",
      "Epoch 19 | Train Loss: 0.7362 | Val Loss: 0.7018\n",
      "Epoch 20 | Train Loss: 0.7434 | Val Loss: 0.6987\n",
      "Epoch 21 | Train Loss: 0.7626 | Val Loss: 0.6842\n",
      "Epoch 22 | Train Loss: 0.7586 | Val Loss: 0.6646\n",
      "Epoch 23 | Train Loss: 0.7599 | Val Loss: 0.6916\n",
      "Epoch 24 | Train Loss: 0.7462 | Val Loss: 0.6884\n",
      "Epoch 25 | Train Loss: 0.7226 | Val Loss: 0.6637\n",
      "Epoch 26 | Train Loss: 0.7284 | Val Loss: 0.6646\n",
      "Epoch 27 | Train Loss: 0.7539 | Val Loss: 0.6745\n",
      "Epoch 28 | Train Loss: 0.7305 | Val Loss: 0.6647\n",
      "Epoch 29 | Train Loss: 0.7429 | Val Loss: 0.6866\n",
      "Epoch 30 | Train Loss: 0.7354 | Val Loss: 0.6832\n",
      "Epoch 31 | Train Loss: 0.7371 | Val Loss: 0.6676\n",
      "Epoch 32 | Train Loss: 0.7156 | Val Loss: 0.6847\n",
      "Epoch 33 | Train Loss: 0.7463 | Val Loss: 0.7014\n",
      "Epoch 34 | Train Loss: 0.7393 | Val Loss: 0.6645\n",
      "Epoch 35 | Train Loss: 0.7376 | Val Loss: 0.6614\n",
      "Epoch 36 | Train Loss: 0.7286 | Val Loss: 0.6778\n",
      "Epoch 37 | Train Loss: 0.7348 | Val Loss: 0.7013\n",
      "Epoch 38 | Train Loss: 0.7286 | Val Loss: 0.6832\n",
      "Epoch 39 | Train Loss: 0.7370 | Val Loss: 0.6869\n",
      "Epoch 40 | Train Loss: 0.7281 | Val Loss: 0.6630\n",
      "Epoch 41 | Train Loss: 0.7493 | Val Loss: 0.7041\n",
      "Epoch 42 | Train Loss: 0.7214 | Val Loss: 0.6827\n",
      "Epoch 43 | Train Loss: 0.7380 | Val Loss: 0.6823\n",
      "Epoch 44 | Train Loss: 0.7209 | Val Loss: 0.6865\n",
      "Epoch 45 | Train Loss: 0.7077 | Val Loss: 0.6721\n",
      "Epoch 46 | Train Loss: 0.7188 | Val Loss: 0.6747\n",
      "Epoch 47 | Train Loss: 0.7341 | Val Loss: 0.6894\n",
      "Epoch 48 | Train Loss: 0.7122 | Val Loss: 0.6615\n",
      "Epoch 49 | Train Loss: 0.7431 | Val Loss: 0.7502\n",
      "Epoch 50 | Train Loss: 0.7638 | Val Loss: 0.6508\n",
      "Fold 4 ‚ñ∂ AUC: 0.789, Balanced Acc: 0.540\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9531 | Val Loss: 0.9127\n",
      "Epoch 02 | Train Loss: 0.8927 | Val Loss: 0.8872\n",
      "Epoch 03 | Train Loss: 0.8887 | Val Loss: 0.9060\n",
      "Epoch 04 | Train Loss: 0.8912 | Val Loss: 0.8763\n",
      "Epoch 05 | Train Loss: 0.8871 | Val Loss: 0.8913\n",
      "Epoch 06 | Train Loss: 0.8390 | Val Loss: 0.8695\n",
      "Epoch 07 | Train Loss: 0.8099 | Val Loss: 0.8576\n",
      "Epoch 08 | Train Loss: 0.8080 | Val Loss: 0.8480\n",
      "Epoch 09 | Train Loss: 0.7903 | Val Loss: 0.8554\n",
      "Epoch 10 | Train Loss: 0.7863 | Val Loss: 0.8460\n",
      "Epoch 11 | Train Loss: 0.7897 | Val Loss: 0.8450\n",
      "Epoch 12 | Train Loss: 0.7572 | Val Loss: 0.8407\n",
      "Epoch 13 | Train Loss: 0.7777 | Val Loss: 0.8349\n",
      "Epoch 14 | Train Loss: 0.7634 | Val Loss: 0.8392\n",
      "Epoch 15 | Train Loss: 0.7430 | Val Loss: 0.8225\n",
      "Epoch 16 | Train Loss: 0.7479 | Val Loss: 0.8337\n",
      "Epoch 17 | Train Loss: 0.7657 | Val Loss: 0.8243\n",
      "Epoch 18 | Train Loss: 0.7461 | Val Loss: 0.8247\n",
      "Epoch 19 | Train Loss: 0.7355 | Val Loss: 0.8607\n",
      "Epoch 20 | Train Loss: 0.7470 | Val Loss: 0.8716\n",
      "Epoch 21 | Train Loss: 0.7180 | Val Loss: 0.8327\n",
      "Epoch 22 | Train Loss: 0.7120 | Val Loss: 0.8190\n",
      "Epoch 23 | Train Loss: 0.7479 | Val Loss: 0.8251\n",
      "Epoch 24 | Train Loss: 0.7767 | Val Loss: 0.8250\n",
      "Epoch 25 | Train Loss: 0.7514 | Val Loss: 0.9020\n",
      "Epoch 26 | Train Loss: 0.7396 | Val Loss: 0.7965\n",
      "Epoch 27 | Train Loss: 0.7156 | Val Loss: 0.7898\n",
      "Epoch 28 | Train Loss: 0.7312 | Val Loss: 0.8201\n",
      "Epoch 29 | Train Loss: 0.7106 | Val Loss: 0.7961\n",
      "Epoch 30 | Train Loss: 0.7263 | Val Loss: 0.8100\n",
      "Epoch 31 | Train Loss: 0.7193 | Val Loss: 0.7839\n",
      "Epoch 32 | Train Loss: 0.7062 | Val Loss: 0.8017\n",
      "Epoch 33 | Train Loss: 0.7347 | Val Loss: 0.8106\n",
      "Epoch 34 | Train Loss: 0.7251 | Val Loss: 0.8040\n",
      "Epoch 35 | Train Loss: 0.7304 | Val Loss: 0.8272\n",
      "Epoch 36 | Train Loss: 0.7131 | Val Loss: 0.8078\n",
      "Epoch 37 | Train Loss: 0.7199 | Val Loss: 0.8126\n",
      "Epoch 38 | Train Loss: 0.7444 | Val Loss: 0.7829\n",
      "Epoch 39 | Train Loss: 0.7186 | Val Loss: 0.8058\n",
      "Epoch 40 | Train Loss: 0.7116 | Val Loss: 0.7952\n",
      "Epoch 41 | Train Loss: 0.7166 | Val Loss: 0.7875\n",
      "Epoch 42 | Train Loss: 0.7382 | Val Loss: 0.8007\n",
      "Epoch 43 | Train Loss: 0.7488 | Val Loss: 0.8081\n",
      "Epoch 44 | Train Loss: 0.7432 | Val Loss: 0.8238\n",
      "Epoch 45 | Train Loss: 0.7067 | Val Loss: 0.7982\n",
      "Epoch 46 | Train Loss: 0.7337 | Val Loss: 0.7882\n",
      "Epoch 47 | Train Loss: 0.6999 | Val Loss: 0.8202\n",
      "Epoch 48 | Train Loss: 0.7036 | Val Loss: 0.7901\n",
      "Epoch 49 | Train Loss: 0.7273 | Val Loss: 0.7881\n",
      "Epoch 50 | Train Loss: 0.7182 | Val Loss: 0.7992\n",
      "Fold 5 ‚ñ∂ AUC: 0.727, Balanced Acc: 0.442\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9324 | Val Loss: 0.8995\n",
      "Epoch 02 | Train Loss: 0.8756 | Val Loss: 0.9284\n",
      "Epoch 03 | Train Loss: 0.8506 | Val Loss: 0.9014\n",
      "Epoch 04 | Train Loss: 0.8420 | Val Loss: 0.9064\n",
      "Epoch 05 | Train Loss: 0.8359 | Val Loss: 0.8698\n",
      "Epoch 06 | Train Loss: 0.8236 | Val Loss: 0.9068\n",
      "Epoch 07 | Train Loss: 0.8127 | Val Loss: 0.8666\n",
      "Epoch 08 | Train Loss: 0.8316 | Val Loss: 0.8391\n",
      "Epoch 09 | Train Loss: 0.7972 | Val Loss: 0.8491\n",
      "Epoch 10 | Train Loss: 0.8024 | Val Loss: 0.8505\n",
      "Epoch 11 | Train Loss: 0.7769 | Val Loss: 0.8433\n",
      "Epoch 12 | Train Loss: 0.7652 | Val Loss: 0.8536\n",
      "Epoch 13 | Train Loss: 0.7622 | Val Loss: 0.8336\n",
      "Epoch 14 | Train Loss: 0.7547 | Val Loss: 0.8244\n",
      "Epoch 15 | Train Loss: 0.7397 | Val Loss: 0.8258\n",
      "Epoch 16 | Train Loss: 0.7352 | Val Loss: 0.8559\n",
      "Epoch 17 | Train Loss: 0.7823 | Val Loss: 0.8191\n",
      "Epoch 18 | Train Loss: 0.7538 | Val Loss: 0.8374\n",
      "Epoch 19 | Train Loss: 0.7172 | Val Loss: 0.8350\n",
      "Epoch 20 | Train Loss: 0.7195 | Val Loss: 0.8322\n",
      "Epoch 21 | Train Loss: 0.7161 | Val Loss: 0.8358\n",
      "Epoch 22 | Train Loss: 0.7469 | Val Loss: 0.8313\n",
      "Epoch 23 | Train Loss: 0.7219 | Val Loss: 0.8541\n",
      "Epoch 24 | Train Loss: 0.7394 | Val Loss: 0.8510\n",
      "Epoch 25 | Train Loss: 0.7260 | Val Loss: 0.8450\n",
      "Epoch 26 | Train Loss: 0.7380 | Val Loss: 0.8358\n",
      "Epoch 27 | Train Loss: 0.7376 | Val Loss: 0.8288\n",
      "Epoch 28 | Train Loss: 0.7190 | Val Loss: 0.8313\n",
      "Epoch 29 | Train Loss: 0.7207 | Val Loss: 0.8635\n",
      "Epoch 30 | Train Loss: 0.7525 | Val Loss: 0.8443\n",
      "Epoch 31 | Train Loss: 0.7419 | Val Loss: 0.8411\n",
      "Epoch 32 | Train Loss: 0.7037 | Val Loss: 0.8310\n",
      "Epoch 33 | Train Loss: 0.7073 | Val Loss: 0.8228\n",
      "Epoch 34 | Train Loss: 0.7015 | Val Loss: 0.8512\n",
      "Epoch 35 | Train Loss: 0.7505 | Val Loss: 0.8343\n",
      "Epoch 36 | Train Loss: 0.7446 | Val Loss: 0.8249\n",
      "Epoch 37 | Train Loss: 0.7011 | Val Loss: 0.8363\n",
      "Epoch 38 | Train Loss: 0.7360 | Val Loss: 0.8728\n",
      "Epoch 39 | Train Loss: 0.7317 | Val Loss: 0.8142\n",
      "Epoch 40 | Train Loss: 0.6998 | Val Loss: 0.8387\n",
      "Epoch 41 | Train Loss: 0.6992 | Val Loss: 0.8416\n",
      "Epoch 42 | Train Loss: 0.7104 | Val Loss: 0.8570\n",
      "Epoch 43 | Train Loss: 0.7207 | Val Loss: 0.8503\n",
      "Epoch 44 | Train Loss: 0.7158 | Val Loss: 0.8344\n",
      "Epoch 45 | Train Loss: 0.7088 | Val Loss: 0.8399\n",
      "Epoch 46 | Train Loss: 0.7121 | Val Loss: 0.8358\n",
      "Epoch 47 | Train Loss: 0.7117 | Val Loss: 0.8378\n",
      "Epoch 48 | Train Loss: 0.6884 | Val Loss: 0.8349\n",
      "Epoch 49 | Train Loss: 0.7076 | Val Loss: 0.8552\n",
      "Epoch 50 | Train Loss: 0.7144 | Val Loss: 0.8297\n",
      "Fold 6 ‚ñ∂ AUC: 0.727, Balanced Acc: 0.454\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9463 | Val Loss: 0.9125\n",
      "Epoch 02 | Train Loss: 0.8801 | Val Loss: 0.8585\n",
      "Epoch 03 | Train Loss: 0.8878 | Val Loss: 0.8675\n",
      "Epoch 04 | Train Loss: 0.8692 | Val Loss: 0.8382\n",
      "Epoch 05 | Train Loss: 0.8301 | Val Loss: 0.8125\n",
      "Epoch 06 | Train Loss: 0.8287 | Val Loss: 0.8566\n",
      "Epoch 07 | Train Loss: 0.8542 | Val Loss: 0.8417\n",
      "Epoch 08 | Train Loss: 0.8243 | Val Loss: 0.7734\n",
      "Epoch 09 | Train Loss: 0.7809 | Val Loss: 0.7379\n",
      "Epoch 10 | Train Loss: 0.7958 | Val Loss: 0.7420\n",
      "Epoch 11 | Train Loss: 0.7865 | Val Loss: 0.7848\n",
      "Epoch 12 | Train Loss: 0.7784 | Val Loss: 0.7384\n",
      "Epoch 13 | Train Loss: 0.7503 | Val Loss: 0.7339\n",
      "Epoch 14 | Train Loss: 0.7689 | Val Loss: 0.7272\n",
      "Epoch 15 | Train Loss: 0.7709 | Val Loss: 0.7446\n",
      "Epoch 16 | Train Loss: 0.7648 | Val Loss: 0.7226\n",
      "Epoch 17 | Train Loss: 0.7765 | Val Loss: 0.7202\n",
      "Epoch 18 | Train Loss: 0.7393 | Val Loss: 0.7096\n",
      "Epoch 19 | Train Loss: 0.7269 | Val Loss: 0.7195\n",
      "Epoch 20 | Train Loss: 0.7562 | Val Loss: 0.7469\n",
      "Epoch 21 | Train Loss: 0.7435 | Val Loss: 0.7353\n",
      "Epoch 22 | Train Loss: 0.7620 | Val Loss: 0.7850\n",
      "Epoch 23 | Train Loss: 0.7646 | Val Loss: 0.7101\n",
      "Epoch 24 | Train Loss: 0.7491 | Val Loss: 0.7105\n",
      "Epoch 25 | Train Loss: 0.7495 | Val Loss: 0.7222\n",
      "Epoch 26 | Train Loss: 0.7380 | Val Loss: 0.7231\n",
      "Epoch 27 | Train Loss: 0.7304 | Val Loss: 0.7381\n",
      "Epoch 28 | Train Loss: 0.7423 | Val Loss: 0.7214\n",
      "Epoch 29 | Train Loss: 0.7308 | Val Loss: 0.7174\n",
      "Epoch 30 | Train Loss: 0.7223 | Val Loss: 0.7138\n",
      "Epoch 31 | Train Loss: 0.7435 | Val Loss: 0.7172\n",
      "Epoch 32 | Train Loss: 0.7215 | Val Loss: 0.7446\n",
      "Epoch 33 | Train Loss: 0.7326 | Val Loss: 0.7297\n",
      "Epoch 34 | Train Loss: 0.7411 | Val Loss: 0.7207\n",
      "Epoch 35 | Train Loss: 0.7389 | Val Loss: 0.7209\n",
      "Epoch 36 | Train Loss: 0.7358 | Val Loss: 0.7095\n",
      "Epoch 37 | Train Loss: 0.7414 | Val Loss: 0.7279\n",
      "Epoch 38 | Train Loss: 0.7227 | Val Loss: 0.7224\n",
      "Epoch 39 | Train Loss: 0.7126 | Val Loss: 0.7200\n",
      "Epoch 40 | Train Loss: 0.7262 | Val Loss: 0.7261\n",
      "Epoch 41 | Train Loss: 0.7284 | Val Loss: 0.7355\n",
      "Epoch 42 | Train Loss: 0.7357 | Val Loss: 0.7344\n",
      "Epoch 43 | Train Loss: 0.7447 | Val Loss: 0.7599\n",
      "Epoch 44 | Train Loss: 0.7316 | Val Loss: 0.7240\n",
      "Epoch 45 | Train Loss: 0.7401 | Val Loss: 0.7629\n",
      "Epoch 46 | Train Loss: 0.7225 | Val Loss: 0.7142\n",
      "Epoch 47 | Train Loss: 0.7129 | Val Loss: 0.7343\n",
      "Epoch 48 | Train Loss: 0.7137 | Val Loss: 0.7161\n",
      "Epoch 49 | Train Loss: 0.7027 | Val Loss: 0.7414\n",
      "Epoch 50 | Train Loss: 0.7390 | Val Loss: 0.7198\n",
      "Fold 7 ‚ñ∂ AUC: 0.758, Balanced Acc: 0.462\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9631 | Val Loss: 0.8650\n",
      "Epoch 02 | Train Loss: 0.8782 | Val Loss: 0.8855\n",
      "Epoch 03 | Train Loss: 0.8736 | Val Loss: 0.8615\n",
      "Epoch 04 | Train Loss: 0.8561 | Val Loss: 0.8463\n",
      "Epoch 05 | Train Loss: 0.8514 | Val Loss: 0.8335\n",
      "Epoch 06 | Train Loss: 0.8422 | Val Loss: 0.8264\n",
      "Epoch 07 | Train Loss: 0.8159 | Val Loss: 0.8176\n",
      "Epoch 08 | Train Loss: 0.8067 | Val Loss: 0.8812\n",
      "Epoch 09 | Train Loss: 0.8081 | Val Loss: 0.8051\n",
      "Epoch 10 | Train Loss: 0.7517 | Val Loss: 0.8060\n",
      "Epoch 11 | Train Loss: 0.7961 | Val Loss: 0.8303\n",
      "Epoch 12 | Train Loss: 0.7691 | Val Loss: 0.7982\n",
      "Epoch 13 | Train Loss: 0.7520 | Val Loss: 0.8312\n",
      "Epoch 14 | Train Loss: 0.7424 | Val Loss: 0.8308\n",
      "Epoch 15 | Train Loss: 0.7292 | Val Loss: 0.8023\n",
      "Epoch 16 | Train Loss: 0.7873 | Val Loss: 0.8261\n",
      "Epoch 17 | Train Loss: 0.7779 | Val Loss: 0.7943\n",
      "Epoch 18 | Train Loss: 0.7581 | Val Loss: 0.7886\n",
      "Epoch 19 | Train Loss: 0.7347 | Val Loss: 0.7865\n",
      "Epoch 20 | Train Loss: 0.7415 | Val Loss: 0.8278\n",
      "Epoch 21 | Train Loss: 0.7458 | Val Loss: 0.7984\n",
      "Epoch 22 | Train Loss: 0.7473 | Val Loss: 0.7968\n",
      "Epoch 23 | Train Loss: 0.7354 | Val Loss: 0.8476\n",
      "Epoch 24 | Train Loss: 0.7447 | Val Loss: 0.7961\n",
      "Epoch 25 | Train Loss: 0.7207 | Val Loss: 0.8168\n",
      "Epoch 26 | Train Loss: 0.7177 | Val Loss: 0.7964\n",
      "Epoch 27 | Train Loss: 0.7289 | Val Loss: 0.8012\n",
      "Epoch 28 | Train Loss: 0.7352 | Val Loss: 0.7980\n",
      "Epoch 29 | Train Loss: 0.7385 | Val Loss: 0.8061\n",
      "Epoch 30 | Train Loss: 0.7423 | Val Loss: 0.8042\n",
      "Epoch 31 | Train Loss: 0.7416 | Val Loss: 0.8225\n",
      "Epoch 32 | Train Loss: 0.7259 | Val Loss: 0.8066\n",
      "Epoch 33 | Train Loss: 0.7196 | Val Loss: 0.7927\n",
      "Epoch 34 | Train Loss: 0.7182 | Val Loss: 0.8045\n",
      "Epoch 35 | Train Loss: 0.7228 | Val Loss: 0.8256\n",
      "Epoch 36 | Train Loss: 0.7280 | Val Loss: 0.8304\n",
      "Epoch 37 | Train Loss: 0.7309 | Val Loss: 0.7973\n",
      "Epoch 38 | Train Loss: 0.7181 | Val Loss: 0.8341\n",
      "Epoch 39 | Train Loss: 0.7432 | Val Loss: 0.8025\n",
      "Epoch 40 | Train Loss: 0.7286 | Val Loss: 0.8213\n",
      "Epoch 41 | Train Loss: 0.7259 | Val Loss: 0.7988\n",
      "Epoch 42 | Train Loss: 0.7205 | Val Loss: 0.7929\n",
      "Epoch 43 | Train Loss: 0.7332 | Val Loss: 0.7985\n",
      "Epoch 44 | Train Loss: 0.7229 | Val Loss: 0.8012\n",
      "Epoch 45 | Train Loss: 0.7294 | Val Loss: 0.8099\n",
      "Epoch 46 | Train Loss: 0.7120 | Val Loss: 0.8031\n",
      "Epoch 47 | Train Loss: 0.7139 | Val Loss: 0.8079\n",
      "Epoch 48 | Train Loss: 0.7305 | Val Loss: 0.8229\n",
      "Epoch 49 | Train Loss: 0.7218 | Val Loss: 0.8091\n",
      "Epoch 50 | Train Loss: 0.7159 | Val Loss: 0.8578\n",
      "Fold 8 ‚ñ∂ AUC: 0.710, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9240 | Val Loss: 0.8999\n",
      "Epoch 02 | Train Loss: 0.8985 | Val Loss: 0.8758\n",
      "Epoch 03 | Train Loss: 0.8668 | Val Loss: 0.8678\n",
      "Epoch 04 | Train Loss: 0.8548 | Val Loss: 0.8517\n",
      "Epoch 05 | Train Loss: 0.8522 | Val Loss: 0.8396\n",
      "Epoch 06 | Train Loss: 0.8298 | Val Loss: 0.8318\n",
      "Epoch 07 | Train Loss: 0.7953 | Val Loss: 0.8101\n",
      "Epoch 08 | Train Loss: 0.7912 | Val Loss: 0.8300\n",
      "Epoch 09 | Train Loss: 0.7870 | Val Loss: 0.8212\n",
      "Epoch 10 | Train Loss: 0.7823 | Val Loss: 0.7960\n",
      "Epoch 11 | Train Loss: 0.8135 | Val Loss: 0.8084\n",
      "Epoch 12 | Train Loss: 0.8110 | Val Loss: 0.7787\n",
      "Epoch 13 | Train Loss: 0.7643 | Val Loss: 0.7739\n",
      "Epoch 14 | Train Loss: 0.7675 | Val Loss: 0.8729\n",
      "Epoch 15 | Train Loss: 0.7749 | Val Loss: 0.7709\n",
      "Epoch 16 | Train Loss: 0.7504 | Val Loss: 0.7804\n",
      "Epoch 17 | Train Loss: 0.7483 | Val Loss: 0.7737\n",
      "Epoch 18 | Train Loss: 0.7810 | Val Loss: 0.7831\n",
      "Epoch 19 | Train Loss: 0.7954 | Val Loss: 0.7894\n",
      "Epoch 20 | Train Loss: 0.7586 | Val Loss: 0.7553\n",
      "Epoch 21 | Train Loss: 0.7447 | Val Loss: 0.7593\n",
      "Epoch 22 | Train Loss: 0.7575 | Val Loss: 0.7458\n",
      "Epoch 23 | Train Loss: 0.7299 | Val Loss: 0.7456\n",
      "Epoch 24 | Train Loss: 0.7476 | Val Loss: 0.7537\n",
      "Epoch 25 | Train Loss: 0.7529 | Val Loss: 0.7392\n",
      "Epoch 26 | Train Loss: 0.7431 | Val Loss: 0.7634\n",
      "Epoch 27 | Train Loss: 0.7313 | Val Loss: 0.8395\n",
      "Epoch 28 | Train Loss: 0.7475 | Val Loss: 0.7444\n",
      "Epoch 29 | Train Loss: 0.7321 | Val Loss: 0.7415\n",
      "Epoch 30 | Train Loss: 0.7425 | Val Loss: 0.7868\n",
      "Epoch 31 | Train Loss: 0.7302 | Val Loss: 0.7779\n",
      "Epoch 32 | Train Loss: 0.7473 | Val Loss: 0.7791\n",
      "Epoch 33 | Train Loss: 0.7520 | Val Loss: 0.7297\n",
      "Epoch 34 | Train Loss: 0.7444 | Val Loss: 0.7427\n",
      "Epoch 35 | Train Loss: 0.7519 | Val Loss: 0.7333\n",
      "Epoch 36 | Train Loss: 0.7234 | Val Loss: 0.7866\n",
      "Epoch 37 | Train Loss: 0.7241 | Val Loss: 0.7502\n",
      "Epoch 38 | Train Loss: 0.7330 | Val Loss: 0.7456\n",
      "Epoch 39 | Train Loss: 0.7340 | Val Loss: 0.7511\n",
      "Epoch 40 | Train Loss: 0.7055 | Val Loss: 0.7260\n",
      "Epoch 41 | Train Loss: 0.7329 | Val Loss: 0.7238\n",
      "Epoch 42 | Train Loss: 0.7285 | Val Loss: 0.7307\n",
      "Epoch 43 | Train Loss: 0.7220 | Val Loss: 0.7644\n",
      "Epoch 44 | Train Loss: 0.7335 | Val Loss: 0.7440\n",
      "Epoch 45 | Train Loss: 0.7247 | Val Loss: 0.7585\n",
      "Epoch 46 | Train Loss: 0.7120 | Val Loss: 0.7641\n",
      "Epoch 47 | Train Loss: 0.7482 | Val Loss: 0.8047\n",
      "Epoch 48 | Train Loss: 0.7251 | Val Loss: 0.7415\n",
      "Epoch 49 | Train Loss: 0.7215 | Val Loss: 0.7305\n",
      "Epoch 50 | Train Loss: 0.7135 | Val Loss: 0.7944\n",
      "Fold 9 ‚ñ∂ AUC: 0.765, Balanced Acc: 0.472\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9675 | Val Loss: 0.8890\n",
      "Epoch 02 | Train Loss: 0.8699 | Val Loss: 0.8599\n",
      "Epoch 03 | Train Loss: 0.8637 | Val Loss: 0.8415\n",
      "Epoch 04 | Train Loss: 0.8497 | Val Loss: 0.8299\n",
      "Epoch 05 | Train Loss: 0.8414 | Val Loss: 0.8231\n",
      "Epoch 06 | Train Loss: 0.8322 | Val Loss: 0.8014\n",
      "Epoch 07 | Train Loss: 0.8104 | Val Loss: 0.7876\n",
      "Epoch 08 | Train Loss: 0.8218 | Val Loss: 0.7858\n",
      "Epoch 09 | Train Loss: 0.7921 | Val Loss: 0.8005\n",
      "Epoch 10 | Train Loss: 0.7790 | Val Loss: 0.7887\n",
      "Epoch 11 | Train Loss: 0.7885 | Val Loss: 0.8413\n",
      "Epoch 12 | Train Loss: 0.8027 | Val Loss: 0.7830\n",
      "Epoch 13 | Train Loss: 0.7718 | Val Loss: 0.8033\n",
      "Epoch 14 | Train Loss: 0.7687 | Val Loss: 0.8005\n",
      "Epoch 15 | Train Loss: 0.7830 | Val Loss: 0.9065\n",
      "Epoch 16 | Train Loss: 0.7577 | Val Loss: 0.7711\n",
      "Epoch 17 | Train Loss: 0.7528 | Val Loss: 0.7717\n",
      "Epoch 18 | Train Loss: 0.7521 | Val Loss: 0.7638\n",
      "Epoch 19 | Train Loss: 0.7549 | Val Loss: 0.7771\n",
      "Epoch 20 | Train Loss: 0.7429 | Val Loss: 0.8155\n",
      "Epoch 21 | Train Loss: 0.7493 | Val Loss: 0.7755\n",
      "Epoch 22 | Train Loss: 0.7225 | Val Loss: 0.8349\n",
      "Epoch 23 | Train Loss: 0.7615 | Val Loss: 0.7781\n",
      "Epoch 24 | Train Loss: 0.7337 | Val Loss: 0.7854\n",
      "Epoch 25 | Train Loss: 0.7105 | Val Loss: 0.7705\n",
      "Epoch 26 | Train Loss: 0.7220 | Val Loss: 0.7890\n",
      "Epoch 27 | Train Loss: 0.7287 | Val Loss: 0.7873\n",
      "Epoch 28 | Train Loss: 0.7001 | Val Loss: 0.8755\n",
      "Epoch 29 | Train Loss: 0.7330 | Val Loss: 0.7852\n",
      "Epoch 30 | Train Loss: 0.7417 | Val Loss: 0.7775\n",
      "Epoch 31 | Train Loss: 0.7233 | Val Loss: 0.7732\n",
      "Epoch 32 | Train Loss: 0.7268 | Val Loss: 0.7707\n",
      "Epoch 33 | Train Loss: 0.7142 | Val Loss: 0.7825\n",
      "Epoch 34 | Train Loss: 0.7399 | Val Loss: 0.7894\n",
      "Epoch 35 | Train Loss: 0.7385 | Val Loss: 0.7864\n",
      "Epoch 36 | Train Loss: 0.7481 | Val Loss: 0.7849\n",
      "Epoch 37 | Train Loss: 0.8184 | Val Loss: 0.8512\n",
      "Epoch 38 | Train Loss: 0.7346 | Val Loss: 0.7755\n",
      "Epoch 39 | Train Loss: 0.7358 | Val Loss: 0.7834\n",
      "Epoch 40 | Train Loss: 0.7101 | Val Loss: 0.7799\n",
      "Epoch 41 | Train Loss: 0.7297 | Val Loss: 0.7799\n",
      "Epoch 42 | Train Loss: 0.7175 | Val Loss: 0.7876\n",
      "Epoch 43 | Train Loss: 0.7300 | Val Loss: 0.7810\n",
      "Epoch 44 | Train Loss: 0.7324 | Val Loss: 0.7770\n",
      "Epoch 45 | Train Loss: 0.7506 | Val Loss: 0.7882\n",
      "Epoch 46 | Train Loss: 0.7554 | Val Loss: 0.8384\n",
      "Epoch 47 | Train Loss: 0.7325 | Val Loss: 0.7765\n",
      "Epoch 48 | Train Loss: 0.6972 | Val Loss: 0.7860\n",
      "Epoch 49 | Train Loss: 0.7143 | Val Loss: 0.7732\n",
      "Epoch 50 | Train Loss: 0.7093 | Val Loss: 0.7755\n",
      "Fold 10 ‚ñ∂ AUC: 0.706, Balanced Acc: 0.442\n",
      "üîç Summary for hd=256, dp=0.4, lr=0.0005 ‚Üí AUC: 0.7449¬±0.0322 | BalAcc: 0.4754¬±0.0463\n",
      "\n",
      "üîß Config: hidden_dim=256, dropout=0.4, lr=0.0001\n",
      "\n",
      "‚ñ∂Ô∏è Fold 1/10\n",
      "Epoch 01 | Train Loss: 0.9020 | Val Loss: 0.8831\n",
      "Epoch 02 | Train Loss: 0.8899 | Val Loss: 0.8650\n",
      "Epoch 03 | Train Loss: 0.8663 | Val Loss: 0.8537\n",
      "Epoch 04 | Train Loss: 0.8588 | Val Loss: 0.8499\n",
      "Epoch 05 | Train Loss: 0.8553 | Val Loss: 0.8536\n",
      "Epoch 06 | Train Loss: 0.8585 | Val Loss: 0.8385\n",
      "Epoch 07 | Train Loss: 0.8458 | Val Loss: 0.8317\n",
      "Epoch 08 | Train Loss: 0.8375 | Val Loss: 0.8343\n",
      "Epoch 09 | Train Loss: 0.8401 | Val Loss: 0.8199\n",
      "Epoch 10 | Train Loss: 0.8485 | Val Loss: 0.8077\n",
      "Epoch 11 | Train Loss: 0.8170 | Val Loss: 0.8060\n",
      "Epoch 12 | Train Loss: 0.8080 | Val Loss: 0.7999\n",
      "Epoch 13 | Train Loss: 0.8022 | Val Loss: 0.7981\n",
      "Epoch 14 | Train Loss: 0.8088 | Val Loss: 0.7791\n",
      "Epoch 15 | Train Loss: 0.8002 | Val Loss: 0.7893\n",
      "Epoch 16 | Train Loss: 0.7936 | Val Loss: 0.7743\n",
      "Epoch 17 | Train Loss: 0.8193 | Val Loss: 0.7967\n",
      "Epoch 18 | Train Loss: 0.8005 | Val Loss: 0.8257\n",
      "Epoch 19 | Train Loss: 0.8304 | Val Loss: 0.7681\n",
      "Epoch 20 | Train Loss: 0.7719 | Val Loss: 0.7547\n",
      "Epoch 21 | Train Loss: 0.7778 | Val Loss: 0.7476\n",
      "Epoch 22 | Train Loss: 0.7819 | Val Loss: 0.7479\n",
      "Epoch 23 | Train Loss: 0.8086 | Val Loss: 0.7974\n",
      "Epoch 24 | Train Loss: 0.8119 | Val Loss: 0.7583\n",
      "Epoch 25 | Train Loss: 0.7641 | Val Loss: 0.7345\n",
      "Epoch 26 | Train Loss: 0.7546 | Val Loss: 0.7329\n",
      "Epoch 27 | Train Loss: 0.7755 | Val Loss: 0.7254\n",
      "Epoch 28 | Train Loss: 0.7734 | Val Loss: 0.7231\n",
      "Epoch 29 | Train Loss: 0.7687 | Val Loss: 0.7214\n",
      "Epoch 30 | Train Loss: 0.7573 | Val Loss: 0.7259\n",
      "Epoch 31 | Train Loss: 0.7521 | Val Loss: 0.7137\n",
      "Epoch 32 | Train Loss: 0.7588 | Val Loss: 0.7174\n",
      "Epoch 33 | Train Loss: 0.7593 | Val Loss: 0.7073\n",
      "Epoch 34 | Train Loss: 0.7451 | Val Loss: 0.7218\n",
      "Epoch 35 | Train Loss: 0.7502 | Val Loss: 0.7395\n",
      "Epoch 36 | Train Loss: 0.7914 | Val Loss: 0.7093\n",
      "Epoch 37 | Train Loss: 0.7513 | Val Loss: 0.7048\n",
      "Epoch 38 | Train Loss: 0.7573 | Val Loss: 0.7117\n",
      "Epoch 39 | Train Loss: 0.7443 | Val Loss: 0.6993\n",
      "Epoch 40 | Train Loss: 0.7613 | Val Loss: 0.6981\n",
      "Epoch 41 | Train Loss: 0.7627 | Val Loss: 0.6995\n",
      "Epoch 42 | Train Loss: 0.7523 | Val Loss: 0.7026\n",
      "Epoch 43 | Train Loss: 0.7574 | Val Loss: 0.6984\n",
      "Epoch 44 | Train Loss: 0.7493 | Val Loss: 0.6917\n",
      "Epoch 45 | Train Loss: 0.7393 | Val Loss: 0.7012\n",
      "Epoch 46 | Train Loss: 0.7512 | Val Loss: 0.6930\n",
      "Epoch 47 | Train Loss: 0.7490 | Val Loss: 0.6927\n",
      "Epoch 48 | Train Loss: 0.7247 | Val Loss: 0.7184\n",
      "Epoch 49 | Train Loss: 0.7537 | Val Loss: 0.7008\n",
      "Epoch 50 | Train Loss: 0.7286 | Val Loss: 0.6973\n",
      "Fold 1 ‚ñ∂ AUC: 0.773, Balanced Acc: 0.515\n",
      "\n",
      "‚ñ∂Ô∏è Fold 2/10\n",
      "Epoch 01 | Train Loss: 0.9615 | Val Loss: 0.8832\n",
      "Epoch 02 | Train Loss: 0.8803 | Val Loss: 0.8638\n",
      "Epoch 03 | Train Loss: 0.8602 | Val Loss: 0.8593\n",
      "Epoch 04 | Train Loss: 0.8693 | Val Loss: 0.8517\n",
      "Epoch 05 | Train Loss: 0.8621 | Val Loss: 0.8475\n",
      "Epoch 06 | Train Loss: 0.8562 | Val Loss: 0.8461\n",
      "Epoch 07 | Train Loss: 0.8639 | Val Loss: 0.8403\n",
      "Epoch 08 | Train Loss: 0.8441 | Val Loss: 0.8338\n",
      "Epoch 09 | Train Loss: 0.8405 | Val Loss: 0.8420\n",
      "Epoch 10 | Train Loss: 0.8360 | Val Loss: 0.8229\n",
      "Epoch 11 | Train Loss: 0.8291 | Val Loss: 0.8151\n",
      "Epoch 12 | Train Loss: 0.8166 | Val Loss: 0.8157\n",
      "Epoch 13 | Train Loss: 0.8151 | Val Loss: 0.8106\n",
      "Epoch 14 | Train Loss: 0.8115 | Val Loss: 0.7954\n",
      "Epoch 15 | Train Loss: 0.8104 | Val Loss: 0.7874\n",
      "Epoch 16 | Train Loss: 0.8067 | Val Loss: 0.7828\n",
      "Epoch 17 | Train Loss: 0.8048 | Val Loss: 0.8425\n",
      "Epoch 18 | Train Loss: 0.7923 | Val Loss: 0.8211\n",
      "Epoch 19 | Train Loss: 0.8130 | Val Loss: 0.7765\n",
      "Epoch 20 | Train Loss: 0.7801 | Val Loss: 0.7729\n",
      "Epoch 21 | Train Loss: 0.7859 | Val Loss: 0.7542\n",
      "Epoch 22 | Train Loss: 0.7913 | Val Loss: 0.7737\n",
      "Epoch 23 | Train Loss: 0.7900 | Val Loss: 0.7670\n",
      "Epoch 24 | Train Loss: 0.7680 | Val Loss: 0.7730\n",
      "Epoch 25 | Train Loss: 0.7403 | Val Loss: 0.7429\n",
      "Epoch 26 | Train Loss: 0.7498 | Val Loss: 0.7450\n",
      "Epoch 27 | Train Loss: 0.7480 | Val Loss: 0.7491\n",
      "Epoch 28 | Train Loss: 0.7851 | Val Loss: 0.7680\n",
      "Epoch 29 | Train Loss: 0.7833 | Val Loss: 0.7517\n",
      "Epoch 30 | Train Loss: 0.7512 | Val Loss: 0.7990\n",
      "Epoch 31 | Train Loss: 0.7920 | Val Loss: 0.7467\n",
      "Epoch 32 | Train Loss: 0.7564 | Val Loss: 0.7212\n",
      "Epoch 33 | Train Loss: 0.7812 | Val Loss: 0.8553\n",
      "Epoch 34 | Train Loss: 0.7770 | Val Loss: 0.7287\n",
      "Epoch 35 | Train Loss: 0.7500 | Val Loss: 0.7181\n",
      "Epoch 36 | Train Loss: 0.7479 | Val Loss: 0.7365\n",
      "Epoch 37 | Train Loss: 0.7592 | Val Loss: 0.7698\n",
      "Epoch 38 | Train Loss: 0.7642 | Val Loss: 0.7362\n",
      "Epoch 39 | Train Loss: 0.7535 | Val Loss: 0.7286\n",
      "Epoch 40 | Train Loss: 0.7406 | Val Loss: 0.7273\n",
      "Epoch 41 | Train Loss: 0.7424 | Val Loss: 0.7385\n",
      "Epoch 42 | Train Loss: 0.7494 | Val Loss: 0.7438\n",
      "Epoch 43 | Train Loss: 0.7704 | Val Loss: 0.7109\n",
      "Epoch 44 | Train Loss: 0.7416 | Val Loss: 0.7103\n",
      "Epoch 45 | Train Loss: 0.7287 | Val Loss: 0.7615\n",
      "Epoch 46 | Train Loss: 0.7476 | Val Loss: 0.7075\n",
      "Epoch 47 | Train Loss: 0.7581 | Val Loss: 0.7491\n",
      "Epoch 48 | Train Loss: 0.7311 | Val Loss: 0.7408\n",
      "Epoch 49 | Train Loss: 0.7605 | Val Loss: 0.7308\n",
      "Epoch 50 | Train Loss: 0.7477 | Val Loss: 0.7376\n",
      "Fold 2 ‚ñ∂ AUC: 0.655, Balanced Acc: 0.561\n",
      "\n",
      "‚ñ∂Ô∏è Fold 3/10\n",
      "Epoch 01 | Train Loss: 0.9294 | Val Loss: 0.8717\n",
      "Epoch 02 | Train Loss: 0.8953 | Val Loss: 0.8589\n",
      "Epoch 03 | Train Loss: 0.8819 | Val Loss: 0.8577\n",
      "Epoch 04 | Train Loss: 0.8677 | Val Loss: 0.8480\n",
      "Epoch 05 | Train Loss: 0.8723 | Val Loss: 0.8434\n",
      "Epoch 06 | Train Loss: 0.8705 | Val Loss: 0.8395\n",
      "Epoch 07 | Train Loss: 0.8529 | Val Loss: 0.8353\n",
      "Epoch 08 | Train Loss: 0.8549 | Val Loss: 0.8316\n",
      "Epoch 09 | Train Loss: 0.8371 | Val Loss: 0.8326\n",
      "Epoch 10 | Train Loss: 0.8378 | Val Loss: 0.8275\n",
      "Epoch 11 | Train Loss: 0.8504 | Val Loss: 0.8131\n",
      "Epoch 12 | Train Loss: 0.8574 | Val Loss: 0.8151\n",
      "Epoch 13 | Train Loss: 0.8242 | Val Loss: 0.8052\n",
      "Epoch 14 | Train Loss: 0.8413 | Val Loss: 0.7996\n",
      "Epoch 15 | Train Loss: 0.8127 | Val Loss: 0.7922\n",
      "Epoch 16 | Train Loss: 0.8137 | Val Loss: 0.8331\n",
      "Epoch 17 | Train Loss: 0.8103 | Val Loss: 0.8053\n",
      "Epoch 18 | Train Loss: 0.8147 | Val Loss: 0.7860\n",
      "Epoch 19 | Train Loss: 0.8161 | Val Loss: 0.7733\n",
      "Epoch 20 | Train Loss: 0.8003 | Val Loss: 0.7755\n",
      "Epoch 21 | Train Loss: 0.7976 | Val Loss: 0.7620\n",
      "Epoch 22 | Train Loss: 0.7959 | Val Loss: 0.8076\n",
      "Epoch 23 | Train Loss: 0.7909 | Val Loss: 0.7543\n",
      "Epoch 24 | Train Loss: 0.8149 | Val Loss: 0.7534\n",
      "Epoch 25 | Train Loss: 0.7911 | Val Loss: 0.7767\n",
      "Epoch 26 | Train Loss: 0.7686 | Val Loss: 0.7476\n",
      "Epoch 27 | Train Loss: 0.7880 | Val Loss: 0.7844\n",
      "Epoch 28 | Train Loss: 0.7650 | Val Loss: 0.7477\n",
      "Epoch 29 | Train Loss: 0.8105 | Val Loss: 0.7748\n",
      "Epoch 30 | Train Loss: 0.7661 | Val Loss: 0.7522\n",
      "Epoch 31 | Train Loss: 0.7677 | Val Loss: 0.7760\n",
      "Epoch 32 | Train Loss: 0.7753 | Val Loss: 0.7341\n",
      "Epoch 33 | Train Loss: 0.7891 | Val Loss: 0.7350\n",
      "Epoch 34 | Train Loss: 0.7743 | Val Loss: 0.7462\n",
      "Epoch 35 | Train Loss: 0.7747 | Val Loss: 0.7364\n",
      "Epoch 36 | Train Loss: 0.7489 | Val Loss: 0.7605\n",
      "Epoch 37 | Train Loss: 0.7459 | Val Loss: 0.7318\n",
      "Epoch 38 | Train Loss: 0.7403 | Val Loss: 0.7338\n",
      "Epoch 39 | Train Loss: 0.7601 | Val Loss: 0.7340\n",
      "Epoch 40 | Train Loss: 0.7754 | Val Loss: 0.7342\n",
      "Epoch 41 | Train Loss: 0.7332 | Val Loss: 0.7259\n",
      "Epoch 42 | Train Loss: 0.7513 | Val Loss: 0.7346\n",
      "Epoch 43 | Train Loss: 0.7541 | Val Loss: 0.7631\n",
      "Epoch 44 | Train Loss: 0.7425 | Val Loss: 0.7240\n",
      "Epoch 45 | Train Loss: 0.7252 | Val Loss: 0.7241\n",
      "Epoch 46 | Train Loss: 0.7499 | Val Loss: 0.7228\n",
      "Epoch 47 | Train Loss: 0.7376 | Val Loss: 0.7586\n",
      "Epoch 48 | Train Loss: 0.7376 | Val Loss: 0.7650\n",
      "Epoch 49 | Train Loss: 0.7320 | Val Loss: 0.7188\n",
      "Epoch 50 | Train Loss: 0.7532 | Val Loss: 0.7308\n",
      "Fold 3 ‚ñ∂ AUC: 0.766, Balanced Acc: 0.511\n",
      "\n",
      "‚ñ∂Ô∏è Fold 4/10\n",
      "Epoch 01 | Train Loss: 0.8995 | Val Loss: 0.8461\n",
      "Epoch 02 | Train Loss: 0.8651 | Val Loss: 0.8385\n",
      "Epoch 03 | Train Loss: 0.8575 | Val Loss: 0.8354\n",
      "Epoch 04 | Train Loss: 0.8568 | Val Loss: 0.8473\n",
      "Epoch 05 | Train Loss: 0.8475 | Val Loss: 0.8241\n",
      "Epoch 06 | Train Loss: 0.8402 | Val Loss: 0.8193\n",
      "Epoch 07 | Train Loss: 0.8341 | Val Loss: 0.8093\n",
      "Epoch 08 | Train Loss: 0.8468 | Val Loss: 0.8323\n",
      "Epoch 09 | Train Loss: 0.8283 | Val Loss: 0.7994\n",
      "Epoch 10 | Train Loss: 0.8263 | Val Loss: 0.7837\n",
      "Epoch 11 | Train Loss: 0.8076 | Val Loss: 0.7757\n",
      "Epoch 12 | Train Loss: 0.8162 | Val Loss: 0.7714\n",
      "Epoch 13 | Train Loss: 0.7938 | Val Loss: 0.7621\n",
      "Epoch 14 | Train Loss: 0.8151 | Val Loss: 0.7695\n",
      "Epoch 15 | Train Loss: 0.8008 | Val Loss: 0.7510\n",
      "Epoch 16 | Train Loss: 0.7848 | Val Loss: 0.7428\n",
      "Epoch 17 | Train Loss: 0.7855 | Val Loss: 0.7367\n",
      "Epoch 18 | Train Loss: 0.7910 | Val Loss: 0.7281\n",
      "Epoch 19 | Train Loss: 0.7891 | Val Loss: 0.7615\n",
      "Epoch 20 | Train Loss: 0.7902 | Val Loss: 0.7433\n",
      "Epoch 21 | Train Loss: 0.8014 | Val Loss: 0.7333\n",
      "Epoch 22 | Train Loss: 0.7823 | Val Loss: 0.7167\n",
      "Epoch 23 | Train Loss: 0.7607 | Val Loss: 0.7145\n",
      "Epoch 24 | Train Loss: 0.7688 | Val Loss: 0.7067\n",
      "Epoch 25 | Train Loss: 0.7648 | Val Loss: 0.7014\n",
      "Epoch 26 | Train Loss: 0.7698 | Val Loss: 0.7053\n",
      "Epoch 27 | Train Loss: 0.7904 | Val Loss: 0.7025\n",
      "Epoch 28 | Train Loss: 0.7665 | Val Loss: 0.7400\n",
      "Epoch 29 | Train Loss: 0.7770 | Val Loss: 0.7339\n",
      "Epoch 30 | Train Loss: 0.7992 | Val Loss: 0.6953\n",
      "Epoch 31 | Train Loss: 0.7897 | Val Loss: 0.6959\n",
      "Epoch 32 | Train Loss: 0.7644 | Val Loss: 0.6981\n",
      "Epoch 33 | Train Loss: 0.7483 | Val Loss: 0.7096\n",
      "Epoch 34 | Train Loss: 0.7637 | Val Loss: 0.6887\n",
      "Epoch 35 | Train Loss: 0.7488 | Val Loss: 0.6870\n",
      "Epoch 36 | Train Loss: 0.7898 | Val Loss: 0.6837\n",
      "Epoch 37 | Train Loss: 0.7753 | Val Loss: 0.6871\n",
      "Epoch 38 | Train Loss: 0.7498 | Val Loss: 0.6856\n",
      "Epoch 39 | Train Loss: 0.7454 | Val Loss: 0.6841\n",
      "Epoch 40 | Train Loss: 0.7513 | Val Loss: 0.6786\n",
      "Epoch 41 | Train Loss: 0.7674 | Val Loss: 0.7248\n",
      "Epoch 42 | Train Loss: 0.7550 | Val Loss: 0.6880\n",
      "Epoch 43 | Train Loss: 0.7415 | Val Loss: 0.6764\n",
      "Epoch 44 | Train Loss: 0.7461 | Val Loss: 0.6744\n",
      "Epoch 45 | Train Loss: 0.7520 | Val Loss: 0.6683\n",
      "Epoch 46 | Train Loss: 0.7357 | Val Loss: 0.6799\n",
      "Epoch 47 | Train Loss: 0.7252 | Val Loss: 0.6666\n",
      "Epoch 48 | Train Loss: 0.7437 | Val Loss: 0.6645\n",
      "Epoch 49 | Train Loss: 0.7462 | Val Loss: 0.7074\n",
      "Epoch 50 | Train Loss: 0.7558 | Val Loss: 0.6730\n",
      "Fold 4 ‚ñ∂ AUC: 0.798, Balanced Acc: 0.528\n",
      "\n",
      "‚ñ∂Ô∏è Fold 5/10\n",
      "Epoch 01 | Train Loss: 0.9206 | Val Loss: 0.9264\n",
      "Epoch 02 | Train Loss: 0.8763 | Val Loss: 0.9052\n",
      "Epoch 03 | Train Loss: 0.8696 | Val Loss: 0.8914\n",
      "Epoch 04 | Train Loss: 0.8600 | Val Loss: 0.8820\n",
      "Epoch 05 | Train Loss: 0.8586 | Val Loss: 0.8909\n",
      "Epoch 06 | Train Loss: 0.8481 | Val Loss: 0.8742\n",
      "Epoch 07 | Train Loss: 0.8403 | Val Loss: 0.8771\n",
      "Epoch 08 | Train Loss: 0.8268 | Val Loss: 0.8726\n",
      "Epoch 09 | Train Loss: 0.8385 | Val Loss: 0.8728\n",
      "Epoch 10 | Train Loss: 0.8415 | Val Loss: 0.8776\n",
      "Epoch 11 | Train Loss: 0.8246 | Val Loss: 0.8686\n",
      "Epoch 12 | Train Loss: 0.8425 | Val Loss: 0.8527\n",
      "Epoch 13 | Train Loss: 0.8126 | Val Loss: 0.8497\n",
      "Epoch 14 | Train Loss: 0.8034 | Val Loss: 0.8485\n",
      "Epoch 15 | Train Loss: 0.8007 | Val Loss: 0.8374\n",
      "Epoch 16 | Train Loss: 0.7872 | Val Loss: 0.8401\n",
      "Epoch 17 | Train Loss: 0.7876 | Val Loss: 0.8257\n",
      "Epoch 18 | Train Loss: 0.7648 | Val Loss: 0.8250\n",
      "Epoch 19 | Train Loss: 0.8019 | Val Loss: 0.8225\n",
      "Epoch 20 | Train Loss: 0.7749 | Val Loss: 0.8134\n",
      "Epoch 21 | Train Loss: 0.7624 | Val Loss: 0.8135\n",
      "Epoch 22 | Train Loss: 0.7770 | Val Loss: 0.8148\n",
      "Epoch 23 | Train Loss: 0.7686 | Val Loss: 0.8023\n",
      "Epoch 24 | Train Loss: 0.7666 | Val Loss: 0.8063\n",
      "Epoch 25 | Train Loss: 0.7580 | Val Loss: 0.7997\n",
      "Epoch 26 | Train Loss: 0.7866 | Val Loss: 0.8162\n",
      "Epoch 27 | Train Loss: 0.7758 | Val Loss: 0.7998\n",
      "Epoch 28 | Train Loss: 0.7429 | Val Loss: 0.7987\n",
      "Epoch 29 | Train Loss: 0.7677 | Val Loss: 0.8314\n",
      "Epoch 30 | Train Loss: 0.7743 | Val Loss: 0.8060\n",
      "Epoch 31 | Train Loss: 0.7513 | Val Loss: 0.8050\n",
      "Epoch 32 | Train Loss: 0.7465 | Val Loss: 0.8007\n",
      "Epoch 33 | Train Loss: 0.7291 | Val Loss: 0.7930\n",
      "Epoch 34 | Train Loss: 0.7327 | Val Loss: 0.8035\n",
      "Epoch 35 | Train Loss: 0.7501 | Val Loss: 0.8468\n",
      "Epoch 36 | Train Loss: 0.7540 | Val Loss: 0.7945\n",
      "Epoch 37 | Train Loss: 0.7516 | Val Loss: 0.7916\n",
      "Epoch 38 | Train Loss: 0.7203 | Val Loss: 0.7975\n",
      "Epoch 39 | Train Loss: 0.7378 | Val Loss: 0.7979\n",
      "Epoch 40 | Train Loss: 0.7394 | Val Loss: 0.8077\n",
      "Epoch 41 | Train Loss: 0.7465 | Val Loss: 0.8044\n",
      "Epoch 42 | Train Loss: 0.7405 | Val Loss: 0.7911\n",
      "Epoch 43 | Train Loss: 0.7493 | Val Loss: 0.7898\n",
      "Epoch 44 | Train Loss: 0.7307 | Val Loss: 0.7888\n",
      "Epoch 45 | Train Loss: 0.7210 | Val Loss: 0.8089\n",
      "Epoch 46 | Train Loss: 0.7414 | Val Loss: 0.7852\n",
      "Epoch 47 | Train Loss: 0.7214 | Val Loss: 0.7905\n",
      "Epoch 48 | Train Loss: 0.7345 | Val Loss: 0.7809\n",
      "Epoch 49 | Train Loss: 0.7233 | Val Loss: 0.7770\n",
      "Epoch 50 | Train Loss: 0.7214 | Val Loss: 0.7798\n",
      "Fold 5 ‚ñ∂ AUC: 0.750, Balanced Acc: 0.497\n",
      "\n",
      "‚ñ∂Ô∏è Fold 6/10\n",
      "Epoch 01 | Train Loss: 0.9809 | Val Loss: 0.9416\n",
      "Epoch 02 | Train Loss: 0.8809 | Val Loss: 0.9168\n",
      "Epoch 03 | Train Loss: 0.8706 | Val Loss: 0.8926\n",
      "Epoch 04 | Train Loss: 0.8624 | Val Loss: 0.8910\n",
      "Epoch 05 | Train Loss: 0.8474 | Val Loss: 0.8884\n",
      "Epoch 06 | Train Loss: 0.8483 | Val Loss: 0.8907\n",
      "Epoch 07 | Train Loss: 0.8665 | Val Loss: 0.8863\n",
      "Epoch 08 | Train Loss: 0.8490 | Val Loss: 0.8748\n",
      "Epoch 09 | Train Loss: 0.8311 | Val Loss: 0.8769\n",
      "Epoch 10 | Train Loss: 0.8334 | Val Loss: 0.8872\n",
      "Epoch 11 | Train Loss: 0.8343 | Val Loss: 0.8830\n",
      "Epoch 12 | Train Loss: 0.8319 | Val Loss: 0.8668\n",
      "Epoch 13 | Train Loss: 0.8102 | Val Loss: 0.8642\n",
      "Epoch 14 | Train Loss: 0.8050 | Val Loss: 0.8591\n",
      "Epoch 15 | Train Loss: 0.8017 | Val Loss: 0.8714\n",
      "Epoch 16 | Train Loss: 0.7910 | Val Loss: 0.8808\n",
      "Epoch 17 | Train Loss: 0.7987 | Val Loss: 0.8714\n",
      "Epoch 18 | Train Loss: 0.8032 | Val Loss: 0.8652\n",
      "Epoch 19 | Train Loss: 0.7771 | Val Loss: 0.8499\n",
      "Epoch 20 | Train Loss: 0.7712 | Val Loss: 0.8593\n",
      "Epoch 21 | Train Loss: 0.7815 | Val Loss: 0.8559\n",
      "Epoch 22 | Train Loss: 0.7642 | Val Loss: 0.8425\n",
      "Epoch 23 | Train Loss: 0.7597 | Val Loss: 0.8535\n",
      "Epoch 24 | Train Loss: 0.7768 | Val Loss: 0.8694\n",
      "Epoch 25 | Train Loss: 0.7526 | Val Loss: 0.8426\n",
      "Epoch 26 | Train Loss: 0.7515 | Val Loss: 0.8465\n",
      "Epoch 27 | Train Loss: 0.7529 | Val Loss: 0.8412\n",
      "Epoch 28 | Train Loss: 0.7378 | Val Loss: 0.8329\n",
      "Epoch 29 | Train Loss: 0.7702 | Val Loss: 0.8459\n",
      "Epoch 30 | Train Loss: 0.7514 | Val Loss: 0.8368\n",
      "Epoch 31 | Train Loss: 0.7346 | Val Loss: 0.8372\n",
      "Epoch 32 | Train Loss: 0.7357 | Val Loss: 0.8526\n",
      "Epoch 33 | Train Loss: 0.7286 | Val Loss: 0.8841\n",
      "Epoch 34 | Train Loss: 0.7983 | Val Loss: 0.8386\n",
      "Epoch 35 | Train Loss: 0.7666 | Val Loss: 0.8742\n",
      "Epoch 36 | Train Loss: 0.7562 | Val Loss: 0.8263\n",
      "Epoch 37 | Train Loss: 0.7329 | Val Loss: 0.8300\n",
      "Epoch 38 | Train Loss: 0.7626 | Val Loss: 0.8338\n",
      "Epoch 39 | Train Loss: 0.7210 | Val Loss: 0.8277\n",
      "Epoch 40 | Train Loss: 0.7341 | Val Loss: 0.8420\n",
      "Epoch 41 | Train Loss: 0.7318 | Val Loss: 0.8333\n",
      "Epoch 42 | Train Loss: 0.7359 | Val Loss: 0.8224\n",
      "Epoch 43 | Train Loss: 0.7379 | Val Loss: 0.8443\n",
      "Epoch 44 | Train Loss: 0.7412 | Val Loss: 0.8227\n",
      "Epoch 45 | Train Loss: 0.7305 | Val Loss: 0.8242\n",
      "Epoch 46 | Train Loss: 0.7296 | Val Loss: 0.8258\n",
      "Epoch 47 | Train Loss: 0.7234 | Val Loss: 0.8294\n",
      "Epoch 48 | Train Loss: 0.7243 | Val Loss: 0.8244\n",
      "Epoch 49 | Train Loss: 0.7353 | Val Loss: 0.8395\n",
      "Epoch 50 | Train Loss: 0.7337 | Val Loss: 0.8239\n",
      "Fold 6 ‚ñ∂ AUC: 0.717, Balanced Acc: 0.454\n",
      "\n",
      "‚ñ∂Ô∏è Fold 7/10\n",
      "Epoch 01 | Train Loss: 0.9332 | Val Loss: 0.8623\n",
      "Epoch 02 | Train Loss: 0.8865 | Val Loss: 0.8545\n",
      "Epoch 03 | Train Loss: 0.8832 | Val Loss: 0.8565\n",
      "Epoch 04 | Train Loss: 0.8598 | Val Loss: 0.8438\n",
      "Epoch 05 | Train Loss: 0.8636 | Val Loss: 0.8399\n",
      "Epoch 06 | Train Loss: 0.8663 | Val Loss: 0.8329\n",
      "Epoch 07 | Train Loss: 0.8499 | Val Loss: 0.8238\n",
      "Epoch 08 | Train Loss: 0.8463 | Val Loss: 0.8608\n",
      "Epoch 09 | Train Loss: 0.8789 | Val Loss: 0.8230\n",
      "Epoch 10 | Train Loss: 0.8625 | Val Loss: 0.8140\n",
      "Epoch 11 | Train Loss: 0.8589 | Val Loss: 0.8230\n",
      "Epoch 12 | Train Loss: 0.8419 | Val Loss: 0.8018\n",
      "Epoch 13 | Train Loss: 0.8392 | Val Loss: 0.7972\n",
      "Epoch 14 | Train Loss: 0.8177 | Val Loss: 0.7971\n",
      "Epoch 15 | Train Loss: 0.8252 | Val Loss: 0.8254\n",
      "Epoch 16 | Train Loss: 0.8290 | Val Loss: 0.7857\n",
      "Epoch 17 | Train Loss: 0.8081 | Val Loss: 0.7671\n",
      "Epoch 18 | Train Loss: 0.8045 | Val Loss: 0.7594\n",
      "Epoch 19 | Train Loss: 0.7939 | Val Loss: 0.7599\n",
      "Epoch 20 | Train Loss: 0.7822 | Val Loss: 0.7525\n",
      "Epoch 21 | Train Loss: 0.7851 | Val Loss: 0.7416\n",
      "Epoch 22 | Train Loss: 0.7966 | Val Loss: 0.7465\n",
      "Epoch 23 | Train Loss: 0.7861 | Val Loss: 0.7307\n",
      "Epoch 24 | Train Loss: 0.7861 | Val Loss: 0.7399\n",
      "Epoch 25 | Train Loss: 0.7897 | Val Loss: 0.7516\n",
      "Epoch 26 | Train Loss: 0.7770 | Val Loss: 0.7213\n",
      "Epoch 27 | Train Loss: 0.7641 | Val Loss: 0.7240\n",
      "Epoch 28 | Train Loss: 0.7684 | Val Loss: 0.7223\n",
      "Epoch 29 | Train Loss: 0.7578 | Val Loss: 0.7418\n",
      "Epoch 30 | Train Loss: 0.7842 | Val Loss: 0.7099\n",
      "Epoch 31 | Train Loss: 0.7712 | Val Loss: 0.7165\n",
      "Epoch 32 | Train Loss: 0.7685 | Val Loss: 0.7059\n",
      "Epoch 33 | Train Loss: 0.7539 | Val Loss: 0.7091\n",
      "Epoch 34 | Train Loss: 0.7657 | Val Loss: 0.7126\n",
      "Epoch 35 | Train Loss: 0.7645 | Val Loss: 0.7051\n",
      "Epoch 36 | Train Loss: 0.7471 | Val Loss: 0.7310\n",
      "Epoch 37 | Train Loss: 0.7709 | Val Loss: 0.7129\n",
      "Epoch 38 | Train Loss: 0.7567 | Val Loss: 0.7128\n",
      "Epoch 39 | Train Loss: 0.7436 | Val Loss: 0.7154\n",
      "Epoch 40 | Train Loss: 0.7469 | Val Loss: 0.7071\n",
      "Epoch 41 | Train Loss: 0.7744 | Val Loss: 0.7085\n",
      "Epoch 42 | Train Loss: 0.7597 | Val Loss: 0.7273\n",
      "Epoch 43 | Train Loss: 0.7632 | Val Loss: 0.7341\n",
      "Epoch 44 | Train Loss: 0.7406 | Val Loss: 0.7235\n",
      "Epoch 45 | Train Loss: 0.7506 | Val Loss: 0.7217\n",
      "Epoch 46 | Train Loss: 0.7832 | Val Loss: 0.7221\n",
      "Epoch 47 | Train Loss: 0.7348 | Val Loss: 0.7111\n",
      "Epoch 48 | Train Loss: 0.7415 | Val Loss: 0.7058\n",
      "Epoch 49 | Train Loss: 0.7464 | Val Loss: 0.7099\n",
      "Epoch 50 | Train Loss: 0.7537 | Val Loss: 0.7200\n",
      "Fold 7 ‚ñ∂ AUC: 0.773, Balanced Acc: 0.493\n",
      "\n",
      "‚ñ∂Ô∏è Fold 8/10\n",
      "Epoch 01 | Train Loss: 0.9995 | Val Loss: 0.8970\n",
      "Epoch 02 | Train Loss: 0.8746 | Val Loss: 0.8851\n",
      "Epoch 03 | Train Loss: 0.8805 | Val Loss: 0.8725\n",
      "Epoch 04 | Train Loss: 0.8671 | Val Loss: 0.8612\n",
      "Epoch 05 | Train Loss: 0.8556 | Val Loss: 0.8561\n",
      "Epoch 06 | Train Loss: 0.8707 | Val Loss: 0.8550\n",
      "Epoch 07 | Train Loss: 0.8637 | Val Loss: 0.8473\n",
      "Epoch 08 | Train Loss: 0.8547 | Val Loss: 0.8425\n",
      "Epoch 09 | Train Loss: 0.8440 | Val Loss: 0.8449\n",
      "Epoch 10 | Train Loss: 0.8498 | Val Loss: 0.8287\n",
      "Epoch 11 | Train Loss: 0.8430 | Val Loss: 0.8331\n",
      "Epoch 12 | Train Loss: 0.8344 | Val Loss: 0.8178\n",
      "Epoch 13 | Train Loss: 0.8207 | Val Loss: 0.8171\n",
      "Epoch 14 | Train Loss: 0.8232 | Val Loss: 0.8135\n",
      "Epoch 15 | Train Loss: 0.8029 | Val Loss: 0.8099\n",
      "Epoch 16 | Train Loss: 0.7920 | Val Loss: 0.8056\n",
      "Epoch 17 | Train Loss: 0.8148 | Val Loss: 0.8098\n",
      "Epoch 18 | Train Loss: 0.7809 | Val Loss: 0.8024\n",
      "Epoch 19 | Train Loss: 0.7759 | Val Loss: 0.8234\n",
      "Epoch 20 | Train Loss: 0.7746 | Val Loss: 0.8174\n",
      "Epoch 21 | Train Loss: 0.7877 | Val Loss: 0.8026\n",
      "Epoch 22 | Train Loss: 0.7591 | Val Loss: 0.8432\n",
      "Epoch 23 | Train Loss: 0.7734 | Val Loss: 0.8139\n",
      "Epoch 24 | Train Loss: 0.7736 | Val Loss: 0.8391\n",
      "Epoch 25 | Train Loss: 0.7744 | Val Loss: 0.8066\n",
      "Epoch 26 | Train Loss: 0.7627 | Val Loss: 0.8395\n",
      "Epoch 27 | Train Loss: 0.7903 | Val Loss: 0.8053\n",
      "Epoch 28 | Train Loss: 0.7621 | Val Loss: 0.8073\n",
      "Epoch 29 | Train Loss: 0.7629 | Val Loss: 0.8213\n",
      "Epoch 30 | Train Loss: 0.7458 | Val Loss: 0.8109\n",
      "Epoch 31 | Train Loss: 0.7329 | Val Loss: 0.8127\n",
      "Epoch 32 | Train Loss: 0.7517 | Val Loss: 0.8141\n",
      "Epoch 33 | Train Loss: 0.7319 | Val Loss: 0.8144\n",
      "Epoch 34 | Train Loss: 0.7428 | Val Loss: 0.8141\n",
      "Epoch 35 | Train Loss: 0.7399 | Val Loss: 0.8142\n",
      "Epoch 36 | Train Loss: 0.7176 | Val Loss: 0.8274\n",
      "Epoch 37 | Train Loss: 0.7456 | Val Loss: 0.8180\n",
      "Epoch 38 | Train Loss: 0.7690 | Val Loss: 0.8232\n",
      "Epoch 39 | Train Loss: 0.7538 | Val Loss: 0.8168\n",
      "Epoch 40 | Train Loss: 0.7317 | Val Loss: 0.8066\n",
      "Epoch 41 | Train Loss: 0.7417 | Val Loss: 0.8094\n",
      "Epoch 42 | Train Loss: 0.7256 | Val Loss: 0.8259\n",
      "Epoch 43 | Train Loss: 0.7458 | Val Loss: 0.8188\n",
      "Epoch 44 | Train Loss: 0.7256 | Val Loss: 0.8118\n",
      "Epoch 45 | Train Loss: 0.7397 | Val Loss: 0.8434\n",
      "Epoch 46 | Train Loss: 0.7350 | Val Loss: 0.8084\n",
      "Epoch 47 | Train Loss: 0.7516 | Val Loss: 0.8163\n",
      "Epoch 48 | Train Loss: 0.7168 | Val Loss: 0.8102\n",
      "Epoch 49 | Train Loss: 0.7092 | Val Loss: 0.8154\n",
      "Epoch 50 | Train Loss: 0.7166 | Val Loss: 0.8269\n",
      "Fold 8 ‚ñ∂ AUC: 0.693, Balanced Acc: 0.398\n",
      "\n",
      "‚ñ∂Ô∏è Fold 9/10\n",
      "Epoch 01 | Train Loss: 0.9634 | Val Loss: 0.8825\n",
      "Epoch 02 | Train Loss: 0.8738 | Val Loss: 0.8671\n",
      "Epoch 03 | Train Loss: 0.8652 | Val Loss: 0.8695\n",
      "Epoch 04 | Train Loss: 0.8591 | Val Loss: 0.8651\n",
      "Epoch 05 | Train Loss: 0.8801 | Val Loss: 0.8580\n",
      "Epoch 06 | Train Loss: 0.8548 | Val Loss: 0.8542\n",
      "Epoch 07 | Train Loss: 0.8596 | Val Loss: 0.8711\n",
      "Epoch 08 | Train Loss: 0.8497 | Val Loss: 0.8499\n",
      "Epoch 09 | Train Loss: 0.8328 | Val Loss: 0.8439\n",
      "Epoch 10 | Train Loss: 0.8218 | Val Loss: 0.8524\n",
      "Epoch 11 | Train Loss: 0.8213 | Val Loss: 0.8466\n",
      "Epoch 12 | Train Loss: 0.8222 | Val Loss: 0.8377\n",
      "Epoch 13 | Train Loss: 0.8165 | Val Loss: 0.8316\n",
      "Epoch 14 | Train Loss: 0.8011 | Val Loss: 0.8330\n",
      "Epoch 15 | Train Loss: 0.8041 | Val Loss: 0.8280\n",
      "Epoch 16 | Train Loss: 0.7747 | Val Loss: 0.8242\n",
      "Epoch 17 | Train Loss: 0.7901 | Val Loss: 0.8313\n",
      "Epoch 18 | Train Loss: 0.7748 | Val Loss: 0.8586\n",
      "Epoch 19 | Train Loss: 0.7786 | Val Loss: 0.8232\n",
      "Epoch 20 | Train Loss: 0.7838 | Val Loss: 0.8203\n",
      "Epoch 21 | Train Loss: 0.7604 | Val Loss: 0.8315\n",
      "Epoch 22 | Train Loss: 0.7537 | Val Loss: 0.8193\n",
      "Epoch 23 | Train Loss: 0.7670 | Val Loss: 0.8177\n",
      "Epoch 24 | Train Loss: 0.7466 | Val Loss: 0.8478\n",
      "Epoch 25 | Train Loss: 0.7608 | Val Loss: 0.8378\n",
      "Epoch 26 | Train Loss: 0.7869 | Val Loss: 0.8957\n",
      "Epoch 27 | Train Loss: 0.7815 | Val Loss: 0.8248\n",
      "Epoch 28 | Train Loss: 0.7702 | Val Loss: 0.8062\n",
      "Epoch 29 | Train Loss: 0.7562 | Val Loss: 0.8055\n",
      "Epoch 30 | Train Loss: 0.7466 | Val Loss: 0.7991\n",
      "Epoch 31 | Train Loss: 0.7593 | Val Loss: 0.8174\n",
      "Epoch 32 | Train Loss: 0.7568 | Val Loss: 0.8034\n",
      "Epoch 33 | Train Loss: 0.7427 | Val Loss: 0.7988\n",
      "Epoch 34 | Train Loss: 0.7454 | Val Loss: 0.7911\n",
      "Epoch 35 | Train Loss: 0.7262 | Val Loss: 0.7946\n",
      "Epoch 36 | Train Loss: 0.7272 | Val Loss: 0.8351\n",
      "Epoch 37 | Train Loss: 0.7431 | Val Loss: 0.8002\n",
      "Epoch 38 | Train Loss: 0.7325 | Val Loss: 0.8107\n",
      "Epoch 39 | Train Loss: 0.7566 | Val Loss: 0.7934\n",
      "Epoch 40 | Train Loss: 0.7585 | Val Loss: 0.7975\n",
      "Epoch 41 | Train Loss: 0.7487 | Val Loss: 0.7852\n",
      "Epoch 42 | Train Loss: 0.7355 | Val Loss: 0.7911\n",
      "Epoch 43 | Train Loss: 0.7532 | Val Loss: 0.8008\n",
      "Epoch 44 | Train Loss: 0.7527 | Val Loss: 0.7801\n",
      "Epoch 45 | Train Loss: 0.7383 | Val Loss: 0.7768\n",
      "Epoch 46 | Train Loss: 0.7297 | Val Loss: 0.7757\n",
      "Epoch 47 | Train Loss: 0.7310 | Val Loss: 0.7921\n",
      "Epoch 48 | Train Loss: 0.7402 | Val Loss: 0.7900\n",
      "Epoch 49 | Train Loss: 0.7217 | Val Loss: 0.7832\n",
      "Epoch 50 | Train Loss: 0.7279 | Val Loss: 0.7770\n",
      "Fold 9 ‚ñ∂ AUC: 0.726, Balanced Acc: 0.486\n",
      "\n",
      "‚ñ∂Ô∏è Fold 10/10\n",
      "Epoch 01 | Train Loss: 0.9503 | Val Loss: 0.9046\n",
      "Epoch 02 | Train Loss: 0.8802 | Val Loss: 0.8666\n",
      "Epoch 03 | Train Loss: 0.8642 | Val Loss: 0.8601\n",
      "Epoch 04 | Train Loss: 0.8539 | Val Loss: 0.8514\n",
      "Epoch 05 | Train Loss: 0.8584 | Val Loss: 0.8488\n",
      "Epoch 06 | Train Loss: 0.8452 | Val Loss: 0.8420\n",
      "Epoch 07 | Train Loss: 0.8436 | Val Loss: 0.8394\n",
      "Epoch 08 | Train Loss: 0.8469 | Val Loss: 0.8402\n",
      "Epoch 09 | Train Loss: 0.8333 | Val Loss: 0.8274\n",
      "Epoch 10 | Train Loss: 0.8371 | Val Loss: 0.8167\n",
      "Epoch 11 | Train Loss: 0.8215 | Val Loss: 0.8177\n",
      "Epoch 12 | Train Loss: 0.8122 | Val Loss: 0.8079\n",
      "Epoch 13 | Train Loss: 0.7979 | Val Loss: 0.7993\n",
      "Epoch 14 | Train Loss: 0.8166 | Val Loss: 0.7890\n",
      "Epoch 15 | Train Loss: 0.8113 | Val Loss: 0.7916\n",
      "Epoch 16 | Train Loss: 0.8085 | Val Loss: 0.7859\n",
      "Epoch 17 | Train Loss: 0.7848 | Val Loss: 0.7953\n",
      "Epoch 18 | Train Loss: 0.8142 | Val Loss: 0.7774\n",
      "Epoch 19 | Train Loss: 0.7894 | Val Loss: 0.7938\n",
      "Epoch 20 | Train Loss: 0.8121 | Val Loss: 0.8443\n",
      "Epoch 21 | Train Loss: 0.8093 | Val Loss: 0.7746\n",
      "Epoch 22 | Train Loss: 0.7994 | Val Loss: 0.7789\n",
      "Epoch 23 | Train Loss: 0.7964 | Val Loss: 0.7746\n",
      "Epoch 24 | Train Loss: 0.7833 | Val Loss: 0.7843\n",
      "Epoch 25 | Train Loss: 0.7627 | Val Loss: 0.7703\n",
      "Epoch 26 | Train Loss: 0.7475 | Val Loss: 0.7619\n",
      "Epoch 27 | Train Loss: 0.7743 | Val Loss: 0.7665\n",
      "Epoch 28 | Train Loss: 0.7744 | Val Loss: 0.7598\n",
      "Epoch 29 | Train Loss: 0.7591 | Val Loss: 0.7738\n",
      "Epoch 30 | Train Loss: 0.7622 | Val Loss: 0.7628\n",
      "Epoch 31 | Train Loss: 0.7414 | Val Loss: 0.7668\n",
      "Epoch 32 | Train Loss: 0.7483 | Val Loss: 0.7588\n",
      "Epoch 33 | Train Loss: 0.7586 | Val Loss: 0.7638\n",
      "Epoch 34 | Train Loss: 0.7483 | Val Loss: 0.7648\n",
      "Epoch 35 | Train Loss: 0.7378 | Val Loss: 0.7559\n",
      "Epoch 36 | Train Loss: 0.7365 | Val Loss: 0.7551\n",
      "Epoch 37 | Train Loss: 0.7579 | Val Loss: 0.8435\n",
      "Epoch 38 | Train Loss: 0.7499 | Val Loss: 0.7539\n",
      "Epoch 39 | Train Loss: 0.7629 | Val Loss: 0.7537\n",
      "Epoch 40 | Train Loss: 0.7517 | Val Loss: 0.7929\n",
      "Epoch 41 | Train Loss: 0.7390 | Val Loss: 0.7705\n",
      "Epoch 42 | Train Loss: 0.7196 | Val Loss: 0.7742\n",
      "Epoch 43 | Train Loss: 0.7346 | Val Loss: 0.7549\n",
      "Epoch 44 | Train Loss: 0.7316 | Val Loss: 0.8082\n",
      "Epoch 45 | Train Loss: 0.7270 | Val Loss: 0.7673\n",
      "Epoch 46 | Train Loss: 0.7368 | Val Loss: 0.7670\n",
      "Epoch 47 | Train Loss: 0.7252 | Val Loss: 0.7560\n",
      "Epoch 48 | Train Loss: 0.7544 | Val Loss: 0.7790\n",
      "Epoch 49 | Train Loss: 0.7211 | Val Loss: 0.8054\n",
      "Epoch 50 | Train Loss: 0.7446 | Val Loss: 0.7567\n",
      "Fold 10 ‚ñ∂ AUC: 0.716, Balanced Acc: 0.486\n",
      "üîç Summary for hd=256, dp=0.4, lr=0.0001 ‚Üí AUC: 0.7367¬±0.0412 | BalAcc: 0.4930¬±0.0417\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>std_auc</th>\n",
       "      <th>mean_balanced_acc</th>\n",
       "      <th>std_balanced_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.740911</td>\n",
       "      <td>0.040183</td>\n",
       "      <td>0.495892</td>\n",
       "      <td>0.031040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.741266</td>\n",
       "      <td>0.029381</td>\n",
       "      <td>0.494863</td>\n",
       "      <td>0.061726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.736698</td>\n",
       "      <td>0.041194</td>\n",
       "      <td>0.492965</td>\n",
       "      <td>0.041652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.734273</td>\n",
       "      <td>0.031274</td>\n",
       "      <td>0.489354</td>\n",
       "      <td>0.037088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.735719</td>\n",
       "      <td>0.032935</td>\n",
       "      <td>0.488238</td>\n",
       "      <td>0.034522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.744519</td>\n",
       "      <td>0.030233</td>\n",
       "      <td>0.487379</td>\n",
       "      <td>0.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.747255</td>\n",
       "      <td>0.032457</td>\n",
       "      <td>0.486776</td>\n",
       "      <td>0.039727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.741190</td>\n",
       "      <td>0.027803</td>\n",
       "      <td>0.483712</td>\n",
       "      <td>0.028075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.743077</td>\n",
       "      <td>0.037701</td>\n",
       "      <td>0.483521</td>\n",
       "      <td>0.048390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.742395</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>0.483151</td>\n",
       "      <td>0.045603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.738845</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>0.482219</td>\n",
       "      <td>0.049343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.736104</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.481959</td>\n",
       "      <td>0.047363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.740673</td>\n",
       "      <td>0.031771</td>\n",
       "      <td>0.481773</td>\n",
       "      <td>0.041116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.740508</td>\n",
       "      <td>0.031440</td>\n",
       "      <td>0.481391</td>\n",
       "      <td>0.044832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.726405</td>\n",
       "      <td>0.046838</td>\n",
       "      <td>0.481073</td>\n",
       "      <td>0.040531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.738809</td>\n",
       "      <td>0.025446</td>\n",
       "      <td>0.480287</td>\n",
       "      <td>0.040081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.734616</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>0.478990</td>\n",
       "      <td>0.039648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.744078</td>\n",
       "      <td>0.031139</td>\n",
       "      <td>0.477640</td>\n",
       "      <td>0.043663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.744854</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>0.475350</td>\n",
       "      <td>0.046297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.743757</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.474454</td>\n",
       "      <td>0.043190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.733188</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.472939</td>\n",
       "      <td>0.048838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.731037</td>\n",
       "      <td>0.041229</td>\n",
       "      <td>0.471535</td>\n",
       "      <td>0.040714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.747885</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>0.470759</td>\n",
       "      <td>0.043256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.744525</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.464322</td>\n",
       "      <td>0.042747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.718716</td>\n",
       "      <td>0.064865</td>\n",
       "      <td>0.446225</td>\n",
       "      <td>0.029829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.706759</td>\n",
       "      <td>0.048682</td>\n",
       "      <td>0.439937</td>\n",
       "      <td>0.041025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.731189</td>\n",
       "      <td>0.056731</td>\n",
       "      <td>0.431267</td>\n",
       "      <td>0.043335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_dim  dropout      lr  mean_auc   std_auc  mean_balanced_acc  \\\n",
       "0           64      0.0  0.0010  0.740911  0.040183           0.495892   \n",
       "19         256      0.0  0.0005  0.741266  0.029381           0.494863   \n",
       "26         256      0.4  0.0001  0.736698  0.041194           0.492965   \n",
       "7           64      0.4  0.0005  0.734273  0.031274           0.489354   \n",
       "13         128      0.2  0.0005  0.735719  0.032935           0.488238   \n",
       "6           64      0.4  0.0010  0.744519  0.030233           0.487379   \n",
       "1           64      0.0  0.0005  0.747255  0.032457           0.486776   \n",
       "18         256      0.0  0.0010  0.741190  0.027803           0.483712   \n",
       "22         256      0.2  0.0005  0.743077  0.037701           0.483521   \n",
       "20         256      0.0  0.0001  0.742395  0.039246           0.483151   \n",
       "23         256      0.2  0.0001  0.738845  0.039698           0.482219   \n",
       "4           64      0.2  0.0005  0.736104  0.032720           0.481959   \n",
       "10         128      0.0  0.0005  0.740673  0.031771           0.481773   \n",
       "3           64      0.2  0.0010  0.740508  0.031440           0.481391   \n",
       "17         128      0.4  0.0001  0.726405  0.046838           0.481073   \n",
       "24         256      0.4  0.0010  0.738809  0.025446           0.480287   \n",
       "11         128      0.0  0.0001  0.734616  0.043379           0.478990   \n",
       "15         128      0.4  0.0010  0.744078  0.031139           0.477640   \n",
       "25         256      0.4  0.0005  0.744854  0.032181           0.475350   \n",
       "21         256      0.2  0.0010  0.743757  0.032268           0.474454   \n",
       "16         128      0.4  0.0005  0.733188  0.034818           0.472939   \n",
       "14         128      0.2  0.0001  0.731037  0.041229           0.471535   \n",
       "12         128      0.2  0.0010  0.747885  0.027783           0.470759   \n",
       "9          128      0.0  0.0010  0.744525  0.034469           0.464322   \n",
       "8           64      0.4  0.0001  0.718716  0.064865           0.446225   \n",
       "2           64      0.0  0.0001  0.706759  0.048682           0.439937   \n",
       "5           64      0.2  0.0001  0.731189  0.056731           0.431267   \n",
       "\n",
       "    std_balanced_acc  \n",
       "0           0.031040  \n",
       "19          0.061726  \n",
       "26          0.041652  \n",
       "7           0.037088  \n",
       "13          0.034522  \n",
       "6           0.042169  \n",
       "1           0.039727  \n",
       "18          0.028075  \n",
       "22          0.048390  \n",
       "20          0.045603  \n",
       "23          0.049343  \n",
       "4           0.047363  \n",
       "10          0.041116  \n",
       "3           0.044832  \n",
       "17          0.040531  \n",
       "24          0.040081  \n",
       "11          0.039648  \n",
       "15          0.043663  \n",
       "25          0.046297  \n",
       "21          0.043190  \n",
       "16          0.048838  \n",
       "14          0.040714  \n",
       "12          0.043256  \n",
       "9           0.042747  \n",
       "8           0.029829  \n",
       "2           0.041025  \n",
       "5           0.043335  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "hidden_dims = [64, 128, 256]\n",
    "dropouts    = [0.0, 0.2, 0.4]\n",
    "lrs         = [1e-3, 5e-4, 1e-4]\n",
    "\n",
    "results = []\n",
    "\n",
    "for hd in hidden_dims:\n",
    "    for dp in dropouts:\n",
    "        for lr in lrs:\n",
    "            print(f\"\\nüîß Config: hidden_dim={hd}, dropout={dp}, lr={lr}\")\n",
    "            auc_scores = []\n",
    "            bal_scores = []\n",
    "\n",
    "            for fold in range(10):\n",
    "                print(f\"\\n‚ñ∂Ô∏è Fold {fold+1}/10\")\n",
    "                # 1) Load data\n",
    "                train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "                val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "                tr_loader  = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                                        worker_init_fn=seed_worker, generator=generator)\n",
    "                vl_loader  = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "                # 2) Init model & optimizer\n",
    "                model = MPNN(\n",
    "                    train_data[0].x.size(1),\n",
    "                    train_data[0].edge_attr.size(1),\n",
    "                    hidden_dim=hd,\n",
    "                    output_dim=num_classes,\n",
    "                    dropout=dp\n",
    "                ).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                # 3) Train + validate each epoch\n",
    "                for epoch in range(1, 51):\n",
    "                    # --- train ---\n",
    "                    model.train()\n",
    "                    total_train_loss = 0.0\n",
    "                    for batch in tr_loader:\n",
    "                        batch = batch.to(device)\n",
    "                        optimizer.zero_grad()\n",
    "                        out = model(batch)\n",
    "                        loss = F.cross_entropy(out, batch.y.long())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_train_loss += loss.item()\n",
    "                    avg_train_loss = total_train_loss / len(tr_loader)\n",
    "\n",
    "                    # --- validate ---\n",
    "                    model.eval()\n",
    "                    preds_val, labels_val = evaluate(model, vl_loader)\n",
    "                    val_loss = F.cross_entropy(preds_val, labels_val.long()).item()\n",
    "\n",
    "                    # Print per‚Äëepoch\n",
    "                    print(f\"Epoch {epoch:02d} | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "                # 4) After 50 epochs, compute fold‚Äêlevel metrics\n",
    "                y_true  = labels_val.numpy().astype(int)\n",
    "                y_probs = F.softmax(preds_val, dim=1).cpu().numpy()\n",
    "                y_pred  = preds_val.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "                # AUC‚ÄëROC\n",
    "                auc = roc_auc_score(\n",
    "                    label_binarize(y_true, classes=np.arange(num_classes)),\n",
    "                    y_probs,\n",
    "                    multi_class='ovr'\n",
    "                )\n",
    "                auc_scores.append(auc)\n",
    "\n",
    "                # Balanced Accuracy\n",
    "                bal = balanced_accuracy_score(y_true, y_pred)\n",
    "                bal_scores.append(bal)\n",
    "\n",
    "                print(f\"Fold {fold+1} ‚ñ∂ AUC: {auc:.3f}, Balanced Acc: {bal:.3f}\")\n",
    "\n",
    "            # 5) Record mean¬±std for both metrics\n",
    "            results.append({\n",
    "                \"hidden_dim\":        hd,\n",
    "                \"dropout\":           dp,\n",
    "                \"lr\":                lr,\n",
    "                \"mean_auc\":          np.mean(auc_scores),\n",
    "                \"std_auc\":           np.std(auc_scores),\n",
    "                \"mean_balanced_acc\": np.mean(bal_scores),\n",
    "                \"std_balanced_acc\":  np.std(bal_scores),\n",
    "            })\n",
    "\n",
    "            print(\n",
    "                f\"üîç Summary for hd={hd}, dp={dp}, lr={lr} ‚Üí \"\n",
    "                f\"AUC: {np.mean(auc_scores):.4f}¬±{np.std(auc_scores):.4f} | \"\n",
    "                f\"BalAcc: {np.mean(bal_scores):.4f}¬±{np.std(bal_scores):.4f}\"\n",
    "            )\n",
    "\n",
    "# 6) Build & save the sweep DataFrame\n",
    "sweep_df = pd.DataFrame(results)\n",
    "display(sweep_df.sort_values(\"mean_balanced_acc\", ascending=False))\n",
    "sweep_df.to_csv(os.path.join(results_dir, \"sweep_results.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a388d8c",
   "metadata": {},
   "source": [
    "# Use this section to manually define the best hyperparameters based on the sweep above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47bef626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: hidden_dim=64, dropout=0.0, lr=0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the best model configuration\n",
    "#best_config = sweep_df.loc[sweep_df[\"mean_balanced_acc\"].idxmax()]\n",
    "best_hidden_dim = 64 #best_config[\"hidden_dim\"]\n",
    "best_dropout = 0.0 #best_config[\"dropout\"]\n",
    "best_lr = 0.001 #best_config[\"lr\"]\n",
    "print(f\"Best config: hidden_dim={best_hidden_dim}, dropout={best_dropout}, lr={best_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97989bc2",
   "metadata": {},
   "source": [
    "# ## Step 5a: Retrain All Folds with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8712251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Retraining Fold 1/10\n",
      "Epoch 001 | Train Loss: 0.9326 | Val Loss: 0.8690\n",
      "Epoch 002 | Train Loss: 0.8846 | Val Loss: 0.8552\n",
      "Epoch 003 | Train Loss: 0.8665 | Val Loss: 0.8470\n",
      "Epoch 004 | Train Loss: 0.8461 | Val Loss: 0.8456\n",
      "Epoch 005 | Train Loss: 0.8591 | Val Loss: 0.8276\n",
      "Epoch 006 | Train Loss: 0.8340 | Val Loss: 0.8260\n",
      "Epoch 007 | Train Loss: 0.8396 | Val Loss: 0.8117\n",
      "Epoch 008 | Train Loss: 0.8163 | Val Loss: 0.8564\n",
      "Epoch 009 | Train Loss: 0.8267 | Val Loss: 0.7733\n",
      "Epoch 010 | Train Loss: 0.7883 | Val Loss: 0.7571\n",
      "Epoch 011 | Train Loss: 0.7798 | Val Loss: 0.7439\n",
      "Epoch 012 | Train Loss: 0.7752 | Val Loss: 0.7406\n",
      "Epoch 013 | Train Loss: 0.7660 | Val Loss: 0.7453\n",
      "Epoch 014 | Train Loss: 0.7475 | Val Loss: 0.7875\n",
      "Epoch 015 | Train Loss: 0.7779 | Val Loss: 0.7261\n",
      "Epoch 016 | Train Loss: 0.7534 | Val Loss: 0.7273\n",
      "Epoch 017 | Train Loss: 0.7428 | Val Loss: 0.7179\n",
      "Epoch 018 | Train Loss: 0.7507 | Val Loss: 0.7384\n",
      "Epoch 019 | Train Loss: 0.7478 | Val Loss: 0.7189\n",
      "Epoch 020 | Train Loss: 0.7495 | Val Loss: 0.7155\n",
      "Epoch 021 | Train Loss: 0.7336 | Val Loss: 0.7012\n",
      "Epoch 022 | Train Loss: 0.7575 | Val Loss: 0.7159\n",
      "Epoch 023 | Train Loss: 0.7517 | Val Loss: 0.7560\n",
      "Epoch 024 | Train Loss: 0.7808 | Val Loss: 0.7108\n",
      "Epoch 025 | Train Loss: 0.7589 | Val Loss: 0.7108\n",
      "Epoch 026 | Train Loss: 0.7406 | Val Loss: 0.6988\n",
      "Epoch 027 | Train Loss: 0.7672 | Val Loss: 0.7067\n",
      "Epoch 028 | Train Loss: 0.7460 | Val Loss: 0.6965\n",
      "Epoch 029 | Train Loss: 0.7491 | Val Loss: 0.7089\n",
      "Epoch 030 | Train Loss: 0.7163 | Val Loss: 0.6956\n",
      "Epoch 031 | Train Loss: 0.7310 | Val Loss: 0.6973\n",
      "Epoch 032 | Train Loss: 0.7261 | Val Loss: 0.6988\n",
      "Epoch 033 | Train Loss: 0.7366 | Val Loss: 0.6949\n",
      "Epoch 034 | Train Loss: 0.7277 | Val Loss: 0.7153\n",
      "Epoch 035 | Train Loss: 0.7277 | Val Loss: 0.6955\n",
      "Epoch 036 | Train Loss: 0.7291 | Val Loss: 0.6952\n",
      "Epoch 037 | Train Loss: 0.7301 | Val Loss: 0.6952\n",
      "Epoch 038 | Train Loss: 0.7143 | Val Loss: 0.7036\n",
      "Epoch 039 | Train Loss: 0.7324 | Val Loss: 0.6938\n",
      "Epoch 040 | Train Loss: 0.7179 | Val Loss: 0.7007\n",
      "Epoch 041 | Train Loss: 0.7281 | Val Loss: 0.6939\n",
      "Epoch 042 | Train Loss: 0.7080 | Val Loss: 0.7008\n",
      "Epoch 043 | Train Loss: 0.7038 | Val Loss: 0.7097\n",
      "Epoch 044 | Train Loss: 0.7154 | Val Loss: 0.7160\n",
      "Epoch 045 | Train Loss: 0.7138 | Val Loss: 0.7037\n",
      "Epoch 046 | Train Loss: 0.7116 | Val Loss: 0.7109\n",
      "Epoch 047 | Train Loss: 0.7026 | Val Loss: 0.7095\n",
      "Epoch 048 | Train Loss: 0.7216 | Val Loss: 0.7057\n",
      "Epoch 049 | Train Loss: 0.7231 | Val Loss: 0.7017\n",
      "Best val loss: 0.6938 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9149 | Val Loss: 0.8663\n",
      "Epoch 002 | Train Loss: 0.8858 | Val Loss: 0.8658\n",
      "Epoch 003 | Train Loss: 0.8741 | Val Loss: 0.8587\n",
      "Epoch 004 | Train Loss: 0.8569 | Val Loss: 0.8720\n",
      "Epoch 005 | Train Loss: 0.8742 | Val Loss: 0.8525\n",
      "Epoch 006 | Train Loss: 0.8757 | Val Loss: 0.8368\n",
      "Epoch 007 | Train Loss: 0.8515 | Val Loss: 0.8492\n",
      "Epoch 008 | Train Loss: 0.8418 | Val Loss: 0.8535\n",
      "Epoch 009 | Train Loss: 0.8428 | Val Loss: 0.7936\n",
      "Epoch 010 | Train Loss: 0.8474 | Val Loss: 0.7919\n",
      "Epoch 011 | Train Loss: 0.8167 | Val Loss: 0.7722\n",
      "Epoch 012 | Train Loss: 0.8058 | Val Loss: 0.7391\n",
      "Epoch 013 | Train Loss: 0.8154 | Val Loss: 0.7498\n",
      "Epoch 014 | Train Loss: 0.8093 | Val Loss: 0.8016\n",
      "Epoch 015 | Train Loss: 0.7640 | Val Loss: 0.7482\n",
      "Epoch 016 | Train Loss: 0.7418 | Val Loss: 0.7299\n",
      "Epoch 017 | Train Loss: 0.7392 | Val Loss: 0.7027\n",
      "Epoch 018 | Train Loss: 0.7598 | Val Loss: 0.7088\n",
      "Epoch 019 | Train Loss: 0.7459 | Val Loss: 0.6986\n",
      "Epoch 020 | Train Loss: 0.7570 | Val Loss: 0.7256\n",
      "Epoch 021 | Train Loss: 0.7267 | Val Loss: 0.7214\n",
      "Epoch 022 | Train Loss: 0.7569 | Val Loss: 0.7242\n",
      "Epoch 023 | Train Loss: 0.7346 | Val Loss: 0.6996\n",
      "Epoch 024 | Train Loss: 0.7501 | Val Loss: 0.7004\n",
      "Epoch 025 | Train Loss: 0.7162 | Val Loss: 0.7262\n",
      "Epoch 026 | Train Loss: 0.7332 | Val Loss: 0.6885\n",
      "Epoch 027 | Train Loss: 0.7298 | Val Loss: 0.7262\n",
      "Epoch 028 | Train Loss: 0.7497 | Val Loss: 0.7090\n",
      "Epoch 029 | Train Loss: 0.7340 | Val Loss: 0.7602\n",
      "Epoch 030 | Train Loss: 0.7240 | Val Loss: 0.7136\n",
      "Epoch 031 | Train Loss: 0.7315 | Val Loss: 0.7075\n",
      "Epoch 032 | Train Loss: 0.7062 | Val Loss: 0.7221\n",
      "Epoch 033 | Train Loss: 0.7362 | Val Loss: 0.6860\n",
      "Epoch 034 | Train Loss: 0.7410 | Val Loss: 0.6895\n",
      "Epoch 035 | Train Loss: 0.7159 | Val Loss: 0.7074\n",
      "Epoch 036 | Train Loss: 0.7067 | Val Loss: 0.6879\n",
      "Epoch 037 | Train Loss: 0.7290 | Val Loss: 0.6843\n",
      "Epoch 038 | Train Loss: 0.7142 | Val Loss: 0.7042\n",
      "Epoch 039 | Train Loss: 0.7313 | Val Loss: 0.6918\n",
      "Epoch 040 | Train Loss: 0.7284 | Val Loss: 0.7010\n",
      "Epoch 041 | Train Loss: 0.7148 | Val Loss: 0.6927\n",
      "Epoch 042 | Train Loss: 0.7249 | Val Loss: 0.7011\n",
      "Epoch 043 | Train Loss: 0.7407 | Val Loss: 0.7454\n",
      "Epoch 044 | Train Loss: 0.7289 | Val Loss: 0.7510\n",
      "Epoch 045 | Train Loss: 0.7026 | Val Loss: 0.7150\n",
      "Epoch 046 | Train Loss: 0.7067 | Val Loss: 0.7799\n",
      "Epoch 047 | Train Loss: 0.6983 | Val Loss: 0.7029\n",
      "Best val loss: 0.6843 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9320 | Val Loss: 0.8718\n",
      "Epoch 002 | Train Loss: 0.9034 | Val Loss: 0.8749\n",
      "Epoch 003 | Train Loss: 0.8725 | Val Loss: 0.8479\n",
      "Epoch 004 | Train Loss: 0.8751 | Val Loss: 0.8512\n",
      "Epoch 005 | Train Loss: 0.8527 | Val Loss: 0.8396\n",
      "Epoch 006 | Train Loss: 0.8482 | Val Loss: 0.8294\n",
      "Epoch 007 | Train Loss: 0.8681 | Val Loss: 0.8233\n",
      "Epoch 008 | Train Loss: 0.8432 | Val Loss: 0.8106\n",
      "Epoch 009 | Train Loss: 0.8231 | Val Loss: 0.7870\n",
      "Epoch 010 | Train Loss: 0.7943 | Val Loss: 0.7732\n",
      "Epoch 011 | Train Loss: 0.7969 | Val Loss: 0.7792\n",
      "Epoch 012 | Train Loss: 0.7862 | Val Loss: 0.7559\n",
      "Epoch 013 | Train Loss: 0.7909 | Val Loss: 0.7723\n",
      "Epoch 014 | Train Loss: 0.7485 | Val Loss: 0.7592\n",
      "Epoch 015 | Train Loss: 0.7814 | Val Loss: 0.7489\n",
      "Epoch 016 | Train Loss: 0.7686 | Val Loss: 0.7489\n",
      "Epoch 017 | Train Loss: 0.7852 | Val Loss: 0.8365\n",
      "Epoch 018 | Train Loss: 0.7470 | Val Loss: 0.7407\n",
      "Epoch 019 | Train Loss: 0.7504 | Val Loss: 0.7380\n",
      "Epoch 020 | Train Loss: 0.7691 | Val Loss: 0.7497\n",
      "Epoch 021 | Train Loss: 0.7376 | Val Loss: 0.7719\n",
      "Epoch 022 | Train Loss: 0.7363 | Val Loss: 0.7361\n",
      "Epoch 023 | Train Loss: 0.7270 | Val Loss: 0.7313\n",
      "Epoch 024 | Train Loss: 0.7386 | Val Loss: 0.7697\n",
      "Epoch 025 | Train Loss: 0.7394 | Val Loss: 0.7279\n",
      "Epoch 026 | Train Loss: 0.7216 | Val Loss: 0.7248\n",
      "Epoch 027 | Train Loss: 0.7452 | Val Loss: 0.7202\n",
      "Epoch 028 | Train Loss: 0.7219 | Val Loss: 0.7265\n",
      "Epoch 029 | Train Loss: 0.7152 | Val Loss: 0.7201\n",
      "Epoch 030 | Train Loss: 0.7207 | Val Loss: 0.7300\n",
      "Epoch 031 | Train Loss: 0.7114 | Val Loss: 0.7179\n",
      "Epoch 032 | Train Loss: 0.7185 | Val Loss: 0.7583\n",
      "Epoch 033 | Train Loss: 0.7424 | Val Loss: 0.7258\n",
      "Epoch 034 | Train Loss: 0.7165 | Val Loss: 0.7197\n",
      "Epoch 035 | Train Loss: 0.7205 | Val Loss: 0.7181\n",
      "Epoch 036 | Train Loss: 0.7236 | Val Loss: 0.7397\n",
      "Epoch 037 | Train Loss: 0.7280 | Val Loss: 0.7394\n",
      "Epoch 038 | Train Loss: 0.7374 | Val Loss: 0.7780\n",
      "Epoch 039 | Train Loss: 0.7369 | Val Loss: 0.7186\n",
      "Epoch 040 | Train Loss: 0.7109 | Val Loss: 0.7144\n",
      "Epoch 041 | Train Loss: 0.7187 | Val Loss: 0.7159\n",
      "Epoch 042 | Train Loss: 0.7009 | Val Loss: 0.7165\n",
      "Epoch 043 | Train Loss: 0.7185 | Val Loss: 0.7290\n",
      "Epoch 044 | Train Loss: 0.7197 | Val Loss: 0.7202\n",
      "Epoch 045 | Train Loss: 0.7198 | Val Loss: 0.7140\n",
      "Epoch 046 | Train Loss: 0.7278 | Val Loss: 0.7176\n",
      "Epoch 047 | Train Loss: 0.7134 | Val Loss: 0.7360\n",
      "Epoch 048 | Train Loss: 0.7157 | Val Loss: 0.7292\n",
      "Epoch 049 | Train Loss: 0.7124 | Val Loss: 0.7177\n",
      "Epoch 050 | Train Loss: 0.7044 | Val Loss: 0.7328\n",
      "Epoch 051 | Train Loss: 0.7109 | Val Loss: 0.7149\n",
      "Epoch 052 | Train Loss: 0.7078 | Val Loss: 0.7196\n",
      "Epoch 053 | Train Loss: 0.7543 | Val Loss: 0.7139\n",
      "Epoch 054 | Train Loss: 0.7098 | Val Loss: 0.7508\n",
      "Epoch 055 | Train Loss: 0.7326 | Val Loss: 0.7315\n",
      "Epoch 056 | Train Loss: 0.7020 | Val Loss: 0.7184\n",
      "Epoch 057 | Train Loss: 0.7300 | Val Loss: 0.7480\n",
      "Epoch 058 | Train Loss: 0.7264 | Val Loss: 0.7254\n",
      "Epoch 059 | Train Loss: 0.6936 | Val Loss: 0.7201\n",
      "Epoch 060 | Train Loss: 0.6936 | Val Loss: 0.7092\n",
      "Epoch 061 | Train Loss: 0.7019 | Val Loss: 0.7148\n",
      "Epoch 062 | Train Loss: 0.7194 | Val Loss: 0.7324\n",
      "Epoch 063 | Train Loss: 0.6873 | Val Loss: 0.7060\n",
      "Epoch 064 | Train Loss: 0.6978 | Val Loss: 0.7060\n",
      "Epoch 065 | Train Loss: 0.7041 | Val Loss: 0.7116\n",
      "Epoch 066 | Train Loss: 0.7168 | Val Loss: 0.7456\n",
      "Epoch 067 | Train Loss: 0.7320 | Val Loss: 0.7399\n",
      "Epoch 068 | Train Loss: 0.7044 | Val Loss: 0.7107\n",
      "Epoch 069 | Train Loss: 0.7159 | Val Loss: 0.7284\n",
      "Epoch 070 | Train Loss: 0.7018 | Val Loss: 0.7466\n",
      "Epoch 071 | Train Loss: 0.7294 | Val Loss: 0.7163\n",
      "Epoch 072 | Train Loss: 0.7012 | Val Loss: 0.7031\n",
      "Epoch 073 | Train Loss: 0.6840 | Val Loss: 0.7507\n",
      "Epoch 074 | Train Loss: 0.7157 | Val Loss: 0.7200\n",
      "Epoch 075 | Train Loss: 0.7232 | Val Loss: 0.7067\n",
      "Epoch 076 | Train Loss: 0.6882 | Val Loss: 0.7449\n",
      "Epoch 077 | Train Loss: 0.6929 | Val Loss: 0.7075\n",
      "Epoch 078 | Train Loss: 0.6879 | Val Loss: 0.7111\n",
      "Epoch 079 | Train Loss: 0.6879 | Val Loss: 0.7069\n",
      "Epoch 080 | Train Loss: 0.6836 | Val Loss: 0.6941\n",
      "Epoch 081 | Train Loss: 0.6844 | Val Loss: 0.6963\n",
      "Epoch 082 | Train Loss: 0.6599 | Val Loss: 0.7130\n",
      "Epoch 083 | Train Loss: 0.6786 | Val Loss: 0.7001\n",
      "Epoch 084 | Train Loss: 0.6967 | Val Loss: 0.7383\n",
      "Epoch 085 | Train Loss: 0.6932 | Val Loss: 0.7041\n",
      "Epoch 086 | Train Loss: 0.7006 | Val Loss: 0.6922\n",
      "Epoch 087 | Train Loss: 0.6656 | Val Loss: 0.7053\n",
      "Epoch 088 | Train Loss: 0.6789 | Val Loss: 0.7477\n",
      "Epoch 089 | Train Loss: 0.6639 | Val Loss: 0.6869\n",
      "Epoch 090 | Train Loss: 0.6745 | Val Loss: 0.6987\n",
      "Epoch 091 | Train Loss: 0.6587 | Val Loss: 0.6923\n",
      "Epoch 092 | Train Loss: 0.6572 | Val Loss: 0.6915\n",
      "Epoch 093 | Train Loss: 0.6591 | Val Loss: 0.7048\n",
      "Epoch 094 | Train Loss: 0.6880 | Val Loss: 0.6778\n",
      "Epoch 095 | Train Loss: 0.6795 | Val Loss: 0.6927\n",
      "Epoch 096 | Train Loss: 0.6813 | Val Loss: 0.6870\n",
      "Epoch 097 | Train Loss: 0.6683 | Val Loss: 0.6909\n",
      "Epoch 098 | Train Loss: 0.6712 | Val Loss: 0.6960\n",
      "Epoch 099 | Train Loss: 0.6559 | Val Loss: 0.6888\n",
      "Epoch 100 | Train Loss: 0.6618 | Val Loss: 0.6799\n",
      "Best val loss: 0.6778 | Early stopping patience: 6\n",
      "\n",
      "üîÅ Retraining Fold 4/10\n",
      "Epoch 001 | Train Loss: 0.9388 | Val Loss: 0.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Train Loss: 0.8874 | Val Loss: 0.8571\n",
      "Epoch 003 | Train Loss: 0.8666 | Val Loss: 0.8521\n",
      "Epoch 004 | Train Loss: 0.8676 | Val Loss: 0.8418\n",
      "Epoch 005 | Train Loss: 0.8756 | Val Loss: 0.8399\n",
      "Epoch 006 | Train Loss: 0.8661 | Val Loss: 0.8392\n",
      "Epoch 007 | Train Loss: 0.8483 | Val Loss: 0.8272\n",
      "Epoch 008 | Train Loss: 0.8347 | Val Loss: 0.8050\n",
      "Epoch 009 | Train Loss: 0.8243 | Val Loss: 0.7909\n",
      "Epoch 010 | Train Loss: 0.8192 | Val Loss: 0.7684\n",
      "Epoch 011 | Train Loss: 0.7974 | Val Loss: 0.7515\n",
      "Epoch 012 | Train Loss: 0.8106 | Val Loss: 0.7289\n",
      "Epoch 013 | Train Loss: 0.8006 | Val Loss: 0.7347\n",
      "Epoch 014 | Train Loss: 0.7729 | Val Loss: 0.7186\n",
      "Epoch 015 | Train Loss: 0.7642 | Val Loss: 0.7069\n",
      "Epoch 016 | Train Loss: 0.7677 | Val Loss: 0.7624\n",
      "Epoch 017 | Train Loss: 0.7577 | Val Loss: 0.7081\n",
      "Epoch 018 | Train Loss: 0.7455 | Val Loss: 0.6853\n",
      "Epoch 019 | Train Loss: 0.7509 | Val Loss: 0.7073\n",
      "Epoch 020 | Train Loss: 0.7519 | Val Loss: 0.6771\n",
      "Epoch 021 | Train Loss: 0.7447 | Val Loss: 0.6968\n",
      "Epoch 022 | Train Loss: 0.7612 | Val Loss: 0.6925\n",
      "Epoch 023 | Train Loss: 0.7372 | Val Loss: 0.6722\n",
      "Epoch 024 | Train Loss: 0.7294 | Val Loss: 0.6760\n",
      "Epoch 025 | Train Loss: 0.7339 | Val Loss: 0.6778\n",
      "Epoch 026 | Train Loss: 0.7413 | Val Loss: 0.6711\n",
      "Epoch 027 | Train Loss: 0.7533 | Val Loss: 0.6733\n",
      "Epoch 028 | Train Loss: 0.7551 | Val Loss: 0.6768\n",
      "Epoch 029 | Train Loss: 0.7177 | Val Loss: 0.6637\n",
      "Epoch 030 | Train Loss: 0.7255 | Val Loss: 0.6652\n",
      "Epoch 031 | Train Loss: 0.7213 | Val Loss: 0.6704\n",
      "Epoch 032 | Train Loss: 0.7342 | Val Loss: 0.6658\n",
      "Epoch 033 | Train Loss: 0.7230 | Val Loss: 0.6722\n",
      "Epoch 034 | Train Loss: 0.7415 | Val Loss: 0.6686\n",
      "Epoch 035 | Train Loss: 0.7275 | Val Loss: 0.6730\n",
      "Epoch 036 | Train Loss: 0.7115 | Val Loss: 0.6782\n",
      "Epoch 037 | Train Loss: 0.7304 | Val Loss: 0.6839\n",
      "Epoch 038 | Train Loss: 0.7310 | Val Loss: 0.6705\n",
      "Epoch 039 | Train Loss: 0.7199 | Val Loss: 0.6986\n",
      "Best val loss: 0.6637 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9310 | Val Loss: 0.8985\n",
      "Epoch 002 | Train Loss: 0.8771 | Val Loss: 0.8919\n",
      "Epoch 003 | Train Loss: 0.8614 | Val Loss: 0.8819\n",
      "Epoch 004 | Train Loss: 0.8419 | Val Loss: 0.8801\n",
      "Epoch 005 | Train Loss: 0.8494 | Val Loss: 0.8779\n",
      "Epoch 006 | Train Loss: 0.8202 | Val Loss: 0.8453\n",
      "Epoch 007 | Train Loss: 0.8208 | Val Loss: 0.9116\n",
      "Epoch 008 | Train Loss: 0.8153 | Val Loss: 0.8272\n",
      "Epoch 009 | Train Loss: 0.7861 | Val Loss: 0.8318\n",
      "Epoch 010 | Train Loss: 0.7612 | Val Loss: 0.8179\n",
      "Epoch 011 | Train Loss: 0.7573 | Val Loss: 0.8201\n",
      "Epoch 012 | Train Loss: 0.7749 | Val Loss: 0.8533\n",
      "Epoch 013 | Train Loss: 0.7692 | Val Loss: 0.8325\n",
      "Epoch 014 | Train Loss: 0.7658 | Val Loss: 0.8626\n",
      "Epoch 015 | Train Loss: 0.7643 | Val Loss: 0.8386\n",
      "Epoch 016 | Train Loss: 0.7483 | Val Loss: 0.8257\n",
      "Epoch 017 | Train Loss: 0.7240 | Val Loss: 0.8324\n",
      "Epoch 018 | Train Loss: 0.7327 | Val Loss: 0.8230\n",
      "Epoch 019 | Train Loss: 0.7483 | Val Loss: 0.8199\n",
      "Epoch 020 | Train Loss: 0.7277 | Val Loss: 0.8191\n",
      "Best val loss: 0.8179 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9120 | Val Loss: 0.9271\n",
      "Epoch 002 | Train Loss: 0.8893 | Val Loss: 0.8921\n",
      "Epoch 003 | Train Loss: 0.8746 | Val Loss: 0.8851\n",
      "Epoch 004 | Train Loss: 0.8512 | Val Loss: 0.8775\n",
      "Epoch 005 | Train Loss: 0.8407 | Val Loss: 0.9041\n",
      "Epoch 006 | Train Loss: 0.8544 | Val Loss: 0.9065\n",
      "Epoch 007 | Train Loss: 0.8447 | Val Loss: 0.8675\n",
      "Epoch 008 | Train Loss: 0.8374 | Val Loss: 0.8576\n",
      "Epoch 009 | Train Loss: 0.7935 | Val Loss: 0.8694\n",
      "Epoch 010 | Train Loss: 0.8213 | Val Loss: 0.8395\n",
      "Epoch 011 | Train Loss: 0.7793 | Val Loss: 0.8281\n",
      "Epoch 012 | Train Loss: 0.7650 | Val Loss: 0.8465\n",
      "Epoch 013 | Train Loss: 0.7742 | Val Loss: 0.8328\n",
      "Epoch 014 | Train Loss: 0.7564 | Val Loss: 0.8366\n",
      "Epoch 015 | Train Loss: 0.7585 | Val Loss: 0.8407\n",
      "Epoch 016 | Train Loss: 0.7527 | Val Loss: 0.8351\n",
      "Epoch 017 | Train Loss: 0.7391 | Val Loss: 0.8230\n",
      "Epoch 018 | Train Loss: 0.7213 | Val Loss: 0.8275\n",
      "Epoch 019 | Train Loss: 0.7394 | Val Loss: 0.8285\n",
      "Epoch 020 | Train Loss: 0.7262 | Val Loss: 0.8166\n",
      "Epoch 021 | Train Loss: 0.7230 | Val Loss: 0.8189\n",
      "Epoch 022 | Train Loss: 0.7511 | Val Loss: 0.8229\n",
      "Epoch 023 | Train Loss: 0.7247 | Val Loss: 0.8096\n",
      "Epoch 024 | Train Loss: 0.7309 | Val Loss: 0.8321\n",
      "Epoch 025 | Train Loss: 0.7044 | Val Loss: 0.8225\n",
      "Epoch 026 | Train Loss: 0.7351 | Val Loss: 0.8187\n",
      "Epoch 027 | Train Loss: 0.7314 | Val Loss: 0.8180\n",
      "Epoch 028 | Train Loss: 0.7169 | Val Loss: 0.8191\n",
      "Epoch 029 | Train Loss: 0.7147 | Val Loss: 0.8298\n",
      "Epoch 030 | Train Loss: 0.7160 | Val Loss: 0.8338\n",
      "Epoch 031 | Train Loss: 0.7096 | Val Loss: 0.8239\n",
      "Epoch 032 | Train Loss: 0.7055 | Val Loss: 0.8153\n",
      "Epoch 033 | Train Loss: 0.7014 | Val Loss: 0.8252\n",
      "Best val loss: 0.8096 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9311 | Val Loss: 0.8828\n",
      "Epoch 002 | Train Loss: 0.8768 | Val Loss: 0.8592\n",
      "Epoch 003 | Train Loss: 0.8625 | Val Loss: 0.8523\n",
      "Epoch 004 | Train Loss: 0.8750 | Val Loss: 0.8615\n",
      "Epoch 005 | Train Loss: 0.8643 | Val Loss: 0.8376\n",
      "Epoch 006 | Train Loss: 0.8602 | Val Loss: 0.8434\n",
      "Epoch 007 | Train Loss: 0.8445 | Val Loss: 0.8230\n",
      "Epoch 008 | Train Loss: 0.8278 | Val Loss: 0.8046\n",
      "Epoch 009 | Train Loss: 0.8183 | Val Loss: 0.7770\n",
      "Epoch 010 | Train Loss: 0.8031 | Val Loss: 0.7830\n",
      "Epoch 011 | Train Loss: 0.8056 | Val Loss: 0.7477\n",
      "Epoch 012 | Train Loss: 0.7790 | Val Loss: 0.7362\n",
      "Epoch 013 | Train Loss: 0.7930 | Val Loss: 0.7819\n",
      "Epoch 014 | Train Loss: 0.8056 | Val Loss: 0.8089\n",
      "Epoch 015 | Train Loss: 0.7693 | Val Loss: 0.7408\n",
      "Epoch 016 | Train Loss: 0.7436 | Val Loss: 0.7189\n",
      "Epoch 017 | Train Loss: 0.7298 | Val Loss: 0.7289\n",
      "Epoch 018 | Train Loss: 0.7454 | Val Loss: 0.7240\n",
      "Epoch 019 | Train Loss: 0.7321 | Val Loss: 0.7188\n",
      "Epoch 020 | Train Loss: 0.7187 | Val Loss: 0.7694\n",
      "Epoch 021 | Train Loss: 0.7616 | Val Loss: 0.7369\n",
      "Epoch 022 | Train Loss: 0.7665 | Val Loss: 0.7413\n",
      "Epoch 023 | Train Loss: 0.7720 | Val Loss: 0.7788\n",
      "Epoch 024 | Train Loss: 0.7265 | Val Loss: 0.7172\n",
      "Epoch 025 | Train Loss: 0.7211 | Val Loss: 0.7133\n",
      "Epoch 026 | Train Loss: 0.7188 | Val Loss: 0.7193\n",
      "Epoch 027 | Train Loss: 0.7174 | Val Loss: 0.7211\n",
      "Epoch 028 | Train Loss: 0.7242 | Val Loss: 0.7532\n",
      "Epoch 029 | Train Loss: 0.7243 | Val Loss: 0.7511\n",
      "Epoch 030 | Train Loss: 0.7318 | Val Loss: 0.7261\n",
      "Epoch 031 | Train Loss: 0.7284 | Val Loss: 0.7460\n",
      "Epoch 032 | Train Loss: 0.7185 | Val Loss: 0.7611\n",
      "Epoch 033 | Train Loss: 0.7306 | Val Loss: 0.7330\n",
      "Epoch 034 | Train Loss: 0.7369 | Val Loss: 0.7580\n",
      "Epoch 035 | Train Loss: 0.7387 | Val Loss: 0.8298\n",
      "Best val loss: 0.7133 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9091 | Val Loss: 0.8759\n",
      "Epoch 002 | Train Loss: 0.8717 | Val Loss: 0.8547\n",
      "Epoch 003 | Train Loss: 0.8632 | Val Loss: 0.8390\n",
      "Epoch 004 | Train Loss: 0.8482 | Val Loss: 0.8368\n",
      "Epoch 005 | Train Loss: 0.8436 | Val Loss: 0.8364\n",
      "Epoch 006 | Train Loss: 0.8310 | Val Loss: 0.8079\n",
      "Epoch 007 | Train Loss: 0.8053 | Val Loss: 0.8178\n",
      "Epoch 008 | Train Loss: 0.7961 | Val Loss: 0.8070\n",
      "Epoch 009 | Train Loss: 0.7794 | Val Loss: 0.7854\n",
      "Epoch 010 | Train Loss: 0.7704 | Val Loss: 0.8031\n",
      "Epoch 011 | Train Loss: 0.7721 | Val Loss: 0.7976\n",
      "Epoch 012 | Train Loss: 0.7966 | Val Loss: 0.7931\n",
      "Epoch 013 | Train Loss: 0.7591 | Val Loss: 0.7922\n",
      "Epoch 014 | Train Loss: 0.7560 | Val Loss: 0.8379\n",
      "Epoch 015 | Train Loss: 0.7873 | Val Loss: 0.7942\n",
      "Epoch 016 | Train Loss: 0.7450 | Val Loss: 0.8021\n",
      "Epoch 017 | Train Loss: 0.7431 | Val Loss: 0.8007\n",
      "Epoch 018 | Train Loss: 0.7674 | Val Loss: 0.7947\n",
      "Epoch 019 | Train Loss: 0.7313 | Val Loss: 0.7990\n",
      "Best val loss: 0.7854 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9530 | Val Loss: 0.8849\n",
      "Epoch 002 | Train Loss: 0.8849 | Val Loss: 0.8691\n",
      "Epoch 003 | Train Loss: 0.8752 | Val Loss: 0.8650\n",
      "Epoch 004 | Train Loss: 0.8697 | Val Loss: 0.8601\n",
      "Epoch 005 | Train Loss: 0.8573 | Val Loss: 0.8639\n",
      "Epoch 006 | Train Loss: 0.8674 | Val Loss: 0.8497\n",
      "Epoch 007 | Train Loss: 0.8352 | Val Loss: 0.8452\n",
      "Epoch 008 | Train Loss: 0.8255 | Val Loss: 0.8347\n",
      "Epoch 009 | Train Loss: 0.8088 | Val Loss: 0.8216\n",
      "Epoch 010 | Train Loss: 0.7752 | Val Loss: 0.8146\n",
      "Epoch 011 | Train Loss: 0.7767 | Val Loss: 0.8277\n",
      "Epoch 012 | Train Loss: 0.7592 | Val Loss: 0.7947\n",
      "Epoch 013 | Train Loss: 0.7472 | Val Loss: 0.8112\n",
      "Epoch 014 | Train Loss: 0.7468 | Val Loss: 0.7997\n",
      "Epoch 015 | Train Loss: 0.7347 | Val Loss: 0.7879\n",
      "Epoch 016 | Train Loss: 0.7563 | Val Loss: 0.8046\n",
      "Epoch 017 | Train Loss: 0.7582 | Val Loss: 0.7961\n",
      "Epoch 018 | Train Loss: 0.7415 | Val Loss: 0.7670\n",
      "Epoch 019 | Train Loss: 0.7419 | Val Loss: 0.7700\n",
      "Epoch 020 | Train Loss: 0.7691 | Val Loss: 0.7608\n",
      "Epoch 021 | Train Loss: 0.7408 | Val Loss: 0.7595\n",
      "Epoch 022 | Train Loss: 0.7415 | Val Loss: 0.7609\n",
      "Epoch 023 | Train Loss: 0.7517 | Val Loss: 0.8173\n",
      "Epoch 024 | Train Loss: 0.7227 | Val Loss: 0.7524\n",
      "Epoch 025 | Train Loss: 0.7236 | Val Loss: 0.7522\n",
      "Epoch 026 | Train Loss: 0.7353 | Val Loss: 0.7502\n",
      "Epoch 027 | Train Loss: 0.7369 | Val Loss: 0.7751\n",
      "Epoch 028 | Train Loss: 0.7173 | Val Loss: 0.7567\n",
      "Epoch 029 | Train Loss: 0.7175 | Val Loss: 0.7599\n",
      "Epoch 030 | Train Loss: 0.7181 | Val Loss: 0.8056\n",
      "Epoch 031 | Train Loss: 0.7438 | Val Loss: 0.7528\n",
      "Epoch 032 | Train Loss: 0.7610 | Val Loss: 0.7505\n",
      "Epoch 033 | Train Loss: 0.7231 | Val Loss: 0.7552\n",
      "Epoch 034 | Train Loss: 0.7301 | Val Loss: 0.7837\n",
      "Epoch 035 | Train Loss: 0.7266 | Val Loss: 0.7447\n",
      "Epoch 036 | Train Loss: 0.7290 | Val Loss: 0.7500\n",
      "Epoch 037 | Train Loss: 0.7258 | Val Loss: 0.7433\n",
      "Epoch 038 | Train Loss: 0.7341 | Val Loss: 0.7496\n",
      "Epoch 039 | Train Loss: 0.7328 | Val Loss: 0.7657\n",
      "Epoch 040 | Train Loss: 0.7358 | Val Loss: 0.7780\n",
      "Epoch 041 | Train Loss: 0.7119 | Val Loss: 0.7417\n",
      "Epoch 042 | Train Loss: 0.7134 | Val Loss: 0.7425\n",
      "Epoch 043 | Train Loss: 0.7187 | Val Loss: 0.7920\n",
      "Epoch 044 | Train Loss: 0.6989 | Val Loss: 0.7430\n",
      "Epoch 045 | Train Loss: 0.7181 | Val Loss: 0.7474\n",
      "Epoch 046 | Train Loss: 0.7263 | Val Loss: 0.8116\n",
      "Epoch 047 | Train Loss: 0.7585 | Val Loss: 0.8121\n",
      "Epoch 048 | Train Loss: 0.7457 | Val Loss: 0.7597\n",
      "Epoch 049 | Train Loss: 0.7282 | Val Loss: 0.8553\n",
      "Epoch 050 | Train Loss: 0.7358 | Val Loss: 0.7411\n",
      "Epoch 051 | Train Loss: 0.7077 | Val Loss: 0.7461\n",
      "Epoch 052 | Train Loss: 0.7362 | Val Loss: 0.7807\n",
      "Epoch 053 | Train Loss: 0.7042 | Val Loss: 0.7416\n",
      "Epoch 054 | Train Loss: 0.7261 | Val Loss: 0.7485\n",
      "Epoch 055 | Train Loss: 0.7201 | Val Loss: 0.7537\n",
      "Epoch 056 | Train Loss: 0.7098 | Val Loss: 0.7379\n",
      "Epoch 057 | Train Loss: 0.7287 | Val Loss: 0.7791\n",
      "Epoch 058 | Train Loss: 0.7017 | Val Loss: 0.7379\n",
      "Epoch 059 | Train Loss: 0.7097 | Val Loss: 0.7429\n",
      "Epoch 060 | Train Loss: 0.7387 | Val Loss: 0.7397\n",
      "Epoch 061 | Train Loss: 0.7263 | Val Loss: 0.7431\n",
      "Epoch 062 | Train Loss: 0.7096 | Val Loss: 0.7444\n",
      "Epoch 063 | Train Loss: 0.7066 | Val Loss: 0.7525\n",
      "Epoch 064 | Train Loss: 0.7031 | Val Loss: 0.7473\n",
      "Epoch 065 | Train Loss: 0.7083 | Val Loss: 0.7601\n",
      "Epoch 066 | Train Loss: 0.7128 | Val Loss: 0.7381\n",
      "Epoch 067 | Train Loss: 0.6978 | Val Loss: 0.8047\n",
      "Epoch 068 | Train Loss: 0.7193 | Val Loss: 0.7430\n",
      "Best val loss: 0.7379 | Early stopping patience: 10\n",
      "\n",
      "üîÅ Retraining Fold 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9285 | Val Loss: 0.8751\n",
      "Epoch 002 | Train Loss: 0.8729 | Val Loss: 0.8675\n",
      "Epoch 003 | Train Loss: 0.8745 | Val Loss: 0.8636\n",
      "Epoch 004 | Train Loss: 0.8546 | Val Loss: 0.8741\n",
      "Epoch 005 | Train Loss: 0.8659 | Val Loss: 0.8552\n",
      "Epoch 006 | Train Loss: 0.8474 | Val Loss: 0.8928\n",
      "Epoch 007 | Train Loss: 0.8433 | Val Loss: 0.8470\n",
      "Epoch 008 | Train Loss: 0.8325 | Val Loss: 0.8293\n",
      "Epoch 009 | Train Loss: 0.8260 | Val Loss: 0.8102\n",
      "Epoch 010 | Train Loss: 0.7864 | Val Loss: 0.7870\n",
      "Epoch 011 | Train Loss: 0.7988 | Val Loss: 0.7759\n",
      "Epoch 012 | Train Loss: 0.7537 | Val Loss: 0.7729\n",
      "Epoch 013 | Train Loss: 0.7580 | Val Loss: 0.7637\n",
      "Epoch 014 | Train Loss: 0.7394 | Val Loss: 0.7557\n",
      "Epoch 015 | Train Loss: 0.7427 | Val Loss: 0.7569\n",
      "Epoch 016 | Train Loss: 0.7357 | Val Loss: 0.7882\n",
      "Epoch 017 | Train Loss: 0.7207 | Val Loss: 0.7921\n",
      "Epoch 018 | Train Loss: 0.7435 | Val Loss: 0.8039\n",
      "Epoch 019 | Train Loss: 0.7235 | Val Loss: 0.7612\n",
      "Epoch 020 | Train Loss: 0.7122 | Val Loss: 0.7654\n",
      "Epoch 021 | Train Loss: 0.7192 | Val Loss: 0.7754\n",
      "Epoch 022 | Train Loss: 0.7181 | Val Loss: 0.7938\n",
      "Epoch 023 | Train Loss: 0.7174 | Val Loss: 0.7890\n",
      "Epoch 024 | Train Loss: 0.7091 | Val Loss: 0.7631\n",
      "Best val loss: 0.7557 | Early stopping patience: 10\n",
      "‚úÖ Saved CV summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pandas as pd\n",
    "fold_metrics = []\n",
    "\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\nüîÅ Retraining Fold {fold+1}/10\")\n",
    "    train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "    model = MPNN(train_data[0].x.size(1),\n",
    "                 train_data[0].edge_attr.size(1),\n",
    "                 hidden_dim=best_hidden_dim,\n",
    "                 output_dim=num_classes,\n",
    "                 dropout=best_dropout).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "    tr = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                    worker_init_fn=seed_worker, generator=generator)\n",
    "    vl = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "    best_val_loss = float('inf'); patience=0\n",
    "    for epoch in range(1, 101):\n",
    "        model.train(); total=0\n",
    "        for batch in tr:\n",
    "            batch=batch.to(device); opt.zero_grad(); out=model(batch)\n",
    "            loss=F.cross_entropy(out,batch.y.long()); loss.backward(); opt.step(); total+=loss.item()\n",
    "        preds, labels = evaluate(model, vl)\n",
    "        y_true = labels.numpy().astype(int)\n",
    "        y_probs = F.softmax(preds, dim=1).numpy()\n",
    "        val_loss = F.cross_entropy(preds, labels.long()).item()\n",
    "        print(f\"Epoch {epoch:03d} | Train Loss: {total / len(tr):.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss=val_loss; patience=0\n",
    "            torch.save(model.state_dict(), os.path.join(results_dir, f\"fold{fold+1}_model.pt\"))\n",
    "        else:\n",
    "            patience+=1\n",
    "            if patience>=10: break\n",
    "    print(f\"Best val loss: {best_val_loss:.4f} | Early stopping patience: {patience}\")\n",
    "    \n",
    "\n",
    "    # Metrics\n",
    "    y_pred = preds.argmax(dim=1).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    auc = roc_auc_score(label_binarize(y_true, classes=np.arange(num_classes)), y_probs, multi_class='ovr')\n",
    "    fold_metrics.append({\"fold\":fold+1,\"accuracy\":acc,\"precision\":precision,\"recall\":recall,\"f1_score\":f1,\"auc_roc\":auc})\n",
    "\n",
    "# Save CV summary\n",
    "cv_df = pd.DataFrame(fold_metrics)\n",
    "cv_df.to_csv(os.path.join(results_dir, \"crossval_summary.csv\"), index=False)\n",
    "print(\"‚úÖ Saved CV summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63f613",
   "metadata": {},
   "source": [
    "# ## Step 6: Visualize Cross-Validation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6ce04f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "cv_df = pd.read_csv(os.path.join(results_dir, \"crossval_summary.csv\"))\n",
    "metrics = ['accuracy','precision','recall','f1_score','auc_roc']\n",
    "fig, axs = plt.subplots(1,len(metrics), figsize=(20,4))\n",
    "for i,m in enumerate(metrics):\n",
    "    axs[i].bar(cv_df['fold'], cv_df[m]); axs[i].set_title(m.upper()); axs[i].set_xlabel('Fold'); axs[i].set_ylabel(m)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9ecc1",
   "metadata": {},
   "source": [
    "# ## Step 7: Ensemble Averaging from 10 CV Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ba2fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ensemble preds saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "ess_preds=[]\n",
    "test_data=torch.load(os.path.join(base_path, f\"{task}_test.pt\"))\n",
    "tl=DataLoader(test_data, batch_size=32)\n",
    "for fold in range(10):\n",
    "    model = MPNN(test_data[0].x.size(1), test_data[0].edge_attr.size(1), hidden_dim=best_hidden_dim, output_dim=num_classes, dropout=best_dropout).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(results_dir, f\"fold{fold+1}_model.pt\")))\n",
    "    model.eval(); outs=[]\n",
    "    with torch.no_grad():\n",
    "        for b in tl: outs.append(model(b.to(device)).cpu())\n",
    "    ess_preds.append(torch.cat(outs,0))\n",
    "avg=torch.stack(ess_preds).mean(0)\n",
    "f_pred=avg.argmax(1).numpy(); t_true=torch.cat([d.y for d in test_data]).numpy().astype(int)\n",
    "pd.DataFrame({'True':t_true,'Pred':f_pred}).to_csv(os.path.join(results_dir,'ensemble_preds.csv'),index=False)\n",
    "print('‚úÖ Ensemble preds saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf71a7",
   "metadata": {},
   "source": [
    "# ## Step 7b: Ensemble Model Evaluation ‚Äì Confusion Matrix & AUC‚ÄëROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cd80310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ensemble metrics saved:\n",
      "   accuracy  precision  recall  f1_score  balanced_accuracy  auc_roc\n",
      "0    0.6981     0.6607  0.6981    0.6788             0.4866   0.8347\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- assume avg, f_pred, t_true are in scope from your ensemble cell ---\n",
    "# avg: Tensor of shape [N_samples, num_classes] (averaged logits)\n",
    "# f_pred: numpy array of hard predictions\n",
    "# t_true: numpy array of true labels\n",
    "\n",
    "# 1) Compute softmax probabilities\n",
    "y_probs = F.softmax(avg, dim=1).numpy()\n",
    "\n",
    "# 2) Compute classification metrics\n",
    "accuracy  = accuracy_score(t_true, f_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    t_true, f_pred, average=\"weighted\", zero_division=0\n",
    ")\n",
    "bal_acc   = balanced_accuracy_score(t_true, f_pred)\n",
    "\n",
    "# For multiclass AUC-ROC we need one-hot true labels\n",
    "y_true_bin = label_binarize(t_true, classes=np.arange(num_classes))\n",
    "auc_ovr   = roc_auc_score(y_true_bin, y_probs, multi_class=\"ovr\")\n",
    "\n",
    "# 3) Save metrics to CSV\n",
    "ensemble_metrics = pd.DataFrame([{\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1,\n",
    "    \"balanced_accuracy\": bal_acc,\n",
    "    \"auc_roc\": auc_ovr\n",
    "}])\n",
    "ensemble_metrics.to_csv(\n",
    "    os.path.join(results_dir, \"ensemble_model_metrics.csv\"), index=False\n",
    ")\n",
    "print(\"‚úÖ Ensemble metrics saved:\")\n",
    "print(ensemble_metrics.round(4))\n",
    "\n",
    "# 4) (Optional) display confusion matrix and ROC curves here if you want\n",
    "#    but metrics are now persisted for easy comparison to final_model_metrics.csv\n",
    "\n",
    "# Load ensemble predictions\n",
    "ens_df = pd.read_csv(os.path.join(results_dir, 'ensemble_preds.csv'))\n",
    "y_true_ens = ens_df['True'].values\n",
    "y_pred_ens = ens_df['Pred'].values\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_ens, y_pred_ens)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[class_names[i] for i in range(num_classes)])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Ensemble Model ‚Äì Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC curves\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {auc(fpr, tpr):.2f})\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Ensemble Model ‚Äì AUC‚ÄëROC by Class\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec135d",
   "metadata": {},
   "source": [
    "# ## Step 8: Final Model Training on Combined Data & Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5db00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolapo/anaconda3/envs/erdos_fall_2024/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.8597 | Val Loss:   0.8353 | Best Val:   0.8353 | Patience:   0\n",
      "Epoch 002 | Train Loss: 0.7758 | Val Loss:   0.7393 | Best Val:   0.7393 | Patience:   0\n",
      "Epoch 003 | Train Loss: 0.7435 | Val Loss:   0.7210 | Best Val:   0.7210 | Patience:   0\n",
      "Epoch 004 | Train Loss: 0.7343 | Val Loss:   0.7209 | Best Val:   0.7209 | Patience:   0\n",
      "Epoch 005 | Train Loss: 0.7243 | Val Loss:   0.7037 | Best Val:   0.7037 | Patience:   0\n",
      "Epoch 006 | Train Loss: 0.7236 | Val Loss:   0.7009 | Best Val:   0.7009 | Patience:   0\n",
      "Epoch 007 | Train Loss: 0.7193 | Val Loss:   0.6954 | Best Val:   0.6954 | Patience:   0\n",
      "Epoch 008 | Train Loss: 0.7079 | Val Loss:   0.6822 | Best Val:   0.6822 | Patience:   0\n",
      "Epoch 009 | Train Loss: 0.7086 | Val Loss:   0.6885 | Best Val:   0.6822 | Patience:   1\n",
      "Epoch 010 | Train Loss: 0.7073 | Val Loss:   0.6657 | Best Val:   0.6657 | Patience:   0\n",
      "Epoch 011 | Train Loss: 0.6918 | Val Loss:   0.6540 | Best Val:   0.6540 | Patience:   0\n",
      "Epoch 012 | Train Loss: 0.6779 | Val Loss:   0.6665 | Best Val:   0.6540 | Patience:   1\n",
      "Epoch 013 | Train Loss: 0.6815 | Val Loss:   0.6450 | Best Val:   0.6450 | Patience:   0\n",
      "Epoch 014 | Train Loss: 0.6667 | Val Loss:   0.6403 | Best Val:   0.6403 | Patience:   0\n",
      "Epoch 015 | Train Loss: 0.6484 | Val Loss:   0.6285 | Best Val:   0.6285 | Patience:   0\n",
      "Epoch 016 | Train Loss: 0.6375 | Val Loss:   0.6723 | Best Val:   0.6285 | Patience:   1\n",
      "Epoch 017 | Train Loss: 0.6343 | Val Loss:   0.6161 | Best Val:   0.6161 | Patience:   0\n",
      "Epoch 018 | Train Loss: 0.6171 | Val Loss:   0.6037 | Best Val:   0.6037 | Patience:   0\n",
      "Epoch 019 | Train Loss: 0.6045 | Val Loss:   0.5684 | Best Val:   0.5684 | Patience:   0\n",
      "Epoch 020 | Train Loss: 0.5890 | Val Loss:   0.5619 | Best Val:   0.5619 | Patience:   0\n",
      "Epoch 021 | Train Loss: 0.5838 | Val Loss:   0.5763 | Best Val:   0.5619 | Patience:   1\n",
      "Epoch 022 | Train Loss: 0.5726 | Val Loss:   0.6013 | Best Val:   0.5619 | Patience:   2\n",
      "Epoch 023 | Train Loss: 0.5507 | Val Loss:   0.5707 | Best Val:   0.5619 | Patience:   3\n",
      "Epoch 024 | Train Loss: 0.5416 | Val Loss:   0.5502 | Best Val:   0.5502 | Patience:   0\n",
      "Epoch 025 | Train Loss: 0.5316 | Val Loss:   0.5286 | Best Val:   0.5286 | Patience:   0\n",
      "Epoch 026 | Train Loss: 0.5154 | Val Loss:   0.5937 | Best Val:   0.5286 | Patience:   1\n",
      "Epoch 027 | Train Loss: 0.5118 | Val Loss:   0.4820 | Best Val:   0.4820 | Patience:   0\n",
      "Epoch 028 | Train Loss: 0.5157 | Val Loss:   0.5159 | Best Val:   0.4820 | Patience:   1\n",
      "Epoch 029 | Train Loss: 0.5043 | Val Loss:   0.5388 | Best Val:   0.4820 | Patience:   2\n",
      "Epoch 030 | Train Loss: 0.4873 | Val Loss:   0.4776 | Best Val:   0.4776 | Patience:   0\n",
      "Epoch 031 | Train Loss: 0.4836 | Val Loss:   0.4560 | Best Val:   0.4560 | Patience:   0\n",
      "Epoch 032 | Train Loss: 0.4639 | Val Loss:   0.4327 | Best Val:   0.4327 | Patience:   0\n",
      "Epoch 033 | Train Loss: 0.4732 | Val Loss:   0.4593 | Best Val:   0.4327 | Patience:   1\n",
      "Epoch 034 | Train Loss: 0.4535 | Val Loss:   0.4233 | Best Val:   0.4233 | Patience:   0\n",
      "Epoch 035 | Train Loss: 0.4565 | Val Loss:   0.4523 | Best Val:   0.4233 | Patience:   1\n",
      "Epoch 036 | Train Loss: 0.4604 | Val Loss:   0.4424 | Best Val:   0.4233 | Patience:   2\n",
      "Epoch 037 | Train Loss: 0.4333 | Val Loss:   0.4482 | Best Val:   0.4233 | Patience:   3\n",
      "Epoch 038 | Train Loss: 0.4467 | Val Loss:   0.4041 | Best Val:   0.4041 | Patience:   0\n",
      "Epoch 039 | Train Loss: 0.4271 | Val Loss:   0.4071 | Best Val:   0.4041 | Patience:   1\n",
      "Epoch 040 | Train Loss: 0.4299 | Val Loss:   0.4153 | Best Val:   0.4041 | Patience:   2\n",
      "Epoch 041 | Train Loss: 0.4321 | Val Loss:   0.4631 | Best Val:   0.4041 | Patience:   3\n",
      "Epoch 042 | Train Loss: 0.4216 | Val Loss:   0.4074 | Best Val:   0.4041 | Patience:   4\n",
      "Epoch 043 | Train Loss: 0.4151 | Val Loss:   0.3746 | Best Val:   0.3746 | Patience:   0\n",
      "Epoch 044 | Train Loss: 0.4042 | Val Loss:   0.4086 | Best Val:   0.3746 | Patience:   1\n",
      "Epoch 045 | Train Loss: 0.3958 | Val Loss:   0.3659 | Best Val:   0.3659 | Patience:   0\n",
      "Epoch 046 | Train Loss: 0.4122 | Val Loss:   0.3577 | Best Val:   0.3577 | Patience:   0\n",
      "Epoch 047 | Train Loss: 0.3882 | Val Loss:   0.5226 | Best Val:   0.3577 | Patience:   1\n",
      "Epoch 048 | Train Loss: 0.4060 | Val Loss:   0.3799 | Best Val:   0.3577 | Patience:   2\n",
      "Epoch 049 | Train Loss: 0.3854 | Val Loss:   0.3531 | Best Val:   0.3531 | Patience:   0\n",
      "Epoch 050 | Train Loss: 0.3742 | Val Loss:   0.3769 | Best Val:   0.3531 | Patience:   1\n",
      "Epoch 051 | Train Loss: 0.3748 | Val Loss:   0.3841 | Best Val:   0.3531 | Patience:   2\n",
      "Epoch 052 | Train Loss: 0.3776 | Val Loss:   0.3841 | Best Val:   0.3531 | Patience:   3\n",
      "Epoch 053 | Train Loss: 0.3760 | Val Loss:   0.3396 | Best Val:   0.3396 | Patience:   0\n",
      "Epoch 054 | Train Loss: 0.3708 | Val Loss:   0.3412 | Best Val:   0.3396 | Patience:   1\n",
      "Epoch 055 | Train Loss: 0.3740 | Val Loss:   0.3602 | Best Val:   0.3396 | Patience:   2\n",
      "Epoch 056 | Train Loss: 0.3634 | Val Loss:   0.3835 | Best Val:   0.3396 | Patience:   3\n",
      "Epoch 057 | Train Loss: 0.3744 | Val Loss:   0.4074 | Best Val:   0.3396 | Patience:   4\n",
      "Epoch 058 | Train Loss: 0.3562 | Val Loss:   0.3487 | Best Val:   0.3396 | Patience:   5\n",
      "Epoch 059 | Train Loss: 0.3541 | Val Loss:   0.3304 | Best Val:   0.3304 | Patience:   0\n",
      "Epoch 060 | Train Loss: 0.3618 | Val Loss:   0.3493 | Best Val:   0.3304 | Patience:   1\n",
      "Epoch 061 | Train Loss: 0.3504 | Val Loss:   0.3562 | Best Val:   0.3304 | Patience:   2\n",
      "Epoch 062 | Train Loss: 0.3474 | Val Loss:   0.3588 | Best Val:   0.3304 | Patience:   3\n",
      "Epoch 063 | Train Loss: 0.3484 | Val Loss:   0.3673 | Best Val:   0.3304 | Patience:   4\n",
      "Epoch 064 | Train Loss: 0.3601 | Val Loss:   0.3755 | Best Val:   0.3304 | Patience:   5\n",
      "Epoch 065 | Train Loss: 0.3481 | Val Loss:   0.3869 | Best Val:   0.3304 | Patience:   6\n",
      "Epoch 066 | Train Loss: 0.3207 | Val Loss:   0.2874 | Best Val:   0.2874 | Patience:   0\n",
      "Epoch 067 | Train Loss: 0.3111 | Val Loss:   0.3437 | Best Val:   0.2874 | Patience:   1\n",
      "Epoch 068 | Train Loss: 0.3075 | Val Loss:   0.2938 | Best Val:   0.2874 | Patience:   2\n",
      "Epoch 069 | Train Loss: 0.3203 | Val Loss:   0.2954 | Best Val:   0.2874 | Patience:   3\n",
      "Epoch 070 | Train Loss: 0.3068 | Val Loss:   0.2936 | Best Val:   0.2874 | Patience:   4\n",
      "Epoch 071 | Train Loss: 0.3056 | Val Loss:   0.3276 | Best Val:   0.2874 | Patience:   5\n",
      "Epoch 072 | Train Loss: 0.3075 | Val Loss:   0.3106 | Best Val:   0.2874 | Patience:   6\n",
      "Epoch 073 | Train Loss: 0.2925 | Val Loss:   0.2916 | Best Val:   0.2874 | Patience:   7\n",
      "Epoch 074 | Train Loss: 0.2861 | Val Loss:   0.2713 | Best Val:   0.2713 | Patience:   0\n",
      "Epoch 075 | Train Loss: 0.2855 | Val Loss:   0.2733 | Best Val:   0.2713 | Patience:   1\n",
      "Epoch 076 | Train Loss: 0.2842 | Val Loss:   0.2683 | Best Val:   0.2683 | Patience:   0\n",
      "Epoch 077 | Train Loss: 0.2836 | Val Loss:   0.3137 | Best Val:   0.2683 | Patience:   1\n",
      "Epoch 078 | Train Loss: 0.2821 | Val Loss:   0.2684 | Best Val:   0.2683 | Patience:   2\n",
      "Epoch 079 | Train Loss: 0.2868 | Val Loss:   0.2891 | Best Val:   0.2683 | Patience:   3\n",
      "Epoch 080 | Train Loss: 0.2914 | Val Loss:   0.2634 | Best Val:   0.2634 | Patience:   0\n",
      "Epoch 081 | Train Loss: 0.2804 | Val Loss:   0.2852 | Best Val:   0.2634 | Patience:   1\n",
      "Epoch 082 | Train Loss: 0.2800 | Val Loss:   0.2619 | Best Val:   0.2619 | Patience:   0\n",
      "Epoch 083 | Train Loss: 0.2791 | Val Loss:   0.2686 | Best Val:   0.2619 | Patience:   1\n",
      "Epoch 084 | Train Loss: 0.2749 | Val Loss:   0.2761 | Best Val:   0.2619 | Patience:   2\n",
      "Epoch 085 | Train Loss: 0.2746 | Val Loss:   0.2629 | Best Val:   0.2619 | Patience:   3\n",
      "Epoch 086 | Train Loss: 0.2780 | Val Loss:   0.2720 | Best Val:   0.2619 | Patience:   4\n",
      "Epoch 087 | Train Loss: 0.2763 | Val Loss:   0.2669 | Best Val:   0.2619 | Patience:   5\n",
      "Epoch 088 | Train Loss: 0.2816 | Val Loss:   0.2673 | Best Val:   0.2619 | Patience:   6\n",
      "Epoch 089 | Train Loss: 0.2656 | Val Loss:   0.2547 | Best Val:   0.2547 | Patience:   0\n",
      "Epoch 090 | Train Loss: 0.2660 | Val Loss:   0.2646 | Best Val:   0.2547 | Patience:   1\n",
      "Epoch 091 | Train Loss: 0.2655 | Val Loss:   0.2566 | Best Val:   0.2547 | Patience:   2\n",
      "Epoch 092 | Train Loss: 0.2657 | Val Loss:   0.2573 | Best Val:   0.2547 | Patience:   3\n",
      "Epoch 093 | Train Loss: 0.2635 | Val Loss:   0.2547 | Best Val:   0.2547 | Patience:   0\n",
      "Epoch 094 | Train Loss: 0.2619 | Val Loss:   0.2618 | Best Val:   0.2547 | Patience:   1\n",
      "Epoch 095 | Train Loss: 0.2616 | Val Loss:   0.2567 | Best Val:   0.2547 | Patience:   2\n",
      "Epoch 096 | Train Loss: 0.2606 | Val Loss:   0.2541 | Best Val:   0.2541 | Patience:   0\n",
      "Epoch 097 | Train Loss: 0.2599 | Val Loss:   0.2642 | Best Val:   0.2541 | Patience:   1\n",
      "Epoch 098 | Train Loss: 0.2598 | Val Loss:   0.2523 | Best Val:   0.2523 | Patience:   0\n",
      "Epoch 099 | Train Loss: 0.2615 | Val Loss:   0.2539 | Best Val:   0.2523 | Patience:   1\n",
      "Epoch 100 | Train Loss: 0.2570 | Val Loss:   0.2556 | Best Val:   0.2523 | Patience:   2\n",
      "Epoch 101 | Train Loss: 0.2564 | Val Loss:   0.2551 | Best Val:   0.2523 | Patience:   3\n",
      "Epoch 102 | Train Loss: 0.2561 | Val Loss:   0.2547 | Best Val:   0.2523 | Patience:   4\n",
      "Epoch 103 | Train Loss: 0.2556 | Val Loss:   0.2507 | Best Val:   0.2507 | Patience:   0\n",
      "Epoch 104 | Train Loss: 0.2581 | Val Loss:   0.2607 | Best Val:   0.2507 | Patience:   1\n",
      "Epoch 105 | Train Loss: 0.2574 | Val Loss:   0.2579 | Best Val:   0.2507 | Patience:   2\n",
      "Epoch 106 | Train Loss: 0.2549 | Val Loss:   0.2455 | Best Val:   0.2455 | Patience:   0\n",
      "Epoch 107 | Train Loss: 0.2523 | Val Loss:   0.2544 | Best Val:   0.2455 | Patience:   1\n",
      "Epoch 108 | Train Loss: 0.2524 | Val Loss:   0.2472 | Best Val:   0.2455 | Patience:   2\n",
      "Epoch 109 | Train Loss: 0.2529 | Val Loss:   0.2428 | Best Val:   0.2428 | Patience:   0\n",
      "Epoch 110 | Train Loss: 0.2538 | Val Loss:   0.2472 | Best Val:   0.2428 | Patience:   1\n",
      "Epoch 111 | Train Loss: 0.2526 | Val Loss:   0.2458 | Best Val:   0.2428 | Patience:   2\n",
      "Epoch 112 | Train Loss: 0.2510 | Val Loss:   0.2576 | Best Val:   0.2428 | Patience:   3\n",
      "Epoch 113 | Train Loss: 0.2592 | Val Loss:   0.2432 | Best Val:   0.2428 | Patience:   4\n",
      "Epoch 114 | Train Loss: 0.2514 | Val Loss:   0.2426 | Best Val:   0.2426 | Patience:   0\n",
      "Epoch 115 | Train Loss: 0.2510 | Val Loss:   0.2487 | Best Val:   0.2426 | Patience:   1\n",
      "Epoch 116 | Train Loss: 0.2509 | Val Loss:   0.2449 | Best Val:   0.2426 | Patience:   2\n",
      "Epoch 117 | Train Loss: 0.2492 | Val Loss:   0.2508 | Best Val:   0.2426 | Patience:   3\n",
      "Epoch 118 | Train Loss: 0.2477 | Val Loss:   0.2473 | Best Val:   0.2426 | Patience:   4\n",
      "Epoch 119 | Train Loss: 0.2511 | Val Loss:   0.2481 | Best Val:   0.2426 | Patience:   5\n",
      "Epoch 120 | Train Loss: 0.2488 | Val Loss:   0.2570 | Best Val:   0.2426 | Patience:   6\n",
      "Epoch 121 | Train Loss: 0.2439 | Val Loss:   0.2476 | Best Val:   0.2426 | Patience:   7\n",
      "Epoch 122 | Train Loss: 0.2432 | Val Loss:   0.2431 | Best Val:   0.2426 | Patience:   8\n",
      "Epoch 123 | Train Loss: 0.2425 | Val Loss:   0.2416 | Best Val:   0.2416 | Patience:   0\n",
      "Epoch 124 | Train Loss: 0.2423 | Val Loss:   0.2433 | Best Val:   0.2416 | Patience:   1\n",
      "Epoch 125 | Train Loss: 0.2410 | Val Loss:   0.2380 | Best Val:   0.2380 | Patience:   0\n",
      "Epoch 126 | Train Loss: 0.2402 | Val Loss:   0.2419 | Best Val:   0.2380 | Patience:   1\n",
      "Epoch 127 | Train Loss: 0.2407 | Val Loss:   0.2410 | Best Val:   0.2380 | Patience:   2\n",
      "Epoch 128 | Train Loss: 0.2420 | Val Loss:   0.2410 | Best Val:   0.2380 | Patience:   3\n",
      "Epoch 129 | Train Loss: 0.2437 | Val Loss:   0.2418 | Best Val:   0.2380 | Patience:   4\n",
      "Epoch 130 | Train Loss: 0.2427 | Val Loss:   0.2425 | Best Val:   0.2380 | Patience:   5\n",
      "Epoch 131 | Train Loss: 0.2399 | Val Loss:   0.2394 | Best Val:   0.2380 | Patience:   6\n",
      "Epoch 132 | Train Loss: 0.2376 | Val Loss:   0.2404 | Best Val:   0.2380 | Patience:   7\n",
      "Epoch 133 | Train Loss: 0.2376 | Val Loss:   0.2417 | Best Val:   0.2380 | Patience:   8\n",
      "Epoch 134 | Train Loss: 0.2377 | Val Loss:   0.2392 | Best Val:   0.2380 | Patience:   9\n",
      "‚èπÔ∏è Early stopping\n",
      "\n",
      "üìä Final Test Metrics:\n",
      "Accuracy           : 0.7358\n",
      "Balanced Accuracy  : 0.6048\n",
      "Precision (weighted): 0.7312\n",
      "Recall (weighted)   : 0.7358\n",
      "F1 Score (weighted) : 0.7324\n",
      "AUC-ROC (ovr)       : 0.8548\n",
      "‚úÖ Final metrics saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final confusion matrix saved\n",
      "‚úÖ Final AUC-ROC saved\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, auc\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# 1) Merge train+val folds and reserve 10% for local validation\n",
    "all_data = []\n",
    "for fold in range(10):\n",
    "    all_data += torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    all_data += torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=seed)\n",
    "labels = [int(d.y.item()) for d in all_data]\n",
    "train_idx, val_idx = next(sss.split(all_data, labels))\n",
    "train_split = [all_data[i] for i in train_idx]\n",
    "val_split   = [all_data[i] for i in val_idx]\n",
    "\n",
    "tr_loader = DataLoader(train_split, batch_size=32, shuffle=True,\n",
    "                       worker_init_fn=seed_worker, generator=generator)\n",
    "vl_loader = DataLoader(val_split,   batch_size=32)\n",
    "\n",
    "# 2) Build model, optimizer, scheduler\n",
    "model = MPNN(\n",
    "    all_data[0].x.size(1),\n",
    "    all_data[0].edge_attr.size(1),\n",
    "    hidden_dim=best_hidden_dim,\n",
    "    output_dim=num_classes,\n",
    "    dropout=best_dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', patience=5, factor=0.5, verbose=True\n",
    ")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 0\n",
    "\n",
    "# 3) Train with early stopping\n",
    "for epoch in range(1, 301):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for b in tr_loader:\n",
    "        b = b.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(b)\n",
    "        loss = F.cross_entropy(out, b.y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(tr_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for b in vl_loader:\n",
    "            b = b.to(device)\n",
    "            out = model(b)\n",
    "            val_loss += F.cross_entropy(out, b.y.long()).item()\n",
    "    val_loss /= len(vl_loader)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save best\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), os.path.join(results_dir, 'final_model.pt'))\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= 10:\n",
    "            print(\"‚èπÔ∏è Early stopping\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss:   {val_loss:.4f} | \"\n",
    "          f\"Best Val:   {best_val_loss:.4f} | \"\n",
    "          f\"Patience:   {patience}\")\n",
    "\n",
    "# 4) Final Test Evaluation\n",
    "model.load_state_dict(torch.load(os.path.join(results_dir, 'final_model.pt')))\n",
    "test_data = torch.load(os.path.join(base_path, f\"{task}_test.pt\"))\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "preds, labels = evaluate(model, test_loader)\n",
    "y_true = labels.numpy().astype(int)\n",
    "y_pred = preds.argmax(dim=1).numpy()\n",
    "y_probs = F.softmax(preds, dim=1).cpu().numpy()\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n",
    "\n",
    "# Metrics\n",
    "acc      = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average='weighted', zero_division=0\n",
    ")\n",
    "bal_acc  = balanced_accuracy_score(y_true, y_pred)\n",
    "auc_ovr  = roc_auc_score(y_true_bin, y_probs, multi_class='ovr')\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nüìä Final Test Metrics:\")\n",
    "print(f\"Accuracy           : {acc:.4f}\")\n",
    "print(f\"Balanced Accuracy  : {bal_acc:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted)   : {recall:.4f}\")\n",
    "print(f\"F1 Score (weighted) : {f1:.4f}\")\n",
    "print(f\"AUC-ROC (ovr)       : {auc_ovr:.4f}\")\n",
    "\n",
    "# Save final metrics\n",
    "final_metrics = {\n",
    "    'accuracy': acc,\n",
    "    'balanced_accuracy': bal_acc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'auc_roc': auc_ovr\n",
    "}\n",
    "pd.DataFrame(final_metrics, index=[0]).to_csv(\n",
    "    os.path.join(results_dir, 'final_model_metrics.csv'), index=False\n",
    ")\n",
    "print(\"‚úÖ Final metrics saved\")\n",
    "\n",
    "# 5) Confusion Matrix & AUC-ROC plots\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=list(class_names.values()))\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Final Model ‚Äì Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {auc(fpr, tpr):.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.title('Final Model ‚Äì AUC-ROC by Class')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# Save confusion matrix\n",
    "cm_df = pd.DataFrame(cm, index=class_names.values(), columns=class_names.values())\n",
    "cm_df.to_csv(os.path.join(results_dir, 'final_confusion_matrix.csv'))\n",
    "print(\"‚úÖ Final confusion matrix saved\")\n",
    "# Save AUC-ROC\n",
    "roc_df = pd.DataFrame({'fpr': fpr, 'tpr': tpr})\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_df.to_csv(os.path.join(results_dir, 'final_auc_roc.csv'), index=False)\n",
    "print(\"‚úÖ Final AUC-ROC saved\")\n",
    "    disp.ax_.set_ylabel('True pCHEMBL')\n",
    "    disp.ax_.set_xlabel('Predicted pCHEMBL')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce2b1f",
   "metadata": {},
   "source": [
    "## Step 9: compare ensemble averaging to final model training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39e9c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in ensemble_df: Index(['accuracy', 'precision', 'recall', 'f1_score', 'balanced_accuracy',\n",
      "       'auc_roc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.698113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final</th>\n",
       "      <td>0.735849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy\n",
       "ensemble  0.698113\n",
       "final     0.735849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparison table\n",
    "ensemble_df=pd.read_csv(os.path.join(results_dir,'ensemble_model_metrics.csv'))\n",
    "print(\"Columns in ensemble_df:\", ensemble_df.columns)  # Debugging line to check column names\n",
    "ensemble_acc=accuracy_score(t_true, y_pred_ens)  # Use t_true and y_pred_ens as they represent the true and predicted labels\n",
    "final_metrics = {'ensemble': ensemble_acc, 'final': acc}\n",
    "comp = pd.DataFrame.from_dict(final_metrics, orient='index', columns=['Accuracy'])\n",
    "display(comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
