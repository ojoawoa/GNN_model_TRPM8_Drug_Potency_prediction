{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a72147",
   "metadata": {},
   "source": [
    "# # Full Cross-Validation and Final Training Evaluation Notebook\n",
    "# \n",
    "# This notebook performs graph neural network (GNN)-based classification or regression using a custom Message Passing Neural Network (MPNN) architecture. It supports training with 5-fold cross-validation and then retrains a final model on combined data using early stopping. Performance is evaluated on a held-out test set.\n",
    "# \n",
    "# ## 🧭 Workflow Overview\n",
    "# \n",
    "# ### Step 1. Imports and Setup\n",
    "# - Load libraries including PyTorch, PyTorch Geometric, and scikit-learn.\n",
    "# - Configure plotting and file management tools.\n",
    "# \n",
    "# ### Step 2. Task and Reproducibility Setup\n",
    "# - Set task: `task = \"classification\"` or `\"regression\"`.\n",
    "# - Configure reproducibility with a fixed random seed for reproducibility\n",
    "# - Define class names if applicable and set up result directories.\n",
    "# \n",
    "# ### Step 3. Model Definition\n",
    "# - Define an MPNN layer and model using PyTorch Geometric.\n",
    "# - The model takes node and edge features and outputs class scores or scalar predictions.\n",
    "# \n",
    "# ### Step 4. Evaluation Helper Function\n",
    "# - Implements an `evaluate(model, loader)` function to return model outputs and ground truths.\n",
    "# \n",
    "# ### Step 5. Input Dimensions and Device Setup\n",
    "# - Determine input feature dimensions from dataset.\n",
    "# - Detect and assign appropriate device (CPU or GPU).\n",
    "# \n",
    "# ### Step 6. Cross-Validation Training and Evaluation\n",
    "# - Train the model across 5 folds using pre-split datasets from ../4_train_test_split/5fold_cv/{task}/\n",
    ".\n",
    "# - Log metrics per fold:\n",
    "#   - **Classification**: accuracy, precision, recall, F1, AUC-ROC\n",
    "#   - **Regression**: MAE, MSE, RMSE, R²\n",
    "# - Save all results to CSV.\n",
    "# \n",
    "# ### Step 7. Final Model Training and Test Evaluation\n",
    "# - Merge all training and validation folds.\n",
    "# - Reserve a small stratified/random validation split.\n",
    "# - Train model with:\n",
    "#   - **Early stopping** (based on validation loss)\n",
    "#   - **Learning rate scheduler**\n",
    "#   - **Model checkpointing** (saves best model)\n",
    "# - Evaluate on the held-out test set and save predictions + plots.\n",
    "# \n",
    "# ### Step 8. Cross-Validation Results Visualization\n",
    "# - Plot fold-wise bar charts for key metrics.\n",
    "# - Display mean and standard deviation summary.\n",
    "# \n",
    "# ### Step 9. Interpreting Final Model AUC-ROC and Confusion Matrix\n",
    "# - Provide interpretation of model behavior:\n",
    "#   - AUC-ROC curve → how well the model separates classes\n",
    "#   - Confusion matrix → where the model gets confused\n",
    "# - Identify any class-specific issues \n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ## 🛠 Parameters That Can Be optimized/tuned\n",
    "#\n",
    "# - **Hidden dimension** of MPNN: `hidden_dim`\n",
    "# - **Learning rate**: `lr` in `Adam` optimizer\n",
    "# - **Batch size**: affects convergence speed and generalization\n",
    "# - **Early stopping patience**: number of epochs without improvement\n",
    "# - **Scheduler factor/patience**: reduce LR when plateauing\n",
    "# - **Model depth**: number of MPNN layers\n",
    "# - **Number of epochs**: max training rounds\n",
    "# - **Loss function**: CrossEntropy vs. MSE depending on task\n",
    "# - **Stratified vs. random validation split**\n",
    "\n",
    "# ---\n",
    "#\n",
    "# ✅ This notebook can be extended with additional model types (e.g., GAT, GIN), more complex featurization, or hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f1c0d",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b107243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79ade2",
   "metadata": {},
   "source": [
    "## 2. Task and Reproducibility Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64234a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "task = \"classification\"  # or \"regression\"\n",
    "#task = \"regression\"  # or \"classification\"\n",
    "num_classes = 3\n",
    "class_names = {0: \"Low\", 1: \"Medium\", 2: \"High\"}\n",
    "\n",
    "base_path = f\"../4_train_test_split/10fold_cv/{task}/\"\n",
    "results_dir = f\"MPNN_results/{task}/\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ac03",
   "metadata": {},
   "source": [
    "## 3b. Define MPNN Layer and MPNN Model with Dropout Support\n",
    "# Enhanced MPNN model with dropout layers after each message-passing block to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c517152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "        self.edge_proj = Linear(edge_dim, out_channels)\n",
    "        self.msg_lin = Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.lin(x)\n",
    "        edge_attr = self.edge_proj(edge_attr)\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return self.msg_lin(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return F.relu(aggr_out)\n",
    "\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, edge_dim, hidden_dim, output_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.mp1 = MPNNLayer(input_dim, hidden_dim, edge_dim)\n",
    "        self.mp2 = MPNNLayer(hidden_dim, hidden_dim, edge_dim)\n",
    "        self.out = Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.mp1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.mp2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bd2cc",
   "metadata": {},
   "source": [
    "## 4. Evaluation Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d899a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds.append(out.cpu())\n",
    "            labels.append(batch.y.cpu())\n",
    "    return torch.cat(preds), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063855f",
   "metadata": {},
   "source": [
    "## 5. Input Dimensions and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f3414ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = torch.load(os.path.join(base_path, f\"{task}_train_fold0.pt\"))[0]\n",
    "input_dim = sample_data.x.size(1)\n",
    "edge_dim = sample_data.edge_attr.size(1)\n",
    "output_dim = num_classes if task == \"classification\" else 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ef9f7",
   "metadata": {},
   "source": [
    "# # Steps 3–7: Hyperparameter Tuning, Retraining, and Evaluation\n",
    "# This notebook covers the core stages in training and evaluating a GNN model using 5-fold CV and ensemble averaging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2e937",
   "metadata": {},
   "source": [
    "## Step 3: Cross-Validation Training with Hyperparameter Sweep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5c45c",
   "metadata": {},
   "source": [
    "# ## Step 4: Select Best Hyperparameters\n",
    "# Use this section to manually define the best hyperparameters based on the sweep above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582fe3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [64, 128, 256]\n",
    "dropouts    = [0.0, 0.2, 0.4]\n",
    "lrs         = [1e-3, 5e-4, 1e-4]\n",
    "results = []\n",
    "\n",
    "for hd in hidden_dims:\n",
    "    for dp in dropouts:\n",
    "        for lr in lrs:\n",
    "            print(f\"\\n🔧 Config: hidden_dim={hd}, dropout={dp}, lr={lr}\")\n",
    "            fold_scores = []\n",
    "            for fold in range(10):\n",
    "                # Load fold data\n",
    "                train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "                val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "                \n",
    "                model = MPNN(train_data[0].x.size(1),\n",
    "                             train_data[0].edge_attr.size(1),\n",
    "                             hidden_dim=hd,\n",
    "                             output_dim=num_classes,\n",
    "                             dropout=dp).to(device)\n",
    "                opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                tr = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                                worker_init_fn=seed_worker, generator=generator)\n",
    "                vl = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "                # Train\n",
    "                for epoch in range(1, 51):\n",
    "                    model.train()\n",
    "                    for batch in tr:\n",
    "                        batch = batch.to(device)\n",
    "                        opt.zero_grad()\n",
    "                        out = model(batch)\n",
    "                        loss = F.cross_entropy(out, batch.y.long())\n",
    "                        loss.backward()\n",
    "                        opt.step()\n",
    "                # Eval\n",
    "                preds, labels = evaluate(model, vl)\n",
    "                y_true = labels.numpy().astype(int)\n",
    "                y_probs = F.softmax(preds, dim=1).numpy()\n",
    "                auc = roc_auc_score(label_binarize(y_true, classes=np.arange(num_classes)),\n",
    "                                     y_probs, multi_class='ovr')\n",
    "                fold_scores.append(auc)\n",
    "            results.append((hd, dp, lr, np.mean(fold_scores), np.std(fold_scores)))\n",
    "            print(f\"📊 AUC: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")\n",
    "\n",
    "sweep_df = pd.DataFrame(results,\n",
    "                        columns=[\"hidden_dim\",\"dropout\",\"lr\",\"mean_auc\",\"std_auc\"])\n",
    "display(sweep_df.sort_values(\"mean_auc\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95fd6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "best_hidden_dim = 128\n",
    "best_dropout = 0.0\n",
    "best_lr = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97989bc2",
   "metadata": {},
   "source": [
    "# ## Step 5a: Retrain All Folds with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8712251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pandas as pd\n",
    "fold_metrics = []\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\n🔁 Retraining Fold {fold+1}/10\")\n",
    "    train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "    model = MPNN(train_data[0].x.size(1),\n",
    "                 train_data[0].edge_attr.size(1),\n",
    "                 hidden_dim=best_hidden_dim,\n",
    "                 output_dim=num_classes,\n",
    "                 dropout=best_dropout).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "    tr = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                    worker_init_fn=seed_worker, generator=generator)\n",
    "    vl = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "    best_val_loss = float('inf'); patience=0\n",
    "    for epoch in range(1, 101):\n",
    "        model.train(); total=0\n",
    "        for batch in tr:\n",
    "            batch=batch.to(device); opt.zero_grad(); out=model(batch)\n",
    "            loss=F.cross_entropy(out,batch.y.long()); loss.backward(); opt.step(); total+=loss.item()\n",
    "        preds, labels = evaluate(model, vl)\n",
    "        y_true = labels.numpy().astype(int)\n",
    "        y_probs = F.softmax(preds, dim=1).numpy()\n",
    "        val_loss = F.cross_entropy(preds, labels.long()).item()\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss=val_loss; patience=0\n",
    "            torch.save(model.state_dict(), os.path.join(results_dir, f\"fold{fold+1}_model.pt\"))\n",
    "        else:\n",
    "            patience+=1\n",
    "            if patience>=10: break\n",
    "\n",
    "    # Metrics\n",
    "    y_pred = preds.argmax(dim=1).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    auc = roc_auc_score(label_binarize(y_true, classes=np.arange(num_classes)), y_probs, multi_class='ovr')\n",
    "    fold_metrics.append({\"fold\":fold+1,\"accuracy\":acc,\"precision\":precision,\"recall\":recall,\"f1_score\":f1,\"auc_roc\":auc})\n",
    "\n",
    "# Save CV summary\n",
    "cv_df = pd.DataFrame(fold_metrics)\n",
    "cv_df.to_csv(os.path.join(results_dir, \"crossval_summary.csv\"), index=False)\n",
    "print(\"✅ Saved CV summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63f613",
   "metadata": {},
   "source": [
    "# ## Step 6: Visualize Cross-Validation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "cv_df = pd.read_csv(os.path.join(results_dir, \"crossval_summary.csv\"))\n",
    "metrics = ['accuracy','precision','recall','f1_score','auc_roc']\n",
    "fig, axs = plt.subplots(1,len(metrics), figsize=(20,4))\n",
    "for i,m in enumerate(metrics):\n",
    "    axs[i].bar(cv_df['fold'], cv_df[m]); axs[i].set_title(m.upper()); axs[i].set_xlabel('Fold'); axs[i].set_ylabel(m)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9ecc1",
   "metadata": {},
   "source": [
    "# ## Step 7: Ensemble Averaging from 10 CV Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "ess_preds=[]\n",
    "test_data=torch.load(os.path.join(base_path, f\"{task}_test.pt\"))\n",
    "tl=DataLoader(test_data, batch_size=32)\n",
    "for fold in range(10):\n",
    "    model = MPNN(test_data[0].x.size(1), test_data[0].edge_attr.size(1), hidden_dim=best_hidden_dim, output_dim=num_classes, dropout=best_dropout).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(results_dir, f\"fold{fold+1}_model.pt\")))\n",
    "    model.eval(); outs=[]\n",
    "    with torch.no_grad():\n",
    "        for b in tl: outs.append(model(b.to(device)).cpu())\n",
    "    ess_preds.append(torch.cat(outs,0))\n",
    "avg=torch.stack(ess_preds).mean(0)\n",
    "f_pred=avg.argmax(1).numpy(); t_true=torch.cat([d.y for d in test_data]).numpy().astype(int)\n",
    "pd.DataFrame({'True':t_true,'Pred':f_pred}).to_csv(os.path.join(results_dir,'ensemble_preds.csv'),index=False)\n",
    "print('✅ Ensemble preds saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf71a7",
   "metadata": {},
   "source": [
    "# ## Step 7b: Ensemble Model Evaluation – Confusion Matrix & AUC‑ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd80310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load ensemble predictions\n",
    "ens_df = pd.read_csv(os.path.join(results_dir, 'ensemble_preds.csv'))\n",
    "y_true_ens = ens_df['True'].values\n",
    "y_pred_ens = ens_df['Pred'].values\n",
    "\n",
    "# 1) Confusion matrix\n",
    "cm = confusion_matrix(y_true_ens, y_pred_ens)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[class_names[i] for i in range(num_classes)])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Ensemble Model – Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) AUC‑ROC per class\n",
    "# Need probability estimates – reload avg_output if available or recompute probabilities\n",
    "# If you only have hard preds, rerun ensemble loop with model outputs saved as probs:\n",
    "#     avg_probs = torch.stack(ensemble_prob_lists).mean(0).numpy()\n",
    "# For now, assuming you have `avg_probs`:\n",
    "y_probs = avg_output.softmax(dim=1).numpy()  # or your stored avg_probs\n",
    "y_true_bin = label_binarize(y_true_ens, classes=np.arange(num_classes))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {auc(fpr, tpr):.2f})\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Ensemble Model – AUC‑ROC by Class\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909fd41",
   "metadata": {},
   "source": [
    "# ## Step 7: Final Model Training on Combined Data & Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # GNN Classification Pipeline: 10-Fold CV, Ensemble & Final Model\n",
    "#\n",
    "# This notebook trains a Message Passing Neural Network (MPNN) for a 3-class classification task\n",
    "# (Low/Medium/High) using:\n",
    "# 1. 10-Fold Cross-Validation with hyperparameter tuning\n",
    "# 2. Retraining folds with best hyperparameters + early stopping\n",
    "# 3. Visualizing CV metrics\n",
    "# 4. Ensemble averaging of fold models\n",
    "# 5. Final model training on combined data + hold-out test evaluation\n",
    "\n",
    "# %%\n",
    "# --- Reproducibility & Imports ---\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                             roc_auc_score, confusion_matrix, roc_curve)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "# DataLoader seeding\n",
    "from torch.utils.data import DataLoader as _DL\n",
    "from torch.utils.data import get_worker_info\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = seed + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(seed)\n",
    "\n",
    "# Paths & Task\n",
    "task = \"classification\"\n",
    "num_classes = 3\n",
    "class_names = {0: \"Low\", 1: \"Medium\", 2: \"High\"}\n",
    "base_path  = f\"../4_train_test_split/10fold_cv/{task}/\"\n",
    "results_dir = f\"MPNN_results/{task}/\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 1: Model Definition\n",
    "\n",
    "# %%\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim, dropout=0.0):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "        self.edge_proj = Linear(edge_dim, out_channels)\n",
    "        self.msg_lin = Linear(out_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.lin(x)\n",
    "        edge_attr = self.edge_proj(edge_attr)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        return F.relu(F.dropout(out, p=self.dropout, training=self.training))\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return self.msg_lin(x_j + edge_attr)\n",
    "\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, edge_dim, hidden_dim, output_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.mp1 = MPNNLayer(input_dim, hidden_dim, edge_dim, dropout)\n",
    "        self.mp2 = MPNNLayer(hidden_dim, hidden_dim, edge_dim, dropout)\n",
    "        self.out = Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.mp1(x, edge_index, edge_attr)\n",
    "        x = self.mp2(x, edge_index, edge_attr)\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        return self.out(x)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 2: Evaluation Function\n",
    "\n",
    "# %%\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            preds.append(out.cpu())\n",
    "            labels.append(batch.y.cpu())\n",
    "    return torch.cat(preds), torch.cat(labels)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 3: Hyperparameter Sweep (10-Fold CV)\n",
    "\n",
    "# %%\n",
    "hidden_dims = [64, 128, 256]\n",
    "dropouts    = [0.0, 0.2, 0.4]\n",
    "lrs         = [1e-3, 5e-4]\n",
    "results = []\n",
    "\n",
    "for hd in hidden_dims:\n",
    "    for dp in dropouts:\n",
    "        for lr in lrs:\n",
    "            print(f\"\\n🔧 Config: hidden_dim={hd}, dropout={dp}, lr={lr}\")\n",
    "            fold_scores = []\n",
    "            for fold in range(10):\n",
    "                # Load fold data\n",
    "                train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "                val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "                \n",
    "                model = MPNN(train_data[0].x.size(1),\n",
    "                             train_data[0].edge_attr.size(1),\n",
    "                             hidden_dim=hd,\n",
    "                             output_dim=num_classes,\n",
    "                             dropout=dp).to(device)\n",
    "                opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                tr = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                                worker_init_fn=seed_worker, generator=generator)\n",
    "                vl = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "                # Train\n",
    "                for epoch in range(1, 51):\n",
    "                    model.train()\n",
    "                    for batch in tr:\n",
    "                        batch = batch.to(device)\n",
    "                        opt.zero_grad()\n",
    "                        out = model(batch)\n",
    "                        loss = F.cross_entropy(out, batch.y.long())\n",
    "                        loss.backward()\n",
    "                        opt.step()\n",
    "                # Eval\n",
    "                preds, labels = evaluate(model, vl)\n",
    "                y_true = labels.numpy().astype(int)\n",
    "                y_probs = F.softmax(preds, dim=1).numpy()\n",
    "                auc = roc_auc_score(label_binarize(y_true, classes=np.arange(num_classes)),\n",
    "                                     y_probs, multi_class='ovr')\n",
    "                fold_scores.append(auc)\n",
    "            results.append((hd, dp, lr, np.mean(fold_scores), np.std(fold_scores)))\n",
    "            print(f\"📊 AUC: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")\n",
    "\n",
    "sweep_df = pd.DataFrame(results,\n",
    "                        columns=[\"hidden_dim\",\"dropout\",\"lr\",\"mean_auc\",\"std_auc\"])\n",
    "display(sweep_df.sort_values(\"mean_auc\", ascending=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: Select Best Hyperparameters\n",
    "# Manually set these based on the sweep above.\n",
    "\n",
    "# %%\n",
    "best_hidden_dim = 128\n",
    "best_dropout    = 0.2\n",
    "best_lr         = 0.001\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 5: Retrain & Evaluate 10-Fold CV with Best Hyperparameters\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pandas as pd\n",
    "fold_metrics = []\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\n🔁 Retraining Fold {fold+1}/10\")\n",
    "    train_data = torch.load(os.path.join(base_path, f\"{task}_train_fold{fold}.pt\"))\n",
    "    val_data   = torch.load(os.path.join(base_path, f\"{task}_val_fold{fold}.pt\"))\n",
    "\n",
    "    model = MPNN(train_data[0].x.size(1),\n",
    "                 train_data[0].edge_attr.size(1),\n",
    "                 hidden_dim=best_hidden_dim,\n",
    "                 output_dim=num_classes,\n",
    "                 dropout=best_dropout).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "    tr = DataLoader(train_data, batch_size=32, shuffle=True,\n",
    "                    worker_init_fn=seed_worker, generator=generator)\n",
    "    vl = DataLoader(val_data,   batch_size=32)\n",
    "\n",
    "    best_val_loss = float('inf'); patience=0\n",
    "    for epoch in range(1, 101):\n",
    "        model.train(); total=0\n",
    "        for batch in tr:\n",
    "            batch=batch.to(device); opt.zero_grad(); out=model(batch)\n",
    "            loss=F.cross_entropy(out,batch.y.long()); loss.backward(); opt.step(); total+=loss.item()\n",
    "        preds, labels = evaluate(model, vl)\n",
    "        y_true = labels.numpy().astype(int)\n",
    "        y_probs = F.softmax(preds, dim=1).numpy()\n",
    "        val_loss = F.cross_entropy(preds, labels.long()).item()\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss=val_loss; patience=0\n",
    "            torch.save(model.state_dict(), os.path.join(results_dir, f\"fold{fold+1}_model.pt\"))\n",
    "        else:\n",
    "            patience+=1\n",
    "            if patience>=10: break\n",
    "\n",
    "    # Metrics\n",
    "    y_pred = preds.argmax(dim=1).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    auc = roc_auc_score(label_binarize(y_true, classes=np.arange(num_classes)), y_probs, multi_class='ovr')\n",
    "    fold_metrics.append({\"fold\":fold+1,\"accuracy\":acc,\"precision\":precision,\"recall\":recall,\"f1_score\":f1,\"auc_roc\":auc})\n",
    "\n",
    "# Save CV summary\n",
    "cv_df = pd.DataFrame(fold_metrics)\n",
    "cv_df.to_csv(os.path.join(results_dir, \"crossval_summary.csv\"), index=False)\n",
    "print(\"✅ Saved CV summary\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 6: Visualize Cross-Validation Results\n",
    "\n",
    "# %%\n",
    "cv_df = pd.read_csv(os.path.join(results_dir, \"crossval_summary.csv\"))\n",
    "metrics = ['accuracy','precision','recall','f1_score','auc_roc']\n",
    "fig, axs = plt.subplots(1,len(metrics), figsize=(20,4))\n",
    "for i,m in enumerate(metrics):\n",
    "    axs[i].bar(cv_df['fold'], cv_df[m]); axs[i].set_title(m.upper()); axs[i].set_xlabel('Fold'); axs[i].set_ylabel(m)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 7: Ensemble Averaging from 10 CV Models\n",
    "\n",
    "# %%\n",
    "ess_preds=[]\n",
    "test_data=torch.load(os.path.join(base_path, f\"{task}_test.pt\"))\n",
    "tl=DataLoader(test_data, batch_size=32)\n",
    "for fold in range(10):\n",
    "    model = MPNN(test_data[0].x.size(1), test_data[0].edge_attr.size(1), hidden_dim=best_hidden_dim, output_dim=num_classes, dropout=best_dropout).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(results_dir, f\"fold{fold+1}_model.pt\")))\n",
    "    model.eval(); outs=[]\n",
    "    with torch.no_grad():\n",
    "        for b in tl: outs.append(model(b.to(device)).cpu())\n",
    "    ess_preds.append(torch.cat(outs,0))\n",
    "avg=torch.stack(ess_preds).mean(0)\n",
    "f_pred=avg.argmax(1).numpy(); t_true=torch.cat([d.y for d in test_data]).numpy().astype(int)\n",
    "pd.DataFrame({'True':t_true,'Pred':f_pred}).to_csv(os.path.join(results_dir,'ensemble_preds.csv'),index=False)\n",
    "print('✅ Ensemble preds saved')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 8: Final Model Training on Combined Data & Test Evaluation\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# Merge train+val\n",
    "all_data=[]\n",
    "for fold in range(10):\n",
    "    all_data+=torch.load(os.path.join(base_path,f\"{task}_train_fold{fold}.pt\"))\n",
    "    all_data+=torch.load(os.path.join(base_path,f\"{task}_val_fold{fold}.pt\"))\n",
    "# small val\n",
    "sss=StratifiedShuffleSplit(n_splits=1,test_size=0.1,random_state=seed)\n",
    "labels=[int(d.y.item()) for d in all_data]\n",
    "train_idx,val_idx=next(sss.split(all_data,labels))\n",
    "train_split=[all_data[i] for i in train_idx]; val_split=[all_data[i] for i in val_idx]\n",
    "tr=DataLoader(train_split,batch_size=32,shuffle=True,worker_init_fn=seed_worker,generator=generator)\n",
    "vl=DataLoader(val_split,batch_size=32)\n",
    "model=MPNN(all_data[0].x.size(1),all_data[0].edge_attr.size(1),hidden_dim=best_hidden_dim,output_dim=num_classes,dropout=best_dropout).to(device)\n",
    "opt=torch.optim.Adam(model.parameters(),lr=best_lr)\n",
    "sched=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,mode='min',patience=5,factor=0.5,verbose=True)\n",
    "best_v=1e9;pat=0\n",
    "for epoch in range(1,101):\n",
    "    model.train();tot=0\n",
    "    for b in tr: b=b.to(device);opt.zero_grad();o=model(b);l=F.cross_entropy(o,b.y.long());l.backward();opt.step();tot+=l.item()\n",
    "    preds,labels=evaluate(model,vl);vloss=F.cross_entropy(preds,labels.long()).item();sched.step(vloss)\n",
    "    if vloss<best_v:best_v=vloss;pat=0;torch.save(model.state_dict(),os.path.join(results_dir,'final_model.pt'))\n",
    "    else: pat+=1\n",
    "    if pat>=10:break\n",
    "# test eval\n",
    "model.load_state_dict(torch.load(os.path.join(results_dir,'final_model.pt')))\n",
    "td=DataLoader(torch.load(os.path.join(base_path,f\"{task}_test.pt\")),batch_size=32)\n",
    "preds,labels=evaluate(model,td);y_pred=preds.argmax(1).numpy();y_true=labels.numpy().astype(int)\n",
    "# metrics\n",
    "acc_f=accuracy_score(y_true,y_pred);prec,rec,f1,_=precision_recall_fscore_support(y_true,y_pred,average='weighted')\n",
    "# confusion\n",
    "cm=confusion_matrix(y_true,y_pred);disp=ConfusionMatrixDisplay(cm,display_labels=list(class_names.values()));disp.plot()\n",
    "plt.title('Final Model Confusion Matrix');plt.show()\n",
    "# final auc\n",
    "probs=F.softmax(preds,dim=1).numpy();fpr,tpr,_=roc_curve(label_binarize(y_true,classes=np.arange(num_classes)),probs[:,1]);\n",
    "plt.plot(fpr,tpr);plt.plot([0,1],[0,1],'k--');plt.xlabel('FPR');plt.ylabel('TPR');plt.title('Final AUC-ROC');plt.show()\n",
    "\n",
    "# Comparison table\n",
    "ensemble_df=pd.read_csv(os.path.join(results_dir,'ensemble_preds.csv'))\n",
    "ensemble_acc=accuracy_score(ensemble_df['True'],ensemble_df['Pred'])\n",
    "final_metrics = {'ensemble': ensemble_acc, 'final': acc_f}\n",
    "comp = pd.DataFrame.from_dict(final_metrics, orient='index', columns=['Accuracy'])\n",
    "display(comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de70700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943c16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
