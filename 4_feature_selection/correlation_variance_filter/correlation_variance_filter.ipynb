{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "068c9fd8-b5bb-4ba6-9d26-dd8ea5421464",
   "metadata": {},
   "source": [
    "# Filtering the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f540019-f583-4fb6-aef9-13c1b10ad3f5",
   "metadata": {},
   "source": [
    "Remove features with a variance less than 0.2 and with correlation larger than 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c95491-3c55-40aa-9b78-80a13362328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218cf9b3-1e37-457c-a0a4-df0817b66a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data size is  (555, 1008)\n"
     ]
    }
   ],
   "source": [
    "# Read entire training dataset with all descriptors\n",
    "dataset = pd.read_csv('../../3_train_test_split/train_reg.csv').set_index('Molecule ChEMBL ID')\n",
    "print(\"The original data size is \", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500c1bf-200e-4ace-8d55-6fa6c86be580",
   "metadata": {},
   "source": [
    "## Remove Descriptors with Variance < 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398829e2-d4a7-49e8-b72d-83cac7c5836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after filtering with variance > 0.2, the data size is (555, 1004)\n"
     ]
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0.2) \n",
    "seldataset=sel.fit_transform(dataset)\n",
    "seldataset=dataset[dataset.columns[sel.get_support(indices=True)]]\n",
    "\n",
    "print(\"after filtering with variance > 0.2, the data size is\", seldataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c119a7-f43a-4a0c-9e02-1a11a43ea1ec",
   "metadata": {},
   "source": [
    "## Drop Features with Correlation > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6918277-381b-4fdf-9717-da25d9f4e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after filtering correlations > 0.95, the data size is (555, 564)\n"
     ]
    }
   ],
   "source": [
    "def drop_highcorr(df, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Removes features that have a correlation higher than the specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with features.\n",
    "        threshold (float): The correlation threshold above which features will be removed.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with highly correlated features removed.\n",
    "    \"\"\"\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    # Create a boolean mask for the upper triangle of the correlation matrix\n",
    "    upper_tri = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # Find columns with correlation greater than the threshold\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "    \n",
    "    # Drop the identified columns\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "\n",
    "# Apply filtration to each molecule\n",
    "filtered_df = drop_highcorr(seldataset, threshold=0.95)\n",
    "\n",
    "print(\"after filtering correlations > 0.95, the data size is\", filtered_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ee96e-ef8a-4a3d-bdb0-88f51db1e5b1",
   "metadata": {},
   "source": [
    "## Save Train and Test Sets with Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b3d4d9-42e3-4d9f-817a-ef99c5482346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to ./train_class_5.csv\n",
      "Processed file saved to ./train_class_4.csv\n",
      "Processed file saved to ./train_reg.csv\n",
      "Processed file saved to ./train_class_3.csv\n",
      "Processed file saved to ./train_class_2.csv\n",
      "Processed file saved to ./train_class_1.csv\n",
      "Processed file saved to ./train_reg_5.csv\n",
      "Processed file saved to ./train_reg_4.csv\n",
      "Processed file saved to ./train_reg_1.csv\n",
      "Processed file saved to ./train_reg_3.csv\n",
      "Processed file saved to ./train_reg_2.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['PMI1', 'PMI2', 'Asphericity', 'Eccentricity', 'InertialShapeFactor',\\n       'NPR2', 'PBF', 'SpherocityIndex', 'LabuteASA',\\n       'DoubleCubicLatticePackingDensity',\\n       ...\\n       'aromaticRings', 'HAcceptors', 'HDonors', 'heteroatoms',\\n       'rotatableBonds', 'saturatedCarbocycles', 'saturatedHeterocycles',\\n       'satureatedRings', 'ringCount', 'molLogP'],\\n      dtype='object', length=564)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     21\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMolecule ChEMBL ID\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_columns\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Keep only selected columns\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Add 'is_imputed' dummy variable for regression files\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file_path:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kissim/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kissim/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kissim/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['PMI1', 'PMI2', 'Asphericity', 'Eccentricity', 'InertialShapeFactor',\\n       'NPR2', 'PBF', 'SpherocityIndex', 'LabuteASA',\\n       'DoubleCubicLatticePackingDensity',\\n       ...\\n       'aromaticRings', 'HAcceptors', 'HDonors', 'heteroatoms',\\n       'rotatableBonds', 'saturatedCarbocycles', 'saturatedHeterocycles',\\n       'satureatedRings', 'ringCount', 'molLogP'],\\n      dtype='object', length=564)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "input_dir = \"../../3_train_test_split/\"\n",
    "output_dir = \".\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "# Load descriptors_all.csv to get -logIC50\n",
    "descriptor_file = os.path.join(input_dir, \"descriptors_all.csv\")\n",
    "descriptor_df = pd.read_csv(descriptor_file)[[\"Molecule ChEMBL ID\", \"-logIC50\"]]\n",
    "\n",
    "# Columns to keep (from filtered_df)\n",
    "selected_columns = filtered_df.columns\n",
    "\n",
    "# Define the dummy variable threshold and the target column\n",
    "threshold = 1e-6\n",
    "target_column = \"-logIC50\"\n",
    "\n",
    "# Loop over train, test, and val CSV files\n",
    "for file_type in [\"train\", \"test\", \"val\"]:\n",
    "    files = glob.glob(f\"{input_dir}{file_type}*.csv\") # Find all matching CSV files for this type\n",
    "    \n",
    "    for file_path in files:\n",
    "        df = pd.read_csv(file_path).set_index('Molecule ChEMBL ID') # Read the CSV file\n",
    "        filtered_df = df[selected_columns]  # Keep only selected columns\n",
    "\n",
    "        # Add 'is_imputed' dummy variable for regression files\n",
    "        if \"reg\" in file_path:\n",
    "            merged_df = pd.merge(\n",
    "                descriptor_df, filtered_df, on=\"Molecule ChEMBL ID\", how=\"inner\"\n",
    "            ) # Merge with descriptor_df to include -logIC50\n",
    "            \n",
    "            merged_df['is_imputed'] = (\n",
    "                np.abs(merged_df[target_column] - (-np.log(10000 * 1e-9))) < threshold\n",
    "            ).astype(int) # Add the dummy variable\n",
    "\n",
    "            ### Note: interaction terms didn't help with the predictions \n",
    "            # interaction_features = [\n",
    "            #     col for col in selected_columns \n",
    "            #     if col in merged_df.columns and col != 'is_imputed'\n",
    "            # ] # Create interaction terms\n",
    "            \n",
    "            # X_interactions = merged_df[interaction_features].multiply(merged_df['is_imputed'], axis=0)\n",
    "            # X_interactions.columns = [f\"{col}_is_imputed\" for col in interaction_features]\n",
    "\n",
    "        #     # Combine features and interaction terms\n",
    "        #     merged_df = pd.concat([merged_df[selected_columns], X_interactions], axis=1)\n",
    "\n",
    "            # Assign the processed DataFrame back to filtered_df for saving\n",
    "            filtered_df = merged_df.drop(columns=[target_column]).set_index('Molecule ChEMBL ID')\n",
    "\n",
    "        # Construct the output file path\n",
    "        file_name = os.path.basename(file_path)  # Extract file name\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "        # Save the filtered DataFrame\n",
    "        filtered_df.to_csv(output_path)\n",
    "        print(f\"Processed file saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c58d403-07e8-4dad-a38d-3150d1f674ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../3_train_test_split/train_class_targets.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0fc43-781d-4475-b18d-734b65536323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
