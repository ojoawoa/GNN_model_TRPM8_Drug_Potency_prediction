# GNN_MODEL_TRPM8_DRUG_POTENCY_PREDICTION

Predict TRPM8 ligand potency (classification & ICâ‚…â‚€ regression) using Graph Neural Networks.

---

## ğŸš€ Project Overview
The goal of this project is to predict the potency of small-molecule ligands against the TRPM8 ion channel from ChEMBL, by learning directly on their molecular graph representations. We tackle two complementary tasks:

1. **Potency classification** â€” Low / Medium / High  
2. **ICâ‚…â‚€ regression** â€” Continuous pChEMBL values

We compare five GNN architectures (GIN, GCN, MPNN, GraphSAGE, GAT) through:

- **Data prep**: clean raw measurements, compute atom/bond descriptors  
- **Graph construction**: build PyG `Data` objects  
- **Splitting**: stratified (classification) or random (regression) 10-fold CV + held-out test  
- **Training & tuning**: per-fold training, hyperparameter sweeps (hidden_dim, dropout, lr), early stopping, LR schedulers  
- **Ensembling & final eval**: average fold predictions, retrain final model, plot confusion matrices/AUC (classification) and scatter/MSE/RÂ² (regression)  
- **Baseline comparison**: classical QSAR vs. GNN (bar & radar plots)

---
## ğŸ§  GNN Architectures

- **GIN (Graph Isomorphism Network)**  
 uses MLPs to distinguish different graph structures; strong at capturing subtle subgraph differences.

- **GCN (Graph Convolutional Network)**  
  Classic spectral convolution: aggregates neighbor features via a normalized adjacency; simple and widely used.

- **MPNN (Message Passing Neural Network)**  
  Flexible messageâ€passing framework: learns custom messages along edges, then updates node embeddingsâ€”great for chemistry.

- **GraphSAGE**  
  samples and aggregates a fixed-size neighborhood; efficient for large graphs .

- **GAT (Graph Attention Network)**  
  Attentionâ€based aggregation: learns per-edge attention coefficients, allowing the model to weigh important neighbors more heavily.

---

## ğŸ“‚ Repository Structure

```text
GNN_MODEL_TRPM8_DRUG_POTENCY_PREDICTION/
â”œâ”€â”€ 1_data/
â”‚   â”œâ”€â”€ initial_data/
â”‚   â”‚   â”œâ”€â”€ orca_outputs/
â”‚   â”‚   â””â”€â”€ Pre-process.ipynb
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ .gitkeep
â”‚       â”œâ”€â”€ TRPM8_cleaned_preprocessed.csv
â”‚       â”œâ”€â”€ TRPM8_graph_classification.csv
â”‚       â””â”€â”€ TRPM8_graph_regression.csv
â”œâ”€â”€ 2_feature_extraction/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ Feature_extraction.ipynb
â”‚   â”œâ”€â”€ mulliken_charges.json
â”‚   â”œâ”€â”€ TRPM8_graph_features_class_w_atomic_onehot_encoder.csv
â”‚   â””â”€â”€ TRPM8_graph_features_regression_w_atomic_onehot_encoder.csv
â”œâ”€â”€ 3_graph_data/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ GraphDataset_conversion_for_PyTorch_Geometric.ipynb
â”‚   â”œâ”€â”€ TRPM8_classification_graph_dataset.pt
â”‚   â””â”€â”€ TRPM8_regression_graph_dataset.pt
â”œâ”€â”€ 4_train_test_split/
â”‚   â”œâ”€â”€ 10fold_cv/
â”‚   â”‚   â”œâ”€â”€ regression/
â”‚   â”‚   â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ Graph_dataset_train_test_val_random_split_and_Kfoldsplit.ipynb
â”œâ”€â”€ 5_model_training/
â”‚   â”œâ”€â”€ GAT/
â”‚   â”‚   â”œâ”€â”€ classification_10fold/
â”‚   â”‚   â”œâ”€â”€ regression_10fold/
â”‚   â”‚   â”œâ”€â”€ Final_GAT_training_classification.ipynb
â”‚   â”‚   â””â”€â”€ Final_GAT_training_regression.ipynb
â”‚   â”œâ”€â”€ GCN/
â”‚   â”‚   â”œâ”€â”€ classification_10fold/
â”‚   â”‚   â”œâ”€â”€ regression_10fold/
â”‚   â”‚   â”œâ”€â”€ Final_GCN_training_classification.ipynb
â”‚   â”‚   â””â”€â”€ Final_GCN_training_regression.ipynb
â”‚   â”œâ”€â”€ GIN/
â”‚   â”‚   â”œâ”€â”€ classification_10fold/
â”‚   â”‚   â”œâ”€â”€ regression_10fold/
â”‚   â”‚   â”œâ”€â”€ Final_GIN_training_classification.ipynb
â”‚   â”‚   â””â”€â”€ Final_GIN_training_regression.ipynb
â”‚   â”œâ”€â”€ GraphSAGE/
â”‚   â”‚   â”œâ”€â”€ classification_10fold/
â”‚   â”‚   â”œâ”€â”€ regression_10fold/
â”‚   â”‚   â”œâ”€â”€ Final_GraphSAGE_training_classification.ipynb
â”‚   â”‚   â””â”€â”€ Final_GraphSAGE_training_regression.ipynb
â”‚   â””â”€â”€ MPNN/
â”‚       â”œâ”€â”€ classification_10fold/
â”‚       â”œâ”€â”€ regression_10fold/
â”‚       â”œâ”€â”€ Final_MPNN_training_classification.ipynb
â”‚       â””â”€â”€ Final_MPNN_training_regression.ipynb
â”œâ”€â”€ 6_baseline/
â”‚   â”œâ”€â”€ QSAR_classification_performance_summary.csv
â”‚   â””â”€â”€ QSAR_regression_performance_summary.csv
â”‚   â””â”€â”€ GNN_vs_QSAR_comparison.ipynb
â””â”€â”€ README.md           
